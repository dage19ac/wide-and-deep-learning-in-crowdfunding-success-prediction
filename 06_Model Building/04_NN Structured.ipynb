{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_NN Structured.ipynb","provenance":[],"collapsed_sections":["HyW82680sOSI","lhBR5qnes-TN","QlcazcrXKT5e","6250os8sMSuZ","APCM6IayNmOx","ToMIjd2_QuUK","EmzaXt6qRVbs","qx0cm4AxVzO5","LHMJDfUWYdmN","b31IIEU2alm_","9lD8O0Fud4FF","WrJZ92GieE7O","5qVnuB1FeNh8","WVWcwTZCKTkC","hOGFIopF45iV","bLjTJLI948mu","ZJwKn1WMDre-","V0tUOvOcHAaQ","uXiqpQmKP0Lp","MhuNUHuxQLOu","ASaXIT05SWcQ","RwBkrDXwUVXd","RFuuKLchXfWY","gfyZxPOzg4aE","-YrApbLcvvCg","DbFki3lTy7uS"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HyW82680sOSI"},"source":["#### Setup"]},{"cell_type":"code","metadata":{"id":"tEe4_nY39Z8C"},"source":["!pip install -U tensorflow keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2t35Z4Ax9T7v"},"source":["!pip install -U talos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJgbrWKm43PC"},"source":["# Import general Python libraries\n","import pandas as pd\n","import numpy as np\n","import random\n","import sklearn\n","import seaborn as sns\n","import os\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jeA52DCkXF5J"},"source":["# Specify seeds for random-operations\n","seed_value = 0\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","np.random.seed(seed_value)\n","random.seed(seed_value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCQ21bbY43PO"},"source":["# Import sklearn-specific modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6CQ9UoKFnuP","executionInfo":{"status":"ok","timestamp":1611385973851,"user_tz":-60,"elapsed":2261,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"44b9bcc5-16db-4542-dc45-7975aa16d7ae"},"source":["# Import tensorflow-specific modules\n","import tensorflow as tf\n","tf.random.set_seed(seed_value)\n","print(\"Tensorflow Version: {}\".format(tf.__version__))\n","print(\"Keras Version: {}\".format(tf.keras.__version__))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensorflow Version: 2.4.1\n","Keras Version: 2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_XVE26gMK-r1"},"source":["# Import keras-specific modules\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LayerNormalization, GaussianNoise, Activation\n","from tensorflow.keras.optimizers import Adadelta, RMSprop, Adam, Adamax, Nadam\n","from tensorflow.keras.regularizers import L1, L2\n","from tensorflow.keras.initializers import GlorotNormal, GlorotUniform, LecunNormal, LecunUniform, HeNormal, HeUniform\n","from tensorflow.keras.metrics import AUC, Precision, Recall\n","from tensorflow.keras.utils import plot_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atLk7L7PgjwI"},"source":["# Import talos-specific modules\n","import talos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3NkYJuv43PP"},"source":["# Set pandas options\n","pd.set_option(\"display.max_columns\", None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WI9_Amw06BBV","executionInfo":{"status":"ok","timestamp":1611386002632,"user_tz":-60,"elapsed":23427,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"c9350069-4fbf-4c4b-f856-77873ec4de49"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lhBR5qnes-TN"},"source":["#### a) Prepare Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":151},"id":"v_sYpgrFsMqx","executionInfo":{"status":"ok","timestamp":1611386021489,"user_tz":-60,"elapsed":2124,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"6e1f2be9-0847-4b8e-c81b-0f422374d2bf"},"source":["# Import Dataset\n","kickstarter_df = pd.read_csv(\"04_Final Datasets/Kickstarter_Structured.csv\", index_col=0)\n","print(kickstarter_df.shape)\n","print(len(kickstarter_df.index.unique()))\n","kickstarter_df.head(1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(246891, 35)\n","246891\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>campaign_successful</th>\n","      <th>goal</th>\n","      <th>number_of_collaborators</th>\n","      <th>funding_period</th>\n","      <th>days_between_created_and_launched</th>\n","      <th>launch_quartal</th>\n","      <th>staff_pick</th>\n","      <th>campaign_has_demo_video</th>\n","      <th>campaign_has_environmental_commitments</th>\n","      <th>number_of_images</th>\n","      <th>number_of_videos</th>\n","      <th>number_of_audios</th>\n","      <th>number_of_interactives</th>\n","      <th>number_of_words</th>\n","      <th>number_of_links</th>\n","      <th>creator_verified_identity</th>\n","      <th>creator_fb_auth</th>\n","      <th>creator_has_image</th>\n","      <th>creator_allows_follows</th>\n","      <th>number_of_creator_backings</th>\n","      <th>number_of_creator_projects</th>\n","      <th>facebook_linked</th>\n","      <th>twitter_linked</th>\n","      <th>instagram_linked</th>\n","      <th>linkedin_linked</th>\n","      <th>number_of_rewards</th>\n","      <th>number_of_words_per_reward</th>\n","      <th>lowest_pledge_level</th>\n","      <th>highest_pledge_level</th>\n","      <th>has_limited_rewards</th>\n","      <th>has_shipped_rewards</th>\n","      <th>has_restricted_shipping_rewards</th>\n","      <th>avg_months_until_reward</th>\n","      <th>location</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22821161</th>\n","      <td>0</td>\n","      <td>50000.0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>102</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1378</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>36.75</td>\n","      <td>5.0</td>\n","      <td>1417.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5.5</td>\n","      <td>United States</td>\n","      <td>Design_Product Design</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          campaign_successful     goal  number_of_collaborators  \\\n","22821161                    0  50000.0                        0   \n","\n","          funding_period  days_between_created_and_launched  launch_quartal  \\\n","22821161              45                                102               3   \n","\n","          staff_pick  campaign_has_demo_video  \\\n","22821161           0                        1   \n","\n","          campaign_has_environmental_commitments  number_of_images  \\\n","22821161                                       0                13   \n","\n","          number_of_videos  number_of_audios  number_of_interactives  \\\n","22821161                 0                 0                       0   \n","\n","          number_of_words  number_of_links  creator_verified_identity  \\\n","22821161             1378                2                          1   \n","\n","          creator_fb_auth  creator_has_image  creator_allows_follows  \\\n","22821161                0                  1                       1   \n","\n","          number_of_creator_backings  number_of_creator_projects  \\\n","22821161                           0                           1   \n","\n","          facebook_linked  twitter_linked  instagram_linked  linkedin_linked  \\\n","22821161                0               0                 0                0   \n","\n","          number_of_rewards  number_of_words_per_reward  lowest_pledge_level  \\\n","22821161                  8                       36.75                  5.0   \n","\n","          highest_pledge_level  has_limited_rewards  has_shipped_rewards  \\\n","22821161                1417.0                    0                    1   \n","\n","          has_restricted_shipping_rewards  avg_months_until_reward  \\\n","22821161                                1                      5.5   \n","\n","               location               category  \n","22821161  United States  Design_Product Design  "]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"id":"5burqu6XEJ_C","executionInfo":{"status":"ok","timestamp":1611386022203,"user_tz":-60,"elapsed":2821,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"bebc8088-5be2-4e5e-af19-d4efbb3bf8d4"},"source":["# Convert categorical features into dummy-variables\n","print(\"Before: {}\".format(kickstarter_df.shape))\n","kickstarter_df[\"launch_quartal\"] = kickstarter_df.launch_quartal.apply(str)\n","kickstarter_df = pd.get_dummies(kickstarter_df, prefix=[\"launch_quartal\", \"location\", \"category\"], columns=[\"launch_quartal\", \"location\", \"category\"], drop_first=False)\n","print(\"After: {}\".format(kickstarter_df.shape))\n","kickstarter_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Before: (246891, 35)\n","After: (246891, 234)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>campaign_successful</th>\n","      <th>goal</th>\n","      <th>number_of_collaborators</th>\n","      <th>funding_period</th>\n","      <th>days_between_created_and_launched</th>\n","      <th>staff_pick</th>\n","      <th>campaign_has_demo_video</th>\n","      <th>campaign_has_environmental_commitments</th>\n","      <th>number_of_images</th>\n","      <th>number_of_videos</th>\n","      <th>number_of_audios</th>\n","      <th>number_of_interactives</th>\n","      <th>number_of_words</th>\n","      <th>number_of_links</th>\n","      <th>creator_verified_identity</th>\n","      <th>creator_fb_auth</th>\n","      <th>creator_has_image</th>\n","      <th>creator_allows_follows</th>\n","      <th>number_of_creator_backings</th>\n","      <th>number_of_creator_projects</th>\n","      <th>facebook_linked</th>\n","      <th>twitter_linked</th>\n","      <th>instagram_linked</th>\n","      <th>linkedin_linked</th>\n","      <th>number_of_rewards</th>\n","      <th>number_of_words_per_reward</th>\n","      <th>lowest_pledge_level</th>\n","      <th>highest_pledge_level</th>\n","      <th>has_limited_rewards</th>\n","      <th>has_shipped_rewards</th>\n","      <th>has_restricted_shipping_rewards</th>\n","      <th>avg_months_until_reward</th>\n","      <th>launch_quartal_1</th>\n","      <th>launch_quartal_2</th>\n","      <th>launch_quartal_3</th>\n","      <th>launch_quartal_4</th>\n","      <th>location_Africa</th>\n","      <th>location_Australia</th>\n","      <th>location_Belgium</th>\n","      <th>location_Canada</th>\n","      <th>location_China</th>\n","      <th>location_Denmark</th>\n","      <th>location_France</th>\n","      <th>location_Germany</th>\n","      <th>location_Hong Kong</th>\n","      <th>location_Ireland</th>\n","      <th>location_Italy</th>\n","      <th>location_Japan</th>\n","      <th>location_Latin and South America</th>\n","      <th>location_Mexico</th>\n","      <th>location_Netherlands</th>\n","      <th>location_New Zealand</th>\n","      <th>location_No Location</th>\n","      <th>location_Norway</th>\n","      <th>location_Oceania and Antarctica</th>\n","      <th>location_Rest of Asia</th>\n","      <th>location_Rest of Europe</th>\n","      <th>location_Singapore</th>\n","      <th>location_Spain</th>\n","      <th>location_Sweden</th>\n","      <th>location_Switzerland</th>\n","      <th>location_United Kingdom</th>\n","      <th>location_United States</th>\n","      <th>category_Art_Ceramics</th>\n","      <th>category_Art_Conceptual Art</th>\n","      <th>category_Art_Digital Art</th>\n","      <th>category_Art_Illustration</th>\n","      <th>category_Art_Installations</th>\n","      <th>category_Art_Mixed Media</th>\n","      <th>category_Art_No Subcategory</th>\n","      <th>category_Art_Painting</th>\n","      <th>category_Art_Performance Art</th>\n","      <th>category_Art_Public Art</th>\n","      <th>category_Art_Sculpture</th>\n","      <th>category_Art_Social Practice</th>\n","      <th>category_Art_Textiles</th>\n","      <th>category_Art_Video Art</th>\n","      <th>category_Comics_Anthologies</th>\n","      <th>category_Comics_Comic Books</th>\n","      <th>category_Comics_Events</th>\n","      <th>category_Comics_Graphic Novels</th>\n","      <th>category_Comics_No Subcategory</th>\n","      <th>category_Comics_Webcomics</th>\n","      <th>category_Crafts_Candles</th>\n","      <th>category_Crafts_Crochet</th>\n","      <th>category_Crafts_DIY</th>\n","      <th>category_Crafts_Embroidery</th>\n","      <th>category_Crafts_Glass</th>\n","      <th>category_Crafts_Knitting</th>\n","      <th>category_Crafts_No Subcategory</th>\n","      <th>category_Crafts_Pottery</th>\n","      <th>category_Crafts_Printing</th>\n","      <th>category_Crafts_Quilts</th>\n","      <th>category_Crafts_Stationery</th>\n","      <th>category_Crafts_Taxidermy</th>\n","      <th>category_Crafts_Weaving</th>\n","      <th>category_Crafts_Woodworking</th>\n","      <th>category_Dance_No Subcategory</th>\n","      <th>category_Dance_Performances</th>\n","      <th>category_Dance_Residencies</th>\n","      <th>category_Dance_Spaces</th>\n","      <th>category_Dance_Workshops</th>\n","      <th>category_Design_Architecture</th>\n","      <th>category_Design_Civic Design</th>\n","      <th>category_Design_Graphic Design</th>\n","      <th>category_Design_Interactive Design</th>\n","      <th>category_Design_No Subcategory</th>\n","      <th>category_Design_Product Design</th>\n","      <th>category_Design_Toys</th>\n","      <th>category_Design_Typography</th>\n","      <th>category_Fashion_Accessories</th>\n","      <th>category_Fashion_Apparel</th>\n","      <th>category_Fashion_Childrenswear</th>\n","      <th>category_Fashion_Couture</th>\n","      <th>category_Fashion_Footwear</th>\n","      <th>category_Fashion_Jewelry</th>\n","      <th>category_Fashion_No Subcategory</th>\n","      <th>category_Fashion_Pet Fashion</th>\n","      <th>category_Fashion_Ready-to-wear</th>\n","      <th>category_Film &amp; Video_Action</th>\n","      <th>category_Film &amp; Video_Animation</th>\n","      <th>category_Film &amp; Video_Comedy</th>\n","      <th>category_Film &amp; Video_Documentary</th>\n","      <th>category_Film &amp; Video_Drama</th>\n","      <th>category_Film &amp; Video_Experimental</th>\n","      <th>category_Film &amp; Video_Family</th>\n","      <th>category_Film &amp; Video_Fantasy</th>\n","      <th>category_Film &amp; Video_Festivals</th>\n","      <th>category_Film &amp; Video_Horror</th>\n","      <th>category_Film &amp; Video_Movie Theaters</th>\n","      <th>category_Film &amp; Video_Music Videos</th>\n","      <th>category_Film &amp; Video_Narrative Film</th>\n","      <th>category_Film &amp; Video_No Subcategory</th>\n","      <th>category_Film &amp; Video_Romance</th>\n","      <th>category_Film &amp; Video_Science Fiction</th>\n","      <th>category_Film &amp; Video_Shorts</th>\n","      <th>category_Film &amp; Video_Television</th>\n","      <th>category_Film &amp; Video_Thrillers</th>\n","      <th>category_Film &amp; Video_Webseries</th>\n","      <th>category_Food_Bacon</th>\n","      <th>category_Food_Community Gardens</th>\n","      <th>category_Food_Cookbooks</th>\n","      <th>category_Food_Drinks</th>\n","      <th>category_Food_Events</th>\n","      <th>category_Food_Farmer's Markets</th>\n","      <th>category_Food_Farms</th>\n","      <th>category_Food_Food Trucks</th>\n","      <th>category_Food_No Subcategory</th>\n","      <th>category_Food_Restaurants</th>\n","      <th>category_Food_Small Batch</th>\n","      <th>category_Food_Spaces</th>\n","      <th>category_Food_Vegan</th>\n","      <th>category_Games_Gaming Hardware</th>\n","      <th>category_Games_Live Games</th>\n","      <th>category_Games_Mobile Games</th>\n","      <th>category_Games_No Subcategory</th>\n","      <th>category_Games_Playing Cards</th>\n","      <th>category_Games_Puzzles</th>\n","      <th>category_Games_Tabletop Games</th>\n","      <th>category_Games_Video Games</th>\n","      <th>category_Journalism_Audio</th>\n","      <th>category_Journalism_No Subcategory</th>\n","      <th>category_Journalism_Photo</th>\n","      <th>category_Journalism_Print</th>\n","      <th>category_Journalism_Video</th>\n","      <th>category_Journalism_Web</th>\n","      <th>category_Music_Blues</th>\n","      <th>category_Music_Chiptune</th>\n","      <th>category_Music_Classical Music</th>\n","      <th>category_Music_Comedy</th>\n","      <th>category_Music_Country &amp; Folk</th>\n","      <th>category_Music_Electronic Music</th>\n","      <th>category_Music_Faith</th>\n","      <th>category_Music_Hip-Hop</th>\n","      <th>category_Music_Indie Rock</th>\n","      <th>category_Music_Jazz</th>\n","      <th>category_Music_Kids</th>\n","      <th>category_Music_Latin</th>\n","      <th>category_Music_Metal</th>\n","      <th>category_Music_No Subcategory</th>\n","      <th>category_Music_Pop</th>\n","      <th>category_Music_Punk</th>\n","      <th>category_Music_R&amp;B</th>\n","      <th>category_Music_Rock</th>\n","      <th>category_Music_World Music</th>\n","      <th>category_Photography_Animals</th>\n","      <th>category_Photography_Fine Art</th>\n","      <th>category_Photography_Nature</th>\n","      <th>category_Photography_No Subcategory</th>\n","      <th>category_Photography_People</th>\n","      <th>category_Photography_Photobooks</th>\n","      <th>category_Photography_Places</th>\n","      <th>category_Publishing_Academic</th>\n","      <th>category_Publishing_Anthologies</th>\n","      <th>category_Publishing_Art Books</th>\n","      <th>category_Publishing_Calendars</th>\n","      <th>category_Publishing_Children's Books</th>\n","      <th>category_Publishing_Comedy</th>\n","      <th>category_Publishing_Fiction</th>\n","      <th>category_Publishing_Letterpress</th>\n","      <th>category_Publishing_Literary Journals</th>\n","      <th>category_Publishing_Literary Spaces</th>\n","      <th>category_Publishing_No Subcategory</th>\n","      <th>category_Publishing_Nonfiction</th>\n","      <th>category_Publishing_Periodicals</th>\n","      <th>category_Publishing_Poetry</th>\n","      <th>category_Publishing_Radio &amp; Podcasts</th>\n","      <th>category_Publishing_Translations</th>\n","      <th>category_Publishing_Young Adult</th>\n","      <th>category_Publishing_Zines</th>\n","      <th>category_Technology_3D Printing</th>\n","      <th>category_Technology_Apps</th>\n","      <th>category_Technology_Camera Equipment</th>\n","      <th>category_Technology_DIY Electronics</th>\n","      <th>category_Technology_Fabrication Tools</th>\n","      <th>category_Technology_Flight</th>\n","      <th>category_Technology_Gadgets</th>\n","      <th>category_Technology_Hardware</th>\n","      <th>category_Technology_Makerspaces</th>\n","      <th>category_Technology_No Subcategory</th>\n","      <th>category_Technology_Robots</th>\n","      <th>category_Technology_Software</th>\n","      <th>category_Technology_Sound</th>\n","      <th>category_Technology_Space Exploration</th>\n","      <th>category_Technology_Wearables</th>\n","      <th>category_Technology_Web</th>\n","      <th>category_Theater_Comedy</th>\n","      <th>category_Theater_Experimental</th>\n","      <th>category_Theater_Festivals</th>\n","      <th>category_Theater_Immersive</th>\n","      <th>category_Theater_Musical</th>\n","      <th>category_Theater_No Subcategory</th>\n","      <th>category_Theater_Plays</th>\n","      <th>category_Theater_Spaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22821161</th>\n","      <td>0</td>\n","      <td>50000.0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>102</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1378</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>36.750000</td>\n","      <td>5.0</td>\n","      <td>1417.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22823613</th>\n","      <td>0</td>\n","      <td>750.0</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>256</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>20.500000</td>\n","      <td>15.0</td>\n","      <td>30.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22835897</th>\n","      <td>1</td>\n","      <td>6000.0</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>712</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>44.000000</td>\n","      <td>1.0</td>\n","      <td>6000.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22845619</th>\n","      <td>1</td>\n","      <td>8000.0</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>676</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>64.545455</td>\n","      <td>5.0</td>\n","      <td>5000.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22848517</th>\n","      <td>1</td>\n","      <td>2500.0</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>93</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>497</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>45.875000</td>\n","      <td>1.0</td>\n","      <td>250.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          campaign_successful     goal  number_of_collaborators  \\\n","22821161                    0  50000.0                        0   \n","22823613                    0    750.0                        0   \n","22835897                    1   6000.0                        0   \n","22845619                    1   8000.0                        0   \n","22848517                    1   2500.0                        0   \n","\n","          funding_period  days_between_created_and_launched  staff_pick  \\\n","22821161              45                                102           0   \n","22823613              30                                 13           0   \n","22835897              28                                 10           0   \n","22845619              30                                 25           0   \n","22848517              30                                 93           0   \n","\n","          campaign_has_demo_video  campaign_has_environmental_commitments  \\\n","22821161                        1                                       0   \n","22823613                        0                                       0   \n","22835897                        1                                       0   \n","22845619                        1                                       0   \n","22848517                        1                                       0   \n","\n","          number_of_images  number_of_videos  number_of_audios  \\\n","22821161                13                 0                 0   \n","22823613                 0                 0                 0   \n","22835897                 6                 0                 0   \n","22845619                 1                 0                 0   \n","22848517                 4                 0                 0   \n","\n","          number_of_interactives  number_of_words  number_of_links  \\\n","22821161                       0             1378                2   \n","22823613                       0              256                0   \n","22835897                       0              712                4   \n","22845619                       0              676                3   \n","22848517                       0              497                3   \n","\n","          creator_verified_identity  creator_fb_auth  creator_has_image  \\\n","22821161                          1                0                  1   \n","22823613                          1                0                  1   \n","22835897                          1                0                  1   \n","22845619                          0                0                  1   \n","22848517                          0                1                  1   \n","\n","          creator_allows_follows  number_of_creator_backings  \\\n","22821161                       1                           0   \n","22823613                       1                           0   \n","22835897                       1                           4   \n","22845619                       1                           1   \n","22848517                       1                           0   \n","\n","          number_of_creator_projects  facebook_linked  twitter_linked  \\\n","22821161                           1                0               0   \n","22823613                           1                0               0   \n","22835897                           1                1               0   \n","22845619                           1                1               0   \n","22848517                           1                0               0   \n","\n","          instagram_linked  linkedin_linked  number_of_rewards  \\\n","22821161                 0                0                  8   \n","22823613                 0                0                  2   \n","22835897                 0                0                 12   \n","22845619                 0                0                 11   \n","22848517                 0                0                  8   \n","\n","          number_of_words_per_reward  lowest_pledge_level  \\\n","22821161                   36.750000                  5.0   \n","22823613                   20.500000                 15.0   \n","22835897                   44.000000                  1.0   \n","22845619                   64.545455                  5.0   \n","22848517                   45.875000                  1.0   \n","\n","          highest_pledge_level  has_limited_rewards  has_shipped_rewards  \\\n","22821161                1417.0                    0                    1   \n","22823613                  30.0                    1                    0   \n","22835897                6000.0                    1                    1   \n","22845619                5000.0                    0                    0   \n","22848517                 250.0                    1                    0   \n","\n","          has_restricted_shipping_rewards  avg_months_until_reward  \\\n","22821161                                1                      5.5   \n","22823613                                0                      4.0   \n","22835897                                0                      5.5   \n","22845619                                0                      0.0   \n","22848517                                0                      3.0   \n","\n","          launch_quartal_1  launch_quartal_2  launch_quartal_3  \\\n","22821161                 0                 0                 1   \n","22823613                 1                 0                 0   \n","22835897                 0                 0                 1   \n","22845619                 0                 0                 1   \n","22848517                 0                 1                 0   \n","\n","          launch_quartal_4  location_Africa  location_Australia  \\\n","22821161                 0                0                   0   \n","22823613                 0                0                   0   \n","22835897                 0                0                   0   \n","22845619                 0                0                   0   \n","22848517                 0                0                   0   \n","\n","          location_Belgium  location_Canada  location_China  location_Denmark  \\\n","22821161                 0                0               0                 0   \n","22823613                 0                0               0                 0   \n","22835897                 0                0               0                 0   \n","22845619                 0                0               0                 0   \n","22848517                 0                0               0                 0   \n","\n","          location_France  location_Germany  location_Hong Kong  \\\n","22821161                0                 0                   0   \n","22823613                0                 0                   0   \n","22835897                0                 0                   0   \n","22845619                0                 0                   0   \n","22848517                0                 0                   0   \n","\n","          location_Ireland  location_Italy  location_Japan  \\\n","22821161                 0               0               0   \n","22823613                 0               0               0   \n","22835897                 0               0               0   \n","22845619                 0               0               0   \n","22848517                 0               0               0   \n","\n","          location_Latin and South America  location_Mexico  \\\n","22821161                                 0                0   \n","22823613                                 0                0   \n","22835897                                 0                0   \n","22845619                                 0                0   \n","22848517                                 0                0   \n","\n","          location_Netherlands  location_New Zealand  location_No Location  \\\n","22821161                     0                     0                     0   \n","22823613                     0                     0                     0   \n","22835897                     0                     0                     0   \n","22845619                     0                     0                     0   \n","22848517                     0                     0                     0   \n","\n","          location_Norway  location_Oceania and Antarctica  \\\n","22821161                0                                0   \n","22823613                0                                0   \n","22835897                0                                0   \n","22845619                0                                0   \n","22848517                0                                0   \n","\n","          location_Rest of Asia  location_Rest of Europe  location_Singapore  \\\n","22821161                      0                        0                   0   \n","22823613                      0                        0                   0   \n","22835897                      0                        0                   0   \n","22845619                      0                        0                   0   \n","22848517                      0                        0                   0   \n","\n","          location_Spain  location_Sweden  location_Switzerland  \\\n","22821161               0                0                     0   \n","22823613               0                0                     0   \n","22835897               0                0                     0   \n","22845619               0                0                     0   \n","22848517               0                0                     0   \n","\n","          location_United Kingdom  location_United States  \\\n","22821161                        0                       1   \n","22823613                        0                       1   \n","22835897                        0                       1   \n","22845619                        0                       1   \n","22848517                        0                       1   \n","\n","          category_Art_Ceramics  category_Art_Conceptual Art  \\\n","22821161                      0                            0   \n","22823613                      0                            0   \n","22835897                      0                            0   \n","22845619                      0                            0   \n","22848517                      0                            0   \n","\n","          category_Art_Digital Art  category_Art_Illustration  \\\n","22821161                         0                          0   \n","22823613                         0                          0   \n","22835897                         0                          0   \n","22845619                         0                          0   \n","22848517                         0                          0   \n","\n","          category_Art_Installations  category_Art_Mixed Media  \\\n","22821161                           0                         0   \n","22823613                           0                         0   \n","22835897                           0                         0   \n","22845619                           0                         0   \n","22848517                           0                         0   \n","\n","          category_Art_No Subcategory  category_Art_Painting  \\\n","22821161                            0                      0   \n","22823613                            0                      0   \n","22835897                            0                      0   \n","22845619                            0                      0   \n","22848517                            0                      0   \n","\n","          category_Art_Performance Art  category_Art_Public Art  \\\n","22821161                             0                        0   \n","22823613                             0                        0   \n","22835897                             0                        0   \n","22845619                             0                        0   \n","22848517                             0                        0   \n","\n","          category_Art_Sculpture  category_Art_Social Practice  \\\n","22821161                       0                             0   \n","22823613                       0                             0   \n","22835897                       0                             0   \n","22845619                       0                             0   \n","22848517                       0                             0   \n","\n","          category_Art_Textiles  category_Art_Video Art  \\\n","22821161                      0                       0   \n","22823613                      0                       0   \n","22835897                      0                       0   \n","22845619                      0                       0   \n","22848517                      0                       0   \n","\n","          category_Comics_Anthologies  category_Comics_Comic Books  \\\n","22821161                            0                            0   \n","22823613                            0                            0   \n","22835897                            0                            0   \n","22845619                            0                            0   \n","22848517                            0                            0   \n","\n","          category_Comics_Events  category_Comics_Graphic Novels  \\\n","22821161                       0                               0   \n","22823613                       0                               0   \n","22835897                       0                               0   \n","22845619                       0                               0   \n","22848517                       0                               0   \n","\n","          category_Comics_No Subcategory  category_Comics_Webcomics  \\\n","22821161                               0                          0   \n","22823613                               0                          0   \n","22835897                               0                          0   \n","22845619                               0                          0   \n","22848517                               0                          0   \n","\n","          category_Crafts_Candles  category_Crafts_Crochet  \\\n","22821161                        0                        0   \n","22823613                        0                        0   \n","22835897                        0                        0   \n","22845619                        0                        0   \n","22848517                        0                        0   \n","\n","          category_Crafts_DIY  category_Crafts_Embroidery  \\\n","22821161                    0                           0   \n","22823613                    0                           0   \n","22835897                    0                           0   \n","22845619                    0                           0   \n","22848517                    0                           0   \n","\n","          category_Crafts_Glass  category_Crafts_Knitting  \\\n","22821161                      0                         0   \n","22823613                      0                         0   \n","22835897                      0                         0   \n","22845619                      0                         0   \n","22848517                      0                         0   \n","\n","          category_Crafts_No Subcategory  category_Crafts_Pottery  \\\n","22821161                               0                        0   \n","22823613                               0                        0   \n","22835897                               0                        0   \n","22845619                               0                        0   \n","22848517                               0                        0   \n","\n","          category_Crafts_Printing  category_Crafts_Quilts  \\\n","22821161                         0                       0   \n","22823613                         0                       0   \n","22835897                         0                       0   \n","22845619                         0                       0   \n","22848517                         0                       0   \n","\n","          category_Crafts_Stationery  category_Crafts_Taxidermy  \\\n","22821161                           0                          0   \n","22823613                           0                          0   \n","22835897                           0                          0   \n","22845619                           0                          0   \n","22848517                           0                          0   \n","\n","          category_Crafts_Weaving  category_Crafts_Woodworking  \\\n","22821161                        0                            0   \n","22823613                        0                            0   \n","22835897                        0                            0   \n","22845619                        0                            0   \n","22848517                        0                            0   \n","\n","          category_Dance_No Subcategory  category_Dance_Performances  \\\n","22821161                              0                            0   \n","22823613                              0                            0   \n","22835897                              0                            0   \n","22845619                              0                            0   \n","22848517                              0                            0   \n","\n","          category_Dance_Residencies  category_Dance_Spaces  \\\n","22821161                           0                      0   \n","22823613                           0                      0   \n","22835897                           0                      0   \n","22845619                           0                      0   \n","22848517                           0                      0   \n","\n","          category_Dance_Workshops  category_Design_Architecture  \\\n","22821161                         0                             0   \n","22823613                         0                             0   \n","22835897                         0                             0   \n","22845619                         0                             0   \n","22848517                         0                             0   \n","\n","          category_Design_Civic Design  category_Design_Graphic Design  \\\n","22821161                             0                               0   \n","22823613                             0                               0   \n","22835897                             0                               0   \n","22845619                             0                               0   \n","22848517                             0                               0   \n","\n","          category_Design_Interactive Design  category_Design_No Subcategory  \\\n","22821161                                   0                               0   \n","22823613                                   0                               0   \n","22835897                                   0                               0   \n","22845619                                   0                               0   \n","22848517                                   0                               0   \n","\n","          category_Design_Product Design  category_Design_Toys  \\\n","22821161                               1                     0   \n","22823613                               0                     0   \n","22835897                               0                     0   \n","22845619                               0                     0   \n","22848517                               0                     0   \n","\n","          category_Design_Typography  category_Fashion_Accessories  \\\n","22821161                           0                             0   \n","22823613                           0                             0   \n","22835897                           0                             0   \n","22845619                           0                             0   \n","22848517                           0                             0   \n","\n","          category_Fashion_Apparel  category_Fashion_Childrenswear  \\\n","22821161                         0                               0   \n","22823613                         0                               0   \n","22835897                         0                               0   \n","22845619                         0                               0   \n","22848517                         0                               0   \n","\n","          category_Fashion_Couture  category_Fashion_Footwear  \\\n","22821161                         0                          0   \n","22823613                         0                          0   \n","22835897                         0                          0   \n","22845619                         0                          0   \n","22848517                         0                          0   \n","\n","          category_Fashion_Jewelry  category_Fashion_No Subcategory  \\\n","22821161                         0                                0   \n","22823613                         0                                0   \n","22835897                         0                                0   \n","22845619                         0                                0   \n","22848517                         0                                0   \n","\n","          category_Fashion_Pet Fashion  category_Fashion_Ready-to-wear  \\\n","22821161                             0                               0   \n","22823613                             0                               0   \n","22835897                             0                               0   \n","22845619                             0                               0   \n","22848517                             0                               0   \n","\n","          category_Film & Video_Action  category_Film & Video_Animation  \\\n","22821161                             0                                0   \n","22823613                             0                                0   \n","22835897                             0                                0   \n","22845619                             0                                0   \n","22848517                             0                                0   \n","\n","          category_Film & Video_Comedy  category_Film & Video_Documentary  \\\n","22821161                             0                                  0   \n","22823613                             0                                  0   \n","22835897                             0                                  0   \n","22845619                             0                                  0   \n","22848517                             0                                  0   \n","\n","          category_Film & Video_Drama  category_Film & Video_Experimental  \\\n","22821161                            0                                   0   \n","22823613                            0                                   0   \n","22835897                            0                                   0   \n","22845619                            0                                   0   \n","22848517                            0                                   0   \n","\n","          category_Film & Video_Family  category_Film & Video_Fantasy  \\\n","22821161                             0                              0   \n","22823613                             0                              0   \n","22835897                             0                              0   \n","22845619                             0                              0   \n","22848517                             0                              0   \n","\n","          category_Film & Video_Festivals  category_Film & Video_Horror  \\\n","22821161                                0                             0   \n","22823613                                0                             0   \n","22835897                                0                             0   \n","22845619                                0                             0   \n","22848517                                0                             0   \n","\n","          category_Film & Video_Movie Theaters  \\\n","22821161                                     0   \n","22823613                                     0   \n","22835897                                     0   \n","22845619                                     0   \n","22848517                                     0   \n","\n","          category_Film & Video_Music Videos  \\\n","22821161                                   0   \n","22823613                                   0   \n","22835897                                   0   \n","22845619                                   0   \n","22848517                                   0   \n","\n","          category_Film & Video_Narrative Film  \\\n","22821161                                     0   \n","22823613                                     0   \n","22835897                                     0   \n","22845619                                     0   \n","22848517                                     0   \n","\n","          category_Film & Video_No Subcategory  category_Film & Video_Romance  \\\n","22821161                                     0                              0   \n","22823613                                     0                              0   \n","22835897                                     0                              0   \n","22845619                                     0                              0   \n","22848517                                     0                              0   \n","\n","          category_Film & Video_Science Fiction  category_Film & Video_Shorts  \\\n","22821161                                      0                             0   \n","22823613                                      0                             0   \n","22835897                                      0                             0   \n","22845619                                      0                             0   \n","22848517                                      0                             0   \n","\n","          category_Film & Video_Television  category_Film & Video_Thrillers  \\\n","22821161                                 0                                0   \n","22823613                                 0                                0   \n","22835897                                 0                                0   \n","22845619                                 0                                0   \n","22848517                                 0                                0   \n","\n","          category_Film & Video_Webseries  category_Food_Bacon  \\\n","22821161                                0                    0   \n","22823613                                0                    0   \n","22835897                                0                    0   \n","22845619                                0                    0   \n","22848517                                0                    0   \n","\n","          category_Food_Community Gardens  category_Food_Cookbooks  \\\n","22821161                                0                        0   \n","22823613                                0                        0   \n","22835897                                0                        0   \n","22845619                                0                        0   \n","22848517                                0                        0   \n","\n","          category_Food_Drinks  category_Food_Events  \\\n","22821161                     0                     0   \n","22823613                     0                     0   \n","22835897                     0                     0   \n","22845619                     0                     0   \n","22848517                     0                     0   \n","\n","          category_Food_Farmer's Markets  category_Food_Farms  \\\n","22821161                               0                    0   \n","22823613                               0                    0   \n","22835897                               0                    0   \n","22845619                               0                    0   \n","22848517                               0                    0   \n","\n","          category_Food_Food Trucks  category_Food_No Subcategory  \\\n","22821161                          0                             0   \n","22823613                          0                             0   \n","22835897                          0                             0   \n","22845619                          0                             0   \n","22848517                          0                             0   \n","\n","          category_Food_Restaurants  category_Food_Small Batch  \\\n","22821161                          0                          0   \n","22823613                          0                          0   \n","22835897                          0                          0   \n","22845619                          0                          0   \n","22848517                          0                          0   \n","\n","          category_Food_Spaces  category_Food_Vegan  \\\n","22821161                     0                    0   \n","22823613                     0                    0   \n","22835897                     0                    0   \n","22845619                     0                    0   \n","22848517                     0                    0   \n","\n","          category_Games_Gaming Hardware  category_Games_Live Games  \\\n","22821161                               0                          0   \n","22823613                               0                          0   \n","22835897                               0                          0   \n","22845619                               0                          0   \n","22848517                               0                          0   \n","\n","          category_Games_Mobile Games  category_Games_No Subcategory  \\\n","22821161                            0                              0   \n","22823613                            0                              0   \n","22835897                            0                              0   \n","22845619                            0                              0   \n","22848517                            0                              0   \n","\n","          category_Games_Playing Cards  category_Games_Puzzles  \\\n","22821161                             0                       0   \n","22823613                             0                       0   \n","22835897                             0                       0   \n","22845619                             0                       0   \n","22848517                             0                       0   \n","\n","          category_Games_Tabletop Games  category_Games_Video Games  \\\n","22821161                              0                           0   \n","22823613                              0                           0   \n","22835897                              0                           0   \n","22845619                              0                           0   \n","22848517                              1                           0   \n","\n","          category_Journalism_Audio  category_Journalism_No Subcategory  \\\n","22821161                          0                                   0   \n","22823613                          0                                   0   \n","22835897                          0                                   0   \n","22845619                          0                                   0   \n","22848517                          0                                   0   \n","\n","          category_Journalism_Photo  category_Journalism_Print  \\\n","22821161                          0                          0   \n","22823613                          0                          0   \n","22835897                          0                          0   \n","22845619                          0                          0   \n","22848517                          0                          0   \n","\n","          category_Journalism_Video  category_Journalism_Web  \\\n","22821161                          0                        0   \n","22823613                          0                        0   \n","22835897                          0                        0   \n","22845619                          0                        0   \n","22848517                          0                        0   \n","\n","          category_Music_Blues  category_Music_Chiptune  \\\n","22821161                     0                        0   \n","22823613                     0                        0   \n","22835897                     0                        0   \n","22845619                     0                        0   \n","22848517                     0                        0   \n","\n","          category_Music_Classical Music  category_Music_Comedy  \\\n","22821161                               0                      0   \n","22823613                               0                      0   \n","22835897                               0                      0   \n","22845619                               0                      0   \n","22848517                               0                      0   \n","\n","          category_Music_Country & Folk  category_Music_Electronic Music  \\\n","22821161                              0                                0   \n","22823613                              0                                0   \n","22835897                              0                                0   \n","22845619                              0                                0   \n","22848517                              0                                0   \n","\n","          category_Music_Faith  category_Music_Hip-Hop  \\\n","22821161                     0                       0   \n","22823613                     0                       0   \n","22835897                     0                       0   \n","22845619                     0                       0   \n","22848517                     0                       0   \n","\n","          category_Music_Indie Rock  category_Music_Jazz  category_Music_Kids  \\\n","22821161                          0                    0                    0   \n","22823613                          0                    0                    0   \n","22835897                          0                    0                    0   \n","22845619                          1                    0                    0   \n","22848517                          0                    0                    0   \n","\n","          category_Music_Latin  category_Music_Metal  \\\n","22821161                     0                     0   \n","22823613                     0                     0   \n","22835897                     0                     0   \n","22845619                     0                     0   \n","22848517                     0                     0   \n","\n","          category_Music_No Subcategory  category_Music_Pop  \\\n","22821161                              0                   0   \n","22823613                              0                   0   \n","22835897                              0                   0   \n","22845619                              0                   0   \n","22848517                              0                   0   \n","\n","          category_Music_Punk  category_Music_R&B  category_Music_Rock  \\\n","22821161                    0                   0                    0   \n","22823613                    0                   0                    0   \n","22835897                    0                   0                    0   \n","22845619                    0                   0                    0   \n","22848517                    0                   0                    0   \n","\n","          category_Music_World Music  category_Photography_Animals  \\\n","22821161                           0                             0   \n","22823613                           0                             0   \n","22835897                           0                             0   \n","22845619                           0                             0   \n","22848517                           0                             0   \n","\n","          category_Photography_Fine Art  category_Photography_Nature  \\\n","22821161                              0                            0   \n","22823613                              0                            0   \n","22835897                              0                            0   \n","22845619                              0                            0   \n","22848517                              0                            0   \n","\n","          category_Photography_No Subcategory  category_Photography_People  \\\n","22821161                                    0                            0   \n","22823613                                    0                            0   \n","22835897                                    0                            0   \n","22845619                                    0                            0   \n","22848517                                    0                            0   \n","\n","          category_Photography_Photobooks  category_Photography_Places  \\\n","22821161                                0                            0   \n","22823613                                0                            0   \n","22835897                                0                            0   \n","22845619                                0                            0   \n","22848517                                0                            0   \n","\n","          category_Publishing_Academic  category_Publishing_Anthologies  \\\n","22821161                             0                                0   \n","22823613                             0                                0   \n","22835897                             0                                0   \n","22845619                             0                                0   \n","22848517                             0                                0   \n","\n","          category_Publishing_Art Books  category_Publishing_Calendars  \\\n","22821161                              0                              0   \n","22823613                              0                              0   \n","22835897                              0                              0   \n","22845619                              0                              0   \n","22848517                              0                              0   \n","\n","          category_Publishing_Children's Books  category_Publishing_Comedy  \\\n","22821161                                     0                           0   \n","22823613                                     0                           0   \n","22835897                                     1                           0   \n","22845619                                     0                           0   \n","22848517                                     0                           0   \n","\n","          category_Publishing_Fiction  category_Publishing_Letterpress  \\\n","22821161                            0                                0   \n","22823613                            0                                0   \n","22835897                            0                                0   \n","22845619                            0                                0   \n","22848517                            0                                0   \n","\n","          category_Publishing_Literary Journals  \\\n","22821161                                      0   \n","22823613                                      0   \n","22835897                                      0   \n","22845619                                      0   \n","22848517                                      0   \n","\n","          category_Publishing_Literary Spaces  \\\n","22821161                                    0   \n","22823613                                    0   \n","22835897                                    0   \n","22845619                                    0   \n","22848517                                    0   \n","\n","          category_Publishing_No Subcategory  category_Publishing_Nonfiction  \\\n","22821161                                   0                               0   \n","22823613                                   0                               0   \n","22835897                                   0                               0   \n","22845619                                   0                               0   \n","22848517                                   0                               0   \n","\n","          category_Publishing_Periodicals  category_Publishing_Poetry  \\\n","22821161                                0                           0   \n","22823613                                0                           0   \n","22835897                                0                           0   \n","22845619                                0                           0   \n","22848517                                0                           0   \n","\n","          category_Publishing_Radio & Podcasts  \\\n","22821161                                     0   \n","22823613                                     0   \n","22835897                                     0   \n","22845619                                     0   \n","22848517                                     0   \n","\n","          category_Publishing_Translations  category_Publishing_Young Adult  \\\n","22821161                                 0                                0   \n","22823613                                 0                                0   \n","22835897                                 0                                0   \n","22845619                                 0                                0   \n","22848517                                 0                                0   \n","\n","          category_Publishing_Zines  category_Technology_3D Printing  \\\n","22821161                          0                                0   \n","22823613                          0                                0   \n","22835897                          0                                0   \n","22845619                          0                                0   \n","22848517                          0                                0   \n","\n","          category_Technology_Apps  category_Technology_Camera Equipment  \\\n","22821161                         0                                     0   \n","22823613                         0                                     0   \n","22835897                         0                                     0   \n","22845619                         0                                     0   \n","22848517                         0                                     0   \n","\n","          category_Technology_DIY Electronics  \\\n","22821161                                    0   \n","22823613                                    0   \n","22835897                                    0   \n","22845619                                    0   \n","22848517                                    0   \n","\n","          category_Technology_Fabrication Tools  category_Technology_Flight  \\\n","22821161                                      0                           0   \n","22823613                                      0                           0   \n","22835897                                      0                           0   \n","22845619                                      0                           0   \n","22848517                                      0                           0   \n","\n","          category_Technology_Gadgets  category_Technology_Hardware  \\\n","22821161                            0                             0   \n","22823613                            0                             0   \n","22835897                            0                             0   \n","22845619                            0                             0   \n","22848517                            0                             0   \n","\n","          category_Technology_Makerspaces  category_Technology_No Subcategory  \\\n","22821161                                0                                   0   \n","22823613                                0                                   0   \n","22835897                                0                                   0   \n","22845619                                0                                   0   \n","22848517                                0                                   0   \n","\n","          category_Technology_Robots  category_Technology_Software  \\\n","22821161                           0                             0   \n","22823613                           0                             0   \n","22835897                           0                             0   \n","22845619                           0                             0   \n","22848517                           0                             0   \n","\n","          category_Technology_Sound  category_Technology_Space Exploration  \\\n","22821161                          0                                      0   \n","22823613                          0                                      0   \n","22835897                          0                                      0   \n","22845619                          0                                      0   \n","22848517                          0                                      0   \n","\n","          category_Technology_Wearables  category_Technology_Web  \\\n","22821161                              0                        0   \n","22823613                              0                        1   \n","22835897                              0                        0   \n","22845619                              0                        0   \n","22848517                              0                        0   \n","\n","          category_Theater_Comedy  category_Theater_Experimental  \\\n","22821161                        0                              0   \n","22823613                        0                              0   \n","22835897                        0                              0   \n","22845619                        0                              0   \n","22848517                        0                              0   \n","\n","          category_Theater_Festivals  category_Theater_Immersive  \\\n","22821161                           0                           0   \n","22823613                           0                           0   \n","22835897                           0                           0   \n","22845619                           0                           0   \n","22848517                           0                           0   \n","\n","          category_Theater_Musical  category_Theater_No Subcategory  \\\n","22821161                         0                                0   \n","22823613                         0                                0   \n","22835897                         0                                0   \n","22845619                         0                                0   \n","22848517                         0                                0   \n","\n","          category_Theater_Plays  category_Theater_Spaces  \n","22821161                       0                        0  \n","22823613                       0                        0  \n","22835897                       0                        0  \n","22845619                       0                        0  \n","22848517                       0                        0  "]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdk7Ma-dsMlb","executionInfo":{"status":"ok","timestamp":1611386022446,"user_tz":-60,"elapsed":3053,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"b0d36094-1691-4f68-fb94-ce4bd405ea3b"},"source":["# Convert dataset and target variable to Numpy Arrays\n","y = kickstarter_df[\"campaign_successful\"].to_numpy()\n","kickstarter_notarget_df = kickstarter_df.drop(columns=[\"campaign_successful\"])\n","X = kickstarter_notarget_df.astype(\"float32\").to_numpy()\n","\n","print(type(y))\n","print(y.shape)\n","print(type(X))\n","print(X.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n","(246891,)\n","<class 'numpy.ndarray'>\n","(246891, 233)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3_B_DfqOOLp0"},"source":["# Retrieve column names which will be used for later pre-processing\n","feature_names = kickstarter_notarget_df.columns.values\n","numeric_feature_names = [\"goal\", \"number_of_collaborators\", \"funding_period\", \"days_between_created_and_launched\", \"number_of_images\", \"number_of_videos\", \"number_of_audios\", \"number_of_interactives\", \"number_of_words\", \"number_of_links\", \"number_of_creator_backings\", \"number_of_creator_projects\", \"number_of_rewards\", \"number_of_words_per_reward\", \"lowest_pledge_level\", \"highest_pledge_level\", \"avg_months_until_reward\"]\n","binary_feature_names = [x for x in feature_names if x not in numeric_feature_names]\n","numeric_features = [kickstarter_notarget_df.columns.get_loc(x) for x in numeric_feature_names]\n","binary_features = [kickstarter_notarget_df.columns.get_loc(x) for x in binary_feature_names]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26YyHOP-J_o0","executionInfo":{"status":"ok","timestamp":1611386023574,"user_tz":-60,"elapsed":4160,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"7ad29835-7651-4e9e-a2e1-59c58651070a"},"source":["# Split dataset into training, subtraining, validation, and test set\n","train_size = round(kickstarter_df.shape[0]*0.7*1)\n","val_size = round(kickstarter_df.shape[0]*0.15*1)\n","test_size = round(kickstarter_df.shape[0]*1) - val_size - train_size\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=(train_size+val_size),test_size=test_size, shuffle=True, stratify=y, random_state=seed_value)\n","X_subtrain, X_val, y_subtrain, y_val = train_test_split(X_train, y_train, train_size=train_size, test_size=val_size, shuffle=True, stratify=y_train, random_state=seed_value)\n","\n","print(\"Shape of X_train: {}\".format(X_train.shape))\n","print(\"Shape of y_train: {}\".format(y_train.shape))\n","print(\"Shape of X_subtrain: {}\".format(X_subtrain.shape))\n","print(\"Shape of y_subtrain: {}\".format(y_subtrain.shape))\n","print(\"Shape of X_val: {}\".format(X_val.shape))\n","print(\"Shape of y_val: {}\".format(y_val.shape))\n","print(\"Shape of X_test: {}\".format(X_test.shape))\n","print(\"Shape of y_test: {}\".format(y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of X_train: (209858, 233)\n","Shape of y_train: (209858,)\n","Shape of X_subtrain: (172824, 233)\n","Shape of y_subtrain: (172824,)\n","Shape of X_val: (37034, 233)\n","Shape of y_val: (37034,)\n","Shape of X_test: (37033, 233)\n","Shape of y_test: (37033,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QlcazcrXKT5e"},"source":["#### a) Baseline"]},{"cell_type":"markdown","metadata":{"id":"hu2HEVe5Kf5S"},"source":["This model provides the baseline, which will be used as starting point for the hyperparameter search. The goal is to gradually improve the model performance.\n","\n","**Hyperparameters:**\n","- Untransformed Dataset\n","- Regularizer = None\n","- Optimizer = RMSprop_centered\n","- Weight Initialization = GlorotNormal\n","- Batch Size = 512\n","- Number of Hidden Layers = 1\n","- Number of Neurons = 233\n","- Activation Function = sigmoid"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OK4BeD8a1CIy","executionInfo":{"status":"ok","timestamp":1611306760605,"user_tz":-60,"elapsed":40983,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"3c02fe82-e577-4c16-9ada-d2dad6e587fc"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 1.1019 - binary_accuracy: 0.5965 - val_loss: 0.5333 - val_binary_accuracy: 0.7116\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5182 - binary_accuracy: 0.7265 - val_loss: 0.5231 - val_binary_accuracy: 0.7289\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.5130 - binary_accuracy: 0.7325 - val_loss: 0.5105 - val_binary_accuracy: 0.7382\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.5079 - binary_accuracy: 0.7364 - val_loss: 0.5082 - val_binary_accuracy: 0.7362\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.5047 - binary_accuracy: 0.7420 - val_loss: 0.5123 - val_binary_accuracy: 0.7303\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4988 - binary_accuracy: 0.7466 - val_loss: 0.4979 - val_binary_accuracy: 0.7465\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4996 - binary_accuracy: 0.7464 - val_loss: 0.4937 - val_binary_accuracy: 0.7543\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4968 - binary_accuracy: 0.7498 - val_loss: 0.4917 - val_binary_accuracy: 0.7615\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4936 - binary_accuracy: 0.7522 - val_loss: 0.4926 - val_binary_accuracy: 0.7599\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4898 - binary_accuracy: 0.7540 - val_loss: 0.4832 - val_binary_accuracy: 0.7587\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4894 - binary_accuracy: 0.7554 - val_loss: 0.5146 - val_binary_accuracy: 0.7491\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4907 - binary_accuracy: 0.7538 - val_loss: 0.4791 - val_binary_accuracy: 0.7652\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4897 - binary_accuracy: 0.7553 - val_loss: 0.4717 - val_binary_accuracy: 0.7666\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4877 - binary_accuracy: 0.7563 - val_loss: 0.4855 - val_binary_accuracy: 0.7592\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4857 - binary_accuracy: 0.7580 - val_loss: 0.4855 - val_binary_accuracy: 0.7584\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4851 - binary_accuracy: 0.7592 - val_loss: 0.4878 - val_binary_accuracy: 0.7521\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4826 - binary_accuracy: 0.7619 - val_loss: 0.4939 - val_binary_accuracy: 0.7513\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4849 - binary_accuracy: 0.7599 - val_loss: 0.5016 - val_binary_accuracy: 0.7485\n","Training Accuracy: 0.770\n","Validation Accuracy: 0.767\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6250os8sMSuZ"},"source":["#### b) Test Different Preprocessing Strategies"]},{"cell_type":"markdown","metadata":{"id":"APCM6IayNmOx"},"source":["##### 1. Standardization: Numerical + Binary Attributes"]},{"cell_type":"code","metadata":{"id":"2V-o3yWELd0C"},"source":["# Specify pre-processing pipeline for the different types of attributes\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", StandardScaler(), numeric_features),\n","      (\"binary\", StandardScaler(), binary_features)\n","    ],\n","    remainder=\"drop\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain_transformed = preprocessing.transform(X_subtrain)\n","X_val_transformed = preprocessing.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"YtZlLoT7Ld7l","executionInfo":{"status":"ok","timestamp":1611307113707,"user_tz":-60,"elapsed":521,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"d7cd0d66-5444-491e-8f1a-3b05ad523b88"},"source":["# Validation\n","tmp = pd.DataFrame(X_subtrain_transformed)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(172824, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","      <th>176</th>\n","      <th>177</th>\n","      <th>178</th>\n","      <th>179</th>\n","      <th>180</th>\n","      <th>181</th>\n","      <th>182</th>\n","      <th>183</th>\n","      <th>184</th>\n","      <th>185</th>\n","      <th>186</th>\n","      <th>187</th>\n","      <th>188</th>\n","      <th>189</th>\n","      <th>190</th>\n","      <th>191</th>\n","      <th>192</th>\n","      <th>193</th>\n","      <th>194</th>\n","      <th>195</th>\n","      <th>196</th>\n","      <th>197</th>\n","      <th>198</th>\n","      <th>199</th>\n","      <th>200</th>\n","      <th>201</th>\n","      <th>202</th>\n","      <th>203</th>\n","      <th>204</th>\n","      <th>205</th>\n","      <th>206</th>\n","      <th>207</th>\n","      <th>208</th>\n","      <th>209</th>\n","      <th>210</th>\n","      <th>211</th>\n","      <th>212</th>\n","      <th>213</th>\n","      <th>214</th>\n","      <th>215</th>\n","      <th>216</th>\n","      <th>217</th>\n","      <th>218</th>\n","      <th>219</th>\n","      <th>220</th>\n","      <th>221</th>\n","      <th>222</th>\n","      <th>223</th>\n","      <th>224</th>\n","      <th>225</th>\n","      <th>226</th>\n","      <th>227</th>\n","      <th>228</th>\n","      <th>229</th>\n","      <th>230</th>\n","      <th>231</th>\n","      <th>232</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.298547</td>\n","      <td>-0.198447</td>\n","      <td>-0.941790</td>\n","      <td>-0.301747</td>\n","      <td>-0.542916</td>\n","      <td>-0.264041</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>-1.130397</td>\n","      <td>-0.746823</td>\n","      <td>-0.215401</td>\n","      <td>-0.224846</td>\n","      <td>-0.265058</td>\n","      <td>-0.639590</td>\n","      <td>-0.094083</td>\n","      <td>-0.563342</td>\n","      <td>0.613136</td>\n","      <td>-0.287578</td>\n","      <td>0.675031</td>\n","      <td>-0.08672</td>\n","      <td>-1.081998</td>\n","      <td>-0.947352</td>\n","      <td>0.147337</td>\n","      <td>0.078146</td>\n","      <td>-0.654237</td>\n","      <td>-0.432702</td>\n","      <td>-0.33426</td>\n","      <td>-0.159431</td>\n","      <td>-1.120286</td>\n","      <td>-1.49029</td>\n","      <td>-0.673015</td>\n","      <td>1.766646</td>\n","      <td>-0.594752</td>\n","      <td>-0.607508</td>\n","      <td>-0.541083</td>\n","      <td>-0.033</td>\n","      <td>-0.145087</td>\n","      <td>-0.04121</td>\n","      <td>-0.199623</td>\n","      <td>-0.036584</td>\n","      <td>-0.052331</td>\n","      <td>-0.070387</td>\n","      <td>-0.097759</td>\n","      <td>-0.057777</td>\n","      <td>-0.052387</td>\n","      <td>-0.094291</td>\n","      <td>-0.048765</td>\n","      <td>-0.053432</td>\n","      <td>-0.048346</td>\n","      <td>-0.084526</td>\n","      <td>-0.063451</td>\n","      <td>-0.059955</td>\n","      <td>-0.040139</td>\n","      <td>-0.009622</td>\n","      <td>-0.064318</td>\n","      <td>-0.085869</td>\n","      <td>-0.051829</td>\n","      <td>-0.072474</td>\n","      <td>-0.066504</td>\n","      <td>-0.041839</td>\n","      <td>-0.324079</td>\n","      <td>0.561241</td>\n","      <td>-0.033436</td>\n","      <td>-0.054723</td>\n","      <td>-0.069468</td>\n","      <td>-0.101491</td>\n","      <td>-0.038213</td>\n","      <td>-0.092748</td>\n","      <td>-0.155436</td>\n","      <td>-0.097396</td>\n","      <td>-0.077544</td>\n","      <td>-0.09176</td>\n","      <td>-0.072312</td>\n","      <td>-0.011024</td>\n","      <td>-0.031379</td>\n","      <td>-0.025692</td>\n","      <td>-0.036663</td>\n","      <td>-0.096636</td>\n","      <td>-0.021654</td>\n","      <td>-0.075865</td>\n","      <td>-0.109888</td>\n","      <td>-0.044136</td>\n","      <td>-0.038741</td>\n","      <td>-0.022442</td>\n","      <td>-0.059613</td>\n","      <td>-0.019693</td>\n","      <td>-0.020697</td>\n","      <td>-0.022052</td>\n","      <td>-0.111494</td>\n","      <td>-0.017181</td>\n","      <td>-0.027542</td>\n","      <td>-0.012955</td>\n","      <td>-0.026796</td>\n","      <td>-0.004811</td>\n","      <td>-0.015215</td>\n","      <td>-0.060052</td>\n","      <td>-0.08109</td>\n","      <td>-0.055933</td>\n","      <td>-0.014027</td>\n","      <td>-0.025006</td>\n","      <td>-0.021385</td>\n","      <td>-0.045878</td>\n","      <td>-0.030725</td>\n","      <td>-0.072996</td>\n","      <td>-0.034038</td>\n","      <td>-0.092335</td>\n","      <td>-0.223068</td>\n","      <td>-0.012266</td>\n","      <td>-0.015591</td>\n","      <td>-0.104757</td>\n","      <td>-0.150343</td>\n","      <td>-0.038666</td>\n","      <td>-0.028676</td>\n","      <td>-0.053377</td>\n","      <td>-0.064273</td>\n","      <td>-0.144796</td>\n","      <td>-0.020415</td>\n","      <td>-0.054989</td>\n","      <td>-0.045752</td>\n","      <td>-0.082381</td>\n","      <td>-0.07941</td>\n","      <td>-0.196261</td>\n","      <td>-0.079263</td>\n","      <td>-0.039557</td>\n","      <td>-0.032647</td>\n","      <td>-0.03025</td>\n","      <td>-0.028978</td>\n","      <td>-0.061205</td>\n","      <td>-0.028166</td>\n","      <td>-0.044201</td>\n","      <td>-0.113237</td>\n","      <td>-0.162721</td>\n","      <td>-0.024656</td>\n","      <td>-0.043805</td>\n","      <td>5.617208</td>\n","      <td>-0.053649</td>\n","      <td>-0.048645</td>\n","      <td>-0.12157</td>\n","      <td>-0.018944</td>\n","      <td>-0.028978</td>\n","      <td>-0.038891</td>\n","      <td>-0.090241</td>\n","      <td>-0.042459</td>\n","      <td>-0.036663</td>\n","      <td>-0.060439</td>\n","      <td>-0.076173</td>\n","      <td>-0.166301</td>\n","      <td>-0.097909</td>\n","      <td>-0.072916</td>\n","      <td>-0.039336</td>\n","      <td>-0.047128</td>\n","      <td>-0.031655</td>\n","      <td>-0.055568</td>\n","      <td>-0.089324</td>\n","      <td>-0.078221</td>\n","      <td>-0.088331</td>\n","      <td>-0.029078</td>\n","      <td>-0.172891</td>\n","      <td>-0.151786</td>\n","      <td>-0.035539</td>\n","      <td>-0.068622</td>\n","      <td>-0.022442</td>\n","      <td>-0.045624</td>\n","      <td>-0.034038</td>\n","      <td>-0.058578</td>\n","      <td>-0.028371</td>\n","      <td>-0.009001</td>\n","      <td>-0.084317</td>\n","      <td>-0.0125</td>\n","      <td>-0.114203</td>\n","      <td>-0.07728</td>\n","      <td>-0.057727</td>\n","      <td>-0.106438</td>\n","      <td>-0.124334</td>\n","      <td>-0.073833</td>\n","      <td>-0.030058</td>\n","      <td>-0.020273</td>\n","      <td>-0.047128</td>\n","      <td>-0.215988</td>\n","      <td>-0.095994</td>\n","      <td>-0.03082</td>\n","      <td>-0.03941</td>\n","      <td>-0.138353</td>\n","      <td>-0.076938</td>\n","      <td>-0.026579</td>\n","      <td>-0.043406</td>\n","      <td>-0.040067</td>\n","      <td>-0.122254</td>\n","      <td>-0.055881</td>\n","      <td>-0.065887</td>\n","      <td>-0.043473</td>\n","      <td>-0.053812</td>\n","      <td>-0.035293</td>\n","      <td>-0.08456</td>\n","      <td>-0.0322</td>\n","      <td>-0.139306</td>\n","      <td>-0.02152</td>\n","      <td>-0.156196</td>\n","      <td>-0.012955</td>\n","      <td>-0.029572</td>\n","      <td>-0.016317</td>\n","      <td>-0.120561</td>\n","      <td>-0.147604</td>\n","      <td>-0.054936</td>\n","      <td>-0.064364</td>\n","      <td>-0.053541</td>\n","      <td>-0.02152</td>\n","      <td>-0.049416</td>\n","      <td>-0.036105</td>\n","      <td>-0.03963</td>\n","      <td>-0.14633</td>\n","      <td>-0.029767</td>\n","      <td>-0.048105</td>\n","      <td>-0.026579</td>\n","      <td>-0.031928</td>\n","      <td>-0.089619</td>\n","      <td>-0.092685</td>\n","      <td>-0.025006</td>\n","      <td>-0.11784</td>\n","      <td>-0.037832</td>\n","      <td>-0.093192</td>\n","      <td>-0.040284</td>\n","      <td>-0.029177</td>\n","      <td>-0.054403</td>\n","      <td>-0.103594</td>\n","      <td>-0.025579</td>\n","      <td>-0.0322</td>\n","      <td>-0.040067</td>\n","      <td>-0.0322</td>\n","      <td>-0.051037</td>\n","      <td>-0.141534</td>\n","      <td>-0.066985</td>\n","      <td>-0.022183</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.307414</td>\n","      <td>-0.198447</td>\n","      <td>-2.019196</td>\n","      <td>-0.326723</td>\n","      <td>-0.542916</td>\n","      <td>-0.264041</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>-0.369989</td>\n","      <td>0.009728</td>\n","      <td>-0.028455</td>\n","      <td>-0.224846</td>\n","      <td>-0.636566</td>\n","      <td>-0.636051</td>\n","      <td>-0.067116</td>\n","      <td>-0.563342</td>\n","      <td>-0.513072</td>\n","      <td>-0.287578</td>\n","      <td>0.675031</td>\n","      <td>-0.08672</td>\n","      <td>-1.081998</td>\n","      <td>1.055574</td>\n","      <td>0.147337</td>\n","      <td>0.078146</td>\n","      <td>-0.654237</td>\n","      <td>-0.432702</td>\n","      <td>-0.33426</td>\n","      <td>6.272299</td>\n","      <td>-1.120286</td>\n","      <td>0.67101</td>\n","      <td>1.485850</td>\n","      <td>1.766646</td>\n","      <td>-0.594752</td>\n","      <td>-0.607508</td>\n","      <td>-0.541083</td>\n","      <td>-0.033</td>\n","      <td>-0.145087</td>\n","      <td>-0.04121</td>\n","      <td>-0.199623</td>\n","      <td>-0.036584</td>\n","      <td>-0.052331</td>\n","      <td>-0.070387</td>\n","      <td>-0.097759</td>\n","      <td>-0.057777</td>\n","      <td>-0.052387</td>\n","      <td>-0.094291</td>\n","      <td>-0.048765</td>\n","      <td>-0.053432</td>\n","      <td>-0.048346</td>\n","      <td>-0.084526</td>\n","      <td>-0.063451</td>\n","      <td>-0.059955</td>\n","      <td>-0.040139</td>\n","      <td>-0.009622</td>\n","      <td>-0.064318</td>\n","      <td>-0.085869</td>\n","      <td>-0.051829</td>\n","      <td>-0.072474</td>\n","      <td>-0.066504</td>\n","      <td>-0.041839</td>\n","      <td>-0.324079</td>\n","      <td>0.561241</td>\n","      <td>-0.033436</td>\n","      <td>-0.054723</td>\n","      <td>-0.069468</td>\n","      <td>-0.101491</td>\n","      <td>-0.038213</td>\n","      <td>-0.092748</td>\n","      <td>-0.155436</td>\n","      <td>-0.097396</td>\n","      <td>-0.077544</td>\n","      <td>-0.09176</td>\n","      <td>-0.072312</td>\n","      <td>-0.011024</td>\n","      <td>-0.031379</td>\n","      <td>-0.025692</td>\n","      <td>-0.036663</td>\n","      <td>-0.096636</td>\n","      <td>-0.021654</td>\n","      <td>-0.075865</td>\n","      <td>-0.109888</td>\n","      <td>-0.044136</td>\n","      <td>-0.038741</td>\n","      <td>-0.022442</td>\n","      <td>-0.059613</td>\n","      <td>-0.019693</td>\n","      <td>-0.020697</td>\n","      <td>-0.022052</td>\n","      <td>-0.111494</td>\n","      <td>-0.017181</td>\n","      <td>-0.027542</td>\n","      <td>-0.012955</td>\n","      <td>-0.026796</td>\n","      <td>-0.004811</td>\n","      <td>-0.015215</td>\n","      <td>-0.060052</td>\n","      <td>-0.08109</td>\n","      <td>-0.055933</td>\n","      <td>-0.014027</td>\n","      <td>-0.025006</td>\n","      <td>-0.021385</td>\n","      <td>-0.045878</td>\n","      <td>-0.030725</td>\n","      <td>-0.072996</td>\n","      <td>-0.034038</td>\n","      <td>-0.092335</td>\n","      <td>-0.223068</td>\n","      <td>-0.012266</td>\n","      <td>-0.015591</td>\n","      <td>-0.104757</td>\n","      <td>-0.150343</td>\n","      <td>-0.038666</td>\n","      <td>-0.028676</td>\n","      <td>-0.053377</td>\n","      <td>-0.064273</td>\n","      <td>-0.144796</td>\n","      <td>-0.020415</td>\n","      <td>-0.054989</td>\n","      <td>-0.045752</td>\n","      <td>-0.082381</td>\n","      <td>-0.07941</td>\n","      <td>-0.196261</td>\n","      <td>-0.079263</td>\n","      <td>-0.039557</td>\n","      <td>-0.032647</td>\n","      <td>-0.03025</td>\n","      <td>-0.028978</td>\n","      <td>-0.061205</td>\n","      <td>-0.028166</td>\n","      <td>-0.044201</td>\n","      <td>-0.113237</td>\n","      <td>-0.162721</td>\n","      <td>-0.024656</td>\n","      <td>-0.043805</td>\n","      <td>5.617208</td>\n","      <td>-0.053649</td>\n","      <td>-0.048645</td>\n","      <td>-0.12157</td>\n","      <td>-0.018944</td>\n","      <td>-0.028978</td>\n","      <td>-0.038891</td>\n","      <td>-0.090241</td>\n","      <td>-0.042459</td>\n","      <td>-0.036663</td>\n","      <td>-0.060439</td>\n","      <td>-0.076173</td>\n","      <td>-0.166301</td>\n","      <td>-0.097909</td>\n","      <td>-0.072916</td>\n","      <td>-0.039336</td>\n","      <td>-0.047128</td>\n","      <td>-0.031655</td>\n","      <td>-0.055568</td>\n","      <td>-0.089324</td>\n","      <td>-0.078221</td>\n","      <td>-0.088331</td>\n","      <td>-0.029078</td>\n","      <td>-0.172891</td>\n","      <td>-0.151786</td>\n","      <td>-0.035539</td>\n","      <td>-0.068622</td>\n","      <td>-0.022442</td>\n","      <td>-0.045624</td>\n","      <td>-0.034038</td>\n","      <td>-0.058578</td>\n","      <td>-0.028371</td>\n","      <td>-0.009001</td>\n","      <td>-0.084317</td>\n","      <td>-0.0125</td>\n","      <td>-0.114203</td>\n","      <td>-0.07728</td>\n","      <td>-0.057727</td>\n","      <td>-0.106438</td>\n","      <td>-0.124334</td>\n","      <td>-0.073833</td>\n","      <td>-0.030058</td>\n","      <td>-0.020273</td>\n","      <td>-0.047128</td>\n","      <td>-0.215988</td>\n","      <td>-0.095994</td>\n","      <td>-0.03082</td>\n","      <td>-0.03941</td>\n","      <td>-0.138353</td>\n","      <td>-0.076938</td>\n","      <td>-0.026579</td>\n","      <td>-0.043406</td>\n","      <td>-0.040067</td>\n","      <td>-0.122254</td>\n","      <td>-0.055881</td>\n","      <td>-0.065887</td>\n","      <td>-0.043473</td>\n","      <td>-0.053812</td>\n","      <td>-0.035293</td>\n","      <td>-0.08456</td>\n","      <td>-0.0322</td>\n","      <td>-0.139306</td>\n","      <td>-0.02152</td>\n","      <td>-0.156196</td>\n","      <td>-0.012955</td>\n","      <td>-0.029572</td>\n","      <td>-0.016317</td>\n","      <td>-0.120561</td>\n","      <td>-0.147604</td>\n","      <td>-0.054936</td>\n","      <td>-0.064364</td>\n","      <td>-0.053541</td>\n","      <td>-0.02152</td>\n","      <td>-0.049416</td>\n","      <td>-0.036105</td>\n","      <td>-0.03963</td>\n","      <td>-0.14633</td>\n","      <td>-0.029767</td>\n","      <td>-0.048105</td>\n","      <td>-0.026579</td>\n","      <td>-0.031928</td>\n","      <td>-0.089619</td>\n","      <td>-0.092685</td>\n","      <td>-0.025006</td>\n","      <td>-0.11784</td>\n","      <td>-0.037832</td>\n","      <td>-0.093192</td>\n","      <td>-0.040284</td>\n","      <td>-0.029177</td>\n","      <td>-0.054403</td>\n","      <td>-0.103594</td>\n","      <td>-0.025579</td>\n","      <td>-0.0322</td>\n","      <td>-0.040067</td>\n","      <td>-0.0322</td>\n","      <td>-0.051037</td>\n","      <td>-0.141534</td>\n","      <td>-0.066985</td>\n","      <td>-0.022183</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.288786</td>\n","      <td>-0.198447</td>\n","      <td>-0.326129</td>\n","      <td>1.762865</td>\n","      <td>0.762853</td>\n","      <td>0.903184</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>3.482626</td>\n","      <td>0.261912</td>\n","      <td>1.168003</td>\n","      <td>0.223308</td>\n","      <td>-0.450812</td>\n","      <td>0.610507</td>\n","      <td>-0.094083</td>\n","      <td>-0.587589</td>\n","      <td>-0.400451</td>\n","      <td>-0.287578</td>\n","      <td>0.675031</td>\n","      <td>-0.08672</td>\n","      <td>0.924216</td>\n","      <td>1.055574</td>\n","      <td>0.147337</td>\n","      <td>0.078146</td>\n","      <td>-0.654237</td>\n","      <td>-0.432702</td>\n","      <td>-0.33426</td>\n","      <td>-0.159431</td>\n","      <td>-1.120286</td>\n","      <td>0.67101</td>\n","      <td>-0.673015</td>\n","      <td>-0.566044</td>\n","      <td>-0.594752</td>\n","      <td>-0.607508</td>\n","      <td>1.848147</td>\n","      <td>-0.033</td>\n","      <td>-0.145087</td>\n","      <td>-0.04121</td>\n","      <td>-0.199623</td>\n","      <td>-0.036584</td>\n","      <td>-0.052331</td>\n","      <td>-0.070387</td>\n","      <td>-0.097759</td>\n","      <td>-0.057777</td>\n","      <td>-0.052387</td>\n","      <td>-0.094291</td>\n","      <td>-0.048765</td>\n","      <td>-0.053432</td>\n","      <td>-0.048346</td>\n","      <td>-0.084526</td>\n","      <td>-0.063451</td>\n","      <td>-0.059955</td>\n","      <td>-0.040139</td>\n","      <td>-0.009622</td>\n","      <td>-0.064318</td>\n","      <td>-0.085869</td>\n","      <td>-0.051829</td>\n","      <td>-0.072474</td>\n","      <td>-0.066504</td>\n","      <td>-0.041839</td>\n","      <td>-0.324079</td>\n","      <td>0.561241</td>\n","      <td>-0.033436</td>\n","      <td>-0.054723</td>\n","      <td>-0.069468</td>\n","      <td>-0.101491</td>\n","      <td>-0.038213</td>\n","      <td>-0.092748</td>\n","      <td>-0.155436</td>\n","      <td>-0.097396</td>\n","      <td>-0.077544</td>\n","      <td>-0.09176</td>\n","      <td>-0.072312</td>\n","      <td>-0.011024</td>\n","      <td>-0.031379</td>\n","      <td>-0.025692</td>\n","      <td>-0.036663</td>\n","      <td>-0.096636</td>\n","      <td>-0.021654</td>\n","      <td>-0.075865</td>\n","      <td>-0.109888</td>\n","      <td>-0.044136</td>\n","      <td>-0.038741</td>\n","      <td>-0.022442</td>\n","      <td>-0.059613</td>\n","      <td>-0.019693</td>\n","      <td>-0.020697</td>\n","      <td>-0.022052</td>\n","      <td>-0.111494</td>\n","      <td>-0.017181</td>\n","      <td>-0.027542</td>\n","      <td>-0.012955</td>\n","      <td>-0.026796</td>\n","      <td>-0.004811</td>\n","      <td>-0.015215</td>\n","      <td>-0.060052</td>\n","      <td>-0.08109</td>\n","      <td>-0.055933</td>\n","      <td>-0.014027</td>\n","      <td>-0.025006</td>\n","      <td>-0.021385</td>\n","      <td>-0.045878</td>\n","      <td>-0.030725</td>\n","      <td>-0.072996</td>\n","      <td>-0.034038</td>\n","      <td>-0.092335</td>\n","      <td>-0.223068</td>\n","      <td>-0.012266</td>\n","      <td>-0.015591</td>\n","      <td>-0.104757</td>\n","      <td>-0.150343</td>\n","      <td>-0.038666</td>\n","      <td>-0.028676</td>\n","      <td>-0.053377</td>\n","      <td>-0.064273</td>\n","      <td>-0.144796</td>\n","      <td>-0.020415</td>\n","      <td>-0.054989</td>\n","      <td>-0.045752</td>\n","      <td>-0.082381</td>\n","      <td>-0.07941</td>\n","      <td>-0.196261</td>\n","      <td>-0.079263</td>\n","      <td>-0.039557</td>\n","      <td>-0.032647</td>\n","      <td>-0.03025</td>\n","      <td>-0.028978</td>\n","      <td>-0.061205</td>\n","      <td>-0.028166</td>\n","      <td>-0.044201</td>\n","      <td>-0.113237</td>\n","      <td>-0.162721</td>\n","      <td>-0.024656</td>\n","      <td>-0.043805</td>\n","      <td>-0.178024</td>\n","      <td>-0.053649</td>\n","      <td>-0.048645</td>\n","      <td>-0.12157</td>\n","      <td>-0.018944</td>\n","      <td>-0.028978</td>\n","      <td>-0.038891</td>\n","      <td>-0.090241</td>\n","      <td>-0.042459</td>\n","      <td>-0.036663</td>\n","      <td>-0.060439</td>\n","      <td>-0.076173</td>\n","      <td>-0.166301</td>\n","      <td>-0.097909</td>\n","      <td>-0.072916</td>\n","      <td>-0.039336</td>\n","      <td>-0.047128</td>\n","      <td>-0.031655</td>\n","      <td>-0.055568</td>\n","      <td>-0.089324</td>\n","      <td>-0.078221</td>\n","      <td>-0.088331</td>\n","      <td>-0.029078</td>\n","      <td>5.783990</td>\n","      <td>-0.151786</td>\n","      <td>-0.035539</td>\n","      <td>-0.068622</td>\n","      <td>-0.022442</td>\n","      <td>-0.045624</td>\n","      <td>-0.034038</td>\n","      <td>-0.058578</td>\n","      <td>-0.028371</td>\n","      <td>-0.009001</td>\n","      <td>-0.084317</td>\n","      <td>-0.0125</td>\n","      <td>-0.114203</td>\n","      <td>-0.07728</td>\n","      <td>-0.057727</td>\n","      <td>-0.106438</td>\n","      <td>-0.124334</td>\n","      <td>-0.073833</td>\n","      <td>-0.030058</td>\n","      <td>-0.020273</td>\n","      <td>-0.047128</td>\n","      <td>-0.215988</td>\n","      <td>-0.095994</td>\n","      <td>-0.03082</td>\n","      <td>-0.03941</td>\n","      <td>-0.138353</td>\n","      <td>-0.076938</td>\n","      <td>-0.026579</td>\n","      <td>-0.043406</td>\n","      <td>-0.040067</td>\n","      <td>-0.122254</td>\n","      <td>-0.055881</td>\n","      <td>-0.065887</td>\n","      <td>-0.043473</td>\n","      <td>-0.053812</td>\n","      <td>-0.035293</td>\n","      <td>-0.08456</td>\n","      <td>-0.0322</td>\n","      <td>-0.139306</td>\n","      <td>-0.02152</td>\n","      <td>-0.156196</td>\n","      <td>-0.012955</td>\n","      <td>-0.029572</td>\n","      <td>-0.016317</td>\n","      <td>-0.120561</td>\n","      <td>-0.147604</td>\n","      <td>-0.054936</td>\n","      <td>-0.064364</td>\n","      <td>-0.053541</td>\n","      <td>-0.02152</td>\n","      <td>-0.049416</td>\n","      <td>-0.036105</td>\n","      <td>-0.03963</td>\n","      <td>-0.14633</td>\n","      <td>-0.029767</td>\n","      <td>-0.048105</td>\n","      <td>-0.026579</td>\n","      <td>-0.031928</td>\n","      <td>-0.089619</td>\n","      <td>-0.092685</td>\n","      <td>-0.025006</td>\n","      <td>-0.11784</td>\n","      <td>-0.037832</td>\n","      <td>-0.093192</td>\n","      <td>-0.040284</td>\n","      <td>-0.029177</td>\n","      <td>-0.054403</td>\n","      <td>-0.103594</td>\n","      <td>-0.025579</td>\n","      <td>-0.0322</td>\n","      <td>-0.040067</td>\n","      <td>-0.0322</td>\n","      <td>-0.051037</td>\n","      <td>-0.141534</td>\n","      <td>-0.066985</td>\n","      <td>-0.022183</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0         1         2         3         4         5        6    \\\n","0 -0.298547 -0.198447 -0.941790 -0.301747 -0.542916 -0.264041 -0.08432   \n","1 -0.307414 -0.198447 -2.019196 -0.326723 -0.542916 -0.264041 -0.08432   \n","2 -0.288786 -0.198447 -0.326129  1.762865  0.762853  0.903184 -0.08432   \n","\n","       7         8         9         10        11        12        13   \\\n","0 -0.01557 -1.130397 -0.746823 -0.215401 -0.224846 -0.265058 -0.639590   \n","1 -0.01557 -0.369989  0.009728 -0.028455 -0.224846 -0.636566 -0.636051   \n","2 -0.01557  3.482626  0.261912  1.168003  0.223308 -0.450812  0.610507   \n","\n","        14        15        16        17        18       19        20   \\\n","0 -0.094083 -0.563342  0.613136 -0.287578  0.675031 -0.08672 -1.081998   \n","1 -0.067116 -0.563342 -0.513072 -0.287578  0.675031 -0.08672 -1.081998   \n","2 -0.094083 -0.587589 -0.400451 -0.287578  0.675031 -0.08672  0.924216   \n","\n","        21        22        23        24        25       26        27   \\\n","0 -0.947352  0.147337  0.078146 -0.654237 -0.432702 -0.33426 -0.159431   \n","1  1.055574  0.147337  0.078146 -0.654237 -0.432702 -0.33426  6.272299   \n","2  1.055574  0.147337  0.078146 -0.654237 -0.432702 -0.33426 -0.159431   \n","\n","        28       29        30        31        32        33        34     35   \\\n","0 -1.120286 -1.49029 -0.673015  1.766646 -0.594752 -0.607508 -0.541083 -0.033   \n","1 -1.120286  0.67101  1.485850  1.766646 -0.594752 -0.607508 -0.541083 -0.033   \n","2 -1.120286  0.67101 -0.673015 -0.566044 -0.594752 -0.607508  1.848147 -0.033   \n","\n","        36       37        38        39        40        41        42   \\\n","0 -0.145087 -0.04121 -0.199623 -0.036584 -0.052331 -0.070387 -0.097759   \n","1 -0.145087 -0.04121 -0.199623 -0.036584 -0.052331 -0.070387 -0.097759   \n","2 -0.145087 -0.04121 -0.199623 -0.036584 -0.052331 -0.070387 -0.097759   \n","\n","        43        44        45        46        47        48        49   \\\n","0 -0.057777 -0.052387 -0.094291 -0.048765 -0.053432 -0.048346 -0.084526   \n","1 -0.057777 -0.052387 -0.094291 -0.048765 -0.053432 -0.048346 -0.084526   \n","2 -0.057777 -0.052387 -0.094291 -0.048765 -0.053432 -0.048346 -0.084526   \n","\n","        50        51        52        53        54        55        56   \\\n","0 -0.063451 -0.059955 -0.040139 -0.009622 -0.064318 -0.085869 -0.051829   \n","1 -0.063451 -0.059955 -0.040139 -0.009622 -0.064318 -0.085869 -0.051829   \n","2 -0.063451 -0.059955 -0.040139 -0.009622 -0.064318 -0.085869 -0.051829   \n","\n","        57        58        59        60        61        62        63   \\\n","0 -0.072474 -0.066504 -0.041839 -0.324079  0.561241 -0.033436 -0.054723   \n","1 -0.072474 -0.066504 -0.041839 -0.324079  0.561241 -0.033436 -0.054723   \n","2 -0.072474 -0.066504 -0.041839 -0.324079  0.561241 -0.033436 -0.054723   \n","\n","        64        65        66        67        68        69        70   \\\n","0 -0.069468 -0.101491 -0.038213 -0.092748 -0.155436 -0.097396 -0.077544   \n","1 -0.069468 -0.101491 -0.038213 -0.092748 -0.155436 -0.097396 -0.077544   \n","2 -0.069468 -0.101491 -0.038213 -0.092748 -0.155436 -0.097396 -0.077544   \n","\n","       71        72        73        74        75        76        77   \\\n","0 -0.09176 -0.072312 -0.011024 -0.031379 -0.025692 -0.036663 -0.096636   \n","1 -0.09176 -0.072312 -0.011024 -0.031379 -0.025692 -0.036663 -0.096636   \n","2 -0.09176 -0.072312 -0.011024 -0.031379 -0.025692 -0.036663 -0.096636   \n","\n","        78        79        80        81        82        83        84   \\\n","0 -0.021654 -0.075865 -0.109888 -0.044136 -0.038741 -0.022442 -0.059613   \n","1 -0.021654 -0.075865 -0.109888 -0.044136 -0.038741 -0.022442 -0.059613   \n","2 -0.021654 -0.075865 -0.109888 -0.044136 -0.038741 -0.022442 -0.059613   \n","\n","        85        86        87        88        89        90        91   \\\n","0 -0.019693 -0.020697 -0.022052 -0.111494 -0.017181 -0.027542 -0.012955   \n","1 -0.019693 -0.020697 -0.022052 -0.111494 -0.017181 -0.027542 -0.012955   \n","2 -0.019693 -0.020697 -0.022052 -0.111494 -0.017181 -0.027542 -0.012955   \n","\n","        92        93        94        95       96        97        98   \\\n","0 -0.026796 -0.004811 -0.015215 -0.060052 -0.08109 -0.055933 -0.014027   \n","1 -0.026796 -0.004811 -0.015215 -0.060052 -0.08109 -0.055933 -0.014027   \n","2 -0.026796 -0.004811 -0.015215 -0.060052 -0.08109 -0.055933 -0.014027   \n","\n","        99        100       101       102       103       104       105  \\\n","0 -0.025006 -0.021385 -0.045878 -0.030725 -0.072996 -0.034038 -0.092335   \n","1 -0.025006 -0.021385 -0.045878 -0.030725 -0.072996 -0.034038 -0.092335   \n","2 -0.025006 -0.021385 -0.045878 -0.030725 -0.072996 -0.034038 -0.092335   \n","\n","        106       107       108       109       110       111       112  \\\n","0 -0.223068 -0.012266 -0.015591 -0.104757 -0.150343 -0.038666 -0.028676   \n","1 -0.223068 -0.012266 -0.015591 -0.104757 -0.150343 -0.038666 -0.028676   \n","2 -0.223068 -0.012266 -0.015591 -0.104757 -0.150343 -0.038666 -0.028676   \n","\n","        113       114       115       116       117       118       119  \\\n","0 -0.053377 -0.064273 -0.144796 -0.020415 -0.054989 -0.045752 -0.082381   \n","1 -0.053377 -0.064273 -0.144796 -0.020415 -0.054989 -0.045752 -0.082381   \n","2 -0.053377 -0.064273 -0.144796 -0.020415 -0.054989 -0.045752 -0.082381   \n","\n","       120       121       122       123       124      125       126  \\\n","0 -0.07941 -0.196261 -0.079263 -0.039557 -0.032647 -0.03025 -0.028978   \n","1 -0.07941 -0.196261 -0.079263 -0.039557 -0.032647 -0.03025 -0.028978   \n","2 -0.07941 -0.196261 -0.079263 -0.039557 -0.032647 -0.03025 -0.028978   \n","\n","        127       128       129       130       131       132       133  \\\n","0 -0.061205 -0.028166 -0.044201 -0.113237 -0.162721 -0.024656 -0.043805   \n","1 -0.061205 -0.028166 -0.044201 -0.113237 -0.162721 -0.024656 -0.043805   \n","2 -0.061205 -0.028166 -0.044201 -0.113237 -0.162721 -0.024656 -0.043805   \n","\n","        134       135       136      137       138       139       140  \\\n","0  5.617208 -0.053649 -0.048645 -0.12157 -0.018944 -0.028978 -0.038891   \n","1  5.617208 -0.053649 -0.048645 -0.12157 -0.018944 -0.028978 -0.038891   \n","2 -0.178024 -0.053649 -0.048645 -0.12157 -0.018944 -0.028978 -0.038891   \n","\n","        141       142       143       144       145       146       147  \\\n","0 -0.090241 -0.042459 -0.036663 -0.060439 -0.076173 -0.166301 -0.097909   \n","1 -0.090241 -0.042459 -0.036663 -0.060439 -0.076173 -0.166301 -0.097909   \n","2 -0.090241 -0.042459 -0.036663 -0.060439 -0.076173 -0.166301 -0.097909   \n","\n","        148       149       150       151       152       153       154  \\\n","0 -0.072916 -0.039336 -0.047128 -0.031655 -0.055568 -0.089324 -0.078221   \n","1 -0.072916 -0.039336 -0.047128 -0.031655 -0.055568 -0.089324 -0.078221   \n","2 -0.072916 -0.039336 -0.047128 -0.031655 -0.055568 -0.089324 -0.078221   \n","\n","        155       156       157       158       159       160       161  \\\n","0 -0.088331 -0.029078 -0.172891 -0.151786 -0.035539 -0.068622 -0.022442   \n","1 -0.088331 -0.029078 -0.172891 -0.151786 -0.035539 -0.068622 -0.022442   \n","2 -0.088331 -0.029078  5.783990 -0.151786 -0.035539 -0.068622 -0.022442   \n","\n","        162       163       164       165       166       167     168  \\\n","0 -0.045624 -0.034038 -0.058578 -0.028371 -0.009001 -0.084317 -0.0125   \n","1 -0.045624 -0.034038 -0.058578 -0.028371 -0.009001 -0.084317 -0.0125   \n","2 -0.045624 -0.034038 -0.058578 -0.028371 -0.009001 -0.084317 -0.0125   \n","\n","        169      170       171       172       173       174       175  \\\n","0 -0.114203 -0.07728 -0.057727 -0.106438 -0.124334 -0.073833 -0.030058   \n","1 -0.114203 -0.07728 -0.057727 -0.106438 -0.124334 -0.073833 -0.030058   \n","2 -0.114203 -0.07728 -0.057727 -0.106438 -0.124334 -0.073833 -0.030058   \n","\n","        176       177       178       179      180      181       182  \\\n","0 -0.020273 -0.047128 -0.215988 -0.095994 -0.03082 -0.03941 -0.138353   \n","1 -0.020273 -0.047128 -0.215988 -0.095994 -0.03082 -0.03941 -0.138353   \n","2 -0.020273 -0.047128 -0.215988 -0.095994 -0.03082 -0.03941 -0.138353   \n","\n","        183       184       185       186       187       188       189  \\\n","0 -0.076938 -0.026579 -0.043406 -0.040067 -0.122254 -0.055881 -0.065887   \n","1 -0.076938 -0.026579 -0.043406 -0.040067 -0.122254 -0.055881 -0.065887   \n","2 -0.076938 -0.026579 -0.043406 -0.040067 -0.122254 -0.055881 -0.065887   \n","\n","        190       191       192      193     194       195      196       197  \\\n","0 -0.043473 -0.053812 -0.035293 -0.08456 -0.0322 -0.139306 -0.02152 -0.156196   \n","1 -0.043473 -0.053812 -0.035293 -0.08456 -0.0322 -0.139306 -0.02152 -0.156196   \n","2 -0.043473 -0.053812 -0.035293 -0.08456 -0.0322 -0.139306 -0.02152 -0.156196   \n","\n","        198       199       200       201       202       203       204  \\\n","0 -0.012955 -0.029572 -0.016317 -0.120561 -0.147604 -0.054936 -0.064364   \n","1 -0.012955 -0.029572 -0.016317 -0.120561 -0.147604 -0.054936 -0.064364   \n","2 -0.012955 -0.029572 -0.016317 -0.120561 -0.147604 -0.054936 -0.064364   \n","\n","        205      206       207       208      209      210       211  \\\n","0 -0.053541 -0.02152 -0.049416 -0.036105 -0.03963 -0.14633 -0.029767   \n","1 -0.053541 -0.02152 -0.049416 -0.036105 -0.03963 -0.14633 -0.029767   \n","2 -0.053541 -0.02152 -0.049416 -0.036105 -0.03963 -0.14633 -0.029767   \n","\n","        212       213       214       215       216       217      218  \\\n","0 -0.048105 -0.026579 -0.031928 -0.089619 -0.092685 -0.025006 -0.11784   \n","1 -0.048105 -0.026579 -0.031928 -0.089619 -0.092685 -0.025006 -0.11784   \n","2 -0.048105 -0.026579 -0.031928 -0.089619 -0.092685 -0.025006 -0.11784   \n","\n","        219       220       221       222       223       224       225  \\\n","0 -0.037832 -0.093192 -0.040284 -0.029177 -0.054403 -0.103594 -0.025579   \n","1 -0.037832 -0.093192 -0.040284 -0.029177 -0.054403 -0.103594 -0.025579   \n","2 -0.037832 -0.093192 -0.040284 -0.029177 -0.054403 -0.103594 -0.025579   \n","\n","      226       227     228       229       230       231       232  \n","0 -0.0322 -0.040067 -0.0322 -0.051037 -0.141534 -0.066985 -0.022183  \n","1 -0.0322 -0.040067 -0.0322 -0.051037 -0.141534 -0.066985 -0.022183  \n","2 -0.0322 -0.040067 -0.0322 -0.051037 -0.141534 -0.066985 -0.022183  "]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"Yl-iF9u9LeH1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611307227075,"user_tz":-60,"elapsed":86099,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"606042d7-8951-4a5c-e43d-49ccf6a9c776"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain_transformed, y_subtrain, validation_data=(X_val_transformed, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain_transformed, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val_transformed, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5268 - binary_accuracy: 0.7303 - val_loss: 0.4801 - val_binary_accuracy: 0.7644\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4740 - binary_accuracy: 0.7677 - val_loss: 0.4710 - val_binary_accuracy: 0.7674\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4677 - binary_accuracy: 0.7717 - val_loss: 0.4662 - val_binary_accuracy: 0.7702\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4636 - binary_accuracy: 0.7751 - val_loss: 0.4614 - val_binary_accuracy: 0.7727\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4606 - binary_accuracy: 0.7756 - val_loss: 0.4593 - val_binary_accuracy: 0.7739\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4558 - binary_accuracy: 0.7776 - val_loss: 0.4566 - val_binary_accuracy: 0.7767\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4530 - binary_accuracy: 0.7799 - val_loss: 0.4540 - val_binary_accuracy: 0.7770\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4529 - binary_accuracy: 0.7798 - val_loss: 0.4520 - val_binary_accuracy: 0.7791\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4476 - binary_accuracy: 0.7831 - val_loss: 0.4508 - val_binary_accuracy: 0.7797\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4442 - binary_accuracy: 0.7873 - val_loss: 0.4479 - val_binary_accuracy: 0.7805\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4418 - binary_accuracy: 0.7871 - val_loss: 0.4486 - val_binary_accuracy: 0.7812\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4392 - binary_accuracy: 0.7878 - val_loss: 0.4469 - val_binary_accuracy: 0.7813\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4376 - binary_accuracy: 0.7899 - val_loss: 0.4461 - val_binary_accuracy: 0.7817\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4348 - binary_accuracy: 0.7899 - val_loss: 0.4450 - val_binary_accuracy: 0.7825\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4337 - binary_accuracy: 0.7915 - val_loss: 0.4448 - val_binary_accuracy: 0.7854\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4316 - binary_accuracy: 0.7932 - val_loss: 0.4422 - val_binary_accuracy: 0.7870\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4250 - binary_accuracy: 0.7974 - val_loss: 0.4426 - val_binary_accuracy: 0.7867\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4282 - binary_accuracy: 0.7940 - val_loss: 0.4402 - val_binary_accuracy: 0.7880\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4236 - binary_accuracy: 0.7979 - val_loss: 0.4405 - val_binary_accuracy: 0.7872\n","Epoch 20/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4190 - binary_accuracy: 0.7993 - val_loss: 0.4422 - val_binary_accuracy: 0.7863\n","Epoch 21/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4195 - binary_accuracy: 0.7995 - val_loss: 0.4385 - val_binary_accuracy: 0.7882\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4166 - binary_accuracy: 0.8024 - val_loss: 0.4426 - val_binary_accuracy: 0.7861\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4137 - binary_accuracy: 0.8031 - val_loss: 0.4384 - val_binary_accuracy: 0.7886\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4129 - binary_accuracy: 0.8029 - val_loss: 0.4393 - val_binary_accuracy: 0.7879\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4092 - binary_accuracy: 0.8066 - val_loss: 0.4422 - val_binary_accuracy: 0.7865\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4107 - binary_accuracy: 0.8054 - val_loss: 0.4384 - val_binary_accuracy: 0.7889\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4056 - binary_accuracy: 0.8082 - val_loss: 0.4378 - val_binary_accuracy: 0.7885\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4058 - binary_accuracy: 0.8072 - val_loss: 0.4394 - val_binary_accuracy: 0.7881\n","Epoch 29/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4030 - binary_accuracy: 0.8087 - val_loss: 0.4385 - val_binary_accuracy: 0.7888\n","Epoch 30/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4010 - binary_accuracy: 0.8091 - val_loss: 0.4379 - val_binary_accuracy: 0.7890\n","Epoch 31/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4008 - binary_accuracy: 0.8101 - val_loss: 0.4378 - val_binary_accuracy: 0.7895\n","Epoch 32/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3961 - binary_accuracy: 0.8133 - val_loss: 0.4394 - val_binary_accuracy: 0.7877\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3937 - binary_accuracy: 0.8152 - val_loss: 0.4378 - val_binary_accuracy: 0.7901\n","Epoch 34/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3938 - binary_accuracy: 0.8139 - val_loss: 0.4383 - val_binary_accuracy: 0.7884\n","Epoch 35/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3918 - binary_accuracy: 0.8157 - val_loss: 0.4415 - val_binary_accuracy: 0.7868\n","Epoch 36/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3896 - binary_accuracy: 0.8172 - val_loss: 0.4404 - val_binary_accuracy: 0.7886\n","Epoch 37/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3906 - binary_accuracy: 0.8155 - val_loss: 0.4407 - val_binary_accuracy: 0.7878\n","Epoch 38/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3885 - binary_accuracy: 0.8170 - val_loss: 0.4432 - val_binary_accuracy: 0.7855\n","Training Accuracy: 0.816\n","Validation Accuracy: 0.790\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ToMIjd2_QuUK"},"source":["##### 2. Standardization: Only Numerical Attributes"]},{"cell_type":"code","metadata":{"id":"EuT5OuapQ10U"},"source":["# Specify pre-processing pipeline for the different types of attributes\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", StandardScaler(), numeric_features)\n","    ],\n","    remainder=\"passthrough\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain_transformed = preprocessing.transform(X_subtrain)\n","X_val_transformed = preprocessing.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"Y9Sc9vnVQ10V","executionInfo":{"status":"ok","timestamp":1611307262304,"user_tz":-60,"elapsed":502,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"28a95088-c8d7-49aa-d78f-dc6f6ed509ac"},"source":["# Validation\n","tmp = pd.DataFrame(X_subtrain_transformed)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(172824, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","      <th>176</th>\n","      <th>177</th>\n","      <th>178</th>\n","      <th>179</th>\n","      <th>180</th>\n","      <th>181</th>\n","      <th>182</th>\n","      <th>183</th>\n","      <th>184</th>\n","      <th>185</th>\n","      <th>186</th>\n","      <th>187</th>\n","      <th>188</th>\n","      <th>189</th>\n","      <th>190</th>\n","      <th>191</th>\n","      <th>192</th>\n","      <th>193</th>\n","      <th>194</th>\n","      <th>195</th>\n","      <th>196</th>\n","      <th>197</th>\n","      <th>198</th>\n","      <th>199</th>\n","      <th>200</th>\n","      <th>201</th>\n","      <th>202</th>\n","      <th>203</th>\n","      <th>204</th>\n","      <th>205</th>\n","      <th>206</th>\n","      <th>207</th>\n","      <th>208</th>\n","      <th>209</th>\n","      <th>210</th>\n","      <th>211</th>\n","      <th>212</th>\n","      <th>213</th>\n","      <th>214</th>\n","      <th>215</th>\n","      <th>216</th>\n","      <th>217</th>\n","      <th>218</th>\n","      <th>219</th>\n","      <th>220</th>\n","      <th>221</th>\n","      <th>222</th>\n","      <th>223</th>\n","      <th>224</th>\n","      <th>225</th>\n","      <th>226</th>\n","      <th>227</th>\n","      <th>228</th>\n","      <th>229</th>\n","      <th>230</th>\n","      <th>231</th>\n","      <th>232</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.298547</td>\n","      <td>-0.198447</td>\n","      <td>-0.941790</td>\n","      <td>-0.301747</td>\n","      <td>-0.542916</td>\n","      <td>-0.264041</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>-1.130397</td>\n","      <td>-0.746823</td>\n","      <td>-0.215401</td>\n","      <td>-0.224846</td>\n","      <td>-0.265058</td>\n","      <td>-0.639590</td>\n","      <td>-0.094083</td>\n","      <td>-0.563342</td>\n","      <td>0.613136</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.307414</td>\n","      <td>-0.198447</td>\n","      <td>-2.019196</td>\n","      <td>-0.326723</td>\n","      <td>-0.542916</td>\n","      <td>-0.264041</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>-0.369989</td>\n","      <td>0.009728</td>\n","      <td>-0.028455</td>\n","      <td>-0.224846</td>\n","      <td>-0.636566</td>\n","      <td>-0.636051</td>\n","      <td>-0.067116</td>\n","      <td>-0.563342</td>\n","      <td>-0.513072</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.288786</td>\n","      <td>-0.198447</td>\n","      <td>-0.326129</td>\n","      <td>1.762865</td>\n","      <td>0.762853</td>\n","      <td>0.903184</td>\n","      <td>-0.08432</td>\n","      <td>-0.01557</td>\n","      <td>3.482626</td>\n","      <td>0.261912</td>\n","      <td>1.168003</td>\n","      <td>0.223308</td>\n","      <td>-0.450812</td>\n","      <td>0.610507</td>\n","      <td>-0.094083</td>\n","      <td>-0.587589</td>\n","      <td>-0.400451</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0         1         2         3         4         5        6    \\\n","0 -0.298547 -0.198447 -0.941790 -0.301747 -0.542916 -0.264041 -0.08432   \n","1 -0.307414 -0.198447 -2.019196 -0.326723 -0.542916 -0.264041 -0.08432   \n","2 -0.288786 -0.198447 -0.326129  1.762865  0.762853  0.903184 -0.08432   \n","\n","       7         8         9         10        11        12        13   \\\n","0 -0.01557 -1.130397 -0.746823 -0.215401 -0.224846 -0.265058 -0.639590   \n","1 -0.01557 -0.369989  0.009728 -0.028455 -0.224846 -0.636566 -0.636051   \n","2 -0.01557  3.482626  0.261912  1.168003  0.223308 -0.450812  0.610507   \n","\n","        14        15        16   17   18   19   20   21   22   23   24   25   \\\n","0 -0.094083 -0.563342  0.613136  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n","1 -0.067116 -0.563342 -0.513072  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n","2 -0.094083 -0.587589 -0.400451  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0   \n","\n","   26   27   28   29   30   31   32   33   34   35   36   37   38   39   40   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   71   72   73   74   75   76   77   78   79   80   81   82   83   84   85   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   86   87   88   89   90   91   92   93   94   95   96   97   98   99   100  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   116  117  118  119  120  121  122  123  124  125  126  127  128  129  130  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   131  132  133  134  135  136  137  138  139  140  141  142  143  144  145  \\\n","0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   146  147  148  149  150  151  152  153  154  155  156  157  158  159  160  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n","\n","   161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   176  177  178  179  180  181  182  183  184  185  186  187  188  189  190  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   191  192  193  194  195  196  197  198  199  200  201  202  203  204  205  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   206  207  208  209  210  211  212  213  214  215  216  217  218  219  220  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   221  222  223  224  225  226  227  228  229  230  231  232  \n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84WnQJAnQ10X","executionInfo":{"status":"ok","timestamp":1611307393960,"user_tz":-60,"elapsed":112512,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"a076d537-fbb4-46bf-a0bd-ef6b12423f29"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain_transformed, y_subtrain, validation_data=(X_val_transformed, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain_transformed, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val_transformed, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5443 - binary_accuracy: 0.7134 - val_loss: 0.4730 - val_binary_accuracy: 0.7684\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4690 - binary_accuracy: 0.7701 - val_loss: 0.4665 - val_binary_accuracy: 0.7679\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4635 - binary_accuracy: 0.7737 - val_loss: 0.4606 - val_binary_accuracy: 0.7737\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4608 - binary_accuracy: 0.7761 - val_loss: 0.4571 - val_binary_accuracy: 0.7756\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4586 - binary_accuracy: 0.7762 - val_loss: 0.4559 - val_binary_accuracy: 0.7754\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4546 - binary_accuracy: 0.7783 - val_loss: 0.4530 - val_binary_accuracy: 0.7776\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4522 - binary_accuracy: 0.7782 - val_loss: 0.4497 - val_binary_accuracy: 0.7782\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4526 - binary_accuracy: 0.7792 - val_loss: 0.4480 - val_binary_accuracy: 0.7808\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4475 - binary_accuracy: 0.7826 - val_loss: 0.4467 - val_binary_accuracy: 0.7812\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4449 - binary_accuracy: 0.7861 - val_loss: 0.4448 - val_binary_accuracy: 0.7826\n","Epoch 11/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4434 - binary_accuracy: 0.7852 - val_loss: 0.4454 - val_binary_accuracy: 0.7804\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4413 - binary_accuracy: 0.7857 - val_loss: 0.4442 - val_binary_accuracy: 0.7821\n","Epoch 13/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4399 - binary_accuracy: 0.7869 - val_loss: 0.4416 - val_binary_accuracy: 0.7838\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4385 - binary_accuracy: 0.7861 - val_loss: 0.4397 - val_binary_accuracy: 0.7837\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4381 - binary_accuracy: 0.7877 - val_loss: 0.4412 - val_binary_accuracy: 0.7847\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4372 - binary_accuracy: 0.7880 - val_loss: 0.4384 - val_binary_accuracy: 0.7867\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4316 - binary_accuracy: 0.7914 - val_loss: 0.4393 - val_binary_accuracy: 0.7843\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4359 - binary_accuracy: 0.7876 - val_loss: 0.4357 - val_binary_accuracy: 0.7874\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4326 - binary_accuracy: 0.7912 - val_loss: 0.4348 - val_binary_accuracy: 0.7881\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4295 - binary_accuracy: 0.7918 - val_loss: 0.4385 - val_binary_accuracy: 0.7849\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4306 - binary_accuracy: 0.7920 - val_loss: 0.4336 - val_binary_accuracy: 0.7887\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4285 - binary_accuracy: 0.7935 - val_loss: 0.4394 - val_binary_accuracy: 0.7842\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4272 - binary_accuracy: 0.7934 - val_loss: 0.4321 - val_binary_accuracy: 0.7905\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4274 - binary_accuracy: 0.7915 - val_loss: 0.4320 - val_binary_accuracy: 0.7898\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4244 - binary_accuracy: 0.7956 - val_loss: 0.4367 - val_binary_accuracy: 0.7867\n","Epoch 26/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4262 - binary_accuracy: 0.7958 - val_loss: 0.4305 - val_binary_accuracy: 0.7917\n","Epoch 27/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4235 - binary_accuracy: 0.7961 - val_loss: 0.4292 - val_binary_accuracy: 0.7923\n","Epoch 28/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4246 - binary_accuracy: 0.7950 - val_loss: 0.4287 - val_binary_accuracy: 0.7904\n","Epoch 29/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4226 - binary_accuracy: 0.7953 - val_loss: 0.4292 - val_binary_accuracy: 0.7912\n","Epoch 30/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4226 - binary_accuracy: 0.7962 - val_loss: 0.4274 - val_binary_accuracy: 0.7922\n","Epoch 31/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4228 - binary_accuracy: 0.7954 - val_loss: 0.4274 - val_binary_accuracy: 0.7925\n","Epoch 32/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4194 - binary_accuracy: 0.7972 - val_loss: 0.4265 - val_binary_accuracy: 0.7929\n","Epoch 33/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4185 - binary_accuracy: 0.7993 - val_loss: 0.4256 - val_binary_accuracy: 0.7934\n","Epoch 34/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4199 - binary_accuracy: 0.7985 - val_loss: 0.4252 - val_binary_accuracy: 0.7934\n","Epoch 35/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4184 - binary_accuracy: 0.7972 - val_loss: 0.4271 - val_binary_accuracy: 0.7933\n","Epoch 36/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4179 - binary_accuracy: 0.7985 - val_loss: 0.4245 - val_binary_accuracy: 0.7940\n","Epoch 37/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4188 - binary_accuracy: 0.7985 - val_loss: 0.4256 - val_binary_accuracy: 0.7933\n","Epoch 38/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4188 - binary_accuracy: 0.7978 - val_loss: 0.4256 - val_binary_accuracy: 0.7930\n","Epoch 39/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4159 - binary_accuracy: 0.8001 - val_loss: 0.4237 - val_binary_accuracy: 0.7946\n","Epoch 40/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4133 - binary_accuracy: 0.8025 - val_loss: 0.4233 - val_binary_accuracy: 0.7948\n","Epoch 41/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4155 - binary_accuracy: 0.8010 - val_loss: 0.4230 - val_binary_accuracy: 0.7953\n","Epoch 42/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4142 - binary_accuracy: 0.8015 - val_loss: 0.4236 - val_binary_accuracy: 0.7943\n","Epoch 43/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4141 - binary_accuracy: 0.8013 - val_loss: 0.4238 - val_binary_accuracy: 0.7936\n","Epoch 44/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4124 - binary_accuracy: 0.8025 - val_loss: 0.4225 - val_binary_accuracy: 0.7948\n","Epoch 45/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4109 - binary_accuracy: 0.8032 - val_loss: 0.4220 - val_binary_accuracy: 0.7963\n","Epoch 46/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4124 - binary_accuracy: 0.8023 - val_loss: 0.4233 - val_binary_accuracy: 0.7952\n","Epoch 47/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4098 - binary_accuracy: 0.8036 - val_loss: 0.4216 - val_binary_accuracy: 0.7954\n","Epoch 48/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4101 - binary_accuracy: 0.8035 - val_loss: 0.4229 - val_binary_accuracy: 0.7938\n","Epoch 49/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4105 - binary_accuracy: 0.8036 - val_loss: 0.4209 - val_binary_accuracy: 0.7958\n","Epoch 50/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4124 - binary_accuracy: 0.8010 - val_loss: 0.4216 - val_binary_accuracy: 0.7949\n","Training Accuracy: 0.803\n","Validation Accuracy: 0.796\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iEKyBBZ-RKY8"},"source":["Result:\n","- Standardization helped extremely to increase the performance of the NN\n","- Standardizing only the numerical features and leaving the binary as they are was the best strategy"]},{"cell_type":"markdown","metadata":{"id":"EmzaXt6qRVbs"},"source":["##### 3. Normalization: Numerical + Binary Features"]},{"cell_type":"code","metadata":{"id":"oo3FtCjnRhUd"},"source":["# Specify pre-processing pipeline for the different types of attributes\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", Pipeline([\n","                            (\"normalization\", StandardScaler()),\n","                            (\"standarization\", MinMaxScaler(feature_range=(-1,1)))\n","                          ]), numeric_features),\n","      (\"binary\", MinMaxScaler(feature_range=(-1,1)), binary_features)\n","    ],\n","    remainder=\"drop\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain_transformed = preprocessing.transform(X_subtrain)\n","X_val_transformed = preprocessing.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"K-MQUrS-RhUe","executionInfo":{"status":"ok","timestamp":1611307460481,"user_tz":-60,"elapsed":581,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"9399ff8b-7a01-413e-c680-96c30a726ab0"},"source":["# Validation\n","tmp = pd.DataFrame(X_subtrain_transformed)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(172824, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","      <th>176</th>\n","      <th>177</th>\n","      <th>178</th>\n","      <th>179</th>\n","      <th>180</th>\n","      <th>181</th>\n","      <th>182</th>\n","      <th>183</th>\n","      <th>184</th>\n","      <th>185</th>\n","      <th>186</th>\n","      <th>187</th>\n","      <th>188</th>\n","      <th>189</th>\n","      <th>190</th>\n","      <th>191</th>\n","      <th>192</th>\n","      <th>193</th>\n","      <th>194</th>\n","      <th>195</th>\n","      <th>196</th>\n","      <th>197</th>\n","      <th>198</th>\n","      <th>199</th>\n","      <th>200</th>\n","      <th>201</th>\n","      <th>202</th>\n","      <th>203</th>\n","      <th>204</th>\n","      <th>205</th>\n","      <th>206</th>\n","      <th>207</th>\n","      <th>208</th>\n","      <th>209</th>\n","      <th>210</th>\n","      <th>211</th>\n","      <th>212</th>\n","      <th>213</th>\n","      <th>214</th>\n","      <th>215</th>\n","      <th>216</th>\n","      <th>217</th>\n","      <th>218</th>\n","      <th>219</th>\n","      <th>220</th>\n","      <th>221</th>\n","      <th>222</th>\n","      <th>223</th>\n","      <th>224</th>\n","      <th>225</th>\n","      <th>226</th>\n","      <th>227</th>\n","      <th>228</th>\n","      <th>229</th>\n","      <th>230</th>\n","      <th>231</th>\n","      <th>232</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.999650</td>\n","      <td>-1.0</td>\n","      <td>-0.567010</td>\n","      <td>-0.995506</td>\n","      <td>-1.00000</td>\n","      <td>-1.000000</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-0.988894</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>-0.947137</td>\n","      <td>-0.929240</td>\n","      <td>-0.999815</td>\n","      <td>-0.99200</td>\n","      <td>-0.777778</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.999862</td>\n","      <td>-1.0</td>\n","      <td>-0.855670</td>\n","      <td>-0.997432</td>\n","      <td>-1.00000</td>\n","      <td>-1.000000</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-0.918719</td>\n","      <td>-0.960265</td>\n","      <td>-0.994299</td>\n","      <td>-1.000000</td>\n","      <td>-0.964758</td>\n","      <td>-0.928947</td>\n","      <td>-0.998155</td>\n","      <td>-0.99200</td>\n","      <td>-0.916667</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.999416</td>\n","      <td>-1.0</td>\n","      <td>-0.402062</td>\n","      <td>-0.836276</td>\n","      <td>-0.87027</td>\n","      <td>-0.935484</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-0.563174</td>\n","      <td>-0.947020</td>\n","      <td>-0.957811</td>\n","      <td>-0.963636</td>\n","      <td>-0.955947</td>\n","      <td>-0.825965</td>\n","      <td>-0.999815</td>\n","      <td>-0.99712</td>\n","      <td>-0.902778</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0    1         2         3        4         5    6    7         8    \\\n","0 -0.999650 -1.0 -0.567010 -0.995506 -1.00000 -1.000000 -1.0 -1.0 -0.988894   \n","1 -0.999862 -1.0 -0.855670 -0.997432 -1.00000 -1.000000 -1.0 -1.0 -0.918719   \n","2 -0.999416 -1.0 -0.402062 -0.836276 -0.87027 -0.935484 -1.0 -1.0 -0.563174   \n","\n","        9         10        11        12        13        14       15   \\\n","0 -1.000000 -1.000000 -1.000000 -0.947137 -0.929240 -0.999815 -0.99200   \n","1 -0.960265 -0.994299 -1.000000 -0.964758 -0.928947 -0.998155 -0.99200   \n","2 -0.947020 -0.957811 -0.963636 -0.955947 -0.825965 -0.999815 -0.99712   \n","\n","        16   17   18   19   20   21   22   23   24   25   26   27   28   29   \\\n","0 -0.777778 -1.0  1.0 -1.0 -1.0 -1.0  1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -0.916667 -1.0  1.0 -1.0 -1.0  1.0  1.0  1.0 -1.0 -1.0 -1.0  1.0 -1.0  1.0   \n","2 -0.902778 -1.0  1.0 -1.0  1.0  1.0  1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0  1.0   \n","\n","   30   31   32   33   34   35   36   37   38   39   40   41   42   43   44   \\\n","0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1  1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   45   46   47   48   49   50   51   52   53   54   55   56   57   58   59   \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   \\\n","0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   75   76   77   78   79   80   81   82   83   84   85   86   87   88   89   \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   90   91   92   93   94   95   96   97   98   99   100  101  102  103  104  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   105  106  107  108  109  110  111  112  113  114  115  116  117  118  119  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   120  121  122  123  124  125  126  127  128  129  130  131  132  133  134  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   135  136  137  138  139  140  141  142  143  144  145  146  147  148  149  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   150  151  152  153  154  155  156  157  158  159  160  161  162  163  164  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   165  166  167  168  169  170  171  172  173  174  175  176  177  178  179  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   180  181  182  183  184  185  186  187  188  189  190  191  192  193  194  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   195  196  197  198  199  200  201  202  203  204  205  206  207  208  209  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   210  211  212  213  214  215  216  217  218  219  220  221  222  223  224  \\\n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n","\n","   225  226  227  228  229  230  231  232  \n","0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n","1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n","2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  "]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6U8JJm8wRhUe","executionInfo":{"status":"ok","timestamp":1611307527517,"user_tz":-60,"elapsed":55836,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"116d8cfb-3f09-4aeb-c66c-0c72ed358521"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain_transformed, y_subtrain, validation_data=(X_val_transformed, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain_transformed, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val_transformed, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.6392 - binary_accuracy: 0.6553 - val_loss: 0.5821 - val_binary_accuracy: 0.6938\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5878 - binary_accuracy: 0.6947 - val_loss: 0.6031 - val_binary_accuracy: 0.6834\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5757 - binary_accuracy: 0.7017 - val_loss: 0.5656 - val_binary_accuracy: 0.7182\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5694 - binary_accuracy: 0.7071 - val_loss: 0.5763 - val_binary_accuracy: 0.7090\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5643 - binary_accuracy: 0.7126 - val_loss: 0.5449 - val_binary_accuracy: 0.7239\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5590 - binary_accuracy: 0.7137 - val_loss: 0.5406 - val_binary_accuracy: 0.7287\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5545 - binary_accuracy: 0.7181 - val_loss: 0.5809 - val_binary_accuracy: 0.6955\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5540 - binary_accuracy: 0.7177 - val_loss: 0.5427 - val_binary_accuracy: 0.7234\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5464 - binary_accuracy: 0.7231 - val_loss: 0.5348 - val_binary_accuracy: 0.7310\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5445 - binary_accuracy: 0.7260 - val_loss: 0.5634 - val_binary_accuracy: 0.7055\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5435 - binary_accuracy: 0.7249 - val_loss: 0.5674 - val_binary_accuracy: 0.7065\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5398 - binary_accuracy: 0.7276 - val_loss: 0.5299 - val_binary_accuracy: 0.7374\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5398 - binary_accuracy: 0.7279 - val_loss: 0.5279 - val_binary_accuracy: 0.7375\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5386 - binary_accuracy: 0.7277 - val_loss: 0.5536 - val_binary_accuracy: 0.7160\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5382 - binary_accuracy: 0.7303 - val_loss: 0.5461 - val_binary_accuracy: 0.7264\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5356 - binary_accuracy: 0.7303 - val_loss: 0.5245 - val_binary_accuracy: 0.7384\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5302 - binary_accuracy: 0.7351 - val_loss: 0.5234 - val_binary_accuracy: 0.7393\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5325 - binary_accuracy: 0.7332 - val_loss: 0.5590 - val_binary_accuracy: 0.7124\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5322 - binary_accuracy: 0.7328 - val_loss: 0.5314 - val_binary_accuracy: 0.7314\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.5307 - binary_accuracy: 0.7333 - val_loss: 0.5215 - val_binary_accuracy: 0.7400\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5301 - binary_accuracy: 0.7341 - val_loss: 0.5318 - val_binary_accuracy: 0.7327\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5278 - binary_accuracy: 0.7362 - val_loss: 0.5624 - val_binary_accuracy: 0.7081\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5270 - binary_accuracy: 0.7359 - val_loss: 0.5232 - val_binary_accuracy: 0.7376\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5262 - binary_accuracy: 0.7351 - val_loss: 0.5252 - val_binary_accuracy: 0.7376\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5240 - binary_accuracy: 0.7379 - val_loss: 0.5289 - val_binary_accuracy: 0.7363\n","Training Accuracy: 0.742\n","Validation Accuracy: 0.740\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v_P27C2CVsVf"},"source":["Result: Normalization is not helpful"]},{"cell_type":"markdown","metadata":{"id":"qx0cm4AxVzO5"},"source":["##### 4. Power Transformation of Numerical Features"]},{"cell_type":"code","metadata":{"id":"KiIywtmSWC5I"},"source":["# Specify pre-processing pipeline for the different types of attributes\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", PowerTransformer(method=\"yeo-johnson\", standardize=True), numeric_features)\n","    ],\n","    remainder=\"passthrough\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain_transformed = preprocessing.transform(X_subtrain)\n","X_val_transformed = preprocessing.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"BamqpwPAWC5K","executionInfo":{"status":"ok","timestamp":1611308016298,"user_tz":-60,"elapsed":531,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"99b6fc3f-f6b0-46b7-c228-0f3350a7a609"},"source":["# Validation\n","tmp = pd.DataFrame(X_subtrain_transformed)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(172824, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","      <th>176</th>\n","      <th>177</th>\n","      <th>178</th>\n","      <th>179</th>\n","      <th>180</th>\n","      <th>181</th>\n","      <th>182</th>\n","      <th>183</th>\n","      <th>184</th>\n","      <th>185</th>\n","      <th>186</th>\n","      <th>187</th>\n","      <th>188</th>\n","      <th>189</th>\n","      <th>190</th>\n","      <th>191</th>\n","      <th>192</th>\n","      <th>193</th>\n","      <th>194</th>\n","      <th>195</th>\n","      <th>196</th>\n","      <th>197</th>\n","      <th>198</th>\n","      <th>199</th>\n","      <th>200</th>\n","      <th>201</th>\n","      <th>202</th>\n","      <th>203</th>\n","      <th>204</th>\n","      <th>205</th>\n","      <th>206</th>\n","      <th>207</th>\n","      <th>208</th>\n","      <th>209</th>\n","      <th>210</th>\n","      <th>211</th>\n","      <th>212</th>\n","      <th>213</th>\n","      <th>214</th>\n","      <th>215</th>\n","      <th>216</th>\n","      <th>217</th>\n","      <th>218</th>\n","      <th>219</th>\n","      <th>220</th>\n","      <th>221</th>\n","      <th>222</th>\n","      <th>223</th>\n","      <th>224</th>\n","      <th>225</th>\n","      <th>226</th>\n","      <th>227</th>\n","      <th>228</th>\n","      <th>229</th>\n","      <th>230</th>\n","      <th>231</th>\n","      <th>232</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.083699</td>\n","      <td>-0.239021</td>\n","      <td>-0.986135</td>\n","      <td>-0.190185</td>\n","      <td>-0.933752</td>\n","      <td>-0.366213</td>\n","      <td>-0.13909</td>\n","      <td>-0.025692</td>\n","      <td>-2.667854</td>\n","      <td>-1.554894</td>\n","      <td>-0.878420</td>\n","      <td>-0.612750</td>\n","      <td>-0.063636</td>\n","      <td>-0.619896</td>\n","      <td>-1.382878</td>\n","      <td>-0.74978</td>\n","      <td>0.866256</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.621048</td>\n","      <td>-0.239021</td>\n","      <td>-2.927746</td>\n","      <td>-0.514813</td>\n","      <td>-0.933752</td>\n","      <td>-0.366213</td>\n","      <td>-0.13909</td>\n","      <td>-0.025692</td>\n","      <td>-0.148796</td>\n","      <td>0.467339</td>\n","      <td>1.228547</td>\n","      <td>-0.612750</td>\n","      <td>-0.601676</td>\n","      <td>-0.613763</td>\n","      <td>0.471788</td>\n","      <td>-0.74978</td>\n","      <td>-0.472150</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.768322</td>\n","      <td>-0.239021</td>\n","      <td>-0.229063</td>\n","      <td>1.802791</td>\n","      <td>1.300685</td>\n","      <td>2.727485</td>\n","      <td>-0.13909</td>\n","      <td>-0.025692</td>\n","      <td>2.257514</td>\n","      <td>0.751221</td>\n","      <td>1.769156</td>\n","      <td>1.758142</td>\n","      <td>-0.313814</td>\n","      <td>0.831888</td>\n","      <td>-1.382878</td>\n","      <td>-1.25173</td>\n","      <td>-0.290671</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0         1         2         3         4         5        6    \\\n","0 -1.083699 -0.239021 -0.986135 -0.190185 -0.933752 -0.366213 -0.13909   \n","1 -1.621048 -0.239021 -2.927746 -0.514813 -0.933752 -0.366213 -0.13909   \n","2 -0.768322 -0.239021 -0.229063  1.802791  1.300685  2.727485 -0.13909   \n","\n","        7         8         9         10        11        12        13   \\\n","0 -0.025692 -2.667854 -1.554894 -0.878420 -0.612750 -0.063636 -0.619896   \n","1 -0.025692 -0.148796  0.467339  1.228547 -0.612750 -0.601676 -0.613763   \n","2 -0.025692  2.257514  0.751221  1.769156  1.758142 -0.313814  0.831888   \n","\n","        14       15        16   17   18   19   20   21   22   23   24   25   \\\n","0 -1.382878 -0.74978  0.866256  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n","1  0.471788 -0.74978 -0.472150  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n","2 -1.382878 -1.25173 -0.290671  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0   \n","\n","   26   27   28   29   30   31   32   33   34   35   36   37   38   39   40   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   71   72   73   74   75   76   77   78   79   80   81   82   83   84   85   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   86   87   88   89   90   91   92   93   94   95   96   97   98   99   100  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   116  117  118  119  120  121  122  123  124  125  126  127  128  129  130  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   131  132  133  134  135  136  137  138  139  140  141  142  143  144  145  \\\n","0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   146  147  148  149  150  151  152  153  154  155  156  157  158  159  160  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n","\n","   161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   176  177  178  179  180  181  182  183  184  185  186  187  188  189  190  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   191  192  193  194  195  196  197  198  199  200  201  202  203  204  205  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   206  207  208  209  210  211  212  213  214  215  216  217  218  219  220  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   221  222  223  224  225  226  227  228  229  230  231  232  \n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCLE4qb7WC5L","executionInfo":{"status":"ok","timestamp":1611308107825,"user_tz":-60,"elapsed":89114,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"4c964b26-06e7-419c-9cb1-6c73b5ddfb7a"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain_transformed, y_subtrain, validation_data=(X_val_transformed, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=7, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain_transformed, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val_transformed, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5084 - binary_accuracy: 0.7359 - val_loss: 0.4293 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4245 - binary_accuracy: 0.7943 - val_loss: 0.4293 - val_binary_accuracy: 0.7920\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4225 - binary_accuracy: 0.7967 - val_loss: 0.4260 - val_binary_accuracy: 0.7947\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4227 - binary_accuracy: 0.7969 - val_loss: 0.4247 - val_binary_accuracy: 0.7937\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4224 - binary_accuracy: 0.7965 - val_loss: 0.4243 - val_binary_accuracy: 0.7951\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4204 - binary_accuracy: 0.7984 - val_loss: 0.4238 - val_binary_accuracy: 0.7954\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4213 - binary_accuracy: 0.7961 - val_loss: 0.4231 - val_binary_accuracy: 0.7968\n","Epoch 8/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4217 - binary_accuracy: 0.7968 - val_loss: 0.4219 - val_binary_accuracy: 0.7967\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4194 - binary_accuracy: 0.7984 - val_loss: 0.4228 - val_binary_accuracy: 0.7946\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4163 - binary_accuracy: 0.8000 - val_loss: 0.4212 - val_binary_accuracy: 0.7960\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4169 - binary_accuracy: 0.7994 - val_loss: 0.4210 - val_binary_accuracy: 0.7962\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4163 - binary_accuracy: 0.7997 - val_loss: 0.4208 - val_binary_accuracy: 0.7958\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4154 - binary_accuracy: 0.7990 - val_loss: 0.4205 - val_binary_accuracy: 0.7958\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4153 - binary_accuracy: 0.7991 - val_loss: 0.4187 - val_binary_accuracy: 0.7980\n","Epoch 15/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4150 - binary_accuracy: 0.8006 - val_loss: 0.4206 - val_binary_accuracy: 0.7953\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8003 - val_loss: 0.4184 - val_binary_accuracy: 0.7977\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4094 - binary_accuracy: 0.8046 - val_loss: 0.4184 - val_binary_accuracy: 0.7963\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4153 - binary_accuracy: 0.7997 - val_loss: 0.4163 - val_binary_accuracy: 0.7992\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4123 - binary_accuracy: 0.8018 - val_loss: 0.4153 - val_binary_accuracy: 0.7996\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4093 - binary_accuracy: 0.8030 - val_loss: 0.4173 - val_binary_accuracy: 0.7964\n","Epoch 21/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4108 - binary_accuracy: 0.8035 - val_loss: 0.4137 - val_binary_accuracy: 0.8007\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4085 - binary_accuracy: 0.8035 - val_loss: 0.4185 - val_binary_accuracy: 0.7974\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4070 - binary_accuracy: 0.8051 - val_loss: 0.4131 - val_binary_accuracy: 0.7998\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4077 - binary_accuracy: 0.8028 - val_loss: 0.4137 - val_binary_accuracy: 0.7994\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4054 - binary_accuracy: 0.8059 - val_loss: 0.4154 - val_binary_accuracy: 0.7978\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4069 - binary_accuracy: 0.8060 - val_loss: 0.4115 - val_binary_accuracy: 0.8017\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4052 - binary_accuracy: 0.8065 - val_loss: 0.4113 - val_binary_accuracy: 0.8022\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4055 - binary_accuracy: 0.8054 - val_loss: 0.4109 - val_binary_accuracy: 0.8014\n","Epoch 29/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4048 - binary_accuracy: 0.8059 - val_loss: 0.4114 - val_binary_accuracy: 0.8005\n","Epoch 30/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4048 - binary_accuracy: 0.8052 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 31/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8059 - val_loss: 0.4098 - val_binary_accuracy: 0.8015\n","Epoch 32/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4022 - binary_accuracy: 0.8073 - val_loss: 0.4095 - val_binary_accuracy: 0.8025\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4004 - binary_accuracy: 0.8093 - val_loss: 0.4089 - val_binary_accuracy: 0.8028\n","Epoch 34/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4020 - binary_accuracy: 0.8080 - val_loss: 0.4090 - val_binary_accuracy: 0.8027\n","Epoch 35/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4019 - binary_accuracy: 0.8073 - val_loss: 0.4093 - val_binary_accuracy: 0.8014\n","Epoch 36/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4009 - binary_accuracy: 0.8089 - val_loss: 0.4080 - val_binary_accuracy: 0.8027\n","Epoch 37/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4012 - binary_accuracy: 0.8083 - val_loss: 0.4092 - val_binary_accuracy: 0.8024\n","Epoch 38/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4017 - binary_accuracy: 0.8087 - val_loss: 0.4095 - val_binary_accuracy: 0.8024\n","Epoch 39/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3991 - binary_accuracy: 0.8091 - val_loss: 0.4073 - val_binary_accuracy: 0.8019\n","Epoch 40/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3957 - binary_accuracy: 0.8115 - val_loss: 0.4075 - val_binary_accuracy: 0.8019\n","Training Accuracy: 0.808\n","Validation Accuracy: 0.803\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IMf4ZlKsWn6e"},"source":["Result: Transforming Numerical Features into a Normal Distribution helps extremely"]},{"cell_type":"markdown","metadata":{"id":"LHMJDfUWYdmN"},"source":["##### 5. Decorrelation with PCA"]},{"cell_type":"code","metadata":{"id":"MS6EozXnYu5R"},"source":["# Specify pre-processing pipeline for the different types of attributes\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", Pipeline([\n","                            (\"powertransform\", PowerTransformer(method=\"yeo-johnson\", standardize=True)),\n","                            (\"pca\", PCA())\n","                          ]), numeric_features)\n","    ],\n","    remainder=\"passthrough\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain_transformed = preprocessing.transform(X_subtrain)\n","X_val_transformed = preprocessing.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"8Ev5xgdRYu5S","executionInfo":{"status":"ok","timestamp":1611308582609,"user_tz":-60,"elapsed":506,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"e00bd63a-b564-4e21-eb4f-01f5e17b6b94"},"source":["# Validation\n","tmp = pd.DataFrame(X_subtrain_transformed)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(172824, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","      <th>176</th>\n","      <th>177</th>\n","      <th>178</th>\n","      <th>179</th>\n","      <th>180</th>\n","      <th>181</th>\n","      <th>182</th>\n","      <th>183</th>\n","      <th>184</th>\n","      <th>185</th>\n","      <th>186</th>\n","      <th>187</th>\n","      <th>188</th>\n","      <th>189</th>\n","      <th>190</th>\n","      <th>191</th>\n","      <th>192</th>\n","      <th>193</th>\n","      <th>194</th>\n","      <th>195</th>\n","      <th>196</th>\n","      <th>197</th>\n","      <th>198</th>\n","      <th>199</th>\n","      <th>200</th>\n","      <th>201</th>\n","      <th>202</th>\n","      <th>203</th>\n","      <th>204</th>\n","      <th>205</th>\n","      <th>206</th>\n","      <th>207</th>\n","      <th>208</th>\n","      <th>209</th>\n","      <th>210</th>\n","      <th>211</th>\n","      <th>212</th>\n","      <th>213</th>\n","      <th>214</th>\n","      <th>215</th>\n","      <th>216</th>\n","      <th>217</th>\n","      <th>218</th>\n","      <th>219</th>\n","      <th>220</th>\n","      <th>221</th>\n","      <th>222</th>\n","      <th>223</th>\n","      <th>224</th>\n","      <th>225</th>\n","      <th>226</th>\n","      <th>227</th>\n","      <th>228</th>\n","      <th>229</th>\n","      <th>230</th>\n","      <th>231</th>\n","      <th>232</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-2.601059</td>\n","      <td>-0.410007</td>\n","      <td>-0.404783</td>\n","      <td>1.164287</td>\n","      <td>-0.091849</td>\n","      <td>-0.212521</td>\n","      <td>-0.529216</td>\n","      <td>2.294785</td>\n","      <td>0.580161</td>\n","      <td>0.953602</td>\n","      <td>-0.148654</td>\n","      <td>-0.430559</td>\n","      <td>0.612913</td>\n","      <td>0.851988</td>\n","      <td>-0.351759</td>\n","      <td>0.900483</td>\n","      <td>0.139061</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.390127</td>\n","      <td>-2.211286</td>\n","      <td>0.641949</td>\n","      <td>0.480664</td>\n","      <td>-0.239196</td>\n","      <td>-0.387141</td>\n","      <td>2.109289</td>\n","      <td>0.654540</td>\n","      <td>-0.251707</td>\n","      <td>-0.133599</td>\n","      <td>-0.882627</td>\n","      <td>0.938515</td>\n","      <td>1.286549</td>\n","      <td>-0.575849</td>\n","      <td>0.198403</td>\n","      <td>-0.318513</td>\n","      <td>0.027164</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.884293</td>\n","      <td>-2.409525</td>\n","      <td>2.013652</td>\n","      <td>-0.189625</td>\n","      <td>0.385735</td>\n","      <td>0.039777</td>\n","      <td>-1.415718</td>\n","      <td>0.185991</td>\n","      <td>-2.201274</td>\n","      <td>-0.502807</td>\n","      <td>0.497177</td>\n","      <td>-0.674013</td>\n","      <td>0.354346</td>\n","      <td>0.169585</td>\n","      <td>1.200940</td>\n","      <td>-1.191646</td>\n","      <td>-0.339670</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0         1         2         3         4         5         6    \\\n","0 -2.601059 -0.410007 -0.404783  1.164287 -0.091849 -0.212521 -0.529216   \n","1 -1.390127 -2.211286  0.641949  0.480664 -0.239196 -0.387141  2.109289   \n","2  2.884293 -2.409525  2.013652 -0.189625  0.385735  0.039777 -1.415718   \n","\n","        7         8         9         10        11        12        13   \\\n","0  2.294785  0.580161  0.953602 -0.148654 -0.430559  0.612913  0.851988   \n","1  0.654540 -0.251707 -0.133599 -0.882627  0.938515  1.286549 -0.575849   \n","2  0.185991 -2.201274 -0.502807  0.497177 -0.674013  0.354346  0.169585   \n","\n","        14        15        16   17   18   19   20   21   22   23   24   25   \\\n","0 -0.351759  0.900483  0.139061  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n","1  0.198403 -0.318513  0.027164  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n","2  1.200940 -1.191646 -0.339670  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0   \n","\n","   26   27   28   29   30   31   32   33   34   35   36   37   38   39   40   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   \\\n","0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   71   72   73   74   75   76   77   78   79   80   81   82   83   84   85   \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   86   87   88   89   90   91   92   93   94   95   96   97   98   99   100  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   116  117  118  119  120  121  122  123  124  125  126  127  128  129  130  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   131  132  133  134  135  136  137  138  139  140  141  142  143  144  145  \\\n","0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   146  147  148  149  150  151  152  153  154  155  156  157  158  159  160  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n","\n","   161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   176  177  178  179  180  181  182  183  184  185  186  187  188  189  190  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   191  192  193  194  195  196  197  198  199  200  201  202  203  204  205  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   206  207  208  209  210  211  212  213  214  215  216  217  218  219  220  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","   221  222  223  224  225  226  227  228  229  230  231  232  \n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWOSDy4CYu5T","executionInfo":{"status":"ok","timestamp":1611308736592,"user_tz":-60,"elapsed":150504,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"8fac0ed6-e7cb-451f-d2c6-eb1050bf4908"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain_transformed, y_subtrain, validation_data=(X_val_transformed, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=7, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain_transformed, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val_transformed, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4835 - binary_accuracy: 0.7559 - val_loss: 0.4296 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4247 - binary_accuracy: 0.7943 - val_loss: 0.4297 - val_binary_accuracy: 0.7918\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4230 - binary_accuracy: 0.7963 - val_loss: 0.4270 - val_binary_accuracy: 0.7937\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4235 - binary_accuracy: 0.7963 - val_loss: 0.4259 - val_binary_accuracy: 0.7929\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4235 - binary_accuracy: 0.7960 - val_loss: 0.4255 - val_binary_accuracy: 0.7945\n","Epoch 6/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4214 - binary_accuracy: 0.7975 - val_loss: 0.4248 - val_binary_accuracy: 0.7955\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4221 - binary_accuracy: 0.7954 - val_loss: 0.4238 - val_binary_accuracy: 0.7953\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4221 - binary_accuracy: 0.7970 - val_loss: 0.4223 - val_binary_accuracy: 0.7966\n","Epoch 9/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4197 - binary_accuracy: 0.7980 - val_loss: 0.4229 - val_binary_accuracy: 0.7954\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4164 - binary_accuracy: 0.7999 - val_loss: 0.4213 - val_binary_accuracy: 0.7961\n","Epoch 11/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4170 - binary_accuracy: 0.7998 - val_loss: 0.4211 - val_binary_accuracy: 0.7961\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4163 - binary_accuracy: 0.8001 - val_loss: 0.4206 - val_binary_accuracy: 0.7956\n","Epoch 13/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4154 - binary_accuracy: 0.7992 - val_loss: 0.4204 - val_binary_accuracy: 0.7956\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4152 - binary_accuracy: 0.7993 - val_loss: 0.4183 - val_binary_accuracy: 0.7975\n","Epoch 15/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4148 - binary_accuracy: 0.8006 - val_loss: 0.4202 - val_binary_accuracy: 0.7953\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4155 - binary_accuracy: 0.8004 - val_loss: 0.4180 - val_binary_accuracy: 0.7978\n","Epoch 17/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4092 - binary_accuracy: 0.8047 - val_loss: 0.4180 - val_binary_accuracy: 0.7963\n","Epoch 18/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4149 - binary_accuracy: 0.8006 - val_loss: 0.4160 - val_binary_accuracy: 0.7994\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4119 - binary_accuracy: 0.8022 - val_loss: 0.4148 - val_binary_accuracy: 0.8001\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4090 - binary_accuracy: 0.8033 - val_loss: 0.4166 - val_binary_accuracy: 0.7968\n","Epoch 21/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4102 - binary_accuracy: 0.8034 - val_loss: 0.4132 - val_binary_accuracy: 0.8016\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4079 - binary_accuracy: 0.8041 - val_loss: 0.4174 - val_binary_accuracy: 0.7987\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4064 - binary_accuracy: 0.8060 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4070 - binary_accuracy: 0.8036 - val_loss: 0.4132 - val_binary_accuracy: 0.7997\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4047 - binary_accuracy: 0.8065 - val_loss: 0.4146 - val_binary_accuracy: 0.7982\n","Epoch 26/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4064 - binary_accuracy: 0.8064 - val_loss: 0.4109 - val_binary_accuracy: 0.8020\n","Epoch 27/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4044 - binary_accuracy: 0.8068 - val_loss: 0.4107 - val_binary_accuracy: 0.8020\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4046 - binary_accuracy: 0.8060 - val_loss: 0.4102 - val_binary_accuracy: 0.8024\n","Epoch 29/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4040 - binary_accuracy: 0.8065 - val_loss: 0.4107 - val_binary_accuracy: 0.8007\n","Epoch 30/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4040 - binary_accuracy: 0.8064 - val_loss: 0.4091 - val_binary_accuracy: 0.8030\n","Epoch 31/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4039 - binary_accuracy: 0.8070 - val_loss: 0.4090 - val_binary_accuracy: 0.8029\n","Epoch 32/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4014 - binary_accuracy: 0.8075 - val_loss: 0.4087 - val_binary_accuracy: 0.8032\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3996 - binary_accuracy: 0.8102 - val_loss: 0.4082 - val_binary_accuracy: 0.8036\n","Epoch 34/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4011 - binary_accuracy: 0.8087 - val_loss: 0.4084 - val_binary_accuracy: 0.8034\n","Epoch 35/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4011 - binary_accuracy: 0.8080 - val_loss: 0.4085 - val_binary_accuracy: 0.8030\n","Epoch 36/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3998 - binary_accuracy: 0.8098 - val_loss: 0.4072 - val_binary_accuracy: 0.8038\n","Epoch 37/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4005 - binary_accuracy: 0.8092 - val_loss: 0.4083 - val_binary_accuracy: 0.8021\n","Epoch 38/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4006 - binary_accuracy: 0.8093 - val_loss: 0.4083 - val_binary_accuracy: 0.8022\n","Epoch 39/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3982 - binary_accuracy: 0.8098 - val_loss: 0.4066 - val_binary_accuracy: 0.8027\n","Epoch 40/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3949 - binary_accuracy: 0.8125 - val_loss: 0.4066 - val_binary_accuracy: 0.8034\n","Epoch 41/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3972 - binary_accuracy: 0.8113 - val_loss: 0.4067 - val_binary_accuracy: 0.8032\n","Epoch 42/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3966 - binary_accuracy: 0.8118 - val_loss: 0.4066 - val_binary_accuracy: 0.8038\n","Epoch 43/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3972 - binary_accuracy: 0.8108 - val_loss: 0.4062 - val_binary_accuracy: 0.8030\n","Epoch 44/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3953 - binary_accuracy: 0.8129 - val_loss: 0.4062 - val_binary_accuracy: 0.8028\n","Epoch 45/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3935 - binary_accuracy: 0.8137 - val_loss: 0.4055 - val_binary_accuracy: 0.8035\n","Epoch 46/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3952 - binary_accuracy: 0.8117 - val_loss: 0.4066 - val_binary_accuracy: 0.8034\n","Epoch 47/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3918 - binary_accuracy: 0.8148 - val_loss: 0.4060 - val_binary_accuracy: 0.8037\n","Epoch 48/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3923 - binary_accuracy: 0.8145 - val_loss: 0.4059 - val_binary_accuracy: 0.8025\n","Epoch 49/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3928 - binary_accuracy: 0.8131 - val_loss: 0.4052 - val_binary_accuracy: 0.8040\n","Epoch 50/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3941 - binary_accuracy: 0.8128 - val_loss: 0.4058 - val_binary_accuracy: 0.8039\n","Epoch 51/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3932 - binary_accuracy: 0.8132 - val_loss: 0.4053 - val_binary_accuracy: 0.8045\n","Epoch 52/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3905 - binary_accuracy: 0.8148 - val_loss: 0.4092 - val_binary_accuracy: 0.8014\n","Epoch 53/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3899 - binary_accuracy: 0.8151 - val_loss: 0.4057 - val_binary_accuracy: 0.8046\n","Epoch 54/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3893 - binary_accuracy: 0.8155 - val_loss: 0.4049 - val_binary_accuracy: 0.8039\n","Epoch 55/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3897 - binary_accuracy: 0.8151 - val_loss: 0.4051 - val_binary_accuracy: 0.8047\n","Epoch 56/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3912 - binary_accuracy: 0.8151 - val_loss: 0.4049 - val_binary_accuracy: 0.8048\n","Epoch 57/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3904 - binary_accuracy: 0.8149 - val_loss: 0.4051 - val_binary_accuracy: 0.8042\n","Epoch 58/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3890 - binary_accuracy: 0.8160 - val_loss: 0.4055 - val_binary_accuracy: 0.8045\n","Epoch 59/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3872 - binary_accuracy: 0.8171 - val_loss: 0.4052 - val_binary_accuracy: 0.8054\n","Epoch 60/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3873 - binary_accuracy: 0.8166 - val_loss: 0.4050 - val_binary_accuracy: 0.8047\n","Epoch 61/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3880 - binary_accuracy: 0.8176 - val_loss: 0.4052 - val_binary_accuracy: 0.8040\n","Epoch 62/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3865 - binary_accuracy: 0.8182 - val_loss: 0.4053 - val_binary_accuracy: 0.8039\n","Epoch 63/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3864 - binary_accuracy: 0.8176 - val_loss: 0.4051 - val_binary_accuracy: 0.8041\n","Epoch 64/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3882 - binary_accuracy: 0.8178 - val_loss: 0.4097 - val_binary_accuracy: 0.8020\n","Epoch 65/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3857 - binary_accuracy: 0.8184 - val_loss: 0.4060 - val_binary_accuracy: 0.8038\n","Epoch 66/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3827 - binary_accuracy: 0.8195 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Training Accuracy: 0.817\n","Validation Accuracy: 0.805\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mpv2Y13Dal6P"},"source":["Result: \n","- De-correlated + power-transformed dataset was the best\n","- however, perform this transformation only for numerical attributes, not binary"]},{"cell_type":"markdown","metadata":{"id":"b31IIEU2alm_"},"source":["##### Perform Final Dataset Transformation:"]},{"cell_type":"code","metadata":{"id":"6NH-JrKzQd6v"},"source":["# Strategy: PowerTransform + Standardize + Decorrelate (PCA) Numerical Features; Leave Binary Features as they are\n","preprocessing = ColumnTransformer(\n","    [\n","      (\"numeric\", Pipeline([\n","                            (\"powertransform\", PowerTransformer(method=\"yeo-johnson\", standardize=True)),\n","                            (\"pca\", PCA())\n","                          ]), numeric_features)\n","    ],\n","    remainder=\"passthrough\", verbose=True, n_jobs=-1\n",").fit(X_subtrain)\n","X_subtrain = preprocessing.transform(X_subtrain)\n","X_val = preprocessing.transform(X_val)\n","\n","preprocessing2 = ColumnTransformer(\n","    [\n","      (\"numeric\", Pipeline([\n","                            (\"powertransform\", PowerTransformer(method=\"yeo-johnson\", standardize=True)),\n","                            (\"pca\", PCA())\n","                          ]), numeric_features),\n","    ],\n","    remainder=\"passthrough\", verbose=True, n_jobs=-1\n",").fit(X_train)\n","X_train = preprocessing2.transform(X_train)\n","X_test = preprocessing2.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtryG_j8cRai"},"source":["# Re-arrange feature_names, since they have been changed by the ColumnTransformer\n","feature_names = numeric_feature_names + binary_feature_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230},"id":"tsnMpfPAQdxV","executionInfo":{"status":"ok","timestamp":1611386074282,"user_tz":-60,"elapsed":18607,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"52317de6-5275-47b3-a4b4-0b838df0c504"},"source":["# Validation\n","tmp = pd.DataFrame(X_test, columns=feature_names)\n","print(tmp.shape)\n","tmp.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(37033, 233)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>goal</th>\n","      <th>number_of_collaborators</th>\n","      <th>funding_period</th>\n","      <th>days_between_created_and_launched</th>\n","      <th>number_of_images</th>\n","      <th>number_of_videos</th>\n","      <th>number_of_audios</th>\n","      <th>number_of_interactives</th>\n","      <th>number_of_words</th>\n","      <th>number_of_links</th>\n","      <th>number_of_creator_backings</th>\n","      <th>number_of_creator_projects</th>\n","      <th>number_of_rewards</th>\n","      <th>number_of_words_per_reward</th>\n","      <th>lowest_pledge_level</th>\n","      <th>highest_pledge_level</th>\n","      <th>avg_months_until_reward</th>\n","      <th>staff_pick</th>\n","      <th>campaign_has_demo_video</th>\n","      <th>campaign_has_environmental_commitments</th>\n","      <th>creator_verified_identity</th>\n","      <th>creator_fb_auth</th>\n","      <th>creator_has_image</th>\n","      <th>creator_allows_follows</th>\n","      <th>facebook_linked</th>\n","      <th>twitter_linked</th>\n","      <th>instagram_linked</th>\n","      <th>linkedin_linked</th>\n","      <th>has_limited_rewards</th>\n","      <th>has_shipped_rewards</th>\n","      <th>has_restricted_shipping_rewards</th>\n","      <th>launch_quartal_1</th>\n","      <th>launch_quartal_2</th>\n","      <th>launch_quartal_3</th>\n","      <th>launch_quartal_4</th>\n","      <th>location_Africa</th>\n","      <th>location_Australia</th>\n","      <th>location_Belgium</th>\n","      <th>location_Canada</th>\n","      <th>location_China</th>\n","      <th>location_Denmark</th>\n","      <th>location_France</th>\n","      <th>location_Germany</th>\n","      <th>location_Hong Kong</th>\n","      <th>location_Ireland</th>\n","      <th>location_Italy</th>\n","      <th>location_Japan</th>\n","      <th>location_Latin and South America</th>\n","      <th>location_Mexico</th>\n","      <th>location_Netherlands</th>\n","      <th>location_New Zealand</th>\n","      <th>location_No Location</th>\n","      <th>location_Norway</th>\n","      <th>location_Oceania and Antarctica</th>\n","      <th>location_Rest of Asia</th>\n","      <th>location_Rest of Europe</th>\n","      <th>location_Singapore</th>\n","      <th>location_Spain</th>\n","      <th>location_Sweden</th>\n","      <th>location_Switzerland</th>\n","      <th>location_United Kingdom</th>\n","      <th>location_United States</th>\n","      <th>category_Art_Ceramics</th>\n","      <th>category_Art_Conceptual Art</th>\n","      <th>category_Art_Digital Art</th>\n","      <th>category_Art_Illustration</th>\n","      <th>category_Art_Installations</th>\n","      <th>category_Art_Mixed Media</th>\n","      <th>category_Art_No Subcategory</th>\n","      <th>category_Art_Painting</th>\n","      <th>category_Art_Performance Art</th>\n","      <th>category_Art_Public Art</th>\n","      <th>category_Art_Sculpture</th>\n","      <th>category_Art_Social Practice</th>\n","      <th>category_Art_Textiles</th>\n","      <th>category_Art_Video Art</th>\n","      <th>category_Comics_Anthologies</th>\n","      <th>category_Comics_Comic Books</th>\n","      <th>category_Comics_Events</th>\n","      <th>category_Comics_Graphic Novels</th>\n","      <th>category_Comics_No Subcategory</th>\n","      <th>category_Comics_Webcomics</th>\n","      <th>category_Crafts_Candles</th>\n","      <th>category_Crafts_Crochet</th>\n","      <th>category_Crafts_DIY</th>\n","      <th>category_Crafts_Embroidery</th>\n","      <th>category_Crafts_Glass</th>\n","      <th>category_Crafts_Knitting</th>\n","      <th>category_Crafts_No Subcategory</th>\n","      <th>category_Crafts_Pottery</th>\n","      <th>category_Crafts_Printing</th>\n","      <th>category_Crafts_Quilts</th>\n","      <th>category_Crafts_Stationery</th>\n","      <th>category_Crafts_Taxidermy</th>\n","      <th>category_Crafts_Weaving</th>\n","      <th>category_Crafts_Woodworking</th>\n","      <th>category_Dance_No Subcategory</th>\n","      <th>category_Dance_Performances</th>\n","      <th>category_Dance_Residencies</th>\n","      <th>category_Dance_Spaces</th>\n","      <th>category_Dance_Workshops</th>\n","      <th>category_Design_Architecture</th>\n","      <th>category_Design_Civic Design</th>\n","      <th>category_Design_Graphic Design</th>\n","      <th>category_Design_Interactive Design</th>\n","      <th>category_Design_No Subcategory</th>\n","      <th>category_Design_Product Design</th>\n","      <th>category_Design_Toys</th>\n","      <th>category_Design_Typography</th>\n","      <th>category_Fashion_Accessories</th>\n","      <th>category_Fashion_Apparel</th>\n","      <th>category_Fashion_Childrenswear</th>\n","      <th>category_Fashion_Couture</th>\n","      <th>category_Fashion_Footwear</th>\n","      <th>category_Fashion_Jewelry</th>\n","      <th>category_Fashion_No Subcategory</th>\n","      <th>category_Fashion_Pet Fashion</th>\n","      <th>category_Fashion_Ready-to-wear</th>\n","      <th>category_Film &amp; Video_Action</th>\n","      <th>category_Film &amp; Video_Animation</th>\n","      <th>category_Film &amp; Video_Comedy</th>\n","      <th>category_Film &amp; Video_Documentary</th>\n","      <th>category_Film &amp; Video_Drama</th>\n","      <th>category_Film &amp; Video_Experimental</th>\n","      <th>category_Film &amp; Video_Family</th>\n","      <th>category_Film &amp; Video_Fantasy</th>\n","      <th>category_Film &amp; Video_Festivals</th>\n","      <th>category_Film &amp; Video_Horror</th>\n","      <th>category_Film &amp; Video_Movie Theaters</th>\n","      <th>category_Film &amp; Video_Music Videos</th>\n","      <th>category_Film &amp; Video_Narrative Film</th>\n","      <th>category_Film &amp; Video_No Subcategory</th>\n","      <th>category_Film &amp; Video_Romance</th>\n","      <th>category_Film &amp; Video_Science Fiction</th>\n","      <th>category_Film &amp; Video_Shorts</th>\n","      <th>category_Film &amp; Video_Television</th>\n","      <th>category_Film &amp; Video_Thrillers</th>\n","      <th>category_Film &amp; Video_Webseries</th>\n","      <th>category_Food_Bacon</th>\n","      <th>category_Food_Community Gardens</th>\n","      <th>category_Food_Cookbooks</th>\n","      <th>category_Food_Drinks</th>\n","      <th>category_Food_Events</th>\n","      <th>category_Food_Farmer's Markets</th>\n","      <th>category_Food_Farms</th>\n","      <th>category_Food_Food Trucks</th>\n","      <th>category_Food_No Subcategory</th>\n","      <th>category_Food_Restaurants</th>\n","      <th>category_Food_Small Batch</th>\n","      <th>category_Food_Spaces</th>\n","      <th>category_Food_Vegan</th>\n","      <th>category_Games_Gaming Hardware</th>\n","      <th>category_Games_Live Games</th>\n","      <th>category_Games_Mobile Games</th>\n","      <th>category_Games_No Subcategory</th>\n","      <th>category_Games_Playing Cards</th>\n","      <th>category_Games_Puzzles</th>\n","      <th>category_Games_Tabletop Games</th>\n","      <th>category_Games_Video Games</th>\n","      <th>category_Journalism_Audio</th>\n","      <th>category_Journalism_No Subcategory</th>\n","      <th>category_Journalism_Photo</th>\n","      <th>category_Journalism_Print</th>\n","      <th>category_Journalism_Video</th>\n","      <th>category_Journalism_Web</th>\n","      <th>category_Music_Blues</th>\n","      <th>category_Music_Chiptune</th>\n","      <th>category_Music_Classical Music</th>\n","      <th>category_Music_Comedy</th>\n","      <th>category_Music_Country &amp; Folk</th>\n","      <th>category_Music_Electronic Music</th>\n","      <th>category_Music_Faith</th>\n","      <th>category_Music_Hip-Hop</th>\n","      <th>category_Music_Indie Rock</th>\n","      <th>category_Music_Jazz</th>\n","      <th>category_Music_Kids</th>\n","      <th>category_Music_Latin</th>\n","      <th>category_Music_Metal</th>\n","      <th>category_Music_No Subcategory</th>\n","      <th>category_Music_Pop</th>\n","      <th>category_Music_Punk</th>\n","      <th>category_Music_R&amp;B</th>\n","      <th>category_Music_Rock</th>\n","      <th>category_Music_World Music</th>\n","      <th>category_Photography_Animals</th>\n","      <th>category_Photography_Fine Art</th>\n","      <th>category_Photography_Nature</th>\n","      <th>category_Photography_No Subcategory</th>\n","      <th>category_Photography_People</th>\n","      <th>category_Photography_Photobooks</th>\n","      <th>category_Photography_Places</th>\n","      <th>category_Publishing_Academic</th>\n","      <th>category_Publishing_Anthologies</th>\n","      <th>category_Publishing_Art Books</th>\n","      <th>category_Publishing_Calendars</th>\n","      <th>category_Publishing_Children's Books</th>\n","      <th>category_Publishing_Comedy</th>\n","      <th>category_Publishing_Fiction</th>\n","      <th>category_Publishing_Letterpress</th>\n","      <th>category_Publishing_Literary Journals</th>\n","      <th>category_Publishing_Literary Spaces</th>\n","      <th>category_Publishing_No Subcategory</th>\n","      <th>category_Publishing_Nonfiction</th>\n","      <th>category_Publishing_Periodicals</th>\n","      <th>category_Publishing_Poetry</th>\n","      <th>category_Publishing_Radio &amp; Podcasts</th>\n","      <th>category_Publishing_Translations</th>\n","      <th>category_Publishing_Young Adult</th>\n","      <th>category_Publishing_Zines</th>\n","      <th>category_Technology_3D Printing</th>\n","      <th>category_Technology_Apps</th>\n","      <th>category_Technology_Camera Equipment</th>\n","      <th>category_Technology_DIY Electronics</th>\n","      <th>category_Technology_Fabrication Tools</th>\n","      <th>category_Technology_Flight</th>\n","      <th>category_Technology_Gadgets</th>\n","      <th>category_Technology_Hardware</th>\n","      <th>category_Technology_Makerspaces</th>\n","      <th>category_Technology_No Subcategory</th>\n","      <th>category_Technology_Robots</th>\n","      <th>category_Technology_Software</th>\n","      <th>category_Technology_Sound</th>\n","      <th>category_Technology_Space Exploration</th>\n","      <th>category_Technology_Wearables</th>\n","      <th>category_Technology_Web</th>\n","      <th>category_Theater_Comedy</th>\n","      <th>category_Theater_Experimental</th>\n","      <th>category_Theater_Festivals</th>\n","      <th>category_Theater_Immersive</th>\n","      <th>category_Theater_Musical</th>\n","      <th>category_Theater_No Subcategory</th>\n","      <th>category_Theater_Plays</th>\n","      <th>category_Theater_Spaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.432872</td>\n","      <td>0.459879</td>\n","      <td>-0.421147</td>\n","      <td>0.943741</td>\n","      <td>-0.205250</td>\n","      <td>0.006443</td>\n","      <td>0.144617</td>\n","      <td>0.702618</td>\n","      <td>-0.035818</td>\n","      <td>-0.168432</td>\n","      <td>-0.228239</td>\n","      <td>-0.809985</td>\n","      <td>-0.287800</td>\n","      <td>0.217653</td>\n","      <td>0.107042</td>\n","      <td>-0.850727</td>\n","      <td>0.218370</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.222296</td>\n","      <td>0.989783</td>\n","      <td>2.619387</td>\n","      <td>0.084635</td>\n","      <td>-1.918300</td>\n","      <td>0.364524</td>\n","      <td>-0.117928</td>\n","      <td>-2.108988</td>\n","      <td>2.591784</td>\n","      <td>-0.506616</td>\n","      <td>-1.852593</td>\n","      <td>-0.527323</td>\n","      <td>-1.180490</td>\n","      <td>0.831588</td>\n","      <td>0.284751</td>\n","      <td>0.261354</td>\n","      <td>0.416789</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.640697</td>\n","      <td>-0.153344</td>\n","      <td>-1.808868</td>\n","      <td>-0.077725</td>\n","      <td>-0.044216</td>\n","      <td>0.659137</td>\n","      <td>-2.153080</td>\n","      <td>-2.237971</td>\n","      <td>-0.122080</td>\n","      <td>-0.647870</td>\n","      <td>-0.185191</td>\n","      <td>-1.341788</td>\n","      <td>0.345237</td>\n","      <td>-1.968340</td>\n","      <td>0.137151</td>\n","      <td>-0.138933</td>\n","      <td>-0.028566</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       goal  number_of_collaborators  funding_period  \\\n","0 -1.432872                 0.459879       -0.421147   \n","1 -0.222296                 0.989783        2.619387   \n","2 -2.640697                -0.153344       -1.808868   \n","\n","   days_between_created_and_launched  number_of_images  number_of_videos  \\\n","0                           0.943741         -0.205250          0.006443   \n","1                           0.084635         -1.918300          0.364524   \n","2                          -0.077725         -0.044216          0.659137   \n","\n","   number_of_audios  number_of_interactives  number_of_words  number_of_links  \\\n","0          0.144617                0.702618        -0.035818        -0.168432   \n","1         -0.117928               -2.108988         2.591784        -0.506616   \n","2         -2.153080               -2.237971        -0.122080        -0.647870   \n","\n","   number_of_creator_backings  number_of_creator_projects  number_of_rewards  \\\n","0                   -0.228239                   -0.809985          -0.287800   \n","1                   -1.852593                   -0.527323          -1.180490   \n","2                   -0.185191                   -1.341788           0.345237   \n","\n","   number_of_words_per_reward  lowest_pledge_level  highest_pledge_level  \\\n","0                    0.217653             0.107042             -0.850727   \n","1                    0.831588             0.284751              0.261354   \n","2                   -1.968340             0.137151             -0.138933   \n","\n","   avg_months_until_reward  staff_pick  campaign_has_demo_video  \\\n","0                 0.218370         0.0                      0.0   \n","1                 0.416789         0.0                      1.0   \n","2                -0.028566         0.0                      1.0   \n","\n","   campaign_has_environmental_commitments  creator_verified_identity  \\\n","0                                     0.0                        0.0   \n","1                                     0.0                        1.0   \n","2                                     0.0                        0.0   \n","\n","   creator_fb_auth  creator_has_image  creator_allows_follows  \\\n","0              0.0                1.0                     1.0   \n","1              0.0                1.0                     1.0   \n","2              0.0                1.0                     1.0   \n","\n","   facebook_linked  twitter_linked  instagram_linked  linkedin_linked  \\\n","0              0.0             0.0               0.0              0.0   \n","1              0.0             0.0               0.0              0.0   \n","2              0.0             0.0               0.0              0.0   \n","\n","   has_limited_rewards  has_shipped_rewards  has_restricted_shipping_rewards  \\\n","0                  0.0                  1.0                              1.0   \n","1                  0.0                  0.0                              0.0   \n","2                  0.0                  0.0                              0.0   \n","\n","   launch_quartal_1  launch_quartal_2  launch_quartal_3  launch_quartal_4  \\\n","0               0.0               0.0               1.0               0.0   \n","1               0.0               0.0               0.0               1.0   \n","2               0.0               1.0               0.0               0.0   \n","\n","   location_Africa  location_Australia  location_Belgium  location_Canada  \\\n","0              0.0                 0.0               0.0              0.0   \n","1              0.0                 0.0               0.0              0.0   \n","2              0.0                 0.0               0.0              0.0   \n","\n","   location_China  location_Denmark  location_France  location_Germany  \\\n","0             0.0               0.0              0.0               0.0   \n","1             0.0               0.0              0.0               0.0   \n","2             0.0               0.0              0.0               1.0   \n","\n","   location_Hong Kong  location_Ireland  location_Italy  location_Japan  \\\n","0                 0.0               0.0             0.0             0.0   \n","1                 0.0               0.0             0.0             0.0   \n","2                 0.0               0.0             0.0             0.0   \n","\n","   location_Latin and South America  location_Mexico  location_Netherlands  \\\n","0                               0.0              0.0                   0.0   \n","1                               0.0              0.0                   0.0   \n","2                               0.0              0.0                   0.0   \n","\n","   location_New Zealand  location_No Location  location_Norway  \\\n","0                   0.0                   0.0              0.0   \n","1                   0.0                   0.0              0.0   \n","2                   0.0                   0.0              0.0   \n","\n","   location_Oceania and Antarctica  location_Rest of Asia  \\\n","0                              0.0                    0.0   \n","1                              0.0                    0.0   \n","2                              0.0                    0.0   \n","\n","   location_Rest of Europe  location_Singapore  location_Spain  \\\n","0                      0.0                 0.0             0.0   \n","1                      0.0                 0.0             0.0   \n","2                      0.0                 0.0             0.0   \n","\n","   location_Sweden  location_Switzerland  location_United Kingdom  \\\n","0              0.0                   0.0                      0.0   \n","1              0.0                   0.0                      1.0   \n","2              0.0                   0.0                      0.0   \n","\n","   location_United States  category_Art_Ceramics  category_Art_Conceptual Art  \\\n","0                     1.0                    0.0                          0.0   \n","1                     0.0                    0.0                          0.0   \n","2                     0.0                    0.0                          0.0   \n","\n","   category_Art_Digital Art  category_Art_Illustration  \\\n","0                       0.0                        0.0   \n","1                       0.0                        0.0   \n","2                       0.0                        0.0   \n","\n","   category_Art_Installations  category_Art_Mixed Media  \\\n","0                         0.0                       0.0   \n","1                         0.0                       0.0   \n","2                         0.0                       0.0   \n","\n","   category_Art_No Subcategory  category_Art_Painting  \\\n","0                          0.0                    0.0   \n","1                          0.0                    0.0   \n","2                          0.0                    0.0   \n","\n","   category_Art_Performance Art  category_Art_Public Art  \\\n","0                           0.0                      0.0   \n","1                           0.0                      0.0   \n","2                           0.0                      0.0   \n","\n","   category_Art_Sculpture  category_Art_Social Practice  \\\n","0                     0.0                           0.0   \n","1                     0.0                           0.0   \n","2                     0.0                           0.0   \n","\n","   category_Art_Textiles  category_Art_Video Art  category_Comics_Anthologies  \\\n","0                    0.0                     0.0                          0.0   \n","1                    0.0                     0.0                          0.0   \n","2                    0.0                     0.0                          0.0   \n","\n","   category_Comics_Comic Books  category_Comics_Events  \\\n","0                          0.0                     0.0   \n","1                          0.0                     0.0   \n","2                          0.0                     0.0   \n","\n","   category_Comics_Graphic Novels  category_Comics_No Subcategory  \\\n","0                             0.0                             0.0   \n","1                             0.0                             0.0   \n","2                             0.0                             0.0   \n","\n","   category_Comics_Webcomics  category_Crafts_Candles  \\\n","0                        0.0                      1.0   \n","1                        0.0                      0.0   \n","2                        0.0                      0.0   \n","\n","   category_Crafts_Crochet  category_Crafts_DIY  category_Crafts_Embroidery  \\\n","0                      0.0                  0.0                         0.0   \n","1                      0.0                  0.0                         0.0   \n","2                      0.0                  0.0                         0.0   \n","\n","   category_Crafts_Glass  category_Crafts_Knitting  \\\n","0                    0.0                       0.0   \n","1                    0.0                       0.0   \n","2                    0.0                       0.0   \n","\n","   category_Crafts_No Subcategory  category_Crafts_Pottery  \\\n","0                             0.0                      0.0   \n","1                             0.0                      0.0   \n","2                             0.0                      0.0   \n","\n","   category_Crafts_Printing  category_Crafts_Quilts  \\\n","0                       0.0                     0.0   \n","1                       0.0                     0.0   \n","2                       0.0                     0.0   \n","\n","   category_Crafts_Stationery  category_Crafts_Taxidermy  \\\n","0                         0.0                        0.0   \n","1                         0.0                        0.0   \n","2                         0.0                        0.0   \n","\n","   category_Crafts_Weaving  category_Crafts_Woodworking  \\\n","0                      0.0                          0.0   \n","1                      0.0                          0.0   \n","2                      0.0                          0.0   \n","\n","   category_Dance_No Subcategory  category_Dance_Performances  \\\n","0                            0.0                          0.0   \n","1                            0.0                          0.0   \n","2                            0.0                          0.0   \n","\n","   category_Dance_Residencies  category_Dance_Spaces  \\\n","0                         0.0                    0.0   \n","1                         0.0                    0.0   \n","2                         0.0                    0.0   \n","\n","   category_Dance_Workshops  category_Design_Architecture  \\\n","0                       0.0                           0.0   \n","1                       0.0                           0.0   \n","2                       0.0                           0.0   \n","\n","   category_Design_Civic Design  category_Design_Graphic Design  \\\n","0                           0.0                             0.0   \n","1                           0.0                             0.0   \n","2                           0.0                             0.0   \n","\n","   category_Design_Interactive Design  category_Design_No Subcategory  \\\n","0                                 0.0                             0.0   \n","1                                 0.0                             0.0   \n","2                                 0.0                             0.0   \n","\n","   category_Design_Product Design  category_Design_Toys  \\\n","0                             0.0                   0.0   \n","1                             0.0                   0.0   \n","2                             0.0                   0.0   \n","\n","   category_Design_Typography  category_Fashion_Accessories  \\\n","0                         0.0                           0.0   \n","1                         0.0                           0.0   \n","2                         0.0                           0.0   \n","\n","   category_Fashion_Apparel  category_Fashion_Childrenswear  \\\n","0                       0.0                             0.0   \n","1                       0.0                             0.0   \n","2                       0.0                             0.0   \n","\n","   category_Fashion_Couture  category_Fashion_Footwear  \\\n","0                       0.0                        0.0   \n","1                       0.0                        0.0   \n","2                       0.0                        0.0   \n","\n","   category_Fashion_Jewelry  category_Fashion_No Subcategory  \\\n","0                       0.0                              0.0   \n","1                       0.0                              0.0   \n","2                       0.0                              0.0   \n","\n","   category_Fashion_Pet Fashion  category_Fashion_Ready-to-wear  \\\n","0                           0.0                             0.0   \n","1                           0.0                             0.0   \n","2                           0.0                             0.0   \n","\n","   category_Film & Video_Action  category_Film & Video_Animation  \\\n","0                           0.0                              0.0   \n","1                           0.0                              0.0   \n","2                           0.0                              0.0   \n","\n","   category_Film & Video_Comedy  category_Film & Video_Documentary  \\\n","0                           0.0                                0.0   \n","1                           0.0                                0.0   \n","2                           0.0                                0.0   \n","\n","   category_Film & Video_Drama  category_Film & Video_Experimental  \\\n","0                          0.0                                 0.0   \n","1                          0.0                                 0.0   \n","2                          0.0                                 0.0   \n","\n","   category_Film & Video_Family  category_Film & Video_Fantasy  \\\n","0                           0.0                            0.0   \n","1                           0.0                            0.0   \n","2                           0.0                            0.0   \n","\n","   category_Film & Video_Festivals  category_Film & Video_Horror  \\\n","0                              0.0                           0.0   \n","1                              0.0                           0.0   \n","2                              0.0                           0.0   \n","\n","   category_Film & Video_Movie Theaters  category_Film & Video_Music Videos  \\\n","0                                   0.0                                 0.0   \n","1                                   0.0                                 0.0   \n","2                                   0.0                                 0.0   \n","\n","   category_Film & Video_Narrative Film  category_Film & Video_No Subcategory  \\\n","0                                   0.0                                   0.0   \n","1                                   0.0                                   0.0   \n","2                                   0.0                                   0.0   \n","\n","   category_Film & Video_Romance  category_Film & Video_Science Fiction  \\\n","0                            0.0                                    0.0   \n","1                            0.0                                    0.0   \n","2                            0.0                                    0.0   \n","\n","   category_Film & Video_Shorts  category_Film & Video_Television  \\\n","0                           0.0                               0.0   \n","1                           1.0                               0.0   \n","2                           0.0                               0.0   \n","\n","   category_Film & Video_Thrillers  category_Film & Video_Webseries  \\\n","0                              0.0                              0.0   \n","1                              0.0                              0.0   \n","2                              0.0                              0.0   \n","\n","   category_Food_Bacon  category_Food_Community Gardens  \\\n","0                  0.0                              0.0   \n","1                  0.0                              0.0   \n","2                  0.0                              0.0   \n","\n","   category_Food_Cookbooks  category_Food_Drinks  category_Food_Events  \\\n","0                      0.0                   0.0                   0.0   \n","1                      0.0                   0.0                   0.0   \n","2                      0.0                   0.0                   0.0   \n","\n","   category_Food_Farmer's Markets  category_Food_Farms  \\\n","0                             0.0                  0.0   \n","1                             0.0                  0.0   \n","2                             0.0                  0.0   \n","\n","   category_Food_Food Trucks  category_Food_No Subcategory  \\\n","0                        0.0                           0.0   \n","1                        0.0                           0.0   \n","2                        0.0                           0.0   \n","\n","   category_Food_Restaurants  category_Food_Small Batch  category_Food_Spaces  \\\n","0                        0.0                        0.0                   0.0   \n","1                        0.0                        0.0                   0.0   \n","2                        0.0                        0.0                   0.0   \n","\n","   category_Food_Vegan  category_Games_Gaming Hardware  \\\n","0                  0.0                             0.0   \n","1                  0.0                             0.0   \n","2                  0.0                             0.0   \n","\n","   category_Games_Live Games  category_Games_Mobile Games  \\\n","0                        0.0                          0.0   \n","1                        0.0                          0.0   \n","2                        0.0                          0.0   \n","\n","   category_Games_No Subcategory  category_Games_Playing Cards  \\\n","0                            0.0                           0.0   \n","1                            0.0                           0.0   \n","2                            0.0                           0.0   \n","\n","   category_Games_Puzzles  category_Games_Tabletop Games  \\\n","0                     0.0                            0.0   \n","1                     0.0                            0.0   \n","2                     0.0                            0.0   \n","\n","   category_Games_Video Games  category_Journalism_Audio  \\\n","0                         0.0                        0.0   \n","1                         0.0                        0.0   \n","2                         0.0                        0.0   \n","\n","   category_Journalism_No Subcategory  category_Journalism_Photo  \\\n","0                                 0.0                        0.0   \n","1                                 0.0                        0.0   \n","2                                 0.0                        0.0   \n","\n","   category_Journalism_Print  category_Journalism_Video  \\\n","0                        0.0                        0.0   \n","1                        0.0                        0.0   \n","2                        0.0                        0.0   \n","\n","   category_Journalism_Web  category_Music_Blues  category_Music_Chiptune  \\\n","0                      0.0                   0.0                      0.0   \n","1                      0.0                   0.0                      0.0   \n","2                      0.0                   0.0                      0.0   \n","\n","   category_Music_Classical Music  category_Music_Comedy  \\\n","0                             0.0                    0.0   \n","1                             0.0                    0.0   \n","2                             0.0                    0.0   \n","\n","   category_Music_Country & Folk  category_Music_Electronic Music  \\\n","0                            0.0                              0.0   \n","1                            0.0                              0.0   \n","2                            1.0                              0.0   \n","\n","   category_Music_Faith  category_Music_Hip-Hop  category_Music_Indie Rock  \\\n","0                   0.0                     0.0                        0.0   \n","1                   0.0                     0.0                        0.0   \n","2                   0.0                     0.0                        0.0   \n","\n","   category_Music_Jazz  category_Music_Kids  category_Music_Latin  \\\n","0                  0.0                  0.0                   0.0   \n","1                  0.0                  0.0                   0.0   \n","2                  0.0                  0.0                   0.0   \n","\n","   category_Music_Metal  category_Music_No Subcategory  category_Music_Pop  \\\n","0                   0.0                            0.0                 0.0   \n","1                   0.0                            0.0                 0.0   \n","2                   0.0                            0.0                 0.0   \n","\n","   category_Music_Punk  category_Music_R&B  category_Music_Rock  \\\n","0                  0.0                 0.0                  0.0   \n","1                  0.0                 0.0                  0.0   \n","2                  0.0                 0.0                  0.0   \n","\n","   category_Music_World Music  category_Photography_Animals  \\\n","0                         0.0                           0.0   \n","1                         0.0                           0.0   \n","2                         0.0                           0.0   \n","\n","   category_Photography_Fine Art  category_Photography_Nature  \\\n","0                            0.0                          0.0   \n","1                            0.0                          0.0   \n","2                            0.0                          0.0   \n","\n","   category_Photography_No Subcategory  category_Photography_People  \\\n","0                                  0.0                          0.0   \n","1                                  0.0                          0.0   \n","2                                  0.0                          0.0   \n","\n","   category_Photography_Photobooks  category_Photography_Places  \\\n","0                              0.0                          0.0   \n","1                              0.0                          0.0   \n","2                              0.0                          0.0   \n","\n","   category_Publishing_Academic  category_Publishing_Anthologies  \\\n","0                           0.0                              0.0   \n","1                           0.0                              0.0   \n","2                           0.0                              0.0   \n","\n","   category_Publishing_Art Books  category_Publishing_Calendars  \\\n","0                            0.0                            0.0   \n","1                            0.0                            0.0   \n","2                            0.0                            0.0   \n","\n","   category_Publishing_Children's Books  category_Publishing_Comedy  \\\n","0                                   0.0                         0.0   \n","1                                   0.0                         0.0   \n","2                                   0.0                         0.0   \n","\n","   category_Publishing_Fiction  category_Publishing_Letterpress  \\\n","0                          0.0                              0.0   \n","1                          0.0                              0.0   \n","2                          0.0                              0.0   \n","\n","   category_Publishing_Literary Journals  category_Publishing_Literary Spaces  \\\n","0                                    0.0                                  0.0   \n","1                                    0.0                                  0.0   \n","2                                    0.0                                  0.0   \n","\n","   category_Publishing_No Subcategory  category_Publishing_Nonfiction  \\\n","0                                 0.0                             0.0   \n","1                                 0.0                             0.0   \n","2                                 0.0                             0.0   \n","\n","   category_Publishing_Periodicals  category_Publishing_Poetry  \\\n","0                              0.0                         0.0   \n","1                              0.0                         0.0   \n","2                              0.0                         0.0   \n","\n","   category_Publishing_Radio & Podcasts  category_Publishing_Translations  \\\n","0                                   0.0                               0.0   \n","1                                   0.0                               0.0   \n","2                                   0.0                               0.0   \n","\n","   category_Publishing_Young Adult  category_Publishing_Zines  \\\n","0                              0.0                        0.0   \n","1                              0.0                        0.0   \n","2                              0.0                        0.0   \n","\n","   category_Technology_3D Printing  category_Technology_Apps  \\\n","0                              0.0                       0.0   \n","1                              0.0                       0.0   \n","2                              0.0                       0.0   \n","\n","   category_Technology_Camera Equipment  category_Technology_DIY Electronics  \\\n","0                                   0.0                                  0.0   \n","1                                   0.0                                  0.0   \n","2                                   0.0                                  0.0   \n","\n","   category_Technology_Fabrication Tools  category_Technology_Flight  \\\n","0                                    0.0                         0.0   \n","1                                    0.0                         0.0   \n","2                                    0.0                         0.0   \n","\n","   category_Technology_Gadgets  category_Technology_Hardware  \\\n","0                          0.0                           0.0   \n","1                          0.0                           0.0   \n","2                          0.0                           0.0   \n","\n","   category_Technology_Makerspaces  category_Technology_No Subcategory  \\\n","0                              0.0                                 0.0   \n","1                              0.0                                 0.0   \n","2                              0.0                                 0.0   \n","\n","   category_Technology_Robots  category_Technology_Software  \\\n","0                         0.0                           0.0   \n","1                         0.0                           0.0   \n","2                         0.0                           0.0   \n","\n","   category_Technology_Sound  category_Technology_Space Exploration  \\\n","0                        0.0                                    0.0   \n","1                        0.0                                    0.0   \n","2                        0.0                                    0.0   \n","\n","   category_Technology_Wearables  category_Technology_Web  \\\n","0                            0.0                      0.0   \n","1                            0.0                      0.0   \n","2                            0.0                      0.0   \n","\n","   category_Theater_Comedy  category_Theater_Experimental  \\\n","0                      0.0                            0.0   \n","1                      0.0                            0.0   \n","2                      0.0                            0.0   \n","\n","   category_Theater_Festivals  category_Theater_Immersive  \\\n","0                         0.0                         0.0   \n","1                         0.0                         0.0   \n","2                         0.0                         0.0   \n","\n","   category_Theater_Musical  category_Theater_No Subcategory  \\\n","0                       0.0                              0.0   \n","1                       0.0                              0.0   \n","2                       0.0                              0.0   \n","\n","   category_Theater_Plays  category_Theater_Spaces  \n","0                     0.0                      0.0  \n","1                     0.0                      0.0  \n","2                     0.0                      0.0  "]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"9lD8O0Fud4FF"},"source":["#### c) Test Different Model Hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"WrJZ92GieE7O"},"source":["##### New Baseline:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"697VsbVPsMJ1","executionInfo":{"status":"ok","timestamp":1611320682038,"user_tz":-60,"elapsed":150606,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"8e1631be-fbc9-4554-d40a-a8ff83d213c1"},"source":["model = Sequential()\n","model.add(Dense(233, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(l1=0.0000), kernel_initializer=GlorotNormal(seed=seed_value)))\n","model.compile(optimizer=RMSprop(centered=True), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=512, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=7, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.4835 - binary_accuracy: 0.7559 - val_loss: 0.4296 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4247 - binary_accuracy: 0.7943 - val_loss: 0.4297 - val_binary_accuracy: 0.7918\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4230 - binary_accuracy: 0.7963 - val_loss: 0.4270 - val_binary_accuracy: 0.7937\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4235 - binary_accuracy: 0.7963 - val_loss: 0.4259 - val_binary_accuracy: 0.7929\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4235 - binary_accuracy: 0.7960 - val_loss: 0.4255 - val_binary_accuracy: 0.7945\n","Epoch 6/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4214 - binary_accuracy: 0.7975 - val_loss: 0.4248 - val_binary_accuracy: 0.7955\n","Epoch 7/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4221 - binary_accuracy: 0.7954 - val_loss: 0.4238 - val_binary_accuracy: 0.7953\n","Epoch 8/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4221 - binary_accuracy: 0.7970 - val_loss: 0.4223 - val_binary_accuracy: 0.7966\n","Epoch 9/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4197 - binary_accuracy: 0.7980 - val_loss: 0.4229 - val_binary_accuracy: 0.7954\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4164 - binary_accuracy: 0.7999 - val_loss: 0.4213 - val_binary_accuracy: 0.7961\n","Epoch 11/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4170 - binary_accuracy: 0.7998 - val_loss: 0.4211 - val_binary_accuracy: 0.7961\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4163 - binary_accuracy: 0.8001 - val_loss: 0.4206 - val_binary_accuracy: 0.7956\n","Epoch 13/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4154 - binary_accuracy: 0.7992 - val_loss: 0.4204 - val_binary_accuracy: 0.7956\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4152 - binary_accuracy: 0.7993 - val_loss: 0.4183 - val_binary_accuracy: 0.7975\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4148 - binary_accuracy: 0.8006 - val_loss: 0.4202 - val_binary_accuracy: 0.7953\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4155 - binary_accuracy: 0.8004 - val_loss: 0.4180 - val_binary_accuracy: 0.7978\n","Epoch 17/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4092 - binary_accuracy: 0.8047 - val_loss: 0.4180 - val_binary_accuracy: 0.7963\n","Epoch 18/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4149 - binary_accuracy: 0.8006 - val_loss: 0.4160 - val_binary_accuracy: 0.7994\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4119 - binary_accuracy: 0.8022 - val_loss: 0.4148 - val_binary_accuracy: 0.8001\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4090 - binary_accuracy: 0.8033 - val_loss: 0.4166 - val_binary_accuracy: 0.7968\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4102 - binary_accuracy: 0.8034 - val_loss: 0.4132 - val_binary_accuracy: 0.8016\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4079 - binary_accuracy: 0.8041 - val_loss: 0.4174 - val_binary_accuracy: 0.7987\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4064 - binary_accuracy: 0.8060 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4070 - binary_accuracy: 0.8036 - val_loss: 0.4132 - val_binary_accuracy: 0.7997\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4047 - binary_accuracy: 0.8065 - val_loss: 0.4146 - val_binary_accuracy: 0.7982\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4064 - binary_accuracy: 0.8064 - val_loss: 0.4109 - val_binary_accuracy: 0.8020\n","Epoch 27/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4044 - binary_accuracy: 0.8068 - val_loss: 0.4107 - val_binary_accuracy: 0.8020\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4046 - binary_accuracy: 0.8060 - val_loss: 0.4102 - val_binary_accuracy: 0.8024\n","Epoch 29/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4040 - binary_accuracy: 0.8065 - val_loss: 0.4107 - val_binary_accuracy: 0.8007\n","Epoch 30/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4040 - binary_accuracy: 0.8064 - val_loss: 0.4091 - val_binary_accuracy: 0.8030\n","Epoch 31/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4039 - binary_accuracy: 0.8070 - val_loss: 0.4090 - val_binary_accuracy: 0.8029\n","Epoch 32/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4014 - binary_accuracy: 0.8075 - val_loss: 0.4087 - val_binary_accuracy: 0.8032\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3996 - binary_accuracy: 0.8102 - val_loss: 0.4082 - val_binary_accuracy: 0.8036\n","Epoch 34/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4011 - binary_accuracy: 0.8087 - val_loss: 0.4084 - val_binary_accuracy: 0.8034\n","Epoch 35/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4011 - binary_accuracy: 0.8080 - val_loss: 0.4085 - val_binary_accuracy: 0.8030\n","Epoch 36/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3998 - binary_accuracy: 0.8098 - val_loss: 0.4072 - val_binary_accuracy: 0.8038\n","Epoch 37/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4005 - binary_accuracy: 0.8092 - val_loss: 0.4083 - val_binary_accuracy: 0.8021\n","Epoch 38/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4006 - binary_accuracy: 0.8093 - val_loss: 0.4083 - val_binary_accuracy: 0.8022\n","Epoch 39/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3982 - binary_accuracy: 0.8098 - val_loss: 0.4066 - val_binary_accuracy: 0.8027\n","Epoch 40/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3949 - binary_accuracy: 0.8125 - val_loss: 0.4066 - val_binary_accuracy: 0.8034\n","Epoch 41/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3972 - binary_accuracy: 0.8113 - val_loss: 0.4067 - val_binary_accuracy: 0.8032\n","Epoch 42/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3966 - binary_accuracy: 0.8118 - val_loss: 0.4066 - val_binary_accuracy: 0.8038\n","Epoch 43/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3972 - binary_accuracy: 0.8108 - val_loss: 0.4062 - val_binary_accuracy: 0.8030\n","Epoch 44/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3953 - binary_accuracy: 0.8129 - val_loss: 0.4062 - val_binary_accuracy: 0.8028\n","Epoch 45/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3935 - binary_accuracy: 0.8137 - val_loss: 0.4055 - val_binary_accuracy: 0.8035\n","Epoch 46/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3952 - binary_accuracy: 0.8117 - val_loss: 0.4066 - val_binary_accuracy: 0.8034\n","Epoch 47/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3918 - binary_accuracy: 0.8148 - val_loss: 0.4060 - val_binary_accuracy: 0.8037\n","Epoch 48/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3923 - binary_accuracy: 0.8145 - val_loss: 0.4059 - val_binary_accuracy: 0.8025\n","Epoch 49/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3928 - binary_accuracy: 0.8131 - val_loss: 0.4052 - val_binary_accuracy: 0.8040\n","Epoch 50/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3941 - binary_accuracy: 0.8128 - val_loss: 0.4058 - val_binary_accuracy: 0.8039\n","Epoch 51/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3932 - binary_accuracy: 0.8132 - val_loss: 0.4053 - val_binary_accuracy: 0.8045\n","Epoch 52/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3905 - binary_accuracy: 0.8148 - val_loss: 0.4092 - val_binary_accuracy: 0.8014\n","Epoch 53/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3899 - binary_accuracy: 0.8151 - val_loss: 0.4057 - val_binary_accuracy: 0.8046\n","Epoch 54/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3893 - binary_accuracy: 0.8155 - val_loss: 0.4049 - val_binary_accuracy: 0.8039\n","Epoch 55/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3897 - binary_accuracy: 0.8151 - val_loss: 0.4051 - val_binary_accuracy: 0.8047\n","Epoch 56/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3912 - binary_accuracy: 0.8151 - val_loss: 0.4049 - val_binary_accuracy: 0.8048\n","Epoch 57/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3904 - binary_accuracy: 0.8149 - val_loss: 0.4051 - val_binary_accuracy: 0.8042\n","Epoch 58/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3890 - binary_accuracy: 0.8160 - val_loss: 0.4055 - val_binary_accuracy: 0.8045\n","Epoch 59/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.3872 - binary_accuracy: 0.8171 - val_loss: 0.4052 - val_binary_accuracy: 0.8054\n","Epoch 60/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3873 - binary_accuracy: 0.8166 - val_loss: 0.4050 - val_binary_accuracy: 0.8047\n","Epoch 61/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3880 - binary_accuracy: 0.8176 - val_loss: 0.4052 - val_binary_accuracy: 0.8040\n","Epoch 62/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3865 - binary_accuracy: 0.8182 - val_loss: 0.4053 - val_binary_accuracy: 0.8039\n","Epoch 63/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3864 - binary_accuracy: 0.8176 - val_loss: 0.4051 - val_binary_accuracy: 0.8041\n","Epoch 64/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3882 - binary_accuracy: 0.8178 - val_loss: 0.4097 - val_binary_accuracy: 0.8020\n","Epoch 65/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3857 - binary_accuracy: 0.8184 - val_loss: 0.4060 - val_binary_accuracy: 0.8038\n","Epoch 66/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.3827 - binary_accuracy: 0.8195 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Training Accuracy: 0.817\n","Validation Accuracy: 0.805\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SzCe_hLXerWi"},"source":["Fixed Hyperparameters:\n","- Dataset Transformation = PowerTransform + PCA Numerical Features; No Changes at Binary Features\n","- Loss Function = Binary Crossentropy (Recommended for Binary Classification)\n","- Learning Rate / Learning Rate Annealing = not necessary to tune, since I am using only adaptive learning rate optimizers\n","- Number of Epochs = tuned via Early Stopping\n","\n","Tunable Hyperparameters:\n","- Optimizers = RMSprop, RMSprop_centered, Adam, Adam_amsgrad, Adamax, Nadam\n","- Mini-Batch Size = can be tuned independently from other hyperparameters and then be held fixed, since it mainly affects the convergence time and not the predictive performance (Bengio 2012)\n","- Regularizer = L1, L2 (L2 penalizes larger weights more strongly, whereas L1 penalizes lower weights more strongly; L1 performs automatic feature selection)\n","- Regularization Rate (start with defaul and increase/decrease by factor 10)\n","- Weight Initializer = typically, a clipped-off initializer, such as Glorot, is used\n","- Number of Layers\n","- Number of Hidden Units\n","- Activation Function\n","- Different Types of Regularization (e.g. Dropout, Batch Normalization, Gaussian Noise, Layer Normalization)\n"]},{"cell_type":"markdown","metadata":{"id":"5qVnuB1FeNh8"},"source":["##### Perform Random Search - Iteration 1 To Get First Insights Which Hyperparameter Combinations Perform Best:"]},{"cell_type":"code","metadata":{"id":"5jpeOis4sMF3"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","  if regularization==\"L2\":\n","     reg_rate = params[\"reg_rate\"]\n","  else:\n","    reg_rate=0\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init, kernel_regularizer=L2(reg_rate)))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if regularization==\"batch_normalization\":\n","      model.add(BatchNormalization())\n","    \n","    if regularization==\"layer_normalization\":\n","      model.add(LayerNormalization())\n","    \n","    if regularization==\"gaussian_noise\":\n","      model.add(GaussianNoise(stddev=1))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = number_of_units * network_decay\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L2(l2=reg_rate), kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEExy7hpsMAP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a07182aa-89f6-4a1d-dc02-3ed015d48312"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [1, 2, 3, 5, 10],\n","    \"number_of_units_first_layer\" : [5, 10, 30, 50, 100, 150, 233, 300, 500],\n","    \"network_shape\" : [\"brick\", \"triangle\"],\n","    \"network_decay\" : [0.3, 0.5, 0.7],\n","    \"activation_function\" : [\"sigmoid\", \"tanh\", \"relu\", \"elu\", \"gelu\", \"selu\", \"swish\"],\n","    \"regularization\" : [\"L2\", \"dropout\", \"batch_normalization\", \"layer_normalization\", \"gaussian_noise\"],\n","    \"optimizer\" : [\"RMSprop\", \"RMSprop_centered\", \"Adam\", \"Adam_amsgrad\", \"Adamax\", \"Nadam\"],\n","    \"reg_rate\" : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n","    \"weight_initializer\" : [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\", \"lecun_normal\", \"lecun_uniform\"],\n","    \"batch_size\" : [128, 256, 512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params, fraction_limit=0.00001,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop_centered', 'reg_rate': 0.01, 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 17s 46ms/step - loss: 0.4571 - binary_accuracy: 0.7715 - val_loss: 0.4219 - val_binary_accuracy: 0.7965\n","Epoch 2/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4230 - binary_accuracy: 0.7965 - val_loss: 0.4179 - val_binary_accuracy: 0.7991\n","Epoch 3/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4185 - binary_accuracy: 0.8010 - val_loss: 0.4145 - val_binary_accuracy: 0.8009\n","Epoch 4/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4160 - binary_accuracy: 0.8021 - val_loss: 0.4117 - val_binary_accuracy: 0.8005\n","Epoch 5/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4149 - binary_accuracy: 0.8020 - val_loss: 0.4113 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4126 - binary_accuracy: 0.8046 - val_loss: 0.4091 - val_binary_accuracy: 0.8031\n","Epoch 7/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4117 - binary_accuracy: 0.8034 - val_loss: 0.4109 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4112 - binary_accuracy: 0.8046 - val_loss: 0.4078 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4085 - binary_accuracy: 0.8070 - val_loss: 0.4084 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4060 - binary_accuracy: 0.8087 - val_loss: 0.4085 - val_binary_accuracy: 0.8041\n","Epoch 11/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4065 - binary_accuracy: 0.8094 - val_loss: 0.4071 - val_binary_accuracy: 0.8044\n","Epoch 12/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4046 - binary_accuracy: 0.8089 - val_loss: 0.4072 - val_binary_accuracy: 0.8054\n","Epoch 13/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4037 - binary_accuracy: 0.8092 - val_loss: 0.4086 - val_binary_accuracy: 0.8036\n","Epoch 14/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4028 - binary_accuracy: 0.8085 - val_loss: 0.4063 - val_binary_accuracy: 0.8061\n","Epoch 15/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4023 - binary_accuracy: 0.8104 - val_loss: 0.4071 - val_binary_accuracy: 0.8053\n","Epoch 16/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4045 - binary_accuracy: 0.8097 - val_loss: 0.4138 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3984 - binary_accuracy: 0.8132 - val_loss: 0.4077 - val_binary_accuracy: 0.8035\n","Epoch 18/100\n","338/338 [==============================] - 15s 46ms/step - loss: 0.4023 - binary_accuracy: 0.8122 - val_loss: 0.4064 - val_binary_accuracy: 0.8055\n","Epoch 19/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4008 - binary_accuracy: 0.8104 - val_loss: 0.4078 - val_binary_accuracy: 0.8055\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  1%|         | 1/71 [04:47<5:35:19, 287.43s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 128, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 5, 'optimizer': 'RMSprop', 'reg_rate': 0.01, 'regularization': 'L2', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6878 - binary_accuracy: 0.6496 - val_loss: 0.6571 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6531 - binary_accuracy: 0.6534 - val_loss: 0.6504 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6491 - binary_accuracy: 0.6512 - val_loss: 0.6485 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6503 - val_loss: 0.6478 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6497 - val_loss: 0.6475 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6493 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  3%|         | 2/71 [05:01<3:56:16, 205.45s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'reg_rate': 0.0001, 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 43s 60ms/step - loss: 0.4850 - binary_accuracy: 0.7667 - val_loss: 0.4427 - val_binary_accuracy: 0.7833\n","Epoch 2/100\n","676/676 [==============================] - 40s 58ms/step - loss: 0.4243 - binary_accuracy: 0.7954 - val_loss: 0.4266 - val_binary_accuracy: 0.7934\n","Epoch 3/100\n","676/676 [==============================] - 40s 59ms/step - loss: 0.4153 - binary_accuracy: 0.8015 - val_loss: 0.4211 - val_binary_accuracy: 0.7951\n","Epoch 4/100\n","676/676 [==============================] - 41s 60ms/step - loss: 0.4106 - binary_accuracy: 0.8032 - val_loss: 0.4174 - val_binary_accuracy: 0.7990\n","Epoch 5/100\n","676/676 [==============================] - 40s 60ms/step - loss: 0.4043 - binary_accuracy: 0.8070 - val_loss: 0.4123 - val_binary_accuracy: 0.7997\n","Epoch 6/100\n","676/676 [==============================] - 40s 59ms/step - loss: 0.3964 - binary_accuracy: 0.8120 - val_loss: 0.4124 - val_binary_accuracy: 0.7997\n","Epoch 7/100\n","676/676 [==============================] - 40s 59ms/step - loss: 0.3913 - binary_accuracy: 0.8130 - val_loss: 0.4128 - val_binary_accuracy: 0.7991\n","Epoch 8/100\n","676/676 [==============================] - 41s 60ms/step - loss: 0.3861 - binary_accuracy: 0.8164 - val_loss: 0.4149 - val_binary_accuracy: 0.7996\n","Epoch 9/100\n","676/676 [==============================] - 40s 59ms/step - loss: 0.3779 - binary_accuracy: 0.8211 - val_loss: 0.4248 - val_binary_accuracy: 0.7925\n","Epoch 10/100\n","676/676 [==============================] - 40s 59ms/step - loss: 0.3670 - binary_accuracy: 0.8273 - val_loss: 0.4202 - val_binary_accuracy: 0.7988\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  4%|         | 3/71 [11:46<5:00:29, 265.14s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 300, 'optimizer': 'Adam', 'reg_rate': 10, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.5779 - binary_accuracy: 0.7234 - val_loss: 0.4459 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4487 - binary_accuracy: 0.7833 - val_loss: 0.4367 - val_binary_accuracy: 0.7898\n","Epoch 3/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4394 - binary_accuracy: 0.7885 - val_loss: 0.4270 - val_binary_accuracy: 0.7947\n","Epoch 4/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4363 - binary_accuracy: 0.7882 - val_loss: 0.4263 - val_binary_accuracy: 0.7963\n","Epoch 5/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4334 - binary_accuracy: 0.7901 - val_loss: 0.4239 - val_binary_accuracy: 0.7954\n","Epoch 6/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4300 - binary_accuracy: 0.7917 - val_loss: 0.4217 - val_binary_accuracy: 0.7963\n","Epoch 7/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4308 - binary_accuracy: 0.7902 - val_loss: 0.4243 - val_binary_accuracy: 0.7953\n","Epoch 8/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4293 - binary_accuracy: 0.7934 - val_loss: 0.4219 - val_binary_accuracy: 0.7965\n","Epoch 9/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4279 - binary_accuracy: 0.7935 - val_loss: 0.4189 - val_binary_accuracy: 0.7977\n","Epoch 10/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4230 - binary_accuracy: 0.7964 - val_loss: 0.4178 - val_binary_accuracy: 0.7995\n","Epoch 11/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4236 - binary_accuracy: 0.7958 - val_loss: 0.4184 - val_binary_accuracy: 0.7991\n","Epoch 12/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4239 - binary_accuracy: 0.7952 - val_loss: 0.4187 - val_binary_accuracy: 0.7979\n","Epoch 13/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4222 - binary_accuracy: 0.7960 - val_loss: 0.4175 - val_binary_accuracy: 0.7986\n","Epoch 14/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4228 - binary_accuracy: 0.7966 - val_loss: 0.4178 - val_binary_accuracy: 0.7998\n","Epoch 15/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4210 - binary_accuracy: 0.7985 - val_loss: 0.4172 - val_binary_accuracy: 0.7993\n","Epoch 16/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4226 - binary_accuracy: 0.7972 - val_loss: 0.4163 - val_binary_accuracy: 0.8005\n","Epoch 17/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4161 - binary_accuracy: 0.8009 - val_loss: 0.4164 - val_binary_accuracy: 0.7992\n","Epoch 18/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4216 - binary_accuracy: 0.7987 - val_loss: 0.4157 - val_binary_accuracy: 0.8011\n","Epoch 19/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4193 - binary_accuracy: 0.7980 - val_loss: 0.4143 - val_binary_accuracy: 0.8008\n","Epoch 20/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4168 - binary_accuracy: 0.7992 - val_loss: 0.4175 - val_binary_accuracy: 0.7997\n","Epoch 21/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4180 - binary_accuracy: 0.8003 - val_loss: 0.4135 - val_binary_accuracy: 0.8011\n","Epoch 22/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4155 - binary_accuracy: 0.7998 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 23/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4138 - binary_accuracy: 0.8012 - val_loss: 0.4139 - val_binary_accuracy: 0.8008\n","Epoch 24/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4160 - binary_accuracy: 0.7996 - val_loss: 0.4129 - val_binary_accuracy: 0.8012\n","Epoch 25/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4139 - binary_accuracy: 0.8001 - val_loss: 0.4135 - val_binary_accuracy: 0.8015\n","Epoch 26/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4142 - binary_accuracy: 0.8028 - val_loss: 0.4122 - val_binary_accuracy: 0.8027\n","Epoch 27/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4138 - binary_accuracy: 0.8009 - val_loss: 0.4132 - val_binary_accuracy: 0.8010\n","Epoch 28/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4121 - binary_accuracy: 0.8036 - val_loss: 0.4128 - val_binary_accuracy: 0.8019\n","Epoch 29/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4125 - binary_accuracy: 0.8019 - val_loss: 0.4126 - val_binary_accuracy: 0.8016\n","Epoch 30/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4138 - binary_accuracy: 0.8009 - val_loss: 0.4117 - val_binary_accuracy: 0.8016\n","Epoch 31/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4132 - binary_accuracy: 0.8024 - val_loss: 0.4119 - val_binary_accuracy: 0.8017\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  6%|         | 4/71 [15:09<4:35:22, 246.60s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 10, 'optimizer': 'Nadam', 'reg_rate': 1, 'regularization': 'L2', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 15.7223 - binary_accuracy: 0.6142 - val_loss: 2.1529 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 1.5815 - binary_accuracy: 0.6533 - val_loss: 0.7657 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.7145 - binary_accuracy: 0.6513 - val_loss: 0.6527 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6501 - binary_accuracy: 0.6503 - val_loss: 0.6475 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6477 - binary_accuracy: 0.6496 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6493 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  7%|         | 5/71 [15:16<3:12:15, 174.78s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 128, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 150, 'optimizer': 'Nadam', 'reg_rate': 0.0001, 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","1351/1351 [==============================] - 9s 5ms/step - loss: 0.4559 - binary_accuracy: 0.7765 - val_loss: 0.4251 - val_binary_accuracy: 0.7948\n","Epoch 2/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4146 - binary_accuracy: 0.7992 - val_loss: 0.4177 - val_binary_accuracy: 0.7976\n","Epoch 3/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4064 - binary_accuracy: 0.8068 - val_loss: 0.4161 - val_binary_accuracy: 0.7969\n","Epoch 4/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4032 - binary_accuracy: 0.8060 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3965 - binary_accuracy: 0.8105 - val_loss: 0.4107 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3891 - binary_accuracy: 0.8167 - val_loss: 0.4114 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3869 - binary_accuracy: 0.8167 - val_loss: 0.4155 - val_binary_accuracy: 0.7988\n","Epoch 8/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3823 - binary_accuracy: 0.8189 - val_loss: 0.4179 - val_binary_accuracy: 0.7995\n","Epoch 9/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3768 - binary_accuracy: 0.8226 - val_loss: 0.4205 - val_binary_accuracy: 0.7982\n","Epoch 10/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3679 - binary_accuracy: 0.8268 - val_loss: 0.4222 - val_binary_accuracy: 0.7967\n","Epoch 11/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3636 - binary_accuracy: 0.8308 - val_loss: 0.4271 - val_binary_accuracy: 0.7963\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  8%|         | 6/71 [16:33<2:37:35, 145.47s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 10, 'number_of_units_first_layer': 100, 'optimizer': 'Adam_amsgrad', 'reg_rate': 0.01, 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 29ms/step - loss: 0.4867 - binary_accuracy: 0.7630 - val_loss: 0.4219 - val_binary_accuracy: 0.7966\n","Epoch 2/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4151 - binary_accuracy: 0.7997 - val_loss: 0.4182 - val_binary_accuracy: 0.7987\n","Epoch 3/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4085 - binary_accuracy: 0.8045 - val_loss: 0.4241 - val_binary_accuracy: 0.7889\n","Epoch 4/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4069 - binary_accuracy: 0.8054 - val_loss: 0.4151 - val_binary_accuracy: 0.7997\n","Epoch 5/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4033 - binary_accuracy: 0.8070 - val_loss: 0.4111 - val_binary_accuracy: 0.8017\n","Epoch 6/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3973 - binary_accuracy: 0.8109 - val_loss: 0.4081 - val_binary_accuracy: 0.8024\n","Epoch 7/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3970 - binary_accuracy: 0.8102 - val_loss: 0.4103 - val_binary_accuracy: 0.8039\n","Epoch 8/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3946 - binary_accuracy: 0.8122 - val_loss: 0.4105 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3916 - binary_accuracy: 0.8137 - val_loss: 0.4115 - val_binary_accuracy: 0.8010\n","Epoch 10/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3851 - binary_accuracy: 0.8176 - val_loss: 0.4115 - val_binary_accuracy: 0.8010\n","Epoch 11/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3841 - binary_accuracy: 0.8181 - val_loss: 0.4111 - val_binary_accuracy: 0.8019\n","Epoch 12/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3820 - binary_accuracy: 0.8187 - val_loss: 0.4155 - val_binary_accuracy: 0.8029\n","Epoch 13/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3784 - binary_accuracy: 0.8200 - val_loss: 0.4179 - val_binary_accuracy: 0.8020\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 10%|         | 7/71 [18:42<2:29:50, 140.48s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Nadam', 'reg_rate': 1, 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.8629 - binary_accuracy: 0.7360 - val_loss: 0.4393 - val_binary_accuracy: 0.7898\n","Epoch 2/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4235 - binary_accuracy: 0.7957 - val_loss: 0.4252 - val_binary_accuracy: 0.7949\n","Epoch 3/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4180 - binary_accuracy: 0.8005 - val_loss: 0.4320 - val_binary_accuracy: 0.7893\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4160 - binary_accuracy: 0.8012 - val_loss: 0.4190 - val_binary_accuracy: 0.7964\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4131 - binary_accuracy: 0.8021 - val_loss: 0.4136 - val_binary_accuracy: 0.7991\n","Epoch 6/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4085 - binary_accuracy: 0.8049 - val_loss: 0.4115 - val_binary_accuracy: 0.8016\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4074 - binary_accuracy: 0.8038 - val_loss: 0.4119 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4071 - binary_accuracy: 0.8062 - val_loss: 0.4103 - val_binary_accuracy: 0.8014\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4049 - binary_accuracy: 0.8061 - val_loss: 0.4099 - val_binary_accuracy: 0.8019\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4002 - binary_accuracy: 0.8086 - val_loss: 0.4093 - val_binary_accuracy: 0.8008\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3998 - binary_accuracy: 0.8097 - val_loss: 0.4084 - val_binary_accuracy: 0.8025\n","Epoch 12/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3981 - binary_accuracy: 0.8095 - val_loss: 0.4081 - val_binary_accuracy: 0.8013\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3977 - binary_accuracy: 0.8095 - val_loss: 0.4090 - val_binary_accuracy: 0.8025\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3968 - binary_accuracy: 0.8097 - val_loss: 0.4083 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3958 - binary_accuracy: 0.8121 - val_loss: 0.4082 - val_binary_accuracy: 0.8023\n","Epoch 16/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3951 - binary_accuracy: 0.8123 - val_loss: 0.4082 - val_binary_accuracy: 0.8027\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3891 - binary_accuracy: 0.8156 - val_loss: 0.4084 - val_binary_accuracy: 0.8011\n","Epoch 18/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3946 - binary_accuracy: 0.8137 - val_loss: 0.4062 - val_binary_accuracy: 0.8032\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3920 - binary_accuracy: 0.8146 - val_loss: 0.4091 - val_binary_accuracy: 0.8019\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3877 - binary_accuracy: 0.8166 - val_loss: 0.4109 - val_binary_accuracy: 0.8010\n","Epoch 21/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3903 - binary_accuracy: 0.8153 - val_loss: 0.4065 - val_binary_accuracy: 0.8030\n","Epoch 22/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3862 - binary_accuracy: 0.8170 - val_loss: 0.4095 - val_binary_accuracy: 0.8003\n","Epoch 23/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3836 - binary_accuracy: 0.8186 - val_loss: 0.4086 - val_binary_accuracy: 0.8015\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 11%|        | 8/71 [19:53<2:05:30, 119.53s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'reg_rate': 10, 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 40ms/step - loss: 0.5244 - binary_accuracy: 0.7483 - val_loss: 0.4292 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4327 - binary_accuracy: 0.7906 - val_loss: 0.4325 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4265 - binary_accuracy: 0.7959 - val_loss: 0.4227 - val_binary_accuracy: 0.7959\n","Epoch 4/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4260 - binary_accuracy: 0.7964 - val_loss: 0.4205 - val_binary_accuracy: 0.7946\n","Epoch 5/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4244 - binary_accuracy: 0.7964 - val_loss: 0.4175 - val_binary_accuracy: 0.7999\n","Epoch 6/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4215 - binary_accuracy: 0.7981 - val_loss: 0.4158 - val_binary_accuracy: 0.7990\n","Epoch 7/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4215 - binary_accuracy: 0.7981 - val_loss: 0.4219 - val_binary_accuracy: 0.7995\n","Epoch 8/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4214 - binary_accuracy: 0.7980 - val_loss: 0.4152 - val_binary_accuracy: 0.7993\n","Epoch 9/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4188 - binary_accuracy: 0.8004 - val_loss: 0.4176 - val_binary_accuracy: 0.7981\n","Epoch 10/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4163 - binary_accuracy: 0.8016 - val_loss: 0.4171 - val_binary_accuracy: 0.7999\n","Epoch 11/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4189 - binary_accuracy: 0.8009 - val_loss: 0.4148 - val_binary_accuracy: 0.7988\n","Epoch 12/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4167 - binary_accuracy: 0.8019 - val_loss: 0.4177 - val_binary_accuracy: 0.8002\n","Epoch 13/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4168 - binary_accuracy: 0.8005 - val_loss: 0.4155 - val_binary_accuracy: 0.7988\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4157 - binary_accuracy: 0.8010 - val_loss: 0.4141 - val_binary_accuracy: 0.8001\n","Epoch 15/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4156 - binary_accuracy: 0.8020 - val_loss: 0.4135 - val_binary_accuracy: 0.8012\n","Epoch 16/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4176 - binary_accuracy: 0.8008 - val_loss: 0.4208 - val_binary_accuracy: 0.8016\n","Epoch 17/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4116 - binary_accuracy: 0.8057 - val_loss: 0.4211 - val_binary_accuracy: 0.7954\n","Epoch 18/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4166 - binary_accuracy: 0.8018 - val_loss: 0.4117 - val_binary_accuracy: 0.8022\n","Epoch 19/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4156 - binary_accuracy: 0.8015 - val_loss: 0.4136 - val_binary_accuracy: 0.8006\n","Epoch 20/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4132 - binary_accuracy: 0.8047 - val_loss: 0.4177 - val_binary_accuracy: 0.7994\n","Epoch 21/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4136 - binary_accuracy: 0.8047 - val_loss: 0.4116 - val_binary_accuracy: 0.8019\n","Epoch 22/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4125 - binary_accuracy: 0.8041 - val_loss: 0.4145 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4109 - binary_accuracy: 0.8052 - val_loss: 0.4230 - val_binary_accuracy: 0.8025\n","Epoch 24/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4134 - binary_accuracy: 0.8036 - val_loss: 0.4126 - val_binary_accuracy: 0.7999\n","Epoch 25/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4115 - binary_accuracy: 0.8044 - val_loss: 0.4143 - val_binary_accuracy: 0.8007\n","Epoch 26/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4130 - binary_accuracy: 0.8043 - val_loss: 0.4116 - val_binary_accuracy: 0.8029\n","Epoch 27/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4122 - binary_accuracy: 0.8050 - val_loss: 0.4098 - val_binary_accuracy: 0.8027\n","Epoch 28/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4124 - binary_accuracy: 0.8032 - val_loss: 0.4113 - val_binary_accuracy: 0.8016\n","Epoch 29/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4129 - binary_accuracy: 0.8038 - val_loss: 0.4140 - val_binary_accuracy: 0.8017\n","Epoch 30/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4133 - binary_accuracy: 0.8032 - val_loss: 0.4119 - val_binary_accuracy: 0.8037\n","Epoch 31/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4125 - binary_accuracy: 0.8040 - val_loss: 0.4136 - val_binary_accuracy: 0.8023\n","Epoch 32/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4102 - binary_accuracy: 0.8060 - val_loss: 0.4124 - val_binary_accuracy: 0.8020\n","Epoch 33/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4102 - binary_accuracy: 0.8068 - val_loss: 0.4118 - val_binary_accuracy: 0.8036\n","Epoch 34/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4118 - binary_accuracy: 0.8045 - val_loss: 0.4106 - val_binary_accuracy: 0.8022\n","Epoch 35/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4118 - binary_accuracy: 0.8035 - val_loss: 0.4130 - val_binary_accuracy: 0.8041\n","Epoch 36/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4111 - binary_accuracy: 0.8043 - val_loss: 0.4107 - val_binary_accuracy: 0.8019\n","Epoch 37/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4132 - binary_accuracy: 0.8042 - val_loss: 0.4126 - val_binary_accuracy: 0.7998\n","Epoch 38/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4140 - binary_accuracy: 0.8045 - val_loss: 0.4105 - val_binary_accuracy: 0.8041\n","Epoch 39/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4108 - binary_accuracy: 0.8053 - val_loss: 0.4097 - val_binary_accuracy: 0.8032\n","Epoch 40/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4089 - binary_accuracy: 0.8079 - val_loss: 0.4096 - val_binary_accuracy: 0.8027\n","Epoch 41/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4104 - binary_accuracy: 0.8058 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 42/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4106 - binary_accuracy: 0.8072 - val_loss: 0.4134 - val_binary_accuracy: 0.8046\n","Epoch 43/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4115 - binary_accuracy: 0.8057 - val_loss: 0.4095 - val_binary_accuracy: 0.8030\n","Epoch 44/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4107 - binary_accuracy: 0.8054 - val_loss: 0.4086 - val_binary_accuracy: 0.8029\n","Epoch 45/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4088 - binary_accuracy: 0.8072 - val_loss: 0.4083 - val_binary_accuracy: 0.8043\n","Epoch 46/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4115 - binary_accuracy: 0.8065 - val_loss: 0.4118 - val_binary_accuracy: 0.8027\n","Epoch 47/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4082 - binary_accuracy: 0.8076 - val_loss: 0.4090 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 13%|        | 9/71 [30:32<4:44:38, 275.45s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'reg_rate': 0.01, 'regularization': 'gaussian_noise', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 4s 4ms/step - loss: 0.6123 - binary_accuracy: 0.6724 - val_loss: 0.4367 - val_binary_accuracy: 0.7887\n","Epoch 2/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4423 - binary_accuracy: 0.7824 - val_loss: 0.4292 - val_binary_accuracy: 0.7897\n","Epoch 3/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4337 - binary_accuracy: 0.7889 - val_loss: 0.4256 - val_binary_accuracy: 0.7935\n","Epoch 4/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4298 - binary_accuracy: 0.7924 - val_loss: 0.4263 - val_binary_accuracy: 0.7947\n","Epoch 5/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4271 - binary_accuracy: 0.7933 - val_loss: 0.4224 - val_binary_accuracy: 0.7956\n","Epoch 6/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4235 - binary_accuracy: 0.7954 - val_loss: 0.4203 - val_binary_accuracy: 0.7961\n","Epoch 7/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4247 - binary_accuracy: 0.7940 - val_loss: 0.4227 - val_binary_accuracy: 0.7961\n","Epoch 8/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4249 - binary_accuracy: 0.7938 - val_loss: 0.4242 - val_binary_accuracy: 0.7967\n","Epoch 9/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4227 - binary_accuracy: 0.7953 - val_loss: 0.4204 - val_binary_accuracy: 0.7958\n","Epoch 10/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4186 - binary_accuracy: 0.7983 - val_loss: 0.4191 - val_binary_accuracy: 0.7961\n","Epoch 11/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4204 - binary_accuracy: 0.7979 - val_loss: 0.4211 - val_binary_accuracy: 0.7969\n","Epoch 12/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4193 - binary_accuracy: 0.7969 - val_loss: 0.4220 - val_binary_accuracy: 0.7964\n","Epoch 13/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4183 - binary_accuracy: 0.7966 - val_loss: 0.4193 - val_binary_accuracy: 0.7971\n","Epoch 14/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4190 - binary_accuracy: 0.7969 - val_loss: 0.4190 - val_binary_accuracy: 0.7979\n","Epoch 15/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4183 - binary_accuracy: 0.7972 - val_loss: 0.4187 - val_binary_accuracy: 0.7974\n","Epoch 16/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4194 - binary_accuracy: 0.7975 - val_loss: 0.4233 - val_binary_accuracy: 0.7968\n","Epoch 17/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4139 - binary_accuracy: 0.8019 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 18/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4202 - binary_accuracy: 0.7969 - val_loss: 0.4186 - val_binary_accuracy: 0.7983\n","Epoch 19/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4173 - binary_accuracy: 0.7989 - val_loss: 0.4196 - val_binary_accuracy: 0.7976\n","Epoch 20/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4146 - binary_accuracy: 0.8008 - val_loss: 0.4197 - val_binary_accuracy: 0.7965\n","Epoch 21/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4159 - binary_accuracy: 0.8006 - val_loss: 0.4169 - val_binary_accuracy: 0.7984\n","Epoch 22/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4136 - binary_accuracy: 0.8001 - val_loss: 0.4198 - val_binary_accuracy: 0.7970\n","Epoch 23/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4135 - binary_accuracy: 0.8012 - val_loss: 0.4171 - val_binary_accuracy: 0.7970\n","Epoch 24/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4143 - binary_accuracy: 0.7997 - val_loss: 0.4167 - val_binary_accuracy: 0.7980\n","Epoch 25/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4117 - binary_accuracy: 0.8011 - val_loss: 0.4146 - val_binary_accuracy: 0.7992\n","Epoch 26/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4136 - binary_accuracy: 0.8020 - val_loss: 0.4157 - val_binary_accuracy: 0.7995\n","Epoch 27/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4121 - binary_accuracy: 0.8023 - val_loss: 0.4161 - val_binary_accuracy: 0.7996\n","Epoch 28/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4129 - binary_accuracy: 0.8026 - val_loss: 0.4140 - val_binary_accuracy: 0.8005\n","Epoch 29/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4124 - binary_accuracy: 0.8017 - val_loss: 0.4188 - val_binary_accuracy: 0.7986\n","Epoch 30/100\n","676/676 [==============================] - 3s 5ms/step - loss: 0.4131 - binary_accuracy: 0.8015 - val_loss: 0.4154 - val_binary_accuracy: 0.7996\n","Epoch 31/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4125 - binary_accuracy: 0.8008 - val_loss: 0.4166 - val_binary_accuracy: 0.7993\n","Epoch 32/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4106 - binary_accuracy: 0.8034 - val_loss: 0.4157 - val_binary_accuracy: 0.8000\n","Epoch 33/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4090 - binary_accuracy: 0.8042 - val_loss: 0.4134 - val_binary_accuracy: 0.8005\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 14%|        | 10/71 [32:12<3:46:33, 222.84s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 10, 'optimizer': 'Adamax', 'reg_rate': 0.0001, 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 2s 2ms/step - loss: 0.5261 - binary_accuracy: 0.7355 - val_loss: 0.4326 - val_binary_accuracy: 0.7921\n","Epoch 2/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4271 - binary_accuracy: 0.7926 - val_loss: 0.4280 - val_binary_accuracy: 0.7929\n","Epoch 3/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4242 - binary_accuracy: 0.7961 - val_loss: 0.4274 - val_binary_accuracy: 0.7944\n","Epoch 4/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4251 - binary_accuracy: 0.7956 - val_loss: 0.4271 - val_binary_accuracy: 0.7927\n","Epoch 5/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4252 - binary_accuracy: 0.7946 - val_loss: 0.4261 - val_binary_accuracy: 0.7945\n","Epoch 6/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4233 - binary_accuracy: 0.7966 - val_loss: 0.4268 - val_binary_accuracy: 0.7944\n","Epoch 7/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4251 - binary_accuracy: 0.7944 - val_loss: 0.4272 - val_binary_accuracy: 0.7934\n","Epoch 8/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4257 - binary_accuracy: 0.7943 - val_loss: 0.4261 - val_binary_accuracy: 0.7950\n","Epoch 9/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4241 - binary_accuracy: 0.7952 - val_loss: 0.4263 - val_binary_accuracy: 0.7945\n","Epoch 10/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4209 - binary_accuracy: 0.7973 - val_loss: 0.4258 - val_binary_accuracy: 0.7951\n","Epoch 11/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4217 - binary_accuracy: 0.7970 - val_loss: 0.4249 - val_binary_accuracy: 0.7945\n","Epoch 12/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4210 - binary_accuracy: 0.7980 - val_loss: 0.4243 - val_binary_accuracy: 0.7943\n","Epoch 13/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4208 - binary_accuracy: 0.7971 - val_loss: 0.4239 - val_binary_accuracy: 0.7962\n","Epoch 14/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4210 - binary_accuracy: 0.7965 - val_loss: 0.4233 - val_binary_accuracy: 0.7961\n","Epoch 15/100\n","676/676 [==============================] - 2s 2ms/step - loss: 0.4208 - binary_accuracy: 0.7979 - val_loss: 0.4228 - val_binary_accuracy: 0.7967\n","Epoch 16/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4214 - binary_accuracy: 0.7967 - val_loss: 0.4226 - val_binary_accuracy: 0.7963\n","Epoch 17/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4158 - binary_accuracy: 0.8016 - val_loss: 0.4222 - val_binary_accuracy: 0.7968\n","Epoch 18/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4215 - binary_accuracy: 0.7965 - val_loss: 0.4211 - val_binary_accuracy: 0.7970\n","Epoch 19/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4190 - binary_accuracy: 0.7984 - val_loss: 0.4210 - val_binary_accuracy: 0.7977\n","Epoch 20/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4171 - binary_accuracy: 0.7997 - val_loss: 0.4205 - val_binary_accuracy: 0.7977\n","Epoch 21/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4180 - binary_accuracy: 0.7995 - val_loss: 0.4199 - val_binary_accuracy: 0.7983\n","Epoch 22/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4161 - binary_accuracy: 0.7990 - val_loss: 0.4204 - val_binary_accuracy: 0.7969\n","Epoch 23/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4153 - binary_accuracy: 0.8005 - val_loss: 0.4203 - val_binary_accuracy: 0.7970\n","Epoch 24/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4159 - binary_accuracy: 0.7994 - val_loss: 0.4188 - val_binary_accuracy: 0.7982\n","Epoch 25/100\n","676/676 [==============================] - 2s 2ms/step - loss: 0.4143 - binary_accuracy: 0.8004 - val_loss: 0.4186 - val_binary_accuracy: 0.7984\n","Epoch 26/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4159 - binary_accuracy: 0.8016 - val_loss: 0.4185 - val_binary_accuracy: 0.7986\n","Epoch 27/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4145 - binary_accuracy: 0.8006 - val_loss: 0.4183 - val_binary_accuracy: 0.7985\n","Epoch 28/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4151 - binary_accuracy: 0.8001 - val_loss: 0.4176 - val_binary_accuracy: 0.7987\n","Epoch 29/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4147 - binary_accuracy: 0.7999 - val_loss: 0.4171 - val_binary_accuracy: 0.7989\n","Epoch 30/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4158 - binary_accuracy: 0.7997 - val_loss: 0.4169 - val_binary_accuracy: 0.7988\n","Epoch 31/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4153 - binary_accuracy: 0.7998 - val_loss: 0.4170 - val_binary_accuracy: 0.7998\n","Epoch 32/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4133 - binary_accuracy: 0.8011 - val_loss: 0.4164 - val_binary_accuracy: 0.7995\n","Epoch 33/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4110 - binary_accuracy: 0.8038 - val_loss: 0.4164 - val_binary_accuracy: 0.8001\n","Epoch 34/100\n","676/676 [==============================] - 2s 2ms/step - loss: 0.4133 - binary_accuracy: 0.8025 - val_loss: 0.4162 - val_binary_accuracy: 0.7993\n","Epoch 35/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4139 - binary_accuracy: 0.8014 - val_loss: 0.4157 - val_binary_accuracy: 0.7993\n","Epoch 36/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4135 - binary_accuracy: 0.8017 - val_loss: 0.4154 - val_binary_accuracy: 0.7999\n","Epoch 37/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4136 - binary_accuracy: 0.8018 - val_loss: 0.4155 - val_binary_accuracy: 0.8003\n","Epoch 38/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4145 - binary_accuracy: 0.8014 - val_loss: 0.4151 - val_binary_accuracy: 0.8004\n","Epoch 39/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4127 - binary_accuracy: 0.8007 - val_loss: 0.4148 - val_binary_accuracy: 0.8005\n","Epoch 40/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4089 - binary_accuracy: 0.8050 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 41/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4124 - binary_accuracy: 0.8022 - val_loss: 0.4150 - val_binary_accuracy: 0.8003\n","Epoch 42/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4117 - binary_accuracy: 0.8033 - val_loss: 0.4145 - val_binary_accuracy: 0.7992\n","Epoch 43/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4124 - binary_accuracy: 0.8029 - val_loss: 0.4145 - val_binary_accuracy: 0.7996\n","Epoch 44/100\n","676/676 [==============================] - 1s 2ms/step - loss: 0.4115 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8005\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 15%|        | 11/71 [33:16<2:55:05, 175.10s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 100, 'optimizer': 'Nadam', 'reg_rate': 0.0001, 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 6s 7ms/step - loss: 0.5906 - binary_accuracy: 0.7192 - val_loss: 0.4324 - val_binary_accuracy: 0.7921\n","Epoch 2/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4443 - binary_accuracy: 0.7864 - val_loss: 0.4294 - val_binary_accuracy: 0.7908\n","Epoch 3/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4351 - binary_accuracy: 0.7929 - val_loss: 0.4256 - val_binary_accuracy: 0.7940\n","Epoch 4/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4330 - binary_accuracy: 0.7925 - val_loss: 0.4275 - val_binary_accuracy: 0.7922\n","Epoch 5/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4307 - binary_accuracy: 0.7939 - val_loss: 0.4205 - val_binary_accuracy: 0.7968\n","Epoch 6/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4275 - binary_accuracy: 0.7951 - val_loss: 0.4210 - val_binary_accuracy: 0.7964\n","Epoch 7/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4282 - binary_accuracy: 0.7949 - val_loss: 0.4281 - val_binary_accuracy: 0.7888\n","Epoch 8/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4275 - binary_accuracy: 0.7944 - val_loss: 0.4239 - val_binary_accuracy: 0.7942\n","Epoch 9/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4255 - binary_accuracy: 0.7960 - val_loss: 0.4209 - val_binary_accuracy: 0.7977\n","Epoch 10/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4228 - binary_accuracy: 0.7979 - val_loss: 0.4206 - val_binary_accuracy: 0.7989\n","Epoch 11/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4224 - binary_accuracy: 0.7987 - val_loss: 0.4204 - val_binary_accuracy: 0.7958\n","Epoch 12/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4226 - binary_accuracy: 0.7964 - val_loss: 0.4336 - val_binary_accuracy: 0.7907\n","Epoch 13/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4211 - binary_accuracy: 0.7966 - val_loss: 0.4320 - val_binary_accuracy: 0.7916\n","Epoch 14/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4217 - binary_accuracy: 0.7968 - val_loss: 0.4245 - val_binary_accuracy: 0.7972\n","Epoch 15/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4206 - binary_accuracy: 0.7978 - val_loss: 0.4352 - val_binary_accuracy: 0.7951\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 17%|        | 12/71 [34:31<2:22:42, 145.13s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 128, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 300, 'optimizer': 'Adamax', 'reg_rate': 0.0001, 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4633 - binary_accuracy: 0.7745 - val_loss: 0.4273 - val_binary_accuracy: 0.7938\n","Epoch 2/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4226 - binary_accuracy: 0.7961 - val_loss: 0.4210 - val_binary_accuracy: 0.7961\n","Epoch 3/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4139 - binary_accuracy: 0.8026 - val_loss: 0.4197 - val_binary_accuracy: 0.7961\n","Epoch 4/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4110 - binary_accuracy: 0.8027 - val_loss: 0.4146 - val_binary_accuracy: 0.7978\n","Epoch 5/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4067 - binary_accuracy: 0.8058 - val_loss: 0.4117 - val_binary_accuracy: 0.8002\n","Epoch 6/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4006 - binary_accuracy: 0.8093 - val_loss: 0.4109 - val_binary_accuracy: 0.8008\n","Epoch 7/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4002 - binary_accuracy: 0.8096 - val_loss: 0.4118 - val_binary_accuracy: 0.8013\n","Epoch 8/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.3992 - binary_accuracy: 0.8091 - val_loss: 0.4109 - val_binary_accuracy: 0.8009\n","Epoch 9/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.3959 - binary_accuracy: 0.8119 - val_loss: 0.4112 - val_binary_accuracy: 0.8008\n","Epoch 10/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.3897 - binary_accuracy: 0.8153 - val_loss: 0.4107 - val_binary_accuracy: 0.8000\n","Epoch 11/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.3880 - binary_accuracy: 0.8165 - val_loss: 0.4122 - val_binary_accuracy: 0.7997\n","Epoch 12/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.3853 - binary_accuracy: 0.8189 - val_loss: 0.4117 - val_binary_accuracy: 0.8011\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 18%|        | 13/71 [36:21<2:10:11, 134.69s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop_centered', 'reg_rate': 100, 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 9s 11ms/step - loss: 0.4705 - binary_accuracy: 0.7684 - val_loss: 0.4248 - val_binary_accuracy: 0.7979\n","Epoch 2/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4281 - binary_accuracy: 0.7954 - val_loss: 0.4182 - val_binary_accuracy: 0.7971\n","Epoch 3/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4240 - binary_accuracy: 0.7997 - val_loss: 0.4197 - val_binary_accuracy: 0.7996\n","Epoch 4/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4220 - binary_accuracy: 0.7998 - val_loss: 0.4182 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4206 - binary_accuracy: 0.8012 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 6/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4186 - binary_accuracy: 0.8033 - val_loss: 0.4128 - val_binary_accuracy: 0.8022\n","Epoch 7/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4190 - binary_accuracy: 0.8020 - val_loss: 0.4170 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4189 - binary_accuracy: 0.8027 - val_loss: 0.4148 - val_binary_accuracy: 0.8031\n","Epoch 9/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4167 - binary_accuracy: 0.8040 - val_loss: 0.4124 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4126 - binary_accuracy: 0.8074 - val_loss: 0.4118 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4134 - binary_accuracy: 0.8060 - val_loss: 0.4127 - val_binary_accuracy: 0.8046\n","Epoch 12/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4135 - binary_accuracy: 0.8058 - val_loss: 0.4189 - val_binary_accuracy: 0.8029\n","Epoch 13/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4125 - binary_accuracy: 0.8068 - val_loss: 0.4163 - val_binary_accuracy: 0.8038\n","Epoch 14/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4116 - binary_accuracy: 0.8064 - val_loss: 0.4146 - val_binary_accuracy: 0.8027\n","Epoch 15/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4109 - binary_accuracy: 0.8080 - val_loss: 0.4185 - val_binary_accuracy: 0.8012\n","Epoch 16/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4126 - binary_accuracy: 0.8061 - val_loss: 0.4138 - val_binary_accuracy: 0.8042\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 20%|        | 14/71 [38:21<2:03:43, 130.23s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 10, 'number_of_units_first_layer': 300, 'optimizer': 'Adam_amsgrad', 'reg_rate': 1, 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 56s 79ms/step - loss: 0.4929 - binary_accuracy: 0.7722 - val_loss: 0.4240 - val_binary_accuracy: 0.7994\n","Epoch 2/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.4177 - binary_accuracy: 0.7988 - val_loss: 0.4201 - val_binary_accuracy: 0.8002\n","Epoch 3/100\n","676/676 [==============================] - 54s 79ms/step - loss: 0.4111 - binary_accuracy: 0.8038 - val_loss: 0.4153 - val_binary_accuracy: 0.7988\n","Epoch 4/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.4077 - binary_accuracy: 0.8045 - val_loss: 0.4173 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","676/676 [==============================] - 52s 77ms/step - loss: 0.4040 - binary_accuracy: 0.8062 - val_loss: 0.4114 - val_binary_accuracy: 0.8024\n","Epoch 6/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.3982 - binary_accuracy: 0.8104 - val_loss: 0.4091 - val_binary_accuracy: 0.8029\n","Epoch 7/100\n","676/676 [==============================] - 52s 77ms/step - loss: 0.3965 - binary_accuracy: 0.8107 - val_loss: 0.4089 - val_binary_accuracy: 0.8046\n","Epoch 8/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.3967 - binary_accuracy: 0.8110 - val_loss: 0.4104 - val_binary_accuracy: 0.8027\n","Epoch 9/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.3917 - binary_accuracy: 0.8143 - val_loss: 0.4167 - val_binary_accuracy: 0.7987\n","Epoch 10/100\n","676/676 [==============================] - 52s 78ms/step - loss: 0.3855 - binary_accuracy: 0.8175 - val_loss: 0.4150 - val_binary_accuracy: 0.8006\n","Epoch 11/100\n","676/676 [==============================] - 52s 77ms/step - loss: 0.3837 - binary_accuracy: 0.8179 - val_loss: 0.4127 - val_binary_accuracy: 0.8021\n","Epoch 12/100\n","676/676 [==============================] - 53s 78ms/step - loss: 0.3809 - binary_accuracy: 0.8195 - val_loss: 0.4136 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 21%|        | 15/71 [48:56<4:22:52, 281.65s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 128, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 10, 'number_of_units_first_layer': 5, 'optimizer': 'Adamax', 'reg_rate': 0.01, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","1351/1351 [==============================] - 4s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6496 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6534 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6512 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6503 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6497 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","1351/1351 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6493 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 23%|       | 16/71 [49:13<3:05:16, 202.12s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 5, 'optimizer': 'Adamax', 'reg_rate': 0.1, 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5713 - binary_accuracy: 0.7062 - val_loss: 0.4982 - val_binary_accuracy: 0.7661\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4380 - binary_accuracy: 0.7890 - val_loss: 0.4315 - val_binary_accuracy: 0.7923\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4265 - binary_accuracy: 0.7940 - val_loss: 0.4284 - val_binary_accuracy: 0.7932\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4252 - binary_accuracy: 0.7955 - val_loss: 0.4275 - val_binary_accuracy: 0.7932\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4251 - binary_accuracy: 0.7946 - val_loss: 0.4267 - val_binary_accuracy: 0.7941\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4232 - binary_accuracy: 0.7961 - val_loss: 0.4267 - val_binary_accuracy: 0.7939\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4250 - binary_accuracy: 0.7943 - val_loss: 0.4269 - val_binary_accuracy: 0.7937\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7943 - val_loss: 0.4262 - val_binary_accuracy: 0.7942\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7949 - val_loss: 0.4267 - val_binary_accuracy: 0.7939\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4212 - binary_accuracy: 0.7961 - val_loss: 0.4258 - val_binary_accuracy: 0.7943\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4221 - binary_accuracy: 0.7965 - val_loss: 0.4259 - val_binary_accuracy: 0.7936\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7964 - val_loss: 0.4258 - val_binary_accuracy: 0.7941\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4216 - binary_accuracy: 0.7959 - val_loss: 0.4256 - val_binary_accuracy: 0.7939\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4223 - binary_accuracy: 0.7955 - val_loss: 0.4253 - val_binary_accuracy: 0.7945\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4224 - binary_accuracy: 0.7964 - val_loss: 0.4253 - val_binary_accuracy: 0.7950\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7948 - val_loss: 0.4252 - val_binary_accuracy: 0.7943\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4178 - binary_accuracy: 0.7990 - val_loss: 0.4256 - val_binary_accuracy: 0.7942\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7943 - val_loss: 0.4244 - val_binary_accuracy: 0.7944\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7963 - val_loss: 0.4245 - val_binary_accuracy: 0.7949\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4198 - binary_accuracy: 0.7974 - val_loss: 0.4241 - val_binary_accuracy: 0.7951\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7966 - val_loss: 0.4236 - val_binary_accuracy: 0.7955\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4187 - binary_accuracy: 0.7973 - val_loss: 0.4243 - val_binary_accuracy: 0.7950\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4181 - binary_accuracy: 0.7978 - val_loss: 0.4238 - val_binary_accuracy: 0.7950\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4190 - binary_accuracy: 0.7968 - val_loss: 0.4227 - val_binary_accuracy: 0.7963\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4173 - binary_accuracy: 0.7982 - val_loss: 0.4232 - val_binary_accuracy: 0.7955\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.7989 - val_loss: 0.4226 - val_binary_accuracy: 0.7961\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.7982 - val_loss: 0.4223 - val_binary_accuracy: 0.7966\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4185 - binary_accuracy: 0.7975 - val_loss: 0.4215 - val_binary_accuracy: 0.7965\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4181 - binary_accuracy: 0.7974 - val_loss: 0.4213 - val_binary_accuracy: 0.7969\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.7979 - val_loss: 0.4212 - val_binary_accuracy: 0.7969\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4185 - binary_accuracy: 0.7969 - val_loss: 0.4210 - val_binary_accuracy: 0.7969\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4166 - binary_accuracy: 0.7986 - val_loss: 0.4206 - val_binary_accuracy: 0.7969\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4145 - binary_accuracy: 0.8015 - val_loss: 0.4205 - val_binary_accuracy: 0.7966\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4166 - binary_accuracy: 0.7995 - val_loss: 0.4201 - val_binary_accuracy: 0.7969\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4173 - binary_accuracy: 0.7983 - val_loss: 0.4200 - val_binary_accuracy: 0.7969\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 24%|       | 17/71 [49:46<2:16:18, 151.46s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'reg_rate': 10, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.6454 - binary_accuracy: 0.6408 - val_loss: 0.4854 - val_binary_accuracy: 0.7833\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5529 - binary_accuracy: 0.7197 - val_loss: 0.4559 - val_binary_accuracy: 0.7877\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5321 - binary_accuracy: 0.7303 - val_loss: 0.4482 - val_binary_accuracy: 0.7930\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5198 - binary_accuracy: 0.7336 - val_loss: 0.4405 - val_binary_accuracy: 0.7924\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5153 - binary_accuracy: 0.7398 - val_loss: 0.4387 - val_binary_accuracy: 0.7939\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5106 - binary_accuracy: 0.7434 - val_loss: 0.4391 - val_binary_accuracy: 0.7935\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5089 - binary_accuracy: 0.7444 - val_loss: 0.4368 - val_binary_accuracy: 0.7929\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5045 - binary_accuracy: 0.7497 - val_loss: 0.4380 - val_binary_accuracy: 0.7925\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5042 - binary_accuracy: 0.7497 - val_loss: 0.4351 - val_binary_accuracy: 0.7939\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5007 - binary_accuracy: 0.7539 - val_loss: 0.4336 - val_binary_accuracy: 0.7945\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5001 - binary_accuracy: 0.7560 - val_loss: 0.4343 - val_binary_accuracy: 0.7934\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5006 - binary_accuracy: 0.7553 - val_loss: 0.4352 - val_binary_accuracy: 0.7925\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4965 - binary_accuracy: 0.7563 - val_loss: 0.4315 - val_binary_accuracy: 0.7937\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4986 - binary_accuracy: 0.7547 - val_loss: 0.4285 - val_binary_accuracy: 0.7944\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4977 - binary_accuracy: 0.7566 - val_loss: 0.4311 - val_binary_accuracy: 0.7959\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4980 - binary_accuracy: 0.7569 - val_loss: 0.4254 - val_binary_accuracy: 0.7939\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4927 - binary_accuracy: 0.7603 - val_loss: 0.4264 - val_binary_accuracy: 0.7968\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4952 - binary_accuracy: 0.7558 - val_loss: 0.4269 - val_binary_accuracy: 0.7941\n","Epoch 19/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4943 - binary_accuracy: 0.7597 - val_loss: 0.4281 - val_binary_accuracy: 0.7945\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4918 - binary_accuracy: 0.7587 - val_loss: 0.4261 - val_binary_accuracy: 0.7957\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4919 - binary_accuracy: 0.7597 - val_loss: 0.4269 - val_binary_accuracy: 0.7933\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4913 - binary_accuracy: 0.7611 - val_loss: 0.4279 - val_binary_accuracy: 0.7941\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 25%|       | 18/71 [50:28<1:44:46, 118.62s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 128, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'Adam', 'reg_rate': 1, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.6892 - binary_accuracy: 0.6550 - val_loss: 0.4360 - val_binary_accuracy: 0.7872\n","Epoch 2/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4480 - binary_accuracy: 0.7796 - val_loss: 0.4293 - val_binary_accuracy: 0.7901\n","Epoch 3/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4376 - binary_accuracy: 0.7869 - val_loss: 0.4244 - val_binary_accuracy: 0.7926\n","Epoch 4/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4327 - binary_accuracy: 0.7895 - val_loss: 0.4224 - val_binary_accuracy: 0.7950\n","Epoch 5/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4293 - binary_accuracy: 0.7911 - val_loss: 0.4201 - val_binary_accuracy: 0.7959\n","Epoch 6/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4250 - binary_accuracy: 0.7947 - val_loss: 0.4210 - val_binary_accuracy: 0.7959\n","Epoch 7/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4246 - binary_accuracy: 0.7935 - val_loss: 0.4207 - val_binary_accuracy: 0.7959\n","Epoch 8/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4243 - binary_accuracy: 0.7942 - val_loss: 0.4187 - val_binary_accuracy: 0.7977\n","Epoch 9/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4226 - binary_accuracy: 0.7947 - val_loss: 0.4175 - val_binary_accuracy: 0.7973\n","Epoch 10/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4191 - binary_accuracy: 0.7972 - val_loss: 0.4173 - val_binary_accuracy: 0.7974\n","Epoch 11/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4192 - binary_accuracy: 0.7972 - val_loss: 0.4166 - val_binary_accuracy: 0.7986\n","Epoch 12/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4184 - binary_accuracy: 0.7979 - val_loss: 0.4167 - val_binary_accuracy: 0.7977\n","Epoch 13/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4167 - binary_accuracy: 0.7977 - val_loss: 0.4158 - val_binary_accuracy: 0.7987\n","Epoch 14/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4175 - binary_accuracy: 0.7987 - val_loss: 0.4154 - val_binary_accuracy: 0.7983\n","Epoch 15/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4168 - binary_accuracy: 0.7989 - val_loss: 0.4164 - val_binary_accuracy: 0.7987\n","Epoch 16/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4176 - binary_accuracy: 0.7976 - val_loss: 0.4155 - val_binary_accuracy: 0.7995\n","Epoch 17/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8021 - val_loss: 0.4145 - val_binary_accuracy: 0.8002\n","Epoch 18/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4177 - binary_accuracy: 0.7993 - val_loss: 0.4142 - val_binary_accuracy: 0.8003\n","Epoch 19/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8003 - val_loss: 0.4145 - val_binary_accuracy: 0.8002\n","Epoch 20/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4133 - binary_accuracy: 0.8002 - val_loss: 0.4139 - val_binary_accuracy: 0.8002\n","Epoch 21/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4145 - binary_accuracy: 0.8003 - val_loss: 0.4133 - val_binary_accuracy: 0.8007\n","Epoch 22/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4119 - binary_accuracy: 0.8021 - val_loss: 0.4134 - val_binary_accuracy: 0.8000\n","Epoch 23/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4110 - binary_accuracy: 0.8018 - val_loss: 0.4136 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4115 - binary_accuracy: 0.8011 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 25/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4101 - binary_accuracy: 0.8014 - val_loss: 0.4127 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8016 - val_loss: 0.4122 - val_binary_accuracy: 0.8010\n","Epoch 27/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4103 - binary_accuracy: 0.8042 - val_loss: 0.4133 - val_binary_accuracy: 0.8014\n","Epoch 28/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4113 - binary_accuracy: 0.8020 - val_loss: 0.4118 - val_binary_accuracy: 0.8011\n","Epoch 29/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4108 - binary_accuracy: 0.8024 - val_loss: 0.4131 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","1351/1351 [==============================] - 3s 3ms/step - loss: 0.4107 - binary_accuracy: 0.8012 - val_loss: 0.4118 - val_binary_accuracy: 0.8015\n","Epoch 31/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4108 - binary_accuracy: 0.8023 - val_loss: 0.4118 - val_binary_accuracy: 0.8016\n","Epoch 32/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4090 - binary_accuracy: 0.8042 - val_loss: 0.4113 - val_binary_accuracy: 0.8011\n","Epoch 33/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4075 - binary_accuracy: 0.8056 - val_loss: 0.4117 - val_binary_accuracy: 0.8010\n","Epoch 34/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8038 - val_loss: 0.4112 - val_binary_accuracy: 0.8013\n","Epoch 35/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4095 - binary_accuracy: 0.8025 - val_loss: 0.4110 - val_binary_accuracy: 0.8012\n","Epoch 36/100\n","1351/1351 [==============================] - 4s 3ms/step - loss: 0.4089 - binary_accuracy: 0.8047 - val_loss: 0.4115 - val_binary_accuracy: 0.8009\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 27%|       | 19/71 [52:38<1:45:50, 122.12s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 300, 'optimizer': 'RMSprop', 'reg_rate': 0.01, 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 12s 16ms/step - loss: 0.4926 - binary_accuracy: 0.7689 - val_loss: 0.4462 - val_binary_accuracy: 0.7754\n","Epoch 2/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.4163 - binary_accuracy: 0.7984 - val_loss: 0.4277 - val_binary_accuracy: 0.7943\n","Epoch 3/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.4074 - binary_accuracy: 0.8064 - val_loss: 0.4440 - val_binary_accuracy: 0.7875\n","Epoch 4/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.4039 - binary_accuracy: 0.8067 - val_loss: 0.4261 - val_binary_accuracy: 0.7940\n","Epoch 5/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.3997 - binary_accuracy: 0.8088 - val_loss: 0.4116 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.3936 - binary_accuracy: 0.8129 - val_loss: 0.4120 - val_binary_accuracy: 0.8020\n","Epoch 7/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.3916 - binary_accuracy: 0.8131 - val_loss: 0.4187 - val_binary_accuracy: 0.7991\n","Epoch 8/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.3893 - binary_accuracy: 0.8152 - val_loss: 0.4102 - val_binary_accuracy: 0.8015\n","Epoch 9/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.3846 - binary_accuracy: 0.8180 - val_loss: 0.4179 - val_binary_accuracy: 0.7986\n","Epoch 10/100\n","676/676 [==============================] - 11s 16ms/step - loss: 0.3776 - binary_accuracy: 0.8230 - val_loss: 0.4152 - val_binary_accuracy: 0.7989\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 28%|       | 20/71 [54:27<1:40:19, 118.02s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop_centered', 'reg_rate': 0.001, 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 8ms/step - loss: 0.5457 - binary_accuracy: 0.7264 - val_loss: 0.4405 - val_binary_accuracy: 0.7901\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4602 - binary_accuracy: 0.7783 - val_loss: 0.4442 - val_binary_accuracy: 0.7769\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4434 - binary_accuracy: 0.7876 - val_loss: 0.4380 - val_binary_accuracy: 0.7887\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4366 - binary_accuracy: 0.7913 - val_loss: 0.4389 - val_binary_accuracy: 0.7876\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4336 - binary_accuracy: 0.7923 - val_loss: 0.4363 - val_binary_accuracy: 0.7905\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4305 - binary_accuracy: 0.7936 - val_loss: 0.4459 - val_binary_accuracy: 0.7808\n","Epoch 7/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4309 - binary_accuracy: 0.7914 - val_loss: 0.4387 - val_binary_accuracy: 0.7880\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4307 - binary_accuracy: 0.7919 - val_loss: 0.4399 - val_binary_accuracy: 0.7884\n","Epoch 9/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4284 - binary_accuracy: 0.7944 - val_loss: 0.4421 - val_binary_accuracy: 0.7837\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4260 - binary_accuracy: 0.7942 - val_loss: 0.4417 - val_binary_accuracy: 0.7883\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 30%|       | 21/71 [54:54<1:15:45, 90.91s/it] \u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'reg_rate': 100, 'regularization': 'layer_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 8ms/step - loss: 0.4567 - binary_accuracy: 0.7764 - val_loss: 0.4308 - val_binary_accuracy: 0.7898\n","Epoch 2/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4208 - binary_accuracy: 0.7959 - val_loss: 0.4266 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4165 - binary_accuracy: 0.8007 - val_loss: 0.4418 - val_binary_accuracy: 0.7908\n","Epoch 4/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4145 - binary_accuracy: 0.8017 - val_loss: 0.4266 - val_binary_accuracy: 0.7948\n","Epoch 5/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4119 - binary_accuracy: 0.8026 - val_loss: 0.4169 - val_binary_accuracy: 0.8003\n","Epoch 6/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4089 - binary_accuracy: 0.8041 - val_loss: 0.4153 - val_binary_accuracy: 0.7999\n","Epoch 7/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4088 - binary_accuracy: 0.8034 - val_loss: 0.4231 - val_binary_accuracy: 0.7954\n","Epoch 8/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4086 - binary_accuracy: 0.8051 - val_loss: 0.4161 - val_binary_accuracy: 0.7986\n","Epoch 9/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4059 - binary_accuracy: 0.8061 - val_loss: 0.4167 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4023 - binary_accuracy: 0.8079 - val_loss: 0.4145 - val_binary_accuracy: 0.8001\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 31%|       | 22/71 [55:48<1:05:13, 79.87s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 128, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'Nadam', 'reg_rate': 100, 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","1351/1351 [==============================] - 10s 5ms/step - loss: 0.4604 - binary_accuracy: 0.7763 - val_loss: 0.4213 - val_binary_accuracy: 0.7946\n","Epoch 2/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4173 - binary_accuracy: 0.7979 - val_loss: 0.4197 - val_binary_accuracy: 0.7940\n","Epoch 3/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4112 - binary_accuracy: 0.8036 - val_loss: 0.4140 - val_binary_accuracy: 0.7987\n","Epoch 4/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4097 - binary_accuracy: 0.8030 - val_loss: 0.4139 - val_binary_accuracy: 0.7992\n","Epoch 5/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4068 - binary_accuracy: 0.8058 - val_loss: 0.4087 - val_binary_accuracy: 0.8030\n","Epoch 6/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4010 - binary_accuracy: 0.8099 - val_loss: 0.4075 - val_binary_accuracy: 0.8023\n","Epoch 7/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4017 - binary_accuracy: 0.8083 - val_loss: 0.4093 - val_binary_accuracy: 0.8034\n","Epoch 8/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.4010 - binary_accuracy: 0.8078 - val_loss: 0.4108 - val_binary_accuracy: 0.8014\n","Epoch 9/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3984 - binary_accuracy: 0.8100 - val_loss: 0.4084 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3928 - binary_accuracy: 0.8136 - val_loss: 0.4074 - val_binary_accuracy: 0.8033\n","Epoch 11/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3923 - binary_accuracy: 0.8132 - val_loss: 0.4081 - val_binary_accuracy: 0.8039\n","Epoch 12/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3904 - binary_accuracy: 0.8145 - val_loss: 0.4098 - val_binary_accuracy: 0.8025\n","Epoch 13/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3897 - binary_accuracy: 0.8145 - val_loss: 0.4111 - val_binary_accuracy: 0.8016\n","Epoch 14/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3884 - binary_accuracy: 0.8143 - val_loss: 0.4107 - val_binary_accuracy: 0.8034\n","Epoch 15/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3867 - binary_accuracy: 0.8167 - val_loss: 0.4099 - val_binary_accuracy: 0.8015\n","Epoch 16/100\n","1351/1351 [==============================] - 7s 5ms/step - loss: 0.3845 - binary_accuracy: 0.8179 - val_loss: 0.4148 - val_binary_accuracy: 0.8024\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 32%|      | 23/71 [57:42<1:12:07, 90.15s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 233, 'optimizer': 'Adam', 'reg_rate': 0.0001, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 10s 14ms/step - loss: 0.6724 - binary_accuracy: 0.6874 - val_loss: 0.4356 - val_binary_accuracy: 0.7835\n","Epoch 2/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4423 - binary_accuracy: 0.7821 - val_loss: 0.4294 - val_binary_accuracy: 0.7891\n","Epoch 3/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4338 - binary_accuracy: 0.7891 - val_loss: 0.4216 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4287 - binary_accuracy: 0.7929 - val_loss: 0.4204 - val_binary_accuracy: 0.7951\n","Epoch 5/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4263 - binary_accuracy: 0.7947 - val_loss: 0.4175 - val_binary_accuracy: 0.7990\n","Epoch 6/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4224 - binary_accuracy: 0.7961 - val_loss: 0.4182 - val_binary_accuracy: 0.7968\n","Epoch 7/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4213 - binary_accuracy: 0.7959 - val_loss: 0.4183 - val_binary_accuracy: 0.7983\n","Epoch 8/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4206 - binary_accuracy: 0.7965 - val_loss: 0.4165 - val_binary_accuracy: 0.7997\n","Epoch 9/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4181 - binary_accuracy: 0.7989 - val_loss: 0.4131 - val_binary_accuracy: 0.8006\n","Epoch 10/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4140 - binary_accuracy: 0.8007 - val_loss: 0.4119 - val_binary_accuracy: 0.8008\n","Epoch 11/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4142 - binary_accuracy: 0.8007 - val_loss: 0.4112 - val_binary_accuracy: 0.8024\n","Epoch 12/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4132 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8000\n","Epoch 13/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4125 - binary_accuracy: 0.7998 - val_loss: 0.4103 - val_binary_accuracy: 0.8020\n","Epoch 14/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4116 - binary_accuracy: 0.8008 - val_loss: 0.4099 - val_binary_accuracy: 0.8027\n","Epoch 15/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4108 - binary_accuracy: 0.8028 - val_loss: 0.4117 - val_binary_accuracy: 0.8014\n","Epoch 16/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4121 - binary_accuracy: 0.8022 - val_loss: 0.4095 - val_binary_accuracy: 0.8027\n","Epoch 17/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4047 - binary_accuracy: 0.8066 - val_loss: 0.4091 - val_binary_accuracy: 0.8020\n","Epoch 18/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4115 - binary_accuracy: 0.8035 - val_loss: 0.4085 - val_binary_accuracy: 0.8029\n","Epoch 19/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4086 - binary_accuracy: 0.8035 - val_loss: 0.4080 - val_binary_accuracy: 0.8022\n","Epoch 20/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4054 - binary_accuracy: 0.8065 - val_loss: 0.4091 - val_binary_accuracy: 0.8027\n","Epoch 21/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4067 - binary_accuracy: 0.8047 - val_loss: 0.4081 - val_binary_accuracy: 0.8039\n","Epoch 22/100\n","676/676 [==============================] - 10s 14ms/step - loss: 0.4039 - binary_accuracy: 0.8057 - val_loss: 0.4074 - val_binary_accuracy: 0.8032\n","Epoch 23/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4024 - binary_accuracy: 0.8067 - val_loss: 0.4075 - val_binary_accuracy: 0.8031\n","Epoch 24/100\n","676/676 [==============================] - 9s 14ms/step - loss: 0.4036 - binary_accuracy: 0.8064 - val_loss: 0.4065 - val_binary_accuracy: 0.8025\n","Epoch 25/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4015 - binary_accuracy: 0.8080 - val_loss: 0.4066 - val_binary_accuracy: 0.8037\n","Epoch 26/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4031 - binary_accuracy: 0.8078 - val_loss: 0.4067 - val_binary_accuracy: 0.8045\n","Epoch 27/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4012 - binary_accuracy: 0.8082 - val_loss: 0.4079 - val_binary_accuracy: 0.8045\n","Epoch 28/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4016 - binary_accuracy: 0.8085 - val_loss: 0.4059 - val_binary_accuracy: 0.8042\n","Epoch 29/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4014 - binary_accuracy: 0.8073 - val_loss: 0.4076 - val_binary_accuracy: 0.8036\n","Epoch 30/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4011 - binary_accuracy: 0.8075 - val_loss: 0.4057 - val_binary_accuracy: 0.8035\n","Epoch 31/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4007 - binary_accuracy: 0.8073 - val_loss: 0.4057 - val_binary_accuracy: 0.8037\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 34%|      | 24/71 [1:02:20<1:54:39, 146.36s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 10, 'number_of_units_first_layer': 10, 'optimizer': 'RMSprop', 'reg_rate': 10, 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 4ms/step - loss: 0.6931 - binary_accuracy: 0.6495 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6533 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6513 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6503 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6496 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6493 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 35%|      | 25/71 [1:02:29<1:20:36, 105.14s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop_centered', 'reg_rate': 0.0001, 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 11s 13ms/step - loss: 0.4653 - binary_accuracy: 0.7759 - val_loss: 0.4374 - val_binary_accuracy: 0.7825\n","Epoch 2/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4144 - binary_accuracy: 0.8000 - val_loss: 0.4280 - val_binary_accuracy: 0.7971\n","Epoch 3/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4070 - binary_accuracy: 0.8067 - val_loss: 0.4333 - val_binary_accuracy: 0.7970\n","Epoch 4/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4044 - binary_accuracy: 0.8071 - val_loss: 0.4205 - val_binary_accuracy: 0.7975\n","Epoch 5/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4012 - binary_accuracy: 0.8077 - val_loss: 0.4126 - val_binary_accuracy: 0.8017\n","Epoch 6/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3966 - binary_accuracy: 0.8121 - val_loss: 0.4132 - val_binary_accuracy: 0.8011\n","Epoch 7/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3952 - binary_accuracy: 0.8115 - val_loss: 0.4157 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3943 - binary_accuracy: 0.8118 - val_loss: 0.4126 - val_binary_accuracy: 0.8019\n","Epoch 9/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3901 - binary_accuracy: 0.8148 - val_loss: 0.4138 - val_binary_accuracy: 0.8015\n","Epoch 10/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3844 - binary_accuracy: 0.8193 - val_loss: 0.4154 - val_binary_accuracy: 0.7998\n","Epoch 11/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3832 - binary_accuracy: 0.8190 - val_loss: 0.4169 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3808 - binary_accuracy: 0.8208 - val_loss: 0.4213 - val_binary_accuracy: 0.7935\n","Epoch 13/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3787 - binary_accuracy: 0.8208 - val_loss: 0.4159 - val_binary_accuracy: 0.7986\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 37%|      | 26/71 [1:04:25<1:21:16, 108.36s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 50, 'optimizer': 'Adam', 'reg_rate': 100, 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 6s 6ms/step - loss: 0.4799 - binary_accuracy: 0.7646 - val_loss: 0.4290 - val_binary_accuracy: 0.7930\n","Epoch 2/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4199 - binary_accuracy: 0.7977 - val_loss: 0.4231 - val_binary_accuracy: 0.7915\n","Epoch 3/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4127 - binary_accuracy: 0.8027 - val_loss: 0.4245 - val_binary_accuracy: 0.7935\n","Epoch 4/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4098 - binary_accuracy: 0.8034 - val_loss: 0.4185 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4053 - binary_accuracy: 0.8075 - val_loss: 0.4144 - val_binary_accuracy: 0.7994\n","Epoch 6/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.3989 - binary_accuracy: 0.8102 - val_loss: 0.4147 - val_binary_accuracy: 0.7975\n","Epoch 7/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.3984 - binary_accuracy: 0.8082 - val_loss: 0.4138 - val_binary_accuracy: 0.8010\n","Epoch 8/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3957 - binary_accuracy: 0.8117 - val_loss: 0.4155 - val_binary_accuracy: 0.8001\n","Epoch 9/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3920 - binary_accuracy: 0.8129 - val_loss: 0.4150 - val_binary_accuracy: 0.7985\n","Epoch 10/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.3862 - binary_accuracy: 0.8177 - val_loss: 0.4163 - val_binary_accuracy: 0.7996\n","Epoch 11/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.3849 - binary_accuracy: 0.8183 - val_loss: 0.4178 - val_binary_accuracy: 0.7979\n","Epoch 12/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3822 - binary_accuracy: 0.8204 - val_loss: 0.4160 - val_binary_accuracy: 0.7998\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 38%|      | 27/71 [1:05:12<1:05:57, 89.93s/it] \u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 10, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'layer_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 3s 3ms/step - loss: 0.5261 - binary_accuracy: 0.7324 - val_loss: 0.4273 - val_binary_accuracy: 0.7932\n","Epoch 2/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4224 - binary_accuracy: 0.7948 - val_loss: 0.4239 - val_binary_accuracy: 0.7940\n","Epoch 3/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7978 - val_loss: 0.4221 - val_binary_accuracy: 0.7964\n","Epoch 4/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4189 - binary_accuracy: 0.7980 - val_loss: 0.4228 - val_binary_accuracy: 0.7947\n","Epoch 5/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4178 - binary_accuracy: 0.7983 - val_loss: 0.4207 - val_binary_accuracy: 0.7952\n","Epoch 6/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8000 - val_loss: 0.4192 - val_binary_accuracy: 0.7976\n","Epoch 7/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4165 - binary_accuracy: 0.7991 - val_loss: 0.4234 - val_binary_accuracy: 0.7965\n","Epoch 8/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4166 - binary_accuracy: 0.7996 - val_loss: 0.4188 - val_binary_accuracy: 0.7965\n","Epoch 9/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4146 - binary_accuracy: 0.8006 - val_loss: 0.4178 - val_binary_accuracy: 0.7982\n","Epoch 10/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4115 - binary_accuracy: 0.8031 - val_loss: 0.4171 - val_binary_accuracy: 0.7987\n","Epoch 11/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4117 - binary_accuracy: 0.8029 - val_loss: 0.4165 - val_binary_accuracy: 0.7987\n","Epoch 12/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4117 - binary_accuracy: 0.8024 - val_loss: 0.4166 - val_binary_accuracy: 0.7975\n","Epoch 13/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4104 - binary_accuracy: 0.8018 - val_loss: 0.4158 - val_binary_accuracy: 0.7996\n","Epoch 14/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8026 - val_loss: 0.4160 - val_binary_accuracy: 0.7993\n","Epoch 15/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4101 - binary_accuracy: 0.8047 - val_loss: 0.4163 - val_binary_accuracy: 0.7976\n","Epoch 16/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4116 - binary_accuracy: 0.8033 - val_loss: 0.4159 - val_binary_accuracy: 0.7989\n","Epoch 17/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4057 - binary_accuracy: 0.8066 - val_loss: 0.4154 - val_binary_accuracy: 0.7992\n","Epoch 18/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4118 - binary_accuracy: 0.8032 - val_loss: 0.4150 - val_binary_accuracy: 0.7998\n","Epoch 19/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4097 - binary_accuracy: 0.8048 - val_loss: 0.4148 - val_binary_accuracy: 0.7988\n","Epoch 20/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4068 - binary_accuracy: 0.8055 - val_loss: 0.4150 - val_binary_accuracy: 0.7980\n","Epoch 21/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4087 - binary_accuracy: 0.8054 - val_loss: 0.4136 - val_binary_accuracy: 0.8006\n","Epoch 22/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4069 - binary_accuracy: 0.8057 - val_loss: 0.4136 - val_binary_accuracy: 0.8005\n","Epoch 23/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4054 - binary_accuracy: 0.8067 - val_loss: 0.4141 - val_binary_accuracy: 0.7994\n","Epoch 24/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4069 - binary_accuracy: 0.8050 - val_loss: 0.4133 - val_binary_accuracy: 0.7991\n","Epoch 25/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4053 - binary_accuracy: 0.8062 - val_loss: 0.4134 - val_binary_accuracy: 0.7990\n","Epoch 26/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8061 - val_loss: 0.4140 - val_binary_accuracy: 0.8007\n","Epoch 27/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4055 - binary_accuracy: 0.8067 - val_loss: 0.4138 - val_binary_accuracy: 0.7993\n","Epoch 28/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4057 - binary_accuracy: 0.8061 - val_loss: 0.4136 - val_binary_accuracy: 0.7995\n","Epoch 29/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4060 - binary_accuracy: 0.8060 - val_loss: 0.4131 - val_binary_accuracy: 0.7993\n","Epoch 30/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4066 - binary_accuracy: 0.8051 - val_loss: 0.4128 - val_binary_accuracy: 0.8006\n","Epoch 31/100\n","676/676 [==============================] - 2s 3ms/step - loss: 0.4065 - binary_accuracy: 0.8050 - val_loss: 0.4130 - val_binary_accuracy: 0.8005\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 39%|      | 28/71 [1:06:11<57:50, 80.70s/it]  \u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 128, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'reg_rate': 0.0001, 'regularization': 'gaussian_noise', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","1351/1351 [==============================] - 11s 7ms/step - loss: 0.5378 - binary_accuracy: 0.7221 - val_loss: 0.4396 - val_binary_accuracy: 0.7941\n","Epoch 2/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4309 - binary_accuracy: 0.7904 - val_loss: 0.4255 - val_binary_accuracy: 0.7955\n","Epoch 3/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4265 - binary_accuracy: 0.7948 - val_loss: 0.4235 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4239 - binary_accuracy: 0.7972 - val_loss: 0.4218 - val_binary_accuracy: 0.7975\n","Epoch 5/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4213 - binary_accuracy: 0.7974 - val_loss: 0.4193 - val_binary_accuracy: 0.7983\n","Epoch 6/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4192 - binary_accuracy: 0.7986 - val_loss: 0.4165 - val_binary_accuracy: 0.7987\n","Epoch 7/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4194 - binary_accuracy: 0.7985 - val_loss: 0.4178 - val_binary_accuracy: 0.7990\n","Epoch 8/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4193 - binary_accuracy: 0.7989 - val_loss: 0.4196 - val_binary_accuracy: 0.7988\n","Epoch 9/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4163 - binary_accuracy: 0.8004 - val_loss: 0.4144 - val_binary_accuracy: 0.8000\n","Epoch 10/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4128 - binary_accuracy: 0.8023 - val_loss: 0.4135 - val_binary_accuracy: 0.8002\n","Epoch 11/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4132 - binary_accuracy: 0.8033 - val_loss: 0.4140 - val_binary_accuracy: 0.8005\n","Epoch 12/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4119 - binary_accuracy: 0.8026 - val_loss: 0.4152 - val_binary_accuracy: 0.8017\n","Epoch 13/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4112 - binary_accuracy: 0.8033 - val_loss: 0.4139 - val_binary_accuracy: 0.8000\n","Epoch 14/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4101 - binary_accuracy: 0.8030 - val_loss: 0.4115 - val_binary_accuracy: 0.8014\n","Epoch 15/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4106 - binary_accuracy: 0.8040 - val_loss: 0.4113 - val_binary_accuracy: 0.8007\n","Epoch 16/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4107 - binary_accuracy: 0.8040 - val_loss: 0.4188 - val_binary_accuracy: 0.8023\n","Epoch 17/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4055 - binary_accuracy: 0.8070 - val_loss: 0.4116 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4111 - binary_accuracy: 0.8026 - val_loss: 0.4124 - val_binary_accuracy: 0.8034\n","Epoch 19/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4084 - binary_accuracy: 0.8047 - val_loss: 0.4125 - val_binary_accuracy: 0.8025\n","Epoch 20/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4052 - binary_accuracy: 0.8066 - val_loss: 0.4129 - val_binary_accuracy: 0.8033\n","Epoch 21/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4067 - binary_accuracy: 0.8065 - val_loss: 0.4113 - val_binary_accuracy: 0.8028\n","Epoch 22/100\n","1351/1351 [==============================] - 9s 7ms/step - loss: 0.4044 - binary_accuracy: 0.8072 - val_loss: 0.4140 - val_binary_accuracy: 0.8030\n","Epoch 23/100\n","1351/1351 [==============================] - 10s 7ms/step - loss: 0.4029 - binary_accuracy: 0.8076 - val_loss: 0.4117 - val_binary_accuracy: 0.8024\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 41%|      | 29/71 [1:09:53<1:26:13, 123.18s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 100, 'optimizer': 'Nadam', 'reg_rate': 100, 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5218 - binary_accuracy: 0.7283 - val_loss: 0.4281 - val_binary_accuracy: 0.7937\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4307 - binary_accuracy: 0.7910 - val_loss: 0.4262 - val_binary_accuracy: 0.7935\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4267 - binary_accuracy: 0.7950 - val_loss: 0.4252 - val_binary_accuracy: 0.7943\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4270 - binary_accuracy: 0.7945 - val_loss: 0.4254 - val_binary_accuracy: 0.7938\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4259 - binary_accuracy: 0.7944 - val_loss: 0.4239 - val_binary_accuracy: 0.7954\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4243 - binary_accuracy: 0.7959 - val_loss: 0.4240 - val_binary_accuracy: 0.7950\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4259 - binary_accuracy: 0.7950 - val_loss: 0.4243 - val_binary_accuracy: 0.7944\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4254 - binary_accuracy: 0.7965 - val_loss: 0.4228 - val_binary_accuracy: 0.7955\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4242 - binary_accuracy: 0.7961 - val_loss: 0.4227 - val_binary_accuracy: 0.7954\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4208 - binary_accuracy: 0.7979 - val_loss: 0.4221 - val_binary_accuracy: 0.7962\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4219 - binary_accuracy: 0.7972 - val_loss: 0.4216 - val_binary_accuracy: 0.7953\n","Epoch 12/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4214 - binary_accuracy: 0.7975 - val_loss: 0.4211 - val_binary_accuracy: 0.7959\n","Epoch 13/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4210 - binary_accuracy: 0.7971 - val_loss: 0.4207 - val_binary_accuracy: 0.7963\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4211 - binary_accuracy: 0.7981 - val_loss: 0.4204 - val_binary_accuracy: 0.7970\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4206 - binary_accuracy: 0.7969 - val_loss: 0.4202 - val_binary_accuracy: 0.7972\n","Epoch 16/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4222 - binary_accuracy: 0.7968 - val_loss: 0.4200 - val_binary_accuracy: 0.7972\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4164 - binary_accuracy: 0.8007 - val_loss: 0.4195 - val_binary_accuracy: 0.7967\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4229 - binary_accuracy: 0.7957 - val_loss: 0.4193 - val_binary_accuracy: 0.7971\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4199 - binary_accuracy: 0.7978 - val_loss: 0.4189 - val_binary_accuracy: 0.7978\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4182 - binary_accuracy: 0.7983 - val_loss: 0.4188 - val_binary_accuracy: 0.7983\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4195 - binary_accuracy: 0.7982 - val_loss: 0.4182 - val_binary_accuracy: 0.7979\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4175 - binary_accuracy: 0.7979 - val_loss: 0.4178 - val_binary_accuracy: 0.7986\n","Epoch 23/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4168 - binary_accuracy: 0.7993 - val_loss: 0.4177 - val_binary_accuracy: 0.7980\n","Epoch 24/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4183 - binary_accuracy: 0.7982 - val_loss: 0.4173 - val_binary_accuracy: 0.7985\n","Epoch 25/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4159 - binary_accuracy: 0.7999 - val_loss: 0.4171 - val_binary_accuracy: 0.7990\n","Epoch 26/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4185 - binary_accuracy: 0.7992 - val_loss: 0.4169 - val_binary_accuracy: 0.7992\n","Epoch 27/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4165 - binary_accuracy: 0.8000 - val_loss: 0.4173 - val_binary_accuracy: 0.7988\n","Epoch 28/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4179 - binary_accuracy: 0.7990 - val_loss: 0.4167 - val_binary_accuracy: 0.7984\n","Epoch 29/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4175 - binary_accuracy: 0.7976 - val_loss: 0.4163 - val_binary_accuracy: 0.7986\n","Epoch 30/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4176 - binary_accuracy: 0.7993 - val_loss: 0.4162 - val_binary_accuracy: 0.7987\n","Epoch 31/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4180 - binary_accuracy: 0.7973 - val_loss: 0.4162 - val_binary_accuracy: 0.7988\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 42%|     | 30/71 [1:10:49<1:10:20, 102.94s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 128, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 10, 'number_of_units_first_layer': 10, 'optimizer': 'RMSprop_centered', 'reg_rate': 0.0001, 'regularization': 'L2', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","1351/1351 [==============================] - 5s 2ms/step - loss: 0.6941 - binary_accuracy: 0.6496 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6534 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6512 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6503 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6497 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","1351/1351 [==============================] - 3s 2ms/step - loss: 0.6931 - binary_accuracy: 0.6493 - val_loss: 0.6931 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 44%|     | 31/71 [1:11:09<52:07, 78.19s/it]   \u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop_centered', 'reg_rate': 0.0001, 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.5519 - binary_accuracy: 0.7064 - val_loss: 0.4288 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4446 - binary_accuracy: 0.7883 - val_loss: 0.4233 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4376 - binary_accuracy: 0.7932 - val_loss: 0.4245 - val_binary_accuracy: 0.7959\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4337 - binary_accuracy: 0.7947 - val_loss: 0.4236 - val_binary_accuracy: 0.7961\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4313 - binary_accuracy: 0.7958 - val_loss: 0.4274 - val_binary_accuracy: 0.7968\n","Epoch 6/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4286 - binary_accuracy: 0.7967 - val_loss: 0.4368 - val_binary_accuracy: 0.7968\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4270 - binary_accuracy: 0.7955 - val_loss: 0.4393 - val_binary_accuracy: 0.7964\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4265 - binary_accuracy: 0.7964 - val_loss: 0.4505 - val_binary_accuracy: 0.7978\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4239 - binary_accuracy: 0.7960 - val_loss: 0.4562 - val_binary_accuracy: 0.7970\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4205 - binary_accuracy: 0.7995 - val_loss: 0.4690 - val_binary_accuracy: 0.7981\n","Epoch 11/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4198 - binary_accuracy: 0.7996 - val_loss: 0.4800 - val_binary_accuracy: 0.7975\n","Epoch 12/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4197 - binary_accuracy: 0.7996 - val_loss: 0.4880 - val_binary_accuracy: 0.7976\n","Epoch 13/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4185 - binary_accuracy: 0.7990 - val_loss: 0.4872 - val_binary_accuracy: 0.7993\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4176 - binary_accuracy: 0.7996 - val_loss: 0.4887 - val_binary_accuracy: 0.8001\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4181 - binary_accuracy: 0.8000 - val_loss: 0.5056 - val_binary_accuracy: 0.8004\n","Epoch 16/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4192 - binary_accuracy: 0.7994 - val_loss: 0.5060 - val_binary_accuracy: 0.7967\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4123 - binary_accuracy: 0.8033 - val_loss: 0.5116 - val_binary_accuracy: 0.7956\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4182 - binary_accuracy: 0.7996 - val_loss: 0.5054 - val_binary_accuracy: 0.7931\n","Epoch 19/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4163 - binary_accuracy: 0.8007 - val_loss: 0.5167 - val_binary_accuracy: 0.7870\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4141 - binary_accuracy: 0.8017 - val_loss: 0.5140 - val_binary_accuracy: 0.7908\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 45%|     | 32/71 [1:11:41<41:50, 64.37s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 10, 'number_of_units_first_layer': 150, 'optimizer': 'Nadam', 'reg_rate': 0.01, 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 29s 72ms/step - loss: 0.4849 - binary_accuracy: 0.7641 - val_loss: 0.4288 - val_binary_accuracy: 0.7941\n","Epoch 2/100\n","338/338 [==============================] - 23s 68ms/step - loss: 0.4204 - binary_accuracy: 0.7968 - val_loss: 0.4633 - val_binary_accuracy: 0.7818\n","Epoch 3/100\n","338/338 [==============================] - 24s 71ms/step - loss: 0.4163 - binary_accuracy: 0.8006 - val_loss: 0.4183 - val_binary_accuracy: 0.7981\n","Epoch 4/100\n","338/338 [==============================] - 24s 70ms/step - loss: 0.4123 - binary_accuracy: 0.8025 - val_loss: 0.4189 - val_binary_accuracy: 0.7939\n","Epoch 5/100\n","338/338 [==============================] - 23s 69ms/step - loss: 0.4095 - binary_accuracy: 0.8030 - val_loss: 0.4138 - val_binary_accuracy: 0.7996\n","Epoch 6/100\n","338/338 [==============================] - 23s 69ms/step - loss: 0.4037 - binary_accuracy: 0.8074 - val_loss: 0.4136 - val_binary_accuracy: 0.8003\n","Epoch 7/100\n","338/338 [==============================] - 23s 70ms/step - loss: 0.4025 - binary_accuracy: 0.8073 - val_loss: 0.4167 - val_binary_accuracy: 0.8026\n","Epoch 8/100\n","338/338 [==============================] - 22s 65ms/step - loss: 0.4003 - binary_accuracy: 0.8081 - val_loss: 0.4133 - val_binary_accuracy: 0.8010\n","Epoch 9/100\n","338/338 [==============================] - 23s 68ms/step - loss: 0.3962 - binary_accuracy: 0.8111 - val_loss: 0.4256 - val_binary_accuracy: 0.7978\n","Epoch 10/100\n","338/338 [==============================] - 22s 66ms/step - loss: 0.3902 - binary_accuracy: 0.8151 - val_loss: 0.4177 - val_binary_accuracy: 0.7995\n","Epoch 11/100\n","338/338 [==============================] - 23s 67ms/step - loss: 0.3888 - binary_accuracy: 0.8154 - val_loss: 0.4197 - val_binary_accuracy: 0.7953\n","Epoch 12/100\n","338/338 [==============================] - 22s 66ms/step - loss: 0.3848 - binary_accuracy: 0.8170 - val_loss: 0.4170 - val_binary_accuracy: 0.7975\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 46%|     | 33/71 [1:16:24<1:22:13, 129.83s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'Adamax', 'reg_rate': 100, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.8429 - binary_accuracy: 0.5925 - val_loss: 0.4805 - val_binary_accuracy: 0.7649\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.6171 - binary_accuracy: 0.6712 - val_loss: 0.4679 - val_binary_accuracy: 0.7698\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5562 - binary_accuracy: 0.7003 - val_loss: 0.4576 - val_binary_accuracy: 0.7777\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5152 - binary_accuracy: 0.7294 - val_loss: 0.4512 - val_binary_accuracy: 0.7837\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4883 - binary_accuracy: 0.7559 - val_loss: 0.4467 - val_binary_accuracy: 0.7866\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4727 - binary_accuracy: 0.7706 - val_loss: 0.4426 - val_binary_accuracy: 0.7886\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4684 - binary_accuracy: 0.7736 - val_loss: 0.4399 - val_binary_accuracy: 0.7899\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4618 - binary_accuracy: 0.7760 - val_loss: 0.4381 - val_binary_accuracy: 0.7908\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4573 - binary_accuracy: 0.7807 - val_loss: 0.4365 - val_binary_accuracy: 0.7905\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4504 - binary_accuracy: 0.7833 - val_loss: 0.4349 - val_binary_accuracy: 0.7914\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4493 - binary_accuracy: 0.7834 - val_loss: 0.4337 - val_binary_accuracy: 0.7918\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4474 - binary_accuracy: 0.7838 - val_loss: 0.4327 - val_binary_accuracy: 0.7925\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4449 - binary_accuracy: 0.7836 - val_loss: 0.4320 - val_binary_accuracy: 0.7930\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4442 - binary_accuracy: 0.7853 - val_loss: 0.4310 - val_binary_accuracy: 0.7931\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4417 - binary_accuracy: 0.7858 - val_loss: 0.4305 - val_binary_accuracy: 0.7931\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4410 - binary_accuracy: 0.7871 - val_loss: 0.4299 - val_binary_accuracy: 0.7934\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4369 - binary_accuracy: 0.7885 - val_loss: 0.4295 - val_binary_accuracy: 0.7938\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4406 - binary_accuracy: 0.7864 - val_loss: 0.4288 - val_binary_accuracy: 0.7942\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4388 - binary_accuracy: 0.7881 - val_loss: 0.4284 - val_binary_accuracy: 0.7945\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4355 - binary_accuracy: 0.7890 - val_loss: 0.4282 - val_binary_accuracy: 0.7946\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4357 - binary_accuracy: 0.7902 - val_loss: 0.4276 - val_binary_accuracy: 0.7950\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4329 - binary_accuracy: 0.7909 - val_loss: 0.4274 - val_binary_accuracy: 0.7946\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4331 - binary_accuracy: 0.7907 - val_loss: 0.4269 - val_binary_accuracy: 0.7951\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4325 - binary_accuracy: 0.7907 - val_loss: 0.4265 - val_binary_accuracy: 0.7953\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4317 - binary_accuracy: 0.7908 - val_loss: 0.4262 - val_binary_accuracy: 0.7951\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4319 - binary_accuracy: 0.7911 - val_loss: 0.4260 - val_binary_accuracy: 0.7955\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4309 - binary_accuracy: 0.7922 - val_loss: 0.4258 - val_binary_accuracy: 0.7954\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4317 - binary_accuracy: 0.7908 - val_loss: 0.4255 - val_binary_accuracy: 0.7962\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4310 - binary_accuracy: 0.7911 - val_loss: 0.4252 - val_binary_accuracy: 0.7960\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4319 - binary_accuracy: 0.7910 - val_loss: 0.4249 - val_binary_accuracy: 0.7959\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4310 - binary_accuracy: 0.7908 - val_loss: 0.4248 - val_binary_accuracy: 0.7960\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4287 - binary_accuracy: 0.7932 - val_loss: 0.4244 - val_binary_accuracy: 0.7961\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4261 - binary_accuracy: 0.7943 - val_loss: 0.4241 - val_binary_accuracy: 0.7961\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n"," 48%|     | 34/71 [1:17:08<1:04:12, 104.11s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 128, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 10, 'number_of_units_first_layer': 50, 'optimizer': 'Nadam', 'reg_rate': 10, 'regularization': 'layer_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ijHQu8ZsL8P"},"source":["# Get search results for all evaluated hyperparameter combinations sorted by val_accuracy\n","analyze_object = talos.Analyze(search_object)\n","analyze_object.data[[\"duration\", \"loss\", \"binary_accuracy\", \"val_loss\", \"val_binary_accuracy\", \"optimizer\", \"regularizer\", \"reg_rate\", \"weight_initializer\", \"batch_size\", \"epochs\"]]\\\n",".sort_values(by=\"val_binary_accuracy\", ascending=False).round(4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"od9QnNIXotEp"},"source":["Result: \n","- batch_size = 256 & 512 provided best results -> drop 128\n","- number_of_layers = best models had layer of 3 & 10 -> not sure which value can be dropped\n","- number_of_units = 5, 10, & 30 gave bad results; best models had high number of units (i.e. 100 - 500) -> keep 50, 100, 150, 233, 500\n","- activation = gelu, relu, elu, selu provided best results (maybe also keep swish)\n","- dropout, layer_normalization, and batch_normalization gave best results\n","- network shape = either brick or triangle with low decay (e.g. 0.7) provided good results"]},{"cell_type":"markdown","metadata":{"id":"WVWcwTZCKTkC"},"source":["##### Perform Random Search Iteration 2 with Smaller Hyperparameter Space:"]},{"cell_type":"code","metadata":{"id":"Q2s-ONddKQ44"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","  if regularization==\"L2\":\n","     reg_rate = params[\"reg_rate\"]\n","  else:\n","    reg_rate=0\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init, kernel_regularizer=L2(reg_rate)))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if regularization==\"batch_normalization\":\n","      model.add(BatchNormalization())\n","    \n","    if regularization==\"layer_normalization\":\n","      model.add(LayerNormalization())\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L2(l2=reg_rate), kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOhXXo36KQ44","executionInfo":{"status":"ok","timestamp":1611329550771,"user_tz":-60,"elapsed":7586774,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"cb41e384-262d-4bef-91c5-b57e9fc77d9d"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [1, 2, 3, 5],\n","    \"number_of_units_first_layer\" : [100, 150, 233, 300, 500],\n","    \"network_shape\" : [\"brick\", \"triangle\"],\n","    \"network_decay\" : [0.5, 0.7],\n","    \"activation_function\" : [\"relu\", \"elu\", \"gelu\", \"selu\", \"swish\"],\n","    \"regularization\" : [\"dropout\", \"batch_normalization\", \"layer_normalization\"],\n","    \"optimizer\" : [\"RMSprop\", \"RMSprop_centered\", \"Adam\", \"Adam_amsgrad\"],\n","    \"weight_initializer\" : [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\", \"lecun_normal\", \"lecun_uniform\"],\n","    \"batch_size\" : [256, 512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params, fraction_limit=0.001,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/57 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 300, 'optimizer': 'RMSprop_centered', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 15s 20ms/step - loss: 0.4669 - binary_accuracy: 0.7765 - val_loss: 0.4348 - val_binary_accuracy: 0.7838\n","Epoch 2/100\n","676/676 [==============================] - 13s 20ms/step - loss: 0.4117 - binary_accuracy: 0.8019 - val_loss: 0.4287 - val_binary_accuracy: 0.7973\n","Epoch 3/100\n","676/676 [==============================] - 13s 19ms/step - loss: 0.4033 - binary_accuracy: 0.8085 - val_loss: 0.4390 - val_binary_accuracy: 0.7946\n","Epoch 4/100\n","676/676 [==============================] - 13s 20ms/step - loss: 0.3994 - binary_accuracy: 0.8092 - val_loss: 0.4215 - val_binary_accuracy: 0.7993\n","Epoch 5/100\n","676/676 [==============================] - 13s 19ms/step - loss: 0.3942 - binary_accuracy: 0.8125 - val_loss: 0.4145 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","676/676 [==============================] - 13s 19ms/step - loss: 0.3869 - binary_accuracy: 0.8163 - val_loss: 0.4136 - val_binary_accuracy: 0.8020\n","Epoch 7/100\n","676/676 [==============================] - 13s 20ms/step - loss: 0.3831 - binary_accuracy: 0.8187 - val_loss: 0.4179 - val_binary_accuracy: 0.8020\n","Epoch 8/100\n","676/676 [==============================] - 13s 20ms/step - loss: 0.3793 - binary_accuracy: 0.8207 - val_loss: 0.4157 - val_binary_accuracy: 0.8020\n","Epoch 9/100\n","676/676 [==============================] - 13s 19ms/step - loss: 0.3726 - binary_accuracy: 0.8241 - val_loss: 0.4270 - val_binary_accuracy: 0.7969\n","Epoch 10/100\n","676/676 [==============================] - 13s 20ms/step - loss: 0.3610 - binary_accuracy: 0.8315 - val_loss: 0.4226 - val_binary_accuracy: 0.7977\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|         | 1/57 [02:14<2:05:19, 134.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop_centered', 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 11ms/step - loss: 0.4845 - binary_accuracy: 0.7656 - val_loss: 0.4233 - val_binary_accuracy: 0.7982\n","Epoch 2/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4106 - binary_accuracy: 0.8025 - val_loss: 0.4117 - val_binary_accuracy: 0.8006\n","Epoch 3/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4034 - binary_accuracy: 0.8087 - val_loss: 0.4132 - val_binary_accuracy: 0.7992\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4021 - binary_accuracy: 0.8077 - val_loss: 0.4106 - val_binary_accuracy: 0.7999\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3987 - binary_accuracy: 0.8087 - val_loss: 0.4075 - val_binary_accuracy: 0.8037\n","Epoch 6/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3924 - binary_accuracy: 0.8139 - val_loss: 0.4060 - val_binary_accuracy: 0.8048\n","Epoch 7/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3917 - binary_accuracy: 0.8134 - val_loss: 0.4093 - val_binary_accuracy: 0.8047\n","Epoch 8/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3903 - binary_accuracy: 0.8141 - val_loss: 0.4088 - val_binary_accuracy: 0.8030\n","Epoch 9/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3879 - binary_accuracy: 0.8157 - val_loss: 0.4117 - val_binary_accuracy: 0.8016\n","Epoch 10/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3820 - binary_accuracy: 0.8203 - val_loss: 0.4108 - val_binary_accuracy: 0.8024\n","Epoch 11/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3804 - binary_accuracy: 0.8204 - val_loss: 0.4122 - val_binary_accuracy: 0.8025\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|         | 2/57 [02:53<1:37:02, 105.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 11ms/step - loss: 0.5695 - binary_accuracy: 0.7012 - val_loss: 0.4315 - val_binary_accuracy: 0.7910\n","Epoch 2/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4698 - binary_accuracy: 0.7786 - val_loss: 0.4271 - val_binary_accuracy: 0.7936\n","Epoch 3/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4613 - binary_accuracy: 0.7842 - val_loss: 0.4262 - val_binary_accuracy: 0.7924\n","Epoch 4/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4571 - binary_accuracy: 0.7845 - val_loss: 0.4248 - val_binary_accuracy: 0.7935\n","Epoch 5/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4536 - binary_accuracy: 0.7859 - val_loss: 0.4230 - val_binary_accuracy: 0.7950\n","Epoch 6/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4511 - binary_accuracy: 0.7865 - val_loss: 0.4250 - val_binary_accuracy: 0.7944\n","Epoch 7/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4519 - binary_accuracy: 0.7858 - val_loss: 0.4260 - val_binary_accuracy: 0.7941\n","Epoch 8/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4489 - binary_accuracy: 0.7856 - val_loss: 0.4222 - val_binary_accuracy: 0.7950\n","Epoch 9/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4476 - binary_accuracy: 0.7889 - val_loss: 0.4230 - val_binary_accuracy: 0.7951\n","Epoch 10/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4452 - binary_accuracy: 0.7906 - val_loss: 0.4230 - val_binary_accuracy: 0.7960\n","Epoch 11/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4439 - binary_accuracy: 0.7917 - val_loss: 0.4216 - val_binary_accuracy: 0.7967\n","Epoch 12/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4432 - binary_accuracy: 0.7913 - val_loss: 0.4226 - val_binary_accuracy: 0.7955\n","Epoch 13/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4423 - binary_accuracy: 0.7921 - val_loss: 0.4208 - val_binary_accuracy: 0.7971\n","Epoch 14/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4414 - binary_accuracy: 0.7922 - val_loss: 0.4222 - val_binary_accuracy: 0.7971\n","Epoch 15/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4407 - binary_accuracy: 0.7942 - val_loss: 0.4205 - val_binary_accuracy: 0.7972\n","Epoch 16/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4415 - binary_accuracy: 0.7936 - val_loss: 0.4206 - val_binary_accuracy: 0.7972\n","Epoch 17/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4373 - binary_accuracy: 0.7985 - val_loss: 0.4218 - val_binary_accuracy: 0.7967\n","Epoch 18/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4425 - binary_accuracy: 0.7936 - val_loss: 0.4214 - val_binary_accuracy: 0.7977\n","Epoch 19/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4398 - binary_accuracy: 0.7936 - val_loss: 0.4198 - val_binary_accuracy: 0.7981\n","Epoch 20/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4376 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7974\n","Epoch 21/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4382 - binary_accuracy: 0.7950 - val_loss: 0.4184 - val_binary_accuracy: 0.7977\n","Epoch 22/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4372 - binary_accuracy: 0.7967 - val_loss: 0.4210 - val_binary_accuracy: 0.7984\n","Epoch 23/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4352 - binary_accuracy: 0.7982 - val_loss: 0.4203 - val_binary_accuracy: 0.7989\n","Epoch 24/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4370 - binary_accuracy: 0.7947 - val_loss: 0.4185 - val_binary_accuracy: 0.7992\n","Epoch 25/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4353 - binary_accuracy: 0.7975 - val_loss: 0.4179 - val_binary_accuracy: 0.7999\n","Epoch 26/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4369 - binary_accuracy: 0.7974 - val_loss: 0.4178 - val_binary_accuracy: 0.7992\n","Epoch 27/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4348 - binary_accuracy: 0.7970 - val_loss: 0.4178 - val_binary_accuracy: 0.7998\n","Epoch 28/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4367 - binary_accuracy: 0.7961 - val_loss: 0.4177 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4344 - binary_accuracy: 0.7974 - val_loss: 0.4170 - val_binary_accuracy: 0.8012\n","Epoch 30/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4359 - binary_accuracy: 0.7978 - val_loss: 0.4178 - val_binary_accuracy: 0.7992\n","Epoch 31/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4356 - binary_accuracy: 0.7976 - val_loss: 0.4176 - val_binary_accuracy: 0.8006\n","Epoch 32/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4341 - binary_accuracy: 0.7994 - val_loss: 0.4179 - val_binary_accuracy: 0.8006\n","Epoch 33/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4319 - binary_accuracy: 0.7991 - val_loss: 0.4175 - val_binary_accuracy: 0.8009\n","Epoch 34/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.4330 - binary_accuracy: 0.7990 - val_loss: 0.4167 - val_binary_accuracy: 0.8008\n"],"name":"stdout"},{"output_type":"stream","text":["\r  5%|         | 3/57 [04:59<1:40:37, 111.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 300, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 20ms/step - loss: 0.4900 - binary_accuracy: 0.7501 - val_loss: 0.4198 - val_binary_accuracy: 0.7965\n","Epoch 2/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4265 - binary_accuracy: 0.7950 - val_loss: 0.4159 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4206 - binary_accuracy: 0.7995 - val_loss: 0.4152 - val_binary_accuracy: 0.7999\n","Epoch 4/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4184 - binary_accuracy: 0.8005 - val_loss: 0.4129 - val_binary_accuracy: 0.8005\n","Epoch 5/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4177 - binary_accuracy: 0.8003 - val_loss: 0.4105 - val_binary_accuracy: 0.8020\n","Epoch 6/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4155 - binary_accuracy: 0.8029 - val_loss: 0.4101 - val_binary_accuracy: 0.8023\n","Epoch 7/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4149 - binary_accuracy: 0.8020 - val_loss: 0.4094 - val_binary_accuracy: 0.8024\n","Epoch 8/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4141 - binary_accuracy: 0.8024 - val_loss: 0.4080 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4121 - binary_accuracy: 0.8037 - val_loss: 0.4082 - val_binary_accuracy: 0.8023\n","Epoch 10/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4090 - binary_accuracy: 0.8057 - val_loss: 0.4073 - val_binary_accuracy: 0.8034\n","Epoch 11/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4080 - binary_accuracy: 0.8063 - val_loss: 0.4068 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4083 - binary_accuracy: 0.8058 - val_loss: 0.4068 - val_binary_accuracy: 0.8037\n","Epoch 13/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4070 - binary_accuracy: 0.8066 - val_loss: 0.4064 - val_binary_accuracy: 0.8031\n"],"name":"stdout"},{"output_type":"stream","text":["\r  7%|         | 4/57 [06:25<1:31:52, 104.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 100, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 5s 6ms/step - loss: 0.4631 - binary_accuracy: 0.7760 - val_loss: 0.4134 - val_binary_accuracy: 0.7995\n","Epoch 2/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4080 - binary_accuracy: 0.8039 - val_loss: 0.4105 - val_binary_accuracy: 0.8013\n","Epoch 3/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4008 - binary_accuracy: 0.8092 - val_loss: 0.4111 - val_binary_accuracy: 0.8000\n","Epoch 4/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3980 - binary_accuracy: 0.8098 - val_loss: 0.4092 - val_binary_accuracy: 0.8016\n","Epoch 5/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3948 - binary_accuracy: 0.8117 - val_loss: 0.4093 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3880 - binary_accuracy: 0.8168 - val_loss: 0.4075 - val_binary_accuracy: 0.8026\n","Epoch 7/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3867 - binary_accuracy: 0.8169 - val_loss: 0.4103 - val_binary_accuracy: 0.8013\n","Epoch 8/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3837 - binary_accuracy: 0.8178 - val_loss: 0.4124 - val_binary_accuracy: 0.8007\n","Epoch 9/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3803 - binary_accuracy: 0.8200 - val_loss: 0.4143 - val_binary_accuracy: 0.7989\n","Epoch 10/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3725 - binary_accuracy: 0.8246 - val_loss: 0.4172 - val_binary_accuracy: 0.7990\n","Epoch 11/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3699 - binary_accuracy: 0.8267 - val_loss: 0.4195 - val_binary_accuracy: 0.7976\n"],"name":"stdout"},{"output_type":"stream","text":["\r  9%|         | 5/57 [07:10<1:14:56, 86.47s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 9ms/step - loss: 0.5408 - binary_accuracy: 0.7422 - val_loss: 0.4334 - val_binary_accuracy: 0.7920\n","Epoch 2/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4367 - binary_accuracy: 0.7905 - val_loss: 0.4346 - val_binary_accuracy: 0.7914\n","Epoch 3/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4312 - binary_accuracy: 0.7939 - val_loss: 0.4328 - val_binary_accuracy: 0.7945\n","Epoch 4/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4291 - binary_accuracy: 0.7952 - val_loss: 0.4229 - val_binary_accuracy: 0.7952\n","Epoch 5/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4275 - binary_accuracy: 0.7955 - val_loss: 0.4212 - val_binary_accuracy: 0.7977\n","Epoch 6/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4262 - binary_accuracy: 0.7967 - val_loss: 0.4196 - val_binary_accuracy: 0.7970\n","Epoch 7/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4273 - binary_accuracy: 0.7944 - val_loss: 0.4248 - val_binary_accuracy: 0.7951\n","Epoch 8/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4283 - binary_accuracy: 0.7951 - val_loss: 0.4221 - val_binary_accuracy: 0.7965\n","Epoch 9/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4260 - binary_accuracy: 0.7962 - val_loss: 0.4225 - val_binary_accuracy: 0.7969\n","Epoch 10/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4224 - binary_accuracy: 0.7991 - val_loss: 0.4222 - val_binary_accuracy: 0.7947\n"],"name":"stdout"},{"output_type":"stream","text":["\r 11%|         | 6/57 [08:10<1:06:42, 78.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 300, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 9s 11ms/step - loss: 0.5223 - binary_accuracy: 0.7386 - val_loss: 0.4257 - val_binary_accuracy: 0.7939\n","Epoch 2/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4463 - binary_accuracy: 0.7869 - val_loss: 0.4237 - val_binary_accuracy: 0.7941\n","Epoch 3/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4415 - binary_accuracy: 0.7917 - val_loss: 0.4237 - val_binary_accuracy: 0.7958\n","Epoch 4/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4397 - binary_accuracy: 0.7925 - val_loss: 0.4243 - val_binary_accuracy: 0.7957\n","Epoch 5/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4386 - binary_accuracy: 0.7925 - val_loss: 0.4193 - val_binary_accuracy: 0.7971\n","Epoch 6/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4354 - binary_accuracy: 0.7955 - val_loss: 0.4195 - val_binary_accuracy: 0.7968\n","Epoch 7/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4358 - binary_accuracy: 0.7936 - val_loss: 0.4227 - val_binary_accuracy: 0.7958\n","Epoch 8/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4349 - binary_accuracy: 0.7945 - val_loss: 0.4180 - val_binary_accuracy: 0.7979\n","Epoch 9/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4334 - binary_accuracy: 0.7949 - val_loss: 0.4182 - val_binary_accuracy: 0.7981\n","Epoch 10/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4301 - binary_accuracy: 0.7976 - val_loss: 0.4182 - val_binary_accuracy: 0.7991\n","Epoch 11/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4291 - binary_accuracy: 0.7976 - val_loss: 0.4176 - val_binary_accuracy: 0.7978\n","Epoch 12/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4287 - binary_accuracy: 0.7982 - val_loss: 0.4162 - val_binary_accuracy: 0.7989\n","Epoch 13/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4291 - binary_accuracy: 0.7974 - val_loss: 0.4158 - val_binary_accuracy: 0.8000\n","Epoch 14/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4296 - binary_accuracy: 0.7958 - val_loss: 0.4154 - val_binary_accuracy: 0.7999\n","Epoch 15/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4271 - binary_accuracy: 0.7988 - val_loss: 0.4162 - val_binary_accuracy: 0.8000\n","Epoch 16/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4291 - binary_accuracy: 0.7977 - val_loss: 0.4146 - val_binary_accuracy: 0.8005\n","Epoch 17/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4228 - binary_accuracy: 0.8013 - val_loss: 0.4145 - val_binary_accuracy: 0.7998\n","Epoch 18/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4290 - binary_accuracy: 0.7977 - val_loss: 0.4161 - val_binary_accuracy: 0.8008\n","Epoch 19/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4262 - binary_accuracy: 0.7992 - val_loss: 0.4143 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4238 - binary_accuracy: 0.8005 - val_loss: 0.4134 - val_binary_accuracy: 0.8003\n","Epoch 21/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4262 - binary_accuracy: 0.8008 - val_loss: 0.4123 - val_binary_accuracy: 0.8012\n","Epoch 22/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4226 - binary_accuracy: 0.8010 - val_loss: 0.4135 - val_binary_accuracy: 0.8016\n","Epoch 23/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4221 - binary_accuracy: 0.8016 - val_loss: 0.4126 - val_binary_accuracy: 0.8010\n","Epoch 24/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4234 - binary_accuracy: 0.8011 - val_loss: 0.4114 - val_binary_accuracy: 0.8019\n","Epoch 25/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4207 - binary_accuracy: 0.8028 - val_loss: 0.4120 - val_binary_accuracy: 0.8023\n","Epoch 26/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4230 - binary_accuracy: 0.8017 - val_loss: 0.4123 - val_binary_accuracy: 0.8023\n","Epoch 27/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4209 - binary_accuracy: 0.8018 - val_loss: 0.4121 - val_binary_accuracy: 0.8020\n","Epoch 28/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4228 - binary_accuracy: 0.8013 - val_loss: 0.4114 - val_binary_accuracy: 0.8017\n","Epoch 29/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4214 - binary_accuracy: 0.8018 - val_loss: 0.4111 - val_binary_accuracy: 0.8022\n","Epoch 30/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4225 - binary_accuracy: 0.8009 - val_loss: 0.4111 - val_binary_accuracy: 0.8025\n","Epoch 31/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4214 - binary_accuracy: 0.8014 - val_loss: 0.4112 - val_binary_accuracy: 0.8030\n","Epoch 32/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4202 - binary_accuracy: 0.8024 - val_loss: 0.4103 - val_binary_accuracy: 0.8026\n","Epoch 33/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4192 - binary_accuracy: 0.8042 - val_loss: 0.4111 - val_binary_accuracy: 0.8021\n","Epoch 34/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4207 - binary_accuracy: 0.8023 - val_loss: 0.4119 - val_binary_accuracy: 0.8028\n","Epoch 35/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4207 - binary_accuracy: 0.8016 - val_loss: 0.4103 - val_binary_accuracy: 0.8023\n","Epoch 36/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4192 - binary_accuracy: 0.8040 - val_loss: 0.4105 - val_binary_accuracy: 0.8024\n"],"name":"stdout"},{"output_type":"stream","text":["\r 12%|        | 7/57 [12:52<1:56:06, 139.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop_centered', 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 43s 119ms/step - loss: 0.5293 - binary_accuracy: 0.7612 - val_loss: 0.4405 - val_binary_accuracy: 0.7858\n","Epoch 2/100\n","338/338 [==============================] - 40s 119ms/step - loss: 0.4108 - binary_accuracy: 0.8015 - val_loss: 0.4308 - val_binary_accuracy: 0.8020\n","Epoch 3/100\n","338/338 [==============================] - 41s 122ms/step - loss: 0.3992 - binary_accuracy: 0.8112 - val_loss: 0.4186 - val_binary_accuracy: 0.7968\n","Epoch 4/100\n","338/338 [==============================] - 42s 123ms/step - loss: 0.3936 - binary_accuracy: 0.8118 - val_loss: 0.4123 - val_binary_accuracy: 0.7994\n","Epoch 5/100\n","338/338 [==============================] - 40s 117ms/step - loss: 0.3838 - binary_accuracy: 0.8178 - val_loss: 0.4111 - val_binary_accuracy: 0.8045\n","Epoch 6/100\n","338/338 [==============================] - 40s 118ms/step - loss: 0.3689 - binary_accuracy: 0.8261 - val_loss: 0.4181 - val_binary_accuracy: 0.8013\n","Epoch 7/100\n","338/338 [==============================] - 40s 118ms/step - loss: 0.3548 - binary_accuracy: 0.8352 - val_loss: 0.4300 - val_binary_accuracy: 0.8002\n","Epoch 8/100\n","338/338 [==============================] - 40s 118ms/step - loss: 0.3328 - binary_accuracy: 0.8459 - val_loss: 0.4416 - val_binary_accuracy: 0.7939\n","Epoch 9/100\n","338/338 [==============================] - 40s 118ms/step - loss: 0.3034 - binary_accuracy: 0.8624 - val_loss: 0.4962 - val_binary_accuracy: 0.7865\n","Epoch 10/100\n","338/338 [==============================] - 40s 117ms/step - loss: 0.2643 - binary_accuracy: 0.8819 - val_loss: 0.5233 - val_binary_accuracy: 0.7773\n"],"name":"stdout"},{"output_type":"stream","text":["\r 14%|        | 8/57 [19:37<2:59:00, 219.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 150, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.5094 - binary_accuracy: 0.7344 - val_loss: 0.4224 - val_binary_accuracy: 0.7967\n","Epoch 2/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4289 - binary_accuracy: 0.7938 - val_loss: 0.4161 - val_binary_accuracy: 0.7977\n","Epoch 3/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4198 - binary_accuracy: 0.8006 - val_loss: 0.4152 - val_binary_accuracy: 0.8003\n","Epoch 4/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4160 - binary_accuracy: 0.8021 - val_loss: 0.4117 - val_binary_accuracy: 0.8021\n","Epoch 5/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4137 - binary_accuracy: 0.8034 - val_loss: 0.4101 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4100 - binary_accuracy: 0.8055 - val_loss: 0.4101 - val_binary_accuracy: 0.8028\n","Epoch 7/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4099 - binary_accuracy: 0.8046 - val_loss: 0.4088 - val_binary_accuracy: 0.8027\n","Epoch 8/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4092 - binary_accuracy: 0.8052 - val_loss: 0.4091 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4085 - val_binary_accuracy: 0.8040\n","Epoch 10/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4021 - binary_accuracy: 0.8110 - val_loss: 0.4094 - val_binary_accuracy: 0.8035\n","Epoch 11/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4015 - binary_accuracy: 0.8106 - val_loss: 0.4081 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4004 - binary_accuracy: 0.8095 - val_loss: 0.4095 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3987 - binary_accuracy: 0.8105 - val_loss: 0.4081 - val_binary_accuracy: 0.8034\n","Epoch 14/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4002 - binary_accuracy: 0.8097 - val_loss: 0.4075 - val_binary_accuracy: 0.8045\n","Epoch 15/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3977 - binary_accuracy: 0.8129 - val_loss: 0.4096 - val_binary_accuracy: 0.8041\n","Epoch 16/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3982 - binary_accuracy: 0.8112 - val_loss: 0.4092 - val_binary_accuracy: 0.8028\n","Epoch 17/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3919 - binary_accuracy: 0.8160 - val_loss: 0.4099 - val_binary_accuracy: 0.8040\n","Epoch 18/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3971 - binary_accuracy: 0.8121 - val_loss: 0.4111 - val_binary_accuracy: 0.8022\n","Epoch 19/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3946 - binary_accuracy: 0.8141 - val_loss: 0.4103 - val_binary_accuracy: 0.8046\n","Epoch 20/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3908 - binary_accuracy: 0.8152 - val_loss: 0.4092 - val_binary_accuracy: 0.8020\n","Epoch 21/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3930 - binary_accuracy: 0.8143 - val_loss: 0.4102 - val_binary_accuracy: 0.8030\n","Epoch 22/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3905 - binary_accuracy: 0.8151 - val_loss: 0.4105 - val_binary_accuracy: 0.8030\n","Epoch 23/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3878 - binary_accuracy: 0.8163 - val_loss: 0.4117 - val_binary_accuracy: 0.8031\n","Epoch 24/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3897 - binary_accuracy: 0.8152 - val_loss: 0.4122 - val_binary_accuracy: 0.8015\n"],"name":"stdout"},{"output_type":"stream","text":["\r 16%|        | 9/57 [20:57<2:21:54, 177.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 150, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.8888 - binary_accuracy: 0.6643 - val_loss: 0.4396 - val_binary_accuracy: 0.7835\n","Epoch 2/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4741 - binary_accuracy: 0.7665 - val_loss: 0.4311 - val_binary_accuracy: 0.7897\n","Epoch 3/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4513 - binary_accuracy: 0.7833 - val_loss: 0.4370 - val_binary_accuracy: 0.7909\n","Epoch 4/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4441 - binary_accuracy: 0.7867 - val_loss: 0.4272 - val_binary_accuracy: 0.7926\n","Epoch 5/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4390 - binary_accuracy: 0.7889 - val_loss: 0.4350 - val_binary_accuracy: 0.7952\n","Epoch 6/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4356 - binary_accuracy: 0.7934 - val_loss: 0.4389 - val_binary_accuracy: 0.7941\n","Epoch 7/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4357 - binary_accuracy: 0.7908 - val_loss: 0.4348 - val_binary_accuracy: 0.7948\n","Epoch 8/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4335 - binary_accuracy: 0.7931 - val_loss: 0.4399 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4312 - binary_accuracy: 0.7935 - val_loss: 0.4418 - val_binary_accuracy: 0.7963\n","Epoch 10/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4273 - binary_accuracy: 0.7969 - val_loss: 0.4499 - val_binary_accuracy: 0.7970\n","Epoch 11/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4275 - binary_accuracy: 0.7960 - val_loss: 0.4449 - val_binary_accuracy: 0.7971\n","Epoch 12/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4251 - binary_accuracy: 0.7964 - val_loss: 0.4549 - val_binary_accuracy: 0.7973\n","Epoch 13/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4251 - binary_accuracy: 0.7964 - val_loss: 0.4550 - val_binary_accuracy: 0.7969\n","Epoch 14/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4254 - binary_accuracy: 0.7963 - val_loss: 0.4623 - val_binary_accuracy: 0.7963\n","Epoch 15/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4231 - binary_accuracy: 0.7984 - val_loss: 0.5123 - val_binary_accuracy: 0.7884\n","Epoch 16/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4246 - binary_accuracy: 0.7971 - val_loss: 0.4786 - val_binary_accuracy: 0.7952\n","Epoch 17/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4197 - binary_accuracy: 0.8007 - val_loss: 0.4914 - val_binary_accuracy: 0.7932\n"],"name":"stdout"},{"output_type":"stream","text":["\r 18%|        | 10/57 [23:01<2:06:26, 161.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop', 'regularization': 'layer_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 21ms/step - loss: 0.4684 - binary_accuracy: 0.7691 - val_loss: 0.4191 - val_binary_accuracy: 0.7969\n","Epoch 2/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4090 - binary_accuracy: 0.8026 - val_loss: 0.4257 - val_binary_accuracy: 0.7959\n","Epoch 3/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3985 - binary_accuracy: 0.8105 - val_loss: 0.4129 - val_binary_accuracy: 0.8008\n","Epoch 4/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3932 - binary_accuracy: 0.8129 - val_loss: 0.4129 - val_binary_accuracy: 0.7998\n","Epoch 5/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3867 - binary_accuracy: 0.8167 - val_loss: 0.4128 - val_binary_accuracy: 0.8030\n","Epoch 6/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3773 - binary_accuracy: 0.8223 - val_loss: 0.4132 - val_binary_accuracy: 0.8015\n","Epoch 7/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3726 - binary_accuracy: 0.8244 - val_loss: 0.4193 - val_binary_accuracy: 0.8018\n","Epoch 8/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3663 - binary_accuracy: 0.8287 - val_loss: 0.4203 - val_binary_accuracy: 0.7998\n","Epoch 9/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3585 - binary_accuracy: 0.8326 - val_loss: 0.4314 - val_binary_accuracy: 0.7961\n","Epoch 10/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3470 - binary_accuracy: 0.8389 - val_loss: 0.4335 - val_binary_accuracy: 0.7940\n"],"name":"stdout"},{"output_type":"stream","text":["\r 19%|        | 11/57 [24:12<1:42:51, 134.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'layer_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4483 - binary_accuracy: 0.7817 - val_loss: 0.4133 - val_binary_accuracy: 0.8002\n","Epoch 2/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4087 - binary_accuracy: 0.8026 - val_loss: 0.4111 - val_binary_accuracy: 0.8006\n","Epoch 3/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4009 - binary_accuracy: 0.8092 - val_loss: 0.4102 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3974 - binary_accuracy: 0.8094 - val_loss: 0.4143 - val_binary_accuracy: 0.8003\n","Epoch 5/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3938 - binary_accuracy: 0.8119 - val_loss: 0.4068 - val_binary_accuracy: 0.8048\n","Epoch 6/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3872 - binary_accuracy: 0.8168 - val_loss: 0.4086 - val_binary_accuracy: 0.8019\n","Epoch 7/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3838 - binary_accuracy: 0.8169 - val_loss: 0.4144 - val_binary_accuracy: 0.8016\n","Epoch 8/100\n","676/676 [==============================] - 10s 14ms/step - loss: 0.3805 - binary_accuracy: 0.8210 - val_loss: 0.4116 - val_binary_accuracy: 0.8017\n","Epoch 9/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3748 - binary_accuracy: 0.8227 - val_loss: 0.4132 - val_binary_accuracy: 0.8011\n","Epoch 10/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3655 - binary_accuracy: 0.8280 - val_loss: 0.4177 - val_binary_accuracy: 0.7974\n"],"name":"stdout"},{"output_type":"stream","text":["\r 21%|        | 12/57 [25:37<1:29:33, 119.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop_centered', 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4896 - binary_accuracy: 0.7476 - val_loss: 0.4200 - val_binary_accuracy: 0.7972\n","Epoch 2/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4246 - binary_accuracy: 0.7963 - val_loss: 0.4150 - val_binary_accuracy: 0.7998\n","Epoch 3/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4192 - binary_accuracy: 0.8016 - val_loss: 0.4134 - val_binary_accuracy: 0.8028\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4159 - binary_accuracy: 0.8027 - val_loss: 0.4120 - val_binary_accuracy: 0.8009\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4139 - binary_accuracy: 0.8046 - val_loss: 0.4107 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4103 - binary_accuracy: 0.8072 - val_loss: 0.4103 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4111 - binary_accuracy: 0.8047 - val_loss: 0.4103 - val_binary_accuracy: 0.8022\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4102 - binary_accuracy: 0.8058 - val_loss: 0.4095 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4084 - binary_accuracy: 0.8069 - val_loss: 0.4095 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4047 - binary_accuracy: 0.8103 - val_loss: 0.4094 - val_binary_accuracy: 0.8035\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4052 - binary_accuracy: 0.8102 - val_loss: 0.4091 - val_binary_accuracy: 0.8040\n","Epoch 12/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4042 - binary_accuracy: 0.8086 - val_loss: 0.4102 - val_binary_accuracy: 0.8032\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4043 - binary_accuracy: 0.8094 - val_loss: 0.4088 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4034 - binary_accuracy: 0.8084 - val_loss: 0.4087 - val_binary_accuracy: 0.8036\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4029 - binary_accuracy: 0.8104 - val_loss: 0.4112 - val_binary_accuracy: 0.8042\n","Epoch 16/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4029 - binary_accuracy: 0.8104 - val_loss: 0.4094 - val_binary_accuracy: 0.8026\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3980 - binary_accuracy: 0.8143 - val_loss: 0.4095 - val_binary_accuracy: 0.8038\n","Epoch 18/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4044 - binary_accuracy: 0.8105 - val_loss: 0.4094 - val_binary_accuracy: 0.8028\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4012 - binary_accuracy: 0.8120 - val_loss: 0.4100 - val_binary_accuracy: 0.8038\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3988 - binary_accuracy: 0.8142 - val_loss: 0.4103 - val_binary_accuracy: 0.8044\n","Epoch 21/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4015 - binary_accuracy: 0.8128 - val_loss: 0.4098 - val_binary_accuracy: 0.8035\n","Epoch 22/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3996 - binary_accuracy: 0.8130 - val_loss: 0.4112 - val_binary_accuracy: 0.8032\n","Epoch 23/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3972 - binary_accuracy: 0.8138 - val_loss: 0.4135 - val_binary_accuracy: 0.8034\n","Epoch 24/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3995 - binary_accuracy: 0.8120 - val_loss: 0.4116 - val_binary_accuracy: 0.8026\n","Epoch 25/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3971 - binary_accuracy: 0.8135 - val_loss: 0.4128 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 23%|       | 13/57 [26:56<1:18:43, 107.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.8190 - binary_accuracy: 0.7396 - val_loss: 0.4295 - val_binary_accuracy: 0.7932\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4247 - binary_accuracy: 0.7949 - val_loss: 0.4260 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4222 - binary_accuracy: 0.7979 - val_loss: 0.4274 - val_binary_accuracy: 0.7939\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4214 - binary_accuracy: 0.7974 - val_loss: 0.4242 - val_binary_accuracy: 0.7951\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4199 - binary_accuracy: 0.7983 - val_loss: 0.4195 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4158 - binary_accuracy: 0.8008 - val_loss: 0.4182 - val_binary_accuracy: 0.7975\n","Epoch 7/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4148 - binary_accuracy: 0.8006 - val_loss: 0.4180 - val_binary_accuracy: 0.7977\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4139 - binary_accuracy: 0.8021 - val_loss: 0.4157 - val_binary_accuracy: 0.7988\n","Epoch 9/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4112 - binary_accuracy: 0.8029 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4061 - binary_accuracy: 0.8054 - val_loss: 0.4129 - val_binary_accuracy: 0.8000\n","Epoch 11/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4057 - binary_accuracy: 0.8072 - val_loss: 0.4106 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4043 - binary_accuracy: 0.8060 - val_loss: 0.4130 - val_binary_accuracy: 0.7993\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4037 - binary_accuracy: 0.8064 - val_loss: 0.4116 - val_binary_accuracy: 0.8010\n","Epoch 14/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4030 - binary_accuracy: 0.8069 - val_loss: 0.4105 - val_binary_accuracy: 0.8016\n","Epoch 15/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4021 - binary_accuracy: 0.8083 - val_loss: 0.4105 - val_binary_accuracy: 0.8018\n","Epoch 16/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4019 - binary_accuracy: 0.8085 - val_loss: 0.4103 - val_binary_accuracy: 0.8023\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3960 - binary_accuracy: 0.8122 - val_loss: 0.4098 - val_binary_accuracy: 0.8019\n","Epoch 18/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4018 - binary_accuracy: 0.8087 - val_loss: 0.4085 - val_binary_accuracy: 0.8018\n","Epoch 19/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3991 - binary_accuracy: 0.8100 - val_loss: 0.4099 - val_binary_accuracy: 0.8013\n","Epoch 20/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3959 - binary_accuracy: 0.8120 - val_loss: 0.4097 - val_binary_accuracy: 0.8020\n","Epoch 21/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3988 - binary_accuracy: 0.8102 - val_loss: 0.4080 - val_binary_accuracy: 0.8029\n","Epoch 22/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3951 - binary_accuracy: 0.8118 - val_loss: 0.4108 - val_binary_accuracy: 0.8013\n","Epoch 23/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3933 - binary_accuracy: 0.8126 - val_loss: 0.4085 - val_binary_accuracy: 0.8028\n","Epoch 24/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3950 - binary_accuracy: 0.8118 - val_loss: 0.4088 - val_binary_accuracy: 0.8031\n","Epoch 25/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3928 - binary_accuracy: 0.8126 - val_loss: 0.4076 - val_binary_accuracy: 0.8028\n","Epoch 26/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3949 - binary_accuracy: 0.8131 - val_loss: 0.4095 - val_binary_accuracy: 0.8031\n","Epoch 27/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3933 - binary_accuracy: 0.8126 - val_loss: 0.4100 - val_binary_accuracy: 0.8015\n","Epoch 28/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3929 - binary_accuracy: 0.8137 - val_loss: 0.4105 - val_binary_accuracy: 0.8034\n","Epoch 29/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3928 - binary_accuracy: 0.8136 - val_loss: 0.4091 - val_binary_accuracy: 0.8029\n","Epoch 30/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3930 - binary_accuracy: 0.8127 - val_loss: 0.4078 - val_binary_accuracy: 0.8028\n","Epoch 31/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3930 - binary_accuracy: 0.8131 - val_loss: 0.4078 - val_binary_accuracy: 0.8036\n","Epoch 32/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3908 - binary_accuracy: 0.8148 - val_loss: 0.4098 - val_binary_accuracy: 0.8026\n","Epoch 33/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3888 - binary_accuracy: 0.8146 - val_loss: 0.4087 - val_binary_accuracy: 0.8027\n","Epoch 34/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3901 - binary_accuracy: 0.8156 - val_loss: 0.4123 - val_binary_accuracy: 0.8023\n","Epoch 35/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.3902 - binary_accuracy: 0.8148 - val_loss: 0.4094 - val_binary_accuracy: 0.8023\n","Epoch 36/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.3892 - binary_accuracy: 0.8158 - val_loss: 0.4091 - val_binary_accuracy: 0.8028\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|       | 14/57 [28:38<1:15:54, 105.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'Adam', 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 16ms/step - loss: 0.4923 - binary_accuracy: 0.7641 - val_loss: 0.4201 - val_binary_accuracy: 0.7985\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4096 - binary_accuracy: 0.8035 - val_loss: 0.4132 - val_binary_accuracy: 0.8018\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4018 - binary_accuracy: 0.8090 - val_loss: 0.4159 - val_binary_accuracy: 0.7971\n","Epoch 4/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3989 - binary_accuracy: 0.8098 - val_loss: 0.4107 - val_binary_accuracy: 0.8006\n","Epoch 5/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3957 - binary_accuracy: 0.8118 - val_loss: 0.4119 - val_binary_accuracy: 0.7989\n","Epoch 6/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3888 - binary_accuracy: 0.8172 - val_loss: 0.4088 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3877 - binary_accuracy: 0.8162 - val_loss: 0.4101 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3834 - binary_accuracy: 0.8194 - val_loss: 0.4125 - val_binary_accuracy: 0.7997\n","Epoch 9/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3801 - binary_accuracy: 0.8214 - val_loss: 0.4153 - val_binary_accuracy: 0.7986\n","Epoch 10/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3716 - binary_accuracy: 0.8259 - val_loss: 0.4168 - val_binary_accuracy: 0.7981\n","Epoch 11/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3684 - binary_accuracy: 0.8282 - val_loss: 0.4181 - val_binary_accuracy: 0.7982\n","Epoch 12/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3640 - binary_accuracy: 0.8305 - val_loss: 0.4182 - val_binary_accuracy: 0.7989\n"],"name":"stdout"},{"output_type":"stream","text":["\r 26%|       | 15/57 [29:44<1:05:37, 93.76s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 300, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4700 - binary_accuracy: 0.7659 - val_loss: 0.4277 - val_binary_accuracy: 0.7929\n","Epoch 2/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4273 - binary_accuracy: 0.7942 - val_loss: 0.4269 - val_binary_accuracy: 0.7952\n","Epoch 3/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4232 - binary_accuracy: 0.7971 - val_loss: 0.4244 - val_binary_accuracy: 0.7965\n","Epoch 4/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4221 - binary_accuracy: 0.7965 - val_loss: 0.4234 - val_binary_accuracy: 0.7961\n","Epoch 5/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4206 - binary_accuracy: 0.7988 - val_loss: 0.4189 - val_binary_accuracy: 0.7985\n","Epoch 6/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4190 - binary_accuracy: 0.8003 - val_loss: 0.4165 - val_binary_accuracy: 0.7988\n","Epoch 7/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4189 - binary_accuracy: 0.7985 - val_loss: 0.4188 - val_binary_accuracy: 0.7987\n","Epoch 8/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4197 - binary_accuracy: 0.7991 - val_loss: 0.4162 - val_binary_accuracy: 0.7997\n","Epoch 9/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4171 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.8003\n","Epoch 10/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4141 - binary_accuracy: 0.8025 - val_loss: 0.4147 - val_binary_accuracy: 0.8007\n","Epoch 11/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4158 - binary_accuracy: 0.8034 - val_loss: 0.4183 - val_binary_accuracy: 0.7999\n","Epoch 12/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4138 - binary_accuracy: 0.8025 - val_loss: 0.4177 - val_binary_accuracy: 0.8007\n","Epoch 13/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4141 - binary_accuracy: 0.8021 - val_loss: 0.4140 - val_binary_accuracy: 0.7997\n","Epoch 14/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4140 - binary_accuracy: 0.8027 - val_loss: 0.4137 - val_binary_accuracy: 0.8012\n","Epoch 15/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4136 - binary_accuracy: 0.8033 - val_loss: 0.4140 - val_binary_accuracy: 0.8015\n","Epoch 16/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4147 - binary_accuracy: 0.8014 - val_loss: 0.4215 - val_binary_accuracy: 0.8000\n","Epoch 17/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4092 - binary_accuracy: 0.8064 - val_loss: 0.4154 - val_binary_accuracy: 0.7998\n","Epoch 18/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4145 - binary_accuracy: 0.8027 - val_loss: 0.4144 - val_binary_accuracy: 0.8016\n","Epoch 19/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4132 - binary_accuracy: 0.8032 - val_loss: 0.4170 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4104 - binary_accuracy: 0.8054 - val_loss: 0.4179 - val_binary_accuracy: 0.7989\n","Epoch 21/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4126 - binary_accuracy: 0.8034 - val_loss: 0.4123 - val_binary_accuracy: 0.8017\n","Epoch 22/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4108 - binary_accuracy: 0.8041 - val_loss: 0.4141 - val_binary_accuracy: 0.8012\n","Epoch 23/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4092 - binary_accuracy: 0.8051 - val_loss: 0.4135 - val_binary_accuracy: 0.7993\n","Epoch 24/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4112 - binary_accuracy: 0.8042 - val_loss: 0.4151 - val_binary_accuracy: 0.7986\n","Epoch 25/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4095 - binary_accuracy: 0.8063 - val_loss: 0.4106 - val_binary_accuracy: 0.8025\n","Epoch 26/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4118 - binary_accuracy: 0.8048 - val_loss: 0.4163 - val_binary_accuracy: 0.8019\n","Epoch 27/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4099 - binary_accuracy: 0.8051 - val_loss: 0.4173 - val_binary_accuracy: 0.8017\n","Epoch 28/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4114 - binary_accuracy: 0.8051 - val_loss: 0.4129 - val_binary_accuracy: 0.8016\n","Epoch 29/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4103 - binary_accuracy: 0.8047 - val_loss: 0.4124 - val_binary_accuracy: 0.8027\n","Epoch 30/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4105 - binary_accuracy: 0.8037 - val_loss: 0.4149 - val_binary_accuracy: 0.8021\n","Epoch 31/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4108 - binary_accuracy: 0.8053 - val_loss: 0.4149 - val_binary_accuracy: 0.8023\n","Epoch 32/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4091 - binary_accuracy: 0.8057 - val_loss: 0.4134 - val_binary_accuracy: 0.8018\n","Epoch 33/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4085 - binary_accuracy: 0.8069 - val_loss: 0.4125 - val_binary_accuracy: 0.8021\n","Epoch 34/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4097 - binary_accuracy: 0.8063 - val_loss: 0.4132 - val_binary_accuracy: 0.8017\n"],"name":"stdout"},{"output_type":"stream","text":["\r 28%|       | 16/57 [33:51<1:35:30, 139.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.5126 - binary_accuracy: 0.7643 - val_loss: 0.4281 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4276 - binary_accuracy: 0.7939 - val_loss: 0.4263 - val_binary_accuracy: 0.7939\n","Epoch 3/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4255 - binary_accuracy: 0.7954 - val_loss: 0.4263 - val_binary_accuracy: 0.7932\n","Epoch 4/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4250 - binary_accuracy: 0.7948 - val_loss: 0.4275 - val_binary_accuracy: 0.7932\n","Epoch 5/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4254 - binary_accuracy: 0.7949 - val_loss: 0.4257 - val_binary_accuracy: 0.7950\n","Epoch 6/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4236 - binary_accuracy: 0.7967 - val_loss: 0.4249 - val_binary_accuracy: 0.7944\n","Epoch 7/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4248 - binary_accuracy: 0.7946 - val_loss: 0.4295 - val_binary_accuracy: 0.7906\n","Epoch 8/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4256 - binary_accuracy: 0.7953 - val_loss: 0.4256 - val_binary_accuracy: 0.7954\n","Epoch 9/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4238 - binary_accuracy: 0.7959 - val_loss: 0.4251 - val_binary_accuracy: 0.7936\n","Epoch 10/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4209 - binary_accuracy: 0.7971 - val_loss: 0.4248 - val_binary_accuracy: 0.7956\n","Epoch 11/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4222 - binary_accuracy: 0.7969 - val_loss: 0.4245 - val_binary_accuracy: 0.7952\n","Epoch 12/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4220 - binary_accuracy: 0.7967 - val_loss: 0.4244 - val_binary_accuracy: 0.7948\n","Epoch 13/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4219 - binary_accuracy: 0.7962 - val_loss: 0.4242 - val_binary_accuracy: 0.7963\n","Epoch 14/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4223 - binary_accuracy: 0.7960 - val_loss: 0.4246 - val_binary_accuracy: 0.7952\n","Epoch 15/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4225 - binary_accuracy: 0.7971 - val_loss: 0.4257 - val_binary_accuracy: 0.7951\n","Epoch 16/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.4234 - binary_accuracy: 0.7958 - val_loss: 0.4248 - val_binary_accuracy: 0.7946\n","Epoch 17/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4179 - binary_accuracy: 0.7993 - val_loss: 0.4240 - val_binary_accuracy: 0.7953\n","Epoch 18/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4252 - binary_accuracy: 0.7938 - val_loss: 0.4246 - val_binary_accuracy: 0.7949\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|       | 17/57 [35:39<1:26:47, 130.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 150, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.5981 - binary_accuracy: 0.7548 - val_loss: 0.4199 - val_binary_accuracy: 0.7972\n","Epoch 2/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4158 - binary_accuracy: 0.7999 - val_loss: 0.4131 - val_binary_accuracy: 0.8011\n","Epoch 3/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4091 - binary_accuracy: 0.8061 - val_loss: 0.4131 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4066 - binary_accuracy: 0.8056 - val_loss: 0.4101 - val_binary_accuracy: 0.8005\n","Epoch 5/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4048 - binary_accuracy: 0.8068 - val_loss: 0.4083 - val_binary_accuracy: 0.8029\n","Epoch 6/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3996 - binary_accuracy: 0.8106 - val_loss: 0.4081 - val_binary_accuracy: 0.8036\n","Epoch 7/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3997 - binary_accuracy: 0.8094 - val_loss: 0.4085 - val_binary_accuracy: 0.8023\n","Epoch 8/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3989 - binary_accuracy: 0.8108 - val_loss: 0.4090 - val_binary_accuracy: 0.8032\n","Epoch 9/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3971 - binary_accuracy: 0.8114 - val_loss: 0.4106 - val_binary_accuracy: 0.8024\n","Epoch 10/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3923 - binary_accuracy: 0.8132 - val_loss: 0.4102 - val_binary_accuracy: 0.8019\n","Epoch 11/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.3922 - binary_accuracy: 0.8148 - val_loss: 0.4087 - val_binary_accuracy: 0.8020\n"],"name":"stdout"},{"output_type":"stream","text":["\r 32%|      | 18/57 [36:12<1:05:46, 101.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop_centered', 'regularization': 'layer_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 21s 57ms/step - loss: 0.4997 - binary_accuracy: 0.7621 - val_loss: 0.4259 - val_binary_accuracy: 0.7961\n","Epoch 2/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4159 - binary_accuracy: 0.7999 - val_loss: 0.4403 - val_binary_accuracy: 0.7933\n","Epoch 3/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4074 - binary_accuracy: 0.8057 - val_loss: 0.4156 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4023 - binary_accuracy: 0.8074 - val_loss: 0.4152 - val_binary_accuracy: 0.7967\n","Epoch 5/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.3963 - binary_accuracy: 0.8104 - val_loss: 0.4159 - val_binary_accuracy: 0.8003\n","Epoch 6/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.3878 - binary_accuracy: 0.8171 - val_loss: 0.4133 - val_binary_accuracy: 0.8008\n","Epoch 7/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.3835 - binary_accuracy: 0.8180 - val_loss: 0.4203 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.3774 - binary_accuracy: 0.8203 - val_loss: 0.4171 - val_binary_accuracy: 0.7997\n","Epoch 9/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.3686 - binary_accuracy: 0.8267 - val_loss: 0.4349 - val_binary_accuracy: 0.7980\n","Epoch 10/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.3568 - binary_accuracy: 0.8336 - val_loss: 0.4299 - val_binary_accuracy: 0.7951\n","Epoch 11/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3470 - binary_accuracy: 0.8379 - val_loss: 0.4372 - val_binary_accuracy: 0.7952\n","Epoch 12/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3338 - binary_accuracy: 0.8459 - val_loss: 0.4444 - val_binary_accuracy: 0.7909\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|      | 19/57 [40:02<1:28:28, 139.71s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 9ms/step - loss: 0.4699 - binary_accuracy: 0.7719 - val_loss: 0.4185 - val_binary_accuracy: 0.7964\n","Epoch 2/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4134 - binary_accuracy: 0.8005 - val_loss: 0.4139 - val_binary_accuracy: 0.7992\n","Epoch 3/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4062 - binary_accuracy: 0.8063 - val_loss: 0.4156 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.4047 - binary_accuracy: 0.8061 - val_loss: 0.4118 - val_binary_accuracy: 0.7994\n","Epoch 5/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4025 - binary_accuracy: 0.8077 - val_loss: 0.4095 - val_binary_accuracy: 0.8007\n","Epoch 6/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3963 - binary_accuracy: 0.8117 - val_loss: 0.4084 - val_binary_accuracy: 0.8022\n","Epoch 7/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3965 - binary_accuracy: 0.8104 - val_loss: 0.4089 - val_binary_accuracy: 0.8020\n","Epoch 8/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3956 - binary_accuracy: 0.8113 - val_loss: 0.4104 - val_binary_accuracy: 0.8022\n","Epoch 9/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3931 - binary_accuracy: 0.8135 - val_loss: 0.4097 - val_binary_accuracy: 0.8010\n","Epoch 10/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3881 - binary_accuracy: 0.8155 - val_loss: 0.4113 - val_binary_accuracy: 0.7989\n","Epoch 11/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3877 - binary_accuracy: 0.8169 - val_loss: 0.4107 - val_binary_accuracy: 0.8013\n"],"name":"stdout"},{"output_type":"stream","text":["\r 35%|      | 20/57 [41:06<1:12:05, 116.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 300, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4931 - binary_accuracy: 0.7503 - val_loss: 0.4213 - val_binary_accuracy: 0.7976\n","Epoch 2/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4251 - binary_accuracy: 0.7969 - val_loss: 0.4144 - val_binary_accuracy: 0.8010\n","Epoch 3/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4162 - binary_accuracy: 0.8030 - val_loss: 0.4171 - val_binary_accuracy: 0.8018\n","Epoch 4/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4131 - binary_accuracy: 0.8036 - val_loss: 0.4093 - val_binary_accuracy: 0.8018\n","Epoch 5/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4101 - binary_accuracy: 0.8064 - val_loss: 0.4111 - val_binary_accuracy: 0.8023\n","Epoch 6/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4063 - binary_accuracy: 0.8072 - val_loss: 0.4092 - val_binary_accuracy: 0.8034\n","Epoch 7/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4043 - binary_accuracy: 0.8074 - val_loss: 0.4083 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4032 - binary_accuracy: 0.8086 - val_loss: 0.4071 - val_binary_accuracy: 0.8038\n","Epoch 9/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4000 - binary_accuracy: 0.8121 - val_loss: 0.4078 - val_binary_accuracy: 0.8037\n","Epoch 10/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3952 - binary_accuracy: 0.8146 - val_loss: 0.4077 - val_binary_accuracy: 0.8043\n","Epoch 11/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3940 - binary_accuracy: 0.8145 - val_loss: 0.4072 - val_binary_accuracy: 0.8046\n","Epoch 12/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3927 - binary_accuracy: 0.8149 - val_loss: 0.4066 - val_binary_accuracy: 0.8043\n","Epoch 13/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.3918 - binary_accuracy: 0.8150 - val_loss: 0.4063 - val_binary_accuracy: 0.8038\n","Epoch 14/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3903 - binary_accuracy: 0.8157 - val_loss: 0.4063 - val_binary_accuracy: 0.8026\n","Epoch 15/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3888 - binary_accuracy: 0.8169 - val_loss: 0.4085 - val_binary_accuracy: 0.8036\n","Epoch 16/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.3877 - binary_accuracy: 0.8173 - val_loss: 0.4071 - val_binary_accuracy: 0.8035\n"],"name":"stdout"},{"output_type":"stream","text":["\r 37%|      | 21/57 [43:33<1:15:41, 126.15s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop_centered', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.5219 - binary_accuracy: 0.7544 - val_loss: 0.4277 - val_binary_accuracy: 0.7945\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4303 - binary_accuracy: 0.7914 - val_loss: 0.4252 - val_binary_accuracy: 0.7950\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4256 - binary_accuracy: 0.7949 - val_loss: 0.4237 - val_binary_accuracy: 0.7947\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4251 - binary_accuracy: 0.7948 - val_loss: 0.4232 - val_binary_accuracy: 0.7936\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4237 - binary_accuracy: 0.7962 - val_loss: 0.4210 - val_binary_accuracy: 0.7974\n","Epoch 6/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4216 - binary_accuracy: 0.7978 - val_loss: 0.4206 - val_binary_accuracy: 0.7972\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4215 - binary_accuracy: 0.7962 - val_loss: 0.4206 - val_binary_accuracy: 0.7975\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4220 - binary_accuracy: 0.7972 - val_loss: 0.4190 - val_binary_accuracy: 0.7980\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4199 - binary_accuracy: 0.7984 - val_loss: 0.4188 - val_binary_accuracy: 0.7972\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4171 - binary_accuracy: 0.7995 - val_loss: 0.4180 - val_binary_accuracy: 0.7978\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4163 - binary_accuracy: 0.8001 - val_loss: 0.4170 - val_binary_accuracy: 0.7984\n","Epoch 12/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4164 - binary_accuracy: 0.7995 - val_loss: 0.4170 - val_binary_accuracy: 0.7978\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4159 - binary_accuracy: 0.7998 - val_loss: 0.4166 - val_binary_accuracy: 0.7987\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4166 - binary_accuracy: 0.7997 - val_loss: 0.4162 - val_binary_accuracy: 0.7999\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4158 - binary_accuracy: 0.8007 - val_loss: 0.4167 - val_binary_accuracy: 0.7994\n","Epoch 16/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4170 - binary_accuracy: 0.7993 - val_loss: 0.4159 - val_binary_accuracy: 0.7987\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4105 - binary_accuracy: 0.8042 - val_loss: 0.4151 - val_binary_accuracy: 0.7988\n","Epoch 18/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4173 - binary_accuracy: 0.7988 - val_loss: 0.4148 - val_binary_accuracy: 0.8000\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4150 - binary_accuracy: 0.8011 - val_loss: 0.4143 - val_binary_accuracy: 0.8007\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4124 - binary_accuracy: 0.8022 - val_loss: 0.4160 - val_binary_accuracy: 0.7977\n","Epoch 21/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4140 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8016\n","Epoch 22/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4110 - binary_accuracy: 0.8027 - val_loss: 0.4139 - val_binary_accuracy: 0.7999\n","Epoch 23/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4110 - binary_accuracy: 0.8023 - val_loss: 0.4137 - val_binary_accuracy: 0.8010\n","Epoch 24/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4120 - binary_accuracy: 0.8020 - val_loss: 0.4127 - val_binary_accuracy: 0.8013\n","Epoch 25/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4099 - binary_accuracy: 0.8030 - val_loss: 0.4131 - val_binary_accuracy: 0.8003\n","Epoch 26/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4123 - binary_accuracy: 0.8035 - val_loss: 0.4130 - val_binary_accuracy: 0.8021\n","Epoch 27/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4113 - binary_accuracy: 0.8037 - val_loss: 0.4129 - val_binary_accuracy: 0.8003\n","Epoch 28/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4111 - binary_accuracy: 0.8040 - val_loss: 0.4121 - val_binary_accuracy: 0.8019\n","Epoch 29/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4114 - binary_accuracy: 0.8023 - val_loss: 0.4121 - val_binary_accuracy: 0.8008\n","Epoch 30/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4123 - binary_accuracy: 0.8034 - val_loss: 0.4123 - val_binary_accuracy: 0.8017\n","Epoch 31/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4119 - binary_accuracy: 0.8025 - val_loss: 0.4118 - val_binary_accuracy: 0.8016\n"],"name":"stdout"},{"output_type":"stream","text":["\r 39%|      | 22/57 [45:05<1:07:30, 115.74s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 35ms/step - loss: 0.4773 - binary_accuracy: 0.7726 - val_loss: 0.4218 - val_binary_accuracy: 0.7963\n","Epoch 2/100\n","338/338 [==============================] - 12s 34ms/step - loss: 0.4026 - binary_accuracy: 0.8085 - val_loss: 0.4107 - val_binary_accuracy: 0.8027\n","Epoch 3/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.3911 - binary_accuracy: 0.8151 - val_loss: 0.4154 - val_binary_accuracy: 0.7968\n","Epoch 4/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3835 - binary_accuracy: 0.8183 - val_loss: 0.4176 - val_binary_accuracy: 0.7962\n","Epoch 5/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3758 - binary_accuracy: 0.8223 - val_loss: 0.4195 - val_binary_accuracy: 0.7978\n","Epoch 6/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3622 - binary_accuracy: 0.8321 - val_loss: 0.4190 - val_binary_accuracy: 0.7979\n","Epoch 7/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3541 - binary_accuracy: 0.8353 - val_loss: 0.4291 - val_binary_accuracy: 0.7963\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|      | 23/57 [46:30<1:00:24, 106.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop_centered', 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4570 - binary_accuracy: 0.7733 - val_loss: 0.4236 - val_binary_accuracy: 0.7957\n","Epoch 2/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4211 - binary_accuracy: 0.7971 - val_loss: 0.4189 - val_binary_accuracy: 0.7973\n","Epoch 3/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4177 - binary_accuracy: 0.8002 - val_loss: 0.4177 - val_binary_accuracy: 0.7982\n","Epoch 4/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4166 - binary_accuracy: 0.8003 - val_loss: 0.4173 - val_binary_accuracy: 0.7980\n","Epoch 5/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4153 - binary_accuracy: 0.8006 - val_loss: 0.4133 - val_binary_accuracy: 0.8002\n","Epoch 6/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4126 - binary_accuracy: 0.8028 - val_loss: 0.4124 - val_binary_accuracy: 0.8020\n","Epoch 7/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4122 - binary_accuracy: 0.8027 - val_loss: 0.4146 - val_binary_accuracy: 0.8011\n","Epoch 8/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4131 - binary_accuracy: 0.8022 - val_loss: 0.4116 - val_binary_accuracy: 0.8024\n","Epoch 9/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4107 - binary_accuracy: 0.8032 - val_loss: 0.4113 - val_binary_accuracy: 0.8013\n","Epoch 10/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4075 - binary_accuracy: 0.8063 - val_loss: 0.4112 - val_binary_accuracy: 0.8023\n","Epoch 11/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4082 - binary_accuracy: 0.8065 - val_loss: 0.4109 - val_binary_accuracy: 0.8027\n","Epoch 12/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4071 - binary_accuracy: 0.8053 - val_loss: 0.4106 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4072 - binary_accuracy: 0.8047 - val_loss: 0.4104 - val_binary_accuracy: 0.8017\n","Epoch 14/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4064 - binary_accuracy: 0.8058 - val_loss: 0.4101 - val_binary_accuracy: 0.8035\n","Epoch 15/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4072 - binary_accuracy: 0.8065 - val_loss: 0.4107 - val_binary_accuracy: 0.8029\n","Epoch 16/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4077 - binary_accuracy: 0.8053 - val_loss: 0.4114 - val_binary_accuracy: 0.8020\n","Epoch 17/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4020 - binary_accuracy: 0.8103 - val_loss: 0.4101 - val_binary_accuracy: 0.8024\n","Epoch 18/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4081 - binary_accuracy: 0.8059 - val_loss: 0.4100 - val_binary_accuracy: 0.8025\n","Epoch 19/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4056 - binary_accuracy: 0.8070 - val_loss: 0.4095 - val_binary_accuracy: 0.8022\n"],"name":"stdout"},{"output_type":"stream","text":["\r 42%|     | 24/57 [48:36<1:01:46, 112.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 8ms/step - loss: 0.4655 - binary_accuracy: 0.7732 - val_loss: 0.4223 - val_binary_accuracy: 0.7947\n","Epoch 2/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4070 - binary_accuracy: 0.8045 - val_loss: 0.4157 - val_binary_accuracy: 0.7985\n","Epoch 3/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3978 - binary_accuracy: 0.8107 - val_loss: 0.4108 - val_binary_accuracy: 0.7998\n","Epoch 4/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3933 - binary_accuracy: 0.8135 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 5/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3884 - binary_accuracy: 0.8161 - val_loss: 0.4123 - val_binary_accuracy: 0.8000\n","Epoch 6/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3791 - binary_accuracy: 0.8226 - val_loss: 0.4142 - val_binary_accuracy: 0.8001\n","Epoch 7/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3756 - binary_accuracy: 0.8242 - val_loss: 0.4179 - val_binary_accuracy: 0.7980\n","Epoch 8/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3712 - binary_accuracy: 0.8267 - val_loss: 0.4239 - val_binary_accuracy: 0.7964\n","Epoch 9/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3647 - binary_accuracy: 0.8304 - val_loss: 0.4265 - val_binary_accuracy: 0.7969\n","Epoch 10/100\n","676/676 [==============================] - 5s 8ms/step - loss: 0.3542 - binary_accuracy: 0.8370 - val_loss: 0.4331 - val_binary_accuracy: 0.7944\n","Epoch 11/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.3505 - binary_accuracy: 0.8393 - val_loss: 0.4413 - val_binary_accuracy: 0.7955\n"],"name":"stdout"},{"output_type":"stream","text":["\r 44%|     | 25/57 [49:38<51:57, 97.43s/it]   "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 23s 64ms/step - loss: 0.5098 - binary_accuracy: 0.7674 - val_loss: 0.4241 - val_binary_accuracy: 0.7949\n","Epoch 2/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.4117 - binary_accuracy: 0.8026 - val_loss: 0.4202 - val_binary_accuracy: 0.7996\n","Epoch 3/100\n","338/338 [==============================] - 21s 62ms/step - loss: 0.4002 - binary_accuracy: 0.8104 - val_loss: 0.4146 - val_binary_accuracy: 0.7992\n","Epoch 4/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3954 - binary_accuracy: 0.8113 - val_loss: 0.4200 - val_binary_accuracy: 0.7962\n","Epoch 5/100\n","338/338 [==============================] - 21s 62ms/step - loss: 0.3887 - binary_accuracy: 0.8155 - val_loss: 0.4108 - val_binary_accuracy: 0.8029\n","Epoch 6/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3776 - binary_accuracy: 0.8222 - val_loss: 0.4134 - val_binary_accuracy: 0.8018\n","Epoch 7/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3702 - binary_accuracy: 0.8264 - val_loss: 0.4185 - val_binary_accuracy: 0.8033\n","Epoch 8/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3596 - binary_accuracy: 0.8332 - val_loss: 0.4243 - val_binary_accuracy: 0.7982\n","Epoch 9/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3452 - binary_accuracy: 0.8391 - val_loss: 0.4426 - val_binary_accuracy: 0.7946\n","Epoch 10/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.3229 - binary_accuracy: 0.8521 - val_loss: 0.4542 - val_binary_accuracy: 0.7903\n","Epoch 11/100\n","338/338 [==============================] - 21s 64ms/step - loss: 0.3027 - binary_accuracy: 0.8642 - val_loss: 0.4833 - val_binary_accuracy: 0.7846\n","Epoch 12/100\n","338/338 [==============================] - 21s 64ms/step - loss: 0.2766 - binary_accuracy: 0.8779 - val_loss: 0.5061 - val_binary_accuracy: 0.7760\n"],"name":"stdout"},{"output_type":"stream","text":["\r 46%|     | 26/57 [53:56<1:15:07, 145.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.5124 - binary_accuracy: 0.7494 - val_loss: 0.4283 - val_binary_accuracy: 0.7936\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4300 - binary_accuracy: 0.7922 - val_loss: 0.4270 - val_binary_accuracy: 0.7936\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4262 - binary_accuracy: 0.7953 - val_loss: 0.4263 - val_binary_accuracy: 0.7945\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4264 - binary_accuracy: 0.7954 - val_loss: 0.4264 - val_binary_accuracy: 0.7942\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4262 - binary_accuracy: 0.7949 - val_loss: 0.4251 - val_binary_accuracy: 0.7948\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4243 - binary_accuracy: 0.7965 - val_loss: 0.4259 - val_binary_accuracy: 0.7943\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4257 - binary_accuracy: 0.7947 - val_loss: 0.4259 - val_binary_accuracy: 0.7941\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4260 - binary_accuracy: 0.7945 - val_loss: 0.4250 - val_binary_accuracy: 0.7947\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4252 - binary_accuracy: 0.7951 - val_loss: 0.4254 - val_binary_accuracy: 0.7943\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4215 - binary_accuracy: 0.7962 - val_loss: 0.4251 - val_binary_accuracy: 0.7956\n","Epoch 11/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4226 - binary_accuracy: 0.7962 - val_loss: 0.4251 - val_binary_accuracy: 0.7951\n","Epoch 12/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4224 - binary_accuracy: 0.7971 - val_loss: 0.4254 - val_binary_accuracy: 0.7944\n","Epoch 13/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4222 - binary_accuracy: 0.7961 - val_loss: 0.4248 - val_binary_accuracy: 0.7953\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4229 - binary_accuracy: 0.7961 - val_loss: 0.4253 - val_binary_accuracy: 0.7947\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4227 - binary_accuracy: 0.7966 - val_loss: 0.4247 - val_binary_accuracy: 0.7953\n"],"name":"stdout"},{"output_type":"stream","text":["\r 47%|     | 27/57 [54:40<57:30, 115.02s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 100, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5443 - binary_accuracy: 0.7312 - val_loss: 0.4283 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4344 - binary_accuracy: 0.7890 - val_loss: 0.4261 - val_binary_accuracy: 0.7932\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4282 - binary_accuracy: 0.7935 - val_loss: 0.4250 - val_binary_accuracy: 0.7952\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4271 - binary_accuracy: 0.7949 - val_loss: 0.4245 - val_binary_accuracy: 0.7944\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4264 - binary_accuracy: 0.7945 - val_loss: 0.4233 - val_binary_accuracy: 0.7946\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4246 - binary_accuracy: 0.7958 - val_loss: 0.4234 - val_binary_accuracy: 0.7948\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4259 - binary_accuracy: 0.7943 - val_loss: 0.4231 - val_binary_accuracy: 0.7951\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4253 - binary_accuracy: 0.7951 - val_loss: 0.4221 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4234 - binary_accuracy: 0.7957 - val_loss: 0.4217 - val_binary_accuracy: 0.7957\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4209 - binary_accuracy: 0.7974 - val_loss: 0.4213 - val_binary_accuracy: 0.7966\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4211 - binary_accuracy: 0.7975 - val_loss: 0.4209 - val_binary_accuracy: 0.7963\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4207 - binary_accuracy: 0.7975 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 13/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4203 - binary_accuracy: 0.7961 - val_loss: 0.4199 - val_binary_accuracy: 0.7969\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4202 - binary_accuracy: 0.7975 - val_loss: 0.4197 - val_binary_accuracy: 0.7972\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4202 - binary_accuracy: 0.7977 - val_loss: 0.4192 - val_binary_accuracy: 0.7975\n","Epoch 16/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4217 - binary_accuracy: 0.7974 - val_loss: 0.4189 - val_binary_accuracy: 0.7977\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4154 - binary_accuracy: 0.8010 - val_loss: 0.4185 - val_binary_accuracy: 0.7970\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4225 - binary_accuracy: 0.7961 - val_loss: 0.4183 - val_binary_accuracy: 0.7980\n","Epoch 19/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4191 - binary_accuracy: 0.7987 - val_loss: 0.4181 - val_binary_accuracy: 0.7985\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4173 - binary_accuracy: 0.7992 - val_loss: 0.4177 - val_binary_accuracy: 0.7985\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4184 - binary_accuracy: 0.7994 - val_loss: 0.4174 - val_binary_accuracy: 0.7984\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4158 - binary_accuracy: 0.7995 - val_loss: 0.4168 - val_binary_accuracy: 0.7989\n","Epoch 23/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4162 - binary_accuracy: 0.7995 - val_loss: 0.4166 - val_binary_accuracy: 0.7987\n","Epoch 24/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4170 - binary_accuracy: 0.7987 - val_loss: 0.4162 - val_binary_accuracy: 0.7991\n","Epoch 25/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4152 - binary_accuracy: 0.7993 - val_loss: 0.4163 - val_binary_accuracy: 0.7996\n","Epoch 26/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4165 - binary_accuracy: 0.8003 - val_loss: 0.4158 - val_binary_accuracy: 0.7997\n","Epoch 27/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4156 - binary_accuracy: 0.8007 - val_loss: 0.4162 - val_binary_accuracy: 0.7994\n","Epoch 28/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4164 - binary_accuracy: 0.7992 - val_loss: 0.4158 - val_binary_accuracy: 0.7993\n","Epoch 29/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4168 - binary_accuracy: 0.7996 - val_loss: 0.4154 - val_binary_accuracy: 0.7993\n","Epoch 30/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4163 - binary_accuracy: 0.7993 - val_loss: 0.4154 - val_binary_accuracy: 0.7990\n","Epoch 31/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4178 - binary_accuracy: 0.7984 - val_loss: 0.4155 - val_binary_accuracy: 0.7990\n"],"name":"stdout"},{"output_type":"stream","text":["\r 49%|     | 28/57 [55:37<47:15, 97.76s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 12s 34ms/step - loss: 0.4649 - binary_accuracy: 0.7661 - val_loss: 0.4190 - val_binary_accuracy: 0.7972\n","Epoch 2/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4207 - binary_accuracy: 0.7966 - val_loss: 0.4152 - val_binary_accuracy: 0.7989\n","Epoch 3/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4155 - binary_accuracy: 0.8011 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4148 - binary_accuracy: 0.8020 - val_loss: 0.4126 - val_binary_accuracy: 0.8008\n","Epoch 5/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4128 - binary_accuracy: 0.8019 - val_loss: 0.4097 - val_binary_accuracy: 0.8017\n","Epoch 6/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4100 - binary_accuracy: 0.8043 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 7/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4095 - binary_accuracy: 0.8027 - val_loss: 0.4080 - val_binary_accuracy: 0.8023\n","Epoch 8/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4083 - binary_accuracy: 0.8041 - val_loss: 0.4064 - val_binary_accuracy: 0.8040\n","Epoch 9/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4062 - binary_accuracy: 0.8055 - val_loss: 0.4067 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4034 - binary_accuracy: 0.8073 - val_loss: 0.4059 - val_binary_accuracy: 0.8031\n","Epoch 11/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4032 - binary_accuracy: 0.8087 - val_loss: 0.4051 - val_binary_accuracy: 0.8036\n","Epoch 12/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4027 - binary_accuracy: 0.8074 - val_loss: 0.4060 - val_binary_accuracy: 0.8035\n","Epoch 13/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4011 - binary_accuracy: 0.8080 - val_loss: 0.4048 - val_binary_accuracy: 0.8034\n"],"name":"stdout"},{"output_type":"stream","text":["\r 51%|     | 29/57 [57:44<49:44, 106.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 11s 15ms/step - loss: 0.5525 - binary_accuracy: 0.7497 - val_loss: 0.4263 - val_binary_accuracy: 0.7941\n","Epoch 2/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4332 - binary_accuracy: 0.7901 - val_loss: 0.4219 - val_binary_accuracy: 0.7957\n","Epoch 3/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4267 - binary_accuracy: 0.7940 - val_loss: 0.4203 - val_binary_accuracy: 0.7965\n","Epoch 4/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4252 - binary_accuracy: 0.7957 - val_loss: 0.4204 - val_binary_accuracy: 0.7971\n","Epoch 5/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4239 - binary_accuracy: 0.7957 - val_loss: 0.4172 - val_binary_accuracy: 0.7974\n","Epoch 6/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4198 - binary_accuracy: 0.7985 - val_loss: 0.4140 - val_binary_accuracy: 0.7999\n","Epoch 7/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4207 - binary_accuracy: 0.7973 - val_loss: 0.4213 - val_binary_accuracy: 0.7959\n","Epoch 8/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4206 - binary_accuracy: 0.7978 - val_loss: 0.4155 - val_binary_accuracy: 0.7984\n","Epoch 9/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4177 - binary_accuracy: 0.7991 - val_loss: 0.4122 - val_binary_accuracy: 0.8003\n","Epoch 10/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4146 - binary_accuracy: 0.8008 - val_loss: 0.4144 - val_binary_accuracy: 0.8007\n","Epoch 11/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4150 - binary_accuracy: 0.8015 - val_loss: 0.4120 - val_binary_accuracy: 0.8011\n","Epoch 12/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4146 - binary_accuracy: 0.8006 - val_loss: 0.4124 - val_binary_accuracy: 0.8011\n","Epoch 13/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4147 - binary_accuracy: 0.8001 - val_loss: 0.4124 - val_binary_accuracy: 0.8016\n","Epoch 14/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4136 - binary_accuracy: 0.8008 - val_loss: 0.4116 - val_binary_accuracy: 0.8000\n","Epoch 15/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4131 - binary_accuracy: 0.8018 - val_loss: 0.4130 - val_binary_accuracy: 0.8009\n","Epoch 16/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4145 - binary_accuracy: 0.8019 - val_loss: 0.4158 - val_binary_accuracy: 0.7996\n","Epoch 17/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4081 - binary_accuracy: 0.8067 - val_loss: 0.4125 - val_binary_accuracy: 0.7998\n","Epoch 18/100\n","676/676 [==============================] - 10s 15ms/step - loss: 0.4149 - binary_accuracy: 0.8017 - val_loss: 0.4110 - val_binary_accuracy: 0.8013\n"],"name":"stdout"},{"output_type":"stream","text":["\r 53%|    | 30/57 [1:00:47<58:14, 129.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 150, 'optimizer': 'Adam', 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 16ms/step - loss: 0.4866 - binary_accuracy: 0.7626 - val_loss: 0.4212 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4046 - binary_accuracy: 0.8070 - val_loss: 0.4117 - val_binary_accuracy: 0.7993\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.3940 - binary_accuracy: 0.8139 - val_loss: 0.4148 - val_binary_accuracy: 0.7979\n","Epoch 4/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.3878 - binary_accuracy: 0.8171 - val_loss: 0.4160 - val_binary_accuracy: 0.7980\n","Epoch 5/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.3809 - binary_accuracy: 0.8203 - val_loss: 0.4155 - val_binary_accuracy: 0.7990\n","Epoch 6/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.3704 - binary_accuracy: 0.8269 - val_loss: 0.4190 - val_binary_accuracy: 0.7961\n","Epoch 7/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.3644 - binary_accuracy: 0.8295 - val_loss: 0.4245 - val_binary_accuracy: 0.7966\n"],"name":"stdout"},{"output_type":"stream","text":["\r 54%|    | 31/57 [1:01:24<43:59, 101.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 5s 6ms/step - loss: 0.4775 - binary_accuracy: 0.7610 - val_loss: 0.4201 - val_binary_accuracy: 0.7975\n","Epoch 2/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4207 - binary_accuracy: 0.7965 - val_loss: 0.4155 - val_binary_accuracy: 0.8001\n","Epoch 3/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4150 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 4/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4138 - binary_accuracy: 0.8024 - val_loss: 0.4141 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4128 - binary_accuracy: 0.8034 - val_loss: 0.4107 - val_binary_accuracy: 0.8020\n","Epoch 6/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4097 - binary_accuracy: 0.8048 - val_loss: 0.4103 - val_binary_accuracy: 0.8033\n","Epoch 7/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4100 - binary_accuracy: 0.8035 - val_loss: 0.4117 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4103 - binary_accuracy: 0.8034 - val_loss: 0.4098 - val_binary_accuracy: 0.8037\n","Epoch 9/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4089 - binary_accuracy: 0.8057 - val_loss: 0.4098 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4055 - binary_accuracy: 0.8069 - val_loss: 0.4098 - val_binary_accuracy: 0.8027\n","Epoch 11/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4061 - binary_accuracy: 0.8081 - val_loss: 0.4096 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4050 - binary_accuracy: 0.8068 - val_loss: 0.4093 - val_binary_accuracy: 0.8030\n","Epoch 13/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4052 - binary_accuracy: 0.8080 - val_loss: 0.4091 - val_binary_accuracy: 0.8041\n","Epoch 14/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4047 - binary_accuracy: 0.8074 - val_loss: 0.4091 - val_binary_accuracy: 0.8039\n","Epoch 15/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4044 - binary_accuracy: 0.8082 - val_loss: 0.4091 - val_binary_accuracy: 0.8036\n","Epoch 16/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4059 - binary_accuracy: 0.8064 - val_loss: 0.4097 - val_binary_accuracy: 0.8039\n","Epoch 17/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4003 - binary_accuracy: 0.8111 - val_loss: 0.4091 - val_binary_accuracy: 0.8036\n","Epoch 18/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4064 - binary_accuracy: 0.8080 - val_loss: 0.4091 - val_binary_accuracy: 0.8040\n"],"name":"stdout"},{"output_type":"stream","text":["\r 56%|    | 32/57 [1:02:35<38:29, 92.40s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 10s 12ms/step - loss: 0.4668 - binary_accuracy: 0.7729 - val_loss: 0.4353 - val_binary_accuracy: 0.7858\n","Epoch 2/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4128 - binary_accuracy: 0.8007 - val_loss: 0.4260 - val_binary_accuracy: 0.7989\n","Epoch 3/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4056 - binary_accuracy: 0.8075 - val_loss: 0.4317 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.4026 - binary_accuracy: 0.8073 - val_loss: 0.4211 - val_binary_accuracy: 0.7974\n","Epoch 5/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3979 - binary_accuracy: 0.8111 - val_loss: 0.4165 - val_binary_accuracy: 0.8016\n","Epoch 6/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3921 - binary_accuracy: 0.8144 - val_loss: 0.4117 - val_binary_accuracy: 0.8020\n","Epoch 7/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3905 - binary_accuracy: 0.8149 - val_loss: 0.4216 - val_binary_accuracy: 0.8010\n","Epoch 8/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3880 - binary_accuracy: 0.8161 - val_loss: 0.4142 - val_binary_accuracy: 0.8019\n","Epoch 9/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3825 - binary_accuracy: 0.8183 - val_loss: 0.4195 - val_binary_accuracy: 0.7994\n","Epoch 10/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3751 - binary_accuracy: 0.8242 - val_loss: 0.4200 - val_binary_accuracy: 0.7979\n","Epoch 11/100\n","676/676 [==============================] - 8s 11ms/step - loss: 0.3743 - binary_accuracy: 0.8249 - val_loss: 0.4275 - val_binary_accuracy: 0.7976\n"],"name":"stdout"},{"output_type":"stream","text":["\r 58%|    | 33/57 [1:04:02<36:22, 90.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 16ms/step - loss: 0.4792 - binary_accuracy: 0.7594 - val_loss: 0.4260 - val_binary_accuracy: 0.7936\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4310 - binary_accuracy: 0.7909 - val_loss: 0.4230 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4253 - binary_accuracy: 0.7959 - val_loss: 0.4219 - val_binary_accuracy: 0.7964\n","Epoch 4/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4242 - binary_accuracy: 0.7956 - val_loss: 0.4205 - val_binary_accuracy: 0.7956\n","Epoch 5/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4226 - binary_accuracy: 0.7963 - val_loss: 0.4184 - val_binary_accuracy: 0.7970\n","Epoch 6/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4201 - binary_accuracy: 0.7987 - val_loss: 0.4178 - val_binary_accuracy: 0.7975\n","Epoch 7/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4199 - binary_accuracy: 0.7976 - val_loss: 0.4169 - val_binary_accuracy: 0.7983\n","Epoch 8/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4198 - binary_accuracy: 0.7980 - val_loss: 0.4152 - val_binary_accuracy: 0.7995\n","Epoch 9/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4187 - binary_accuracy: 0.7989 - val_loss: 0.4152 - val_binary_accuracy: 0.8005\n","Epoch 10/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4147 - binary_accuracy: 0.8017 - val_loss: 0.4141 - val_binary_accuracy: 0.8009\n","Epoch 11/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4143 - binary_accuracy: 0.8022 - val_loss: 0.4132 - val_binary_accuracy: 0.8002\n","Epoch 12/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4143 - binary_accuracy: 0.8018 - val_loss: 0.4132 - val_binary_accuracy: 0.7995\n","Epoch 13/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4134 - binary_accuracy: 0.8008 - val_loss: 0.4125 - val_binary_accuracy: 0.8006\n","Epoch 14/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4141 - binary_accuracy: 0.8008 - val_loss: 0.4135 - val_binary_accuracy: 0.8015\n","Epoch 15/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4126 - binary_accuracy: 0.8021 - val_loss: 0.4129 - val_binary_accuracy: 0.8014\n","Epoch 16/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4143 - binary_accuracy: 0.8016 - val_loss: 0.4115 - val_binary_accuracy: 0.8010\n","Epoch 17/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4083 - binary_accuracy: 0.8055 - val_loss: 0.4113 - val_binary_accuracy: 0.8010\n","Epoch 18/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4141 - binary_accuracy: 0.8016 - val_loss: 0.4123 - val_binary_accuracy: 0.8018\n","Epoch 19/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4121 - binary_accuracy: 0.8029 - val_loss: 0.4108 - val_binary_accuracy: 0.8026\n","Epoch 20/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4092 - binary_accuracy: 0.8044 - val_loss: 0.4120 - val_binary_accuracy: 0.8016\n","Epoch 21/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4123 - binary_accuracy: 0.8024 - val_loss: 0.4098 - val_binary_accuracy: 0.8020\n","Epoch 22/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4090 - binary_accuracy: 0.8033 - val_loss: 0.4107 - val_binary_accuracy: 0.8019\n","Epoch 23/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4085 - binary_accuracy: 0.8049 - val_loss: 0.4107 - val_binary_accuracy: 0.8009\n","Epoch 24/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4095 - binary_accuracy: 0.8040 - val_loss: 0.4099 - val_binary_accuracy: 0.8018\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|    | 34/57 [1:06:10<39:02, 101.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 7s 9ms/step - loss: 1.2260 - binary_accuracy: 0.6479 - val_loss: 0.4464 - val_binary_accuracy: 0.7848\n","Epoch 2/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4535 - binary_accuracy: 0.7843 - val_loss: 0.4360 - val_binary_accuracy: 0.7901\n","Epoch 3/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4439 - binary_accuracy: 0.7910 - val_loss: 0.4432 - val_binary_accuracy: 0.7925\n","Epoch 4/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4430 - binary_accuracy: 0.7919 - val_loss: 0.4343 - val_binary_accuracy: 0.7927\n","Epoch 5/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4414 - binary_accuracy: 0.7929 - val_loss: 0.4299 - val_binary_accuracy: 0.7964\n","Epoch 6/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4398 - binary_accuracy: 0.7942 - val_loss: 0.4221 - val_binary_accuracy: 0.7961\n","Epoch 7/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4404 - binary_accuracy: 0.7926 - val_loss: 0.4280 - val_binary_accuracy: 0.7961\n","Epoch 8/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4406 - binary_accuracy: 0.7948 - val_loss: 0.4248 - val_binary_accuracy: 0.7966\n","Epoch 9/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4383 - binary_accuracy: 0.7946 - val_loss: 0.4226 - val_binary_accuracy: 0.7975\n","Epoch 10/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4350 - binary_accuracy: 0.7957 - val_loss: 0.4248 - val_binary_accuracy: 0.7967\n","Epoch 11/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.4359 - binary_accuracy: 0.7965 - val_loss: 0.4332 - val_binary_accuracy: 0.7952\n","Epoch 12/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4349 - binary_accuracy: 0.7961 - val_loss: 0.4353 - val_binary_accuracy: 0.7966\n","Epoch 13/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4350 - binary_accuracy: 0.7964 - val_loss: 0.4203 - val_binary_accuracy: 0.7974\n","Epoch 14/100\n","676/676 [==============================] - 6s 8ms/step - loss: 0.4348 - binary_accuracy: 0.7950 - val_loss: 0.4262 - val_binary_accuracy: 0.7975\n"],"name":"stdout"},{"output_type":"stream","text":["\r 61%|   | 35/57 [1:07:32<35:11, 95.97s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 12ms/step - loss: 0.7067 - binary_accuracy: 0.7489 - val_loss: 0.4274 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4230 - binary_accuracy: 0.7952 - val_loss: 0.4238 - val_binary_accuracy: 0.7939\n","Epoch 3/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4203 - binary_accuracy: 0.7972 - val_loss: 0.4226 - val_binary_accuracy: 0.7953\n","Epoch 4/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4192 - binary_accuracy: 0.7978 - val_loss: 0.4233 - val_binary_accuracy: 0.7939\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4177 - binary_accuracy: 0.7978 - val_loss: 0.4199 - val_binary_accuracy: 0.7956\n","Epoch 6/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4145 - binary_accuracy: 0.8004 - val_loss: 0.4171 - val_binary_accuracy: 0.7979\n","Epoch 7/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4140 - binary_accuracy: 0.7996 - val_loss: 0.4245 - val_binary_accuracy: 0.7930\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4142 - binary_accuracy: 0.8008 - val_loss: 0.4194 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4116 - binary_accuracy: 0.8016 - val_loss: 0.4142 - val_binary_accuracy: 0.8002\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4071 - binary_accuracy: 0.8046 - val_loss: 0.4134 - val_binary_accuracy: 0.8003\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4068 - binary_accuracy: 0.8058 - val_loss: 0.4122 - val_binary_accuracy: 0.8010\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4057 - binary_accuracy: 0.8051 - val_loss: 0.4128 - val_binary_accuracy: 0.7992\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4044 - binary_accuracy: 0.8051 - val_loss: 0.4112 - val_binary_accuracy: 0.8012\n","Epoch 14/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4043 - binary_accuracy: 0.8059 - val_loss: 0.4105 - val_binary_accuracy: 0.8009\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4031 - binary_accuracy: 0.8074 - val_loss: 0.4119 - val_binary_accuracy: 0.7991\n","Epoch 16/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4031 - binary_accuracy: 0.8073 - val_loss: 0.4103 - val_binary_accuracy: 0.8012\n","Epoch 17/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3970 - binary_accuracy: 0.8113 - val_loss: 0.4095 - val_binary_accuracy: 0.8013\n","Epoch 18/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4031 - binary_accuracy: 0.8077 - val_loss: 0.4093 - val_binary_accuracy: 0.8013\n","Epoch 19/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3998 - binary_accuracy: 0.8092 - val_loss: 0.4099 - val_binary_accuracy: 0.8005\n","Epoch 20/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3971 - binary_accuracy: 0.8098 - val_loss: 0.4100 - val_binary_accuracy: 0.8009\n","Epoch 21/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3991 - binary_accuracy: 0.8092 - val_loss: 0.4088 - val_binary_accuracy: 0.8016\n","Epoch 22/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3958 - binary_accuracy: 0.8100 - val_loss: 0.4080 - val_binary_accuracy: 0.8014\n","Epoch 23/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3944 - binary_accuracy: 0.8121 - val_loss: 0.4095 - val_binary_accuracy: 0.8006\n","Epoch 24/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3961 - binary_accuracy: 0.8104 - val_loss: 0.4084 - val_binary_accuracy: 0.8015\n","Epoch 25/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3933 - binary_accuracy: 0.8120 - val_loss: 0.4084 - val_binary_accuracy: 0.8016\n","Epoch 26/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3954 - binary_accuracy: 0.8128 - val_loss: 0.4087 - val_binary_accuracy: 0.8021\n","Epoch 27/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3934 - binary_accuracy: 0.8126 - val_loss: 0.4090 - val_binary_accuracy: 0.8009\n","Epoch 28/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3934 - binary_accuracy: 0.8132 - val_loss: 0.4093 - val_binary_accuracy: 0.8018\n","Epoch 29/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3931 - binary_accuracy: 0.8128 - val_loss: 0.4074 - val_binary_accuracy: 0.8024\n","Epoch 30/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3929 - binary_accuracy: 0.8122 - val_loss: 0.4085 - val_binary_accuracy: 0.8012\n","Epoch 31/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3931 - binary_accuracy: 0.8127 - val_loss: 0.4086 - val_binary_accuracy: 0.8024\n","Epoch 32/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3906 - binary_accuracy: 0.8141 - val_loss: 0.4110 - val_binary_accuracy: 0.7994\n","Epoch 33/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3894 - binary_accuracy: 0.8163 - val_loss: 0.4080 - val_binary_accuracy: 0.8028\n","Epoch 34/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3906 - binary_accuracy: 0.8158 - val_loss: 0.4091 - val_binary_accuracy: 0.8022\n","Epoch 35/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3902 - binary_accuracy: 0.8148 - val_loss: 0.4094 - val_binary_accuracy: 0.8004\n","Epoch 36/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3887 - binary_accuracy: 0.8158 - val_loss: 0.4082 - val_binary_accuracy: 0.8025\n","Epoch 37/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3899 - binary_accuracy: 0.8147 - val_loss: 0.4088 - val_binary_accuracy: 0.8015\n","Epoch 38/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3905 - binary_accuracy: 0.8144 - val_loss: 0.4088 - val_binary_accuracy: 0.8027\n"],"name":"stdout"},{"output_type":"stream","text":["\r 63%|   | 36/57 [1:10:05<39:35, 113.12s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 5s 6ms/step - loss: 0.4563 - binary_accuracy: 0.7779 - val_loss: 0.4229 - val_binary_accuracy: 0.7943\n","Epoch 2/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4125 - binary_accuracy: 0.8004 - val_loss: 0.4182 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4058 - binary_accuracy: 0.8067 - val_loss: 0.4128 - val_binary_accuracy: 0.7985\n","Epoch 4/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8069 - val_loss: 0.4135 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4025 - binary_accuracy: 0.8083 - val_loss: 0.4092 - val_binary_accuracy: 0.8003\n","Epoch 6/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3972 - binary_accuracy: 0.8115 - val_loss: 0.4080 - val_binary_accuracy: 0.8027\n","Epoch 7/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3972 - binary_accuracy: 0.8101 - val_loss: 0.4104 - val_binary_accuracy: 0.8039\n","Epoch 8/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3968 - binary_accuracy: 0.8106 - val_loss: 0.4114 - val_binary_accuracy: 0.8011\n","Epoch 9/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3947 - binary_accuracy: 0.8132 - val_loss: 0.4090 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3899 - binary_accuracy: 0.8154 - val_loss: 0.4109 - val_binary_accuracy: 0.8022\n","Epoch 11/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3895 - binary_accuracy: 0.8160 - val_loss: 0.4134 - val_binary_accuracy: 0.8019\n","Epoch 12/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.3881 - binary_accuracy: 0.8171 - val_loss: 0.4109 - val_binary_accuracy: 0.8002\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|   | 37/57 [1:10:54<31:20, 94.04s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.6028 - binary_accuracy: 0.7631 - val_loss: 0.4261 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4228 - binary_accuracy: 0.7953 - val_loss: 0.4243 - val_binary_accuracy: 0.7939\n","Epoch 3/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4194 - binary_accuracy: 0.7980 - val_loss: 0.4212 - val_binary_accuracy: 0.7960\n","Epoch 4/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4173 - binary_accuracy: 0.7993 - val_loss: 0.4241 - val_binary_accuracy: 0.7943\n","Epoch 5/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4152 - binary_accuracy: 0.7989 - val_loss: 0.4177 - val_binary_accuracy: 0.7966\n","Epoch 6/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4123 - binary_accuracy: 0.8018 - val_loss: 0.4165 - val_binary_accuracy: 0.7982\n","Epoch 7/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4112 - binary_accuracy: 0.8009 - val_loss: 0.4187 - val_binary_accuracy: 0.7972\n","Epoch 8/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4110 - binary_accuracy: 0.8026 - val_loss: 0.4133 - val_binary_accuracy: 0.7999\n","Epoch 9/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4078 - binary_accuracy: 0.8043 - val_loss: 0.4121 - val_binary_accuracy: 0.8001\n","Epoch 10/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4037 - binary_accuracy: 0.8071 - val_loss: 0.4121 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4039 - binary_accuracy: 0.8079 - val_loss: 0.4102 - val_binary_accuracy: 0.8017\n","Epoch 12/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4028 - binary_accuracy: 0.8071 - val_loss: 0.4098 - val_binary_accuracy: 0.8020\n","Epoch 13/100\n","676/676 [==============================] - 4s 6ms/step - loss: 0.4023 - binary_accuracy: 0.8058 - val_loss: 0.4100 - val_binary_accuracy: 0.8014\n","Epoch 14/100\n","676/676 [==============================] - 4s 7ms/step - loss: 0.4008 - binary_accuracy: 0.8071 - val_loss: 0.4090 - val_binary_accuracy: 0.8014\n","Epoch 15/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4001 - binary_accuracy: 0.8098 - val_loss: 0.4090 - val_binary_accuracy: 0.8018\n","Epoch 16/100\n","676/676 [==============================] - 4s 7ms/step - loss: 0.4005 - binary_accuracy: 0.8087 - val_loss: 0.4097 - val_binary_accuracy: 0.8016\n","Epoch 17/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.3941 - binary_accuracy: 0.8130 - val_loss: 0.4098 - val_binary_accuracy: 0.8009\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|   | 38/57 [1:12:11<28:09, 88.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 17s 45ms/step - loss: 0.4814 - binary_accuracy: 0.7703 - val_loss: 0.4189 - val_binary_accuracy: 0.7981\n","Epoch 2/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4110 - binary_accuracy: 0.8028 - val_loss: 0.4292 - val_binary_accuracy: 0.7950\n","Epoch 3/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4014 - binary_accuracy: 0.8097 - val_loss: 0.4130 - val_binary_accuracy: 0.8019\n","Epoch 4/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3960 - binary_accuracy: 0.8113 - val_loss: 0.4126 - val_binary_accuracy: 0.7990\n","Epoch 5/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3891 - binary_accuracy: 0.8153 - val_loss: 0.4131 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3784 - binary_accuracy: 0.8219 - val_loss: 0.4128 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3726 - binary_accuracy: 0.8247 - val_loss: 0.4204 - val_binary_accuracy: 0.8009\n","Epoch 8/100\n","338/338 [==============================] - 16s 46ms/step - loss: 0.3644 - binary_accuracy: 0.8297 - val_loss: 0.4176 - val_binary_accuracy: 0.8009\n"],"name":"stdout"},{"output_type":"stream","text":["\r 68%|   | 39/57 [1:14:15<29:47, 99.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'layer_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.6934 - binary_accuracy: 0.7428 - val_loss: 0.4218 - val_binary_accuracy: 0.7966\n","Epoch 2/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4161 - binary_accuracy: 0.7990 - val_loss: 0.4147 - val_binary_accuracy: 0.7992\n","Epoch 3/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4085 - binary_accuracy: 0.8053 - val_loss: 0.4114 - val_binary_accuracy: 0.8015\n","Epoch 4/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4054 - binary_accuracy: 0.8072 - val_loss: 0.4119 - val_binary_accuracy: 0.8007\n","Epoch 5/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4028 - binary_accuracy: 0.8082 - val_loss: 0.4094 - val_binary_accuracy: 0.8007\n","Epoch 6/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3980 - binary_accuracy: 0.8115 - val_loss: 0.4068 - val_binary_accuracy: 0.8029\n","Epoch 7/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3972 - binary_accuracy: 0.8099 - val_loss: 0.4113 - val_binary_accuracy: 0.8008\n","Epoch 8/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3961 - binary_accuracy: 0.8106 - val_loss: 0.4083 - val_binary_accuracy: 0.8017\n","Epoch 9/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3938 - binary_accuracy: 0.8122 - val_loss: 0.4067 - val_binary_accuracy: 0.8034\n","Epoch 10/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3886 - binary_accuracy: 0.8155 - val_loss: 0.4069 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3876 - binary_accuracy: 0.8163 - val_loss: 0.4067 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3859 - binary_accuracy: 0.8165 - val_loss: 0.4078 - val_binary_accuracy: 0.8021\n","Epoch 13/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3847 - binary_accuracy: 0.8167 - val_loss: 0.4081 - val_binary_accuracy: 0.8040\n","Epoch 14/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3836 - binary_accuracy: 0.8179 - val_loss: 0.4095 - val_binary_accuracy: 0.8028\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3812 - binary_accuracy: 0.8199 - val_loss: 0.4104 - val_binary_accuracy: 0.8024\n","Epoch 16/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.3801 - binary_accuracy: 0.8201 - val_loss: 0.4105 - val_binary_accuracy: 0.8028\n","Epoch 17/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3732 - binary_accuracy: 0.8235 - val_loss: 0.4117 - val_binary_accuracy: 0.8022\n","Epoch 18/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3777 - binary_accuracy: 0.8223 - val_loss: 0.4135 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|   | 40/57 [1:15:34<26:22, 93.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 233, 'optimizer': 'Adam', 'regularization': 'batch_normalization', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 15ms/step - loss: 0.4893 - binary_accuracy: 0.7609 - val_loss: 0.4174 - val_binary_accuracy: 0.7987\n","Epoch 2/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4088 - binary_accuracy: 0.8031 - val_loss: 0.4112 - val_binary_accuracy: 0.8009\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4013 - binary_accuracy: 0.8086 - val_loss: 0.4120 - val_binary_accuracy: 0.7984\n","Epoch 4/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3986 - binary_accuracy: 0.8097 - val_loss: 0.4099 - val_binary_accuracy: 0.8010\n","Epoch 5/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3957 - binary_accuracy: 0.8116 - val_loss: 0.4098 - val_binary_accuracy: 0.8009\n","Epoch 6/100\n","338/338 [==============================] - 6s 17ms/step - loss: 0.3887 - binary_accuracy: 0.8178 - val_loss: 0.4092 - val_binary_accuracy: 0.8013\n","Epoch 7/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.3880 - binary_accuracy: 0.8164 - val_loss: 0.4105 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3839 - binary_accuracy: 0.8179 - val_loss: 0.4133 - val_binary_accuracy: 0.8000\n","Epoch 9/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3802 - binary_accuracy: 0.8212 - val_loss: 0.4161 - val_binary_accuracy: 0.7982\n","Epoch 10/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3728 - binary_accuracy: 0.8252 - val_loss: 0.4163 - val_binary_accuracy: 0.7971\n","Epoch 11/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3695 - binary_accuracy: 0.8270 - val_loss: 0.4155 - val_binary_accuracy: 0.8003\n","Epoch 12/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3656 - binary_accuracy: 0.8294 - val_loss: 0.4187 - val_binary_accuracy: 0.8004\n"],"name":"stdout"},{"output_type":"stream","text":["\r 72%|  | 41/57 [1:16:34<22:14, 83.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n"],"name":"stdout"},{"output_type":"stream","text":["\r 74%|  | 42/57 [1:21:52<38:23, 153.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 233, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 11s 13ms/step - loss: 0.4622 - binary_accuracy: 0.7772 - val_loss: 0.4314 - val_binary_accuracy: 0.7847\n","Epoch 2/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4143 - binary_accuracy: 0.8001 - val_loss: 0.4279 - val_binary_accuracy: 0.7958\n","Epoch 3/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4080 - binary_accuracy: 0.8055 - val_loss: 0.4133 - val_binary_accuracy: 0.7997\n","Epoch 4/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4054 - binary_accuracy: 0.8056 - val_loss: 0.4157 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.4025 - binary_accuracy: 0.8076 - val_loss: 0.4098 - val_binary_accuracy: 0.8016\n","Epoch 6/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3966 - binary_accuracy: 0.8126 - val_loss: 0.4098 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3955 - binary_accuracy: 0.8115 - val_loss: 0.4107 - val_binary_accuracy: 0.8029\n","Epoch 8/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3940 - binary_accuracy: 0.8124 - val_loss: 0.4106 - val_binary_accuracy: 0.8014\n","Epoch 9/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3914 - binary_accuracy: 0.8144 - val_loss: 0.4148 - val_binary_accuracy: 0.8000\n","Epoch 10/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3845 - binary_accuracy: 0.8187 - val_loss: 0.4156 - val_binary_accuracy: 0.7994\n","Epoch 11/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3823 - binary_accuracy: 0.8189 - val_loss: 0.4153 - val_binary_accuracy: 0.8027\n","Epoch 12/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.3794 - binary_accuracy: 0.8218 - val_loss: 0.4217 - val_binary_accuracy: 0.7934\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|  | 43/57 [1:23:39<32:35, 139.71s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 150, 'optimizer': 'Adam', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 13s 18ms/step - loss: 0.4633 - binary_accuracy: 0.7712 - val_loss: 0.4229 - val_binary_accuracy: 0.7946\n","Epoch 2/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.4106 - binary_accuracy: 0.8026 - val_loss: 0.4190 - val_binary_accuracy: 0.7999\n","Epoch 3/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.4018 - binary_accuracy: 0.8095 - val_loss: 0.4129 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","676/676 [==============================] - 12s 17ms/step - loss: 0.3966 - binary_accuracy: 0.8111 - val_loss: 0.4176 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","676/676 [==============================] - 12s 17ms/step - loss: 0.3904 - binary_accuracy: 0.8142 - val_loss: 0.4167 - val_binary_accuracy: 0.8013\n","Epoch 6/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.3819 - binary_accuracy: 0.8193 - val_loss: 0.4159 - val_binary_accuracy: 0.8006\n","Epoch 7/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.3769 - binary_accuracy: 0.8204 - val_loss: 0.4178 - val_binary_accuracy: 0.8013\n","Epoch 8/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.3705 - binary_accuracy: 0.8247 - val_loss: 0.4251 - val_binary_accuracy: 0.8002\n","Epoch 9/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.3617 - binary_accuracy: 0.8290 - val_loss: 0.4397 - val_binary_accuracy: 0.7972\n","Epoch 10/100\n","676/676 [==============================] - 11s 17ms/step - loss: 0.3485 - binary_accuracy: 0.8369 - val_loss: 0.4438 - val_binary_accuracy: 0.7963\n","Epoch 11/100\n","676/676 [==============================] - 12s 17ms/step - loss: 0.3437 - binary_accuracy: 0.8391 - val_loss: 0.4433 - val_binary_accuracy: 0.7939\n","Epoch 12/100\n","676/676 [==============================] - 12s 17ms/step - loss: 0.3339 - binary_accuracy: 0.8434 - val_loss: 0.4483 - val_binary_accuracy: 0.7936\n"],"name":"stdout"},{"output_type":"stream","text":["\r 77%|  | 44/57 [1:25:59<30:18, 139.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4811 - binary_accuracy: 0.7597 - val_loss: 0.4239 - val_binary_accuracy: 0.7949\n","Epoch 2/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4295 - binary_accuracy: 0.7923 - val_loss: 0.4197 - val_binary_accuracy: 0.7965\n","Epoch 3/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4243 - binary_accuracy: 0.7973 - val_loss: 0.4207 - val_binary_accuracy: 0.7973\n","Epoch 4/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4231 - binary_accuracy: 0.7976 - val_loss: 0.4170 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4215 - binary_accuracy: 0.7969 - val_loss: 0.4166 - val_binary_accuracy: 0.7993\n","Epoch 6/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4186 - binary_accuracy: 0.7996 - val_loss: 0.4150 - val_binary_accuracy: 0.7996\n","Epoch 7/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4184 - binary_accuracy: 0.7996 - val_loss: 0.4130 - val_binary_accuracy: 0.8002\n","Epoch 8/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4174 - binary_accuracy: 0.8012 - val_loss: 0.4120 - val_binary_accuracy: 0.8007\n","Epoch 9/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4170 - binary_accuracy: 0.8008 - val_loss: 0.4126 - val_binary_accuracy: 0.8021\n","Epoch 10/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4128 - binary_accuracy: 0.8036 - val_loss: 0.4115 - val_binary_accuracy: 0.8019\n","Epoch 11/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4122 - binary_accuracy: 0.8043 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 12/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4121 - binary_accuracy: 0.8037 - val_loss: 0.4108 - val_binary_accuracy: 0.8013\n","Epoch 13/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4114 - binary_accuracy: 0.8014 - val_loss: 0.4097 - val_binary_accuracy: 0.8016\n","Epoch 14/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4115 - binary_accuracy: 0.8030 - val_loss: 0.4090 - val_binary_accuracy: 0.8026\n","Epoch 15/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4102 - binary_accuracy: 0.8039 - val_loss: 0.4115 - val_binary_accuracy: 0.8019\n","Epoch 16/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4116 - binary_accuracy: 0.8037 - val_loss: 0.4087 - val_binary_accuracy: 0.8033\n","Epoch 17/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4050 - binary_accuracy: 0.8076 - val_loss: 0.4086 - val_binary_accuracy: 0.8032\n","Epoch 18/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4108 - binary_accuracy: 0.8038 - val_loss: 0.4084 - val_binary_accuracy: 0.8038\n","Epoch 19/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4088 - binary_accuracy: 0.8055 - val_loss: 0.4099 - val_binary_accuracy: 0.8036\n","Epoch 20/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4055 - binary_accuracy: 0.8063 - val_loss: 0.4078 - val_binary_accuracy: 0.8040\n","Epoch 21/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4089 - binary_accuracy: 0.8054 - val_loss: 0.4069 - val_binary_accuracy: 0.8035\n","Epoch 22/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4048 - binary_accuracy: 0.8067 - val_loss: 0.4085 - val_binary_accuracy: 0.8028\n","Epoch 23/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4043 - binary_accuracy: 0.8066 - val_loss: 0.4077 - val_binary_accuracy: 0.8034\n","Epoch 24/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4062 - binary_accuracy: 0.8051 - val_loss: 0.4080 - val_binary_accuracy: 0.8039\n","Epoch 25/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4029 - binary_accuracy: 0.8075 - val_loss: 0.4082 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 79%|  | 45/57 [1:29:08<30:53, 154.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop_centered', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 57s 82ms/step - loss: 0.7064 - binary_accuracy: 0.7439 - val_loss: 0.4580 - val_binary_accuracy: 0.7626\n","Epoch 2/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.4239 - binary_accuracy: 0.7948 - val_loss: 0.4403 - val_binary_accuracy: 0.7927\n","Epoch 3/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.4156 - binary_accuracy: 0.8017 - val_loss: 0.4603 - val_binary_accuracy: 0.7902\n","Epoch 4/100\n","676/676 [==============================] - 55s 81ms/step - loss: 0.4121 - binary_accuracy: 0.8027 - val_loss: 0.4285 - val_binary_accuracy: 0.7939\n","Epoch 5/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.4081 - binary_accuracy: 0.8052 - val_loss: 0.4205 - val_binary_accuracy: 0.8007\n","Epoch 6/100\n","676/676 [==============================] - 55s 81ms/step - loss: 0.4039 - binary_accuracy: 0.8082 - val_loss: 0.4132 - val_binary_accuracy: 0.8008\n","Epoch 7/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.4024 - binary_accuracy: 0.8071 - val_loss: 0.4250 - val_binary_accuracy: 0.7987\n","Epoch 8/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.4018 - binary_accuracy: 0.8092 - val_loss: 0.4132 - val_binary_accuracy: 0.8019\n","Epoch 9/100\n","676/676 [==============================] - 54s 81ms/step - loss: 0.3981 - binary_accuracy: 0.8106 - val_loss: 0.4158 - val_binary_accuracy: 0.8006\n","Epoch 10/100\n","676/676 [==============================] - 56s 83ms/step - loss: 0.3930 - binary_accuracy: 0.8145 - val_loss: 0.4146 - val_binary_accuracy: 0.8018\n","Epoch 11/100\n","676/676 [==============================] - 56s 83ms/step - loss: 0.3923 - binary_accuracy: 0.8135 - val_loss: 0.4190 - val_binary_accuracy: 0.8022\n","Epoch 12/100\n","676/676 [==============================] - 56s 83ms/step - loss: 0.3902 - binary_accuracy: 0.8151 - val_loss: 0.4231 - val_binary_accuracy: 0.7962\n","Epoch 13/100\n","676/676 [==============================] - 56s 83ms/step - loss: 0.3880 - binary_accuracy: 0.8142 - val_loss: 0.4116 - val_binary_accuracy: 0.8019\n","Epoch 14/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.3860 - binary_accuracy: 0.8163 - val_loss: 0.4150 - val_binary_accuracy: 0.8013\n","Epoch 15/100\n","676/676 [==============================] - 56s 82ms/step - loss: 0.3833 - binary_accuracy: 0.8187 - val_loss: 0.4176 - val_binary_accuracy: 0.8002\n","Epoch 16/100\n","676/676 [==============================] - 55s 82ms/step - loss: 0.3820 - binary_accuracy: 0.8195 - val_loss: 0.4333 - val_binary_accuracy: 0.8000\n"],"name":"stdout"},{"output_type":"stream","text":["\r 81%|  | 46/57 [1:43:57<1:08:43, 374.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 233, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 9s 13ms/step - loss: 0.5246 - binary_accuracy: 0.7360 - val_loss: 0.4290 - val_binary_accuracy: 0.7961\n","Epoch 2/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4324 - binary_accuracy: 0.7910 - val_loss: 0.4199 - val_binary_accuracy: 0.7996\n","Epoch 3/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4222 - binary_accuracy: 0.7996 - val_loss: 0.4217 - val_binary_accuracy: 0.8025\n","Epoch 4/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4188 - binary_accuracy: 0.8022 - val_loss: 0.4159 - val_binary_accuracy: 0.8019\n","Epoch 5/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4158 - binary_accuracy: 0.8034 - val_loss: 0.4170 - val_binary_accuracy: 0.8029\n","Epoch 6/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4112 - binary_accuracy: 0.8062 - val_loss: 0.4139 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4105 - binary_accuracy: 0.8040 - val_loss: 0.4116 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4090 - binary_accuracy: 0.8052 - val_loss: 0.4137 - val_binary_accuracy: 0.8037\n","Epoch 9/100\n","676/676 [==============================] - 8s 13ms/step - loss: 0.4069 - binary_accuracy: 0.8080 - val_loss: 0.4129 - val_binary_accuracy: 0.8042\n","Epoch 10/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4020 - binary_accuracy: 0.8116 - val_loss: 0.4131 - val_binary_accuracy: 0.8037\n","Epoch 11/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.4011 - binary_accuracy: 0.8113 - val_loss: 0.4125 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3994 - binary_accuracy: 0.8110 - val_loss: 0.4095 - val_binary_accuracy: 0.8037\n","Epoch 13/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3985 - binary_accuracy: 0.8123 - val_loss: 0.4084 - val_binary_accuracy: 0.8051\n","Epoch 14/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3984 - binary_accuracy: 0.8112 - val_loss: 0.4076 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3952 - binary_accuracy: 0.8146 - val_loss: 0.4146 - val_binary_accuracy: 0.8042\n","Epoch 16/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3954 - binary_accuracy: 0.8135 - val_loss: 0.4095 - val_binary_accuracy: 0.8031\n","Epoch 17/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3903 - binary_accuracy: 0.8160 - val_loss: 0.4125 - val_binary_accuracy: 0.8034\n","Epoch 18/100\n","676/676 [==============================] - 8s 12ms/step - loss: 0.3942 - binary_accuracy: 0.8139 - val_loss: 0.4102 - val_binary_accuracy: 0.8044\n"],"name":"stdout"},{"output_type":"stream","text":["\r 82%| | 47/57 [1:46:27<51:12, 307.30s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'regularization': 'batch_normalization', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.6665 - binary_accuracy: 0.7469 - val_loss: 0.4306 - val_binary_accuracy: 0.7903\n","Epoch 2/100\n","338/338 [==============================] - 6s 18ms/step - loss: 0.4057 - binary_accuracy: 0.8072 - val_loss: 0.4103 - val_binary_accuracy: 0.8029\n","Epoch 3/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3954 - binary_accuracy: 0.8138 - val_loss: 0.4118 - val_binary_accuracy: 0.8017\n","Epoch 4/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3895 - binary_accuracy: 0.8155 - val_loss: 0.4132 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3833 - binary_accuracy: 0.8198 - val_loss: 0.4131 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3732 - binary_accuracy: 0.8262 - val_loss: 0.4165 - val_binary_accuracy: 0.7993\n","Epoch 7/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3688 - binary_accuracy: 0.8272 - val_loss: 0.4206 - val_binary_accuracy: 0.8002\n"],"name":"stdout"},{"output_type":"stream","text":["\r 84%| | 48/57 [1:47:01<33:48, 225.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 10s 11ms/step - loss: 0.4639 - binary_accuracy: 0.7774 - val_loss: 0.4270 - val_binary_accuracy: 0.7897\n","Epoch 2/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4127 - binary_accuracy: 0.8004 - val_loss: 0.4239 - val_binary_accuracy: 0.7978\n","Epoch 3/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4055 - binary_accuracy: 0.8067 - val_loss: 0.4140 - val_binary_accuracy: 0.7999\n","Epoch 4/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4020 - binary_accuracy: 0.8079 - val_loss: 0.4181 - val_binary_accuracy: 0.7981\n","Epoch 5/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3984 - binary_accuracy: 0.8100 - val_loss: 0.4117 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.3918 - binary_accuracy: 0.8146 - val_loss: 0.4116 - val_binary_accuracy: 0.8008\n","Epoch 7/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3889 - binary_accuracy: 0.8152 - val_loss: 0.4136 - val_binary_accuracy: 0.8001\n","Epoch 8/100\n","676/676 [==============================] - 7s 11ms/step - loss: 0.3862 - binary_accuracy: 0.8157 - val_loss: 0.4144 - val_binary_accuracy: 0.8023\n","Epoch 9/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3821 - binary_accuracy: 0.8195 - val_loss: 0.4217 - val_binary_accuracy: 0.7998\n","Epoch 10/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3741 - binary_accuracy: 0.8239 - val_loss: 0.4227 - val_binary_accuracy: 0.7982\n","Epoch 11/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3701 - binary_accuracy: 0.8252 - val_loss: 0.4270 - val_binary_accuracy: 0.7987\n","Epoch 12/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3663 - binary_accuracy: 0.8283 - val_loss: 0.4291 - val_binary_accuracy: 0.7929\n","Epoch 13/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.3620 - binary_accuracy: 0.8291 - val_loss: 0.4341 - val_binary_accuracy: 0.7935\n"],"name":"stdout"},{"output_type":"stream","text":["\r 86%| | 49/57 [1:48:35<24:47, 185.99s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 21ms/step - loss: 0.8181 - binary_accuracy: 0.7535 - val_loss: 0.4245 - val_binary_accuracy: 0.7926\n","Epoch 2/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4196 - binary_accuracy: 0.7976 - val_loss: 0.4187 - val_binary_accuracy: 0.7981\n","Epoch 3/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4148 - binary_accuracy: 0.8011 - val_loss: 0.4151 - val_binary_accuracy: 0.7988\n","Epoch 4/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4124 - binary_accuracy: 0.8022 - val_loss: 0.4158 - val_binary_accuracy: 0.7982\n","Epoch 5/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4100 - binary_accuracy: 0.8035 - val_loss: 0.4107 - val_binary_accuracy: 0.8009\n","Epoch 6/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4062 - binary_accuracy: 0.8063 - val_loss: 0.4100 - val_binary_accuracy: 0.8016\n","Epoch 7/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4046 - binary_accuracy: 0.8054 - val_loss: 0.4176 - val_binary_accuracy: 0.7966\n","Epoch 8/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4052 - binary_accuracy: 0.8055 - val_loss: 0.4114 - val_binary_accuracy: 0.8002\n","Epoch 9/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4026 - binary_accuracy: 0.8076 - val_loss: 0.4085 - val_binary_accuracy: 0.8019\n","Epoch 10/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3979 - binary_accuracy: 0.8096 - val_loss: 0.4079 - val_binary_accuracy: 0.8022\n","Epoch 11/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3976 - binary_accuracy: 0.8107 - val_loss: 0.4072 - val_binary_accuracy: 0.8020\n","Epoch 12/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3967 - binary_accuracy: 0.8103 - val_loss: 0.4091 - val_binary_accuracy: 0.8008\n","Epoch 13/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3955 - binary_accuracy: 0.8091 - val_loss: 0.4081 - val_binary_accuracy: 0.8027\n","Epoch 14/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3954 - binary_accuracy: 0.8102 - val_loss: 0.4078 - val_binary_accuracy: 0.8031\n","Epoch 15/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.3938 - binary_accuracy: 0.8124 - val_loss: 0.4089 - val_binary_accuracy: 0.8019\n","Epoch 16/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3931 - binary_accuracy: 0.8117 - val_loss: 0.4082 - val_binary_accuracy: 0.8036\n","Epoch 17/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3870 - binary_accuracy: 0.8156 - val_loss: 0.4087 - val_binary_accuracy: 0.8028\n","Epoch 18/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3921 - binary_accuracy: 0.8130 - val_loss: 0.4081 - val_binary_accuracy: 0.8025\n","Epoch 19/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3891 - binary_accuracy: 0.8141 - val_loss: 0.4093 - val_binary_accuracy: 0.8007\n","Epoch 20/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3849 - binary_accuracy: 0.8158 - val_loss: 0.4115 - val_binary_accuracy: 0.8013\n","Epoch 21/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3873 - binary_accuracy: 0.8147 - val_loss: 0.4086 - val_binary_accuracy: 0.8032\n"],"name":"stdout"},{"output_type":"stream","text":["\r 88%| | 50/57 [1:51:05<20:26, 175.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 300, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'glorot_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 6s 7ms/step - loss: 0.4634 - binary_accuracy: 0.7694 - val_loss: 0.4200 - val_binary_accuracy: 0.7981\n","Epoch 2/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4194 - binary_accuracy: 0.7973 - val_loss: 0.4160 - val_binary_accuracy: 0.7989\n","Epoch 3/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4148 - binary_accuracy: 0.8019 - val_loss: 0.4144 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4138 - binary_accuracy: 0.8012 - val_loss: 0.4150 - val_binary_accuracy: 0.7998\n","Epoch 5/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4126 - binary_accuracy: 0.8029 - val_loss: 0.4113 - val_binary_accuracy: 0.8016\n","Epoch 6/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4099 - binary_accuracy: 0.8052 - val_loss: 0.4107 - val_binary_accuracy: 0.8027\n","Epoch 7/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4100 - binary_accuracy: 0.8036 - val_loss: 0.4122 - val_binary_accuracy: 0.8026\n","Epoch 8/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4103 - binary_accuracy: 0.8045 - val_loss: 0.4101 - val_binary_accuracy: 0.8034\n","Epoch 9/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4085 - binary_accuracy: 0.8056 - val_loss: 0.4099 - val_binary_accuracy: 0.8022\n","Epoch 10/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4054 - binary_accuracy: 0.8086 - val_loss: 0.4099 - val_binary_accuracy: 0.8026\n","Epoch 11/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4059 - binary_accuracy: 0.8069 - val_loss: 0.4096 - val_binary_accuracy: 0.8038\n","Epoch 12/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4045 - binary_accuracy: 0.8067 - val_loss: 0.4095 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4053 - binary_accuracy: 0.8063 - val_loss: 0.4094 - val_binary_accuracy: 0.8022\n","Epoch 14/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4045 - binary_accuracy: 0.8064 - val_loss: 0.4095 - val_binary_accuracy: 0.8026\n","Epoch 15/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4050 - binary_accuracy: 0.8091 - val_loss: 0.4095 - val_binary_accuracy: 0.8029\n","Epoch 16/100\n","676/676 [==============================] - 5s 7ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4102 - val_binary_accuracy: 0.8036\n"],"name":"stdout"},{"output_type":"stream","text":["\r 89%| | 51/57 [1:52:22<14:34, 145.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop_centered', 'regularization': 'layer_normalization', 'weight_initializer': 'lecun_uniform'}\n","Epoch 1/100\n","676/676 [==============================] - 8s 10ms/step - loss: 0.4441 - binary_accuracy: 0.7833 - val_loss: 0.4235 - val_binary_accuracy: 0.7940\n","Epoch 2/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.4101 - binary_accuracy: 0.8029 - val_loss: 0.4208 - val_binary_accuracy: 0.7983\n","Epoch 3/100\n","676/676 [==============================] - 7s 10ms/step - loss: 0.4031 - binary_accuracy: 0.8089 - val_loss: 0.4254 - val_binary_accuracy: 0.7976\n","Epoch 4/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.3998 - binary_accuracy: 0.8082 - val_loss: 0.4159 - val_binary_accuracy: 0.8003\n","Epoch 5/100\n","676/676 [==============================] - 6s 10ms/step - loss: 0.3966 - binary_accuracy: 0.8116 - val_loss: 0.4099 - val_binary_accuracy: 0.8038\n","Epoch 6/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3913 - binary_accuracy: 0.8151 - val_loss: 0.4100 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3887 - binary_accuracy: 0.8146 - val_loss: 0.4127 - val_binary_accuracy: 0.8020\n","Epoch 8/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3878 - binary_accuracy: 0.8164 - val_loss: 0.4111 - val_binary_accuracy: 0.8015\n","Epoch 9/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3833 - binary_accuracy: 0.8183 - val_loss: 0.4160 - val_binary_accuracy: 0.8011\n","Epoch 10/100\n","676/676 [==============================] - 6s 9ms/step - loss: 0.3773 - binary_accuracy: 0.8229 - val_loss: 0.4159 - val_binary_accuracy: 0.8001\n"],"name":"stdout"},{"output_type":"stream","text":["\r 91%| | 52/57 [1:53:27<10:08, 121.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 100, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5530 - binary_accuracy: 0.7078 - val_loss: 0.4269 - val_binary_accuracy: 0.7918\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4462 - binary_accuracy: 0.7857 - val_loss: 0.4222 - val_binary_accuracy: 0.7943\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4367 - binary_accuracy: 0.7933 - val_loss: 0.4206 - val_binary_accuracy: 0.7958\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4345 - binary_accuracy: 0.7937 - val_loss: 0.4202 - val_binary_accuracy: 0.7956\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4329 - binary_accuracy: 0.7938 - val_loss: 0.4186 - val_binary_accuracy: 0.7976\n","Epoch 6/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4312 - binary_accuracy: 0.7951 - val_loss: 0.4181 - val_binary_accuracy: 0.7976\n","Epoch 7/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4320 - binary_accuracy: 0.7941 - val_loss: 0.4176 - val_binary_accuracy: 0.7972\n","Epoch 8/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4300 - binary_accuracy: 0.7946 - val_loss: 0.4166 - val_binary_accuracy: 0.7987\n","Epoch 9/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4291 - binary_accuracy: 0.7962 - val_loss: 0.4165 - val_binary_accuracy: 0.7982\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4266 - binary_accuracy: 0.7977 - val_loss: 0.4161 - val_binary_accuracy: 0.7995\n","Epoch 11/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4257 - binary_accuracy: 0.7980 - val_loss: 0.4151 - val_binary_accuracy: 0.7989\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4257 - binary_accuracy: 0.7988 - val_loss: 0.4151 - val_binary_accuracy: 0.7988\n","Epoch 13/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4245 - binary_accuracy: 0.7986 - val_loss: 0.4146 - val_binary_accuracy: 0.7989\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4243 - binary_accuracy: 0.7988 - val_loss: 0.4144 - val_binary_accuracy: 0.8004\n","Epoch 15/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4233 - binary_accuracy: 0.7988 - val_loss: 0.4139 - val_binary_accuracy: 0.7996\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4244 - binary_accuracy: 0.7978 - val_loss: 0.4135 - val_binary_accuracy: 0.8005\n","Epoch 17/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.4187 - binary_accuracy: 0.8025 - val_loss: 0.4135 - val_binary_accuracy: 0.7996\n","Epoch 18/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4251 - binary_accuracy: 0.7975 - val_loss: 0.4136 - val_binary_accuracy: 0.8008\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4224 - binary_accuracy: 0.7994 - val_loss: 0.4131 - val_binary_accuracy: 0.8012\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4198 - binary_accuracy: 0.8015 - val_loss: 0.4125 - val_binary_accuracy: 0.8006\n","Epoch 21/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4222 - binary_accuracy: 0.7996 - val_loss: 0.4127 - val_binary_accuracy: 0.8011\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4192 - binary_accuracy: 0.8018 - val_loss: 0.4122 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4202 - binary_accuracy: 0.8014 - val_loss: 0.4118 - val_binary_accuracy: 0.8006\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4193 - binary_accuracy: 0.8010 - val_loss: 0.4109 - val_binary_accuracy: 0.8023\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4186 - binary_accuracy: 0.8009 - val_loss: 0.4113 - val_binary_accuracy: 0.8015\n","Epoch 26/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4192 - binary_accuracy: 0.8023 - val_loss: 0.4112 - val_binary_accuracy: 0.8024\n","Epoch 27/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4187 - binary_accuracy: 0.8021 - val_loss: 0.4110 - val_binary_accuracy: 0.8017\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4193 - binary_accuracy: 0.8017 - val_loss: 0.4107 - val_binary_accuracy: 0.8025\n","Epoch 29/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4193 - binary_accuracy: 0.8010 - val_loss: 0.4102 - val_binary_accuracy: 0.8030\n","Epoch 30/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4194 - binary_accuracy: 0.8013 - val_loss: 0.4104 - val_binary_accuracy: 0.8026\n","Epoch 31/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4186 - binary_accuracy: 0.8009 - val_loss: 0.4106 - val_binary_accuracy: 0.8017\n","Epoch 32/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4174 - binary_accuracy: 0.8026 - val_loss: 0.4096 - val_binary_accuracy: 0.8033\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4155 - binary_accuracy: 0.8032 - val_loss: 0.4103 - val_binary_accuracy: 0.8019\n","Epoch 34/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4174 - binary_accuracy: 0.8019 - val_loss: 0.4096 - val_binary_accuracy: 0.8031\n","Epoch 35/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4188 - binary_accuracy: 0.8025 - val_loss: 0.4093 - val_binary_accuracy: 0.8029\n","Epoch 36/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4178 - binary_accuracy: 0.8029 - val_loss: 0.4093 - val_binary_accuracy: 0.8034\n","Epoch 37/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4191 - binary_accuracy: 0.8023 - val_loss: 0.4088 - val_binary_accuracy: 0.8031\n","Epoch 38/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4172 - binary_accuracy: 0.8021 - val_loss: 0.4088 - val_binary_accuracy: 0.8029\n","Epoch 39/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4162 - binary_accuracy: 0.8027 - val_loss: 0.4083 - val_binary_accuracy: 0.8034\n","Epoch 40/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4139 - binary_accuracy: 0.8043 - val_loss: 0.4092 - val_binary_accuracy: 0.8020\n","Epoch 41/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4166 - binary_accuracy: 0.8026 - val_loss: 0.4091 - val_binary_accuracy: 0.8029\n"],"name":"stdout"},{"output_type":"stream","text":["\r 93%|| 53/57 [1:55:03<07:35, 113.97s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 256, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'lecun_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 16s 22ms/step - loss: 0.4595 - binary_accuracy: 0.7708 - val_loss: 0.4209 - val_binary_accuracy: 0.7964\n","Epoch 2/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4231 - binary_accuracy: 0.7969 - val_loss: 0.4182 - val_binary_accuracy: 0.7976\n","Epoch 3/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4195 - binary_accuracy: 0.7995 - val_loss: 0.4156 - val_binary_accuracy: 0.7990\n","Epoch 4/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4180 - binary_accuracy: 0.8008 - val_loss: 0.4143 - val_binary_accuracy: 0.8001\n","Epoch 5/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4167 - binary_accuracy: 0.7995 - val_loss: 0.4107 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4135 - binary_accuracy: 0.8033 - val_loss: 0.4093 - val_binary_accuracy: 0.8023\n","Epoch 7/100\n","676/676 [==============================] - 16s 24ms/step - loss: 0.4129 - binary_accuracy: 0.8021 - val_loss: 0.4146 - val_binary_accuracy: 0.7996\n","Epoch 8/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4139 - binary_accuracy: 0.8038 - val_loss: 0.4118 - val_binary_accuracy: 0.8025\n","Epoch 9/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4108 - binary_accuracy: 0.8033 - val_loss: 0.4085 - val_binary_accuracy: 0.8023\n","Epoch 10/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4074 - binary_accuracy: 0.8071 - val_loss: 0.4087 - val_binary_accuracy: 0.8039\n","Epoch 11/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4080 - binary_accuracy: 0.8068 - val_loss: 0.4068 - val_binary_accuracy: 0.8038\n","Epoch 12/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4065 - binary_accuracy: 0.8071 - val_loss: 0.4065 - val_binary_accuracy: 0.8039\n","Epoch 13/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4053 - binary_accuracy: 0.8067 - val_loss: 0.4058 - val_binary_accuracy: 0.8037\n","Epoch 14/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4062 - binary_accuracy: 0.8074 - val_loss: 0.4052 - val_binary_accuracy: 0.8047\n","Epoch 15/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4041 - binary_accuracy: 0.8091 - val_loss: 0.4074 - val_binary_accuracy: 0.8044\n","Epoch 16/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4044 - binary_accuracy: 0.8087 - val_loss: 0.4058 - val_binary_accuracy: 0.8046\n","Epoch 17/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.3991 - binary_accuracy: 0.8121 - val_loss: 0.4054 - val_binary_accuracy: 0.8040\n","Epoch 18/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4049 - binary_accuracy: 0.8096 - val_loss: 0.4064 - val_binary_accuracy: 0.8053\n","Epoch 19/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4014 - binary_accuracy: 0.8103 - val_loss: 0.4057 - val_binary_accuracy: 0.8048\n","Epoch 20/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.3981 - binary_accuracy: 0.8109 - val_loss: 0.4067 - val_binary_accuracy: 0.8031\n","Epoch 21/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.4017 - binary_accuracy: 0.8090 - val_loss: 0.4045 - val_binary_accuracy: 0.8050\n","Epoch 22/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.3984 - binary_accuracy: 0.8110 - val_loss: 0.4052 - val_binary_accuracy: 0.8051\n","Epoch 23/100\n","676/676 [==============================] - 15s 22ms/step - loss: 0.3963 - binary_accuracy: 0.8126 - val_loss: 0.4084 - val_binary_accuracy: 0.8025\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|| 54/57 [2:00:48<09:09, 183.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 300, 'optimizer': 'RMSprop', 'regularization': 'layer_normalization', 'weight_initializer': 'glorot_normal'}\n","Epoch 1/100\n","338/338 [==============================] - 11s 29ms/step - loss: 0.5143 - binary_accuracy: 0.7609 - val_loss: 0.4246 - val_binary_accuracy: 0.7948\n","Epoch 2/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4173 - binary_accuracy: 0.7980 - val_loss: 0.4316 - val_binary_accuracy: 0.7935\n","Epoch 3/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4092 - binary_accuracy: 0.8053 - val_loss: 0.4154 - val_binary_accuracy: 0.7982\n","Epoch 4/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4066 - binary_accuracy: 0.8056 - val_loss: 0.4123 - val_binary_accuracy: 0.7980\n","Epoch 5/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.4034 - binary_accuracy: 0.8076 - val_loss: 0.4113 - val_binary_accuracy: 0.8011\n","Epoch 6/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3981 - binary_accuracy: 0.8107 - val_loss: 0.4088 - val_binary_accuracy: 0.8017\n","Epoch 7/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3974 - binary_accuracy: 0.8096 - val_loss: 0.4110 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3965 - binary_accuracy: 0.8108 - val_loss: 0.4083 - val_binary_accuracy: 0.8033\n","Epoch 9/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3924 - binary_accuracy: 0.8126 - val_loss: 0.4139 - val_binary_accuracy: 0.8013\n","Epoch 10/100\n","338/338 [==============================] - 10s 28ms/step - loss: 0.3878 - binary_accuracy: 0.8157 - val_loss: 0.4113 - val_binary_accuracy: 0.8013\n","Epoch 11/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3875 - binary_accuracy: 0.8163 - val_loss: 0.4106 - val_binary_accuracy: 0.8019\n","Epoch 12/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3855 - binary_accuracy: 0.8165 - val_loss: 0.4095 - val_binary_accuracy: 0.8017\n","Epoch 13/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3842 - binary_accuracy: 0.8158 - val_loss: 0.4113 - val_binary_accuracy: 0.8013\n"],"name":"stdout"},{"output_type":"stream","text":["\r 96%|| 55/57 [2:02:55<05:32, 166.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 14s 39ms/step - loss: 0.5295 - binary_accuracy: 0.7575 - val_loss: 0.4442 - val_binary_accuracy: 0.7837\n","Epoch 2/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4200 - binary_accuracy: 0.7957 - val_loss: 0.4206 - val_binary_accuracy: 0.7965\n","Epoch 3/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4093 - binary_accuracy: 0.8045 - val_loss: 0.4207 - val_binary_accuracy: 0.7936\n","Epoch 4/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4072 - binary_accuracy: 0.8052 - val_loss: 0.4165 - val_binary_accuracy: 0.7984\n","Epoch 5/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4038 - binary_accuracy: 0.8068 - val_loss: 0.4089 - val_binary_accuracy: 0.8011\n","Epoch 6/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.3982 - binary_accuracy: 0.8111 - val_loss: 0.4100 - val_binary_accuracy: 0.8014\n","Epoch 7/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.3977 - binary_accuracy: 0.8102 - val_loss: 0.4117 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.3969 - binary_accuracy: 0.8108 - val_loss: 0.4105 - val_binary_accuracy: 0.8009\n","Epoch 9/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.3937 - binary_accuracy: 0.8130 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 10/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.3888 - binary_accuracy: 0.8161 - val_loss: 0.4098 - val_binary_accuracy: 0.8009\n","Epoch 11/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.3877 - binary_accuracy: 0.8167 - val_loss: 0.4129 - val_binary_accuracy: 0.8007\n","Epoch 12/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.3852 - binary_accuracy: 0.8179 - val_loss: 0.4134 - val_binary_accuracy: 0.7983\n"],"name":"stdout"},{"output_type":"stream","text":["\r 98%|| 56/57 [2:05:32<02:43, 163.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 256, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 150, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_normal'}\n","Epoch 1/100\n","676/676 [==============================] - 4s 5ms/step - loss: 0.4809 - binary_accuracy: 0.7569 - val_loss: 0.4199 - val_binary_accuracy: 0.7975\n","Epoch 2/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4226 - binary_accuracy: 0.7960 - val_loss: 0.4150 - val_binary_accuracy: 0.7998\n","Epoch 3/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4159 - binary_accuracy: 0.8025 - val_loss: 0.4145 - val_binary_accuracy: 0.8019\n","Epoch 4/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4145 - binary_accuracy: 0.8033 - val_loss: 0.4149 - val_binary_accuracy: 0.8010\n","Epoch 5/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4133 - binary_accuracy: 0.8037 - val_loss: 0.4118 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4113 - binary_accuracy: 0.8063 - val_loss: 0.4116 - val_binary_accuracy: 0.8026\n","Epoch 7/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4120 - binary_accuracy: 0.8041 - val_loss: 0.4138 - val_binary_accuracy: 0.8012\n","Epoch 8/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4125 - binary_accuracy: 0.8044 - val_loss: 0.4114 - val_binary_accuracy: 0.8025\n","Epoch 9/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4101 - binary_accuracy: 0.8066 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 10/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4071 - binary_accuracy: 0.8083 - val_loss: 0.4114 - val_binary_accuracy: 0.8028\n","Epoch 11/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4086 - binary_accuracy: 0.8078 - val_loss: 0.4113 - val_binary_accuracy: 0.8027\n","Epoch 12/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4077 - binary_accuracy: 0.8082 - val_loss: 0.4114 - val_binary_accuracy: 0.8029\n","Epoch 13/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4075 - binary_accuracy: 0.8077 - val_loss: 0.4110 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4069 - binary_accuracy: 0.8072 - val_loss: 0.4113 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4072 - binary_accuracy: 0.8079 - val_loss: 0.4110 - val_binary_accuracy: 0.8030\n","Epoch 16/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4085 - binary_accuracy: 0.8072 - val_loss: 0.4118 - val_binary_accuracy: 0.8027\n","Epoch 17/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4030 - binary_accuracy: 0.8112 - val_loss: 0.4112 - val_binary_accuracy: 0.8022\n","Epoch 18/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4094 - binary_accuracy: 0.8069 - val_loss: 0.4120 - val_binary_accuracy: 0.8025\n","Epoch 19/100\n","676/676 [==============================] - 3s 4ms/step - loss: 0.4070 - binary_accuracy: 0.8088 - val_loss: 0.4112 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 57/57 [2:06:26<00:00, 133.09s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"id":"iVz1O8uLKQ45","executionInfo":{"status":"ok","timestamp":1611330813916,"user_tz":-60,"elapsed":530,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"d05b8bff-91ac-46cb-debf-1fab4249b7cc"},"source":["# Get search results for all evaluated hyperparameter combinations sorted by val_accuracy\n","analyze_object = talos.Analyze(search_object)\n","analyze_object.data.sort_values(by=\"val_binary_accuracy\", ascending=False).round(4).head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>duration</th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>binary_accuracy</th>\n","      <th>val_loss</th>\n","      <th>val_binary_accuracy</th>\n","      <th>activation_function</th>\n","      <th>batch_size</th>\n","      <th>network_decay</th>\n","      <th>network_shape</th>\n","      <th>number_of_layers</th>\n","      <th>number_of_units_first_layer</th>\n","      <th>optimizer</th>\n","      <th>regularization</th>\n","      <th>weight_initializer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>41</th>\n","      <td>01/22/21-144240</td>\n","      <td>01/22/21-144757</td>\n","      <td>317.1675</td>\n","      <td>23</td>\n","      <td>0.3924</td>\n","      <td>0.8137</td>\n","      <td>0.4044</td>\n","      <td>0.8060</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>01/22/21-151003</td>\n","      <td>01/22/21-151232</td>\n","      <td>149.3489</td>\n","      <td>18</td>\n","      <td>0.3928</td>\n","      <td>0.8150</td>\n","      <td>0.4102</td>\n","      <td>0.8044</td>\n","      <td>relu</td>\n","      <td>256</td>\n","      <td>0.5</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>233</td>\n","      <td>Adam_amsgrad</td>\n","      <td>dropout</td>\n","      <td>he_normal</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>01/22/21-142729</td>\n","      <td>01/22/21-142840</td>\n","      <td>70.9462</td>\n","      <td>18</td>\n","      <td>0.4040</td>\n","      <td>0.8092</td>\n","      <td>0.4091</td>\n","      <td>0.8040</td>\n","      <td>gelu</td>\n","      <td>256</td>\n","      <td>0.5</td>\n","      <td>brick</td>\n","      <td>1</td>\n","      <td>233</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_normal</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>01/22/21-151710</td>\n","      <td>01/22/21-151827</td>\n","      <td>76.9696</td>\n","      <td>16</td>\n","      <td>0.4044</td>\n","      <td>0.8080</td>\n","      <td>0.4102</td>\n","      <td>0.8036</td>\n","      <td>gelu</td>\n","      <td>256</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>1</td>\n","      <td>300</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>glorot_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>01/22/21-140711</td>\n","      <td>01/22/21-140939</td>\n","      <td>147.5310</td>\n","      <td>16</td>\n","      <td>0.3877</td>\n","      <td>0.8172</td>\n","      <td>0.4071</td>\n","      <td>0.8035</td>\n","      <td>relu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>300</td>\n","      <td>Adam_amsgrad</td>\n","      <td>dropout</td>\n","      <td>glorot_uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              start              end  duration  round_epochs    loss  \\\n","41  01/22/21-144240  01/22/21-144757  317.1675            23  0.3924   \n","46  01/22/21-151003  01/22/21-151232  149.3489            18  0.3928   \n","31  01/22/21-142729  01/22/21-142840   70.9462            18  0.4040   \n","50  01/22/21-151710  01/22/21-151827   76.9696            16  0.4044   \n","20  01/22/21-140711  01/22/21-140939  147.5310            16  0.3877   \n","\n","    binary_accuracy  val_loss  val_binary_accuracy activation_function  \\\n","41           0.8137    0.4044               0.8060                gelu   \n","46           0.8150    0.4102               0.8044                relu   \n","31           0.8092    0.4091               0.8040                gelu   \n","50           0.8080    0.4102               0.8036                gelu   \n","20           0.8172    0.4071               0.8035                relu   \n","\n","    batch_size  network_decay network_shape  number_of_layers  \\\n","41         512            0.7      triangle                 3   \n","46         256            0.5         brick                 3   \n","31         256            0.5         brick                 1   \n","50         256            0.7         brick                 1   \n","20         512            0.7         brick                 3   \n","\n","    number_of_units_first_layer     optimizer regularization  \\\n","41                          500          Adam        dropout   \n","46                          233  Adam_amsgrad        dropout   \n","31                          233       RMSprop        dropout   \n","50                          300       RMSprop        dropout   \n","20                          300  Adam_amsgrad        dropout   \n","\n","   weight_initializer  \n","41         he_uniform  \n","46          he_normal  \n","31          he_normal  \n","50     glorot_uniform  \n","20     glorot_uniform  "]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"a-L__KCRvize"},"source":["Result:\n","- batch_size = 512 performed better -> drop 256\n","- gelu & relu had the highest performance\n","- no significant difference between triangle and brick shape\n","- between 1 and 3 layers provided the best results\n","- number of units didn't influence the performance so strongly anymore; however, best model had 500 units\n","- Adam performed a little bit better than RMSprop\n","- Dropout was the best regularizer; layer-norm. was a little bit better than batch-norm."]},{"cell_type":"markdown","metadata":{"id":"mOGUVml7zCBa"},"source":["##### Fine-Tune The So-Far Best Found Model:"]},{"cell_type":"markdown","metadata":{"id":"hOGFIopF45iV"},"source":["###### New Baseline:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3nllKawKQHj","executionInfo":{"status":"ok","timestamp":1611332253087,"user_tz":-60,"elapsed":326228,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"86d8c658-dc86-48af-da29-4b1c8e644a51"},"source":["# New Baseline which needs to be improved\n","model = Sequential()\n","model.add(Dense(500, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","model.add(Dense(350, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","model.add(Dense(245, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val),batch_size=512, epochs=100, verbose=1, shuffle=True, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 16s 49ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Training Accuracy: 0.819\n","Validation Accuracy: 0.806\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bLjTJLI948mu"},"source":["###### Test different types of regularizers:"]},{"cell_type":"code","metadata":{"id":"EpeCEzjKKP3n"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","  if regularization==\"L2\":\n","     reg_rate = params[\"reg_rate\"]\n","  else:\n","    reg_rate=0\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init, kernel_regularizer=L2(reg_rate)))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if regularization==\"batch_normalization\":\n","      model.add(BatchNormalization())\n","    \n","    if regularization==\"layer_normalization\":\n","      model.add(LayerNormalization())\n","    \n","    if regularization==\"gaussian_noise\":\n","      model.add(GaussianNoise(stddev=0.1))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L2(l2=reg_rate), kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vz6-xZ-AzGpJ","executionInfo":{"status":"ok","timestamp":1611335038952,"user_tz":-60,"elapsed":734217,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"3e49057e-d259-4ab9-d19b-f6b2116b052f"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\", \"batch_normalization\", \"layer_normalization\", \"gaussian_noise\"],\n","    \"reg_rate\" : [0.01],\n","    \"optimizer\" : [\"Adam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 41ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|       | 1/4 [05:17<15:51, 317.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 42ms/step - loss: 0.4903 - binary_accuracy: 0.7700 - val_loss: 0.4175 - val_binary_accuracy: 0.8000\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4029 - binary_accuracy: 0.8076 - val_loss: 0.4137 - val_binary_accuracy: 0.8007\n","Epoch 3/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3918 - binary_accuracy: 0.8153 - val_loss: 0.4165 - val_binary_accuracy: 0.7980\n","Epoch 4/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3857 - binary_accuracy: 0.8181 - val_loss: 0.4170 - val_binary_accuracy: 0.7965\n","Epoch 5/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3768 - binary_accuracy: 0.8233 - val_loss: 0.4174 - val_binary_accuracy: 0.7994\n","Epoch 6/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3608 - binary_accuracy: 0.8331 - val_loss: 0.4211 - val_binary_accuracy: 0.7958\n","Epoch 7/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3491 - binary_accuracy: 0.8399 - val_loss: 0.4352 - val_binary_accuracy: 0.7921\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|     | 2/4 [06:58<08:24, 252.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'layer_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 21s 58ms/step - loss: 0.4661 - binary_accuracy: 0.7758 - val_loss: 0.4136 - val_binary_accuracy: 0.8002\n","Epoch 2/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4046 - binary_accuracy: 0.8066 - val_loss: 0.4106 - val_binary_accuracy: 0.8022\n","Epoch 3/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3947 - binary_accuracy: 0.8129 - val_loss: 0.4125 - val_binary_accuracy: 0.7994\n","Epoch 4/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3892 - binary_accuracy: 0.8146 - val_loss: 0.4150 - val_binary_accuracy: 0.7982\n","Epoch 5/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3810 - binary_accuracy: 0.8193 - val_loss: 0.4130 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3676 - binary_accuracy: 0.8270 - val_loss: 0.4176 - val_binary_accuracy: 0.8003\n","Epoch 7/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.3553 - binary_accuracy: 0.8329 - val_loss: 0.4337 - val_binary_accuracy: 0.7960\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|  | 3/4 [09:15<03:37, 217.80s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 44ms/step - loss: 0.4531 - binary_accuracy: 0.7723 - val_loss: 0.4132 - val_binary_accuracy: 0.7997\n","Epoch 2/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4111 - binary_accuracy: 0.8019 - val_loss: 0.4083 - val_binary_accuracy: 0.8027\n","Epoch 3/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4035 - binary_accuracy: 0.8075 - val_loss: 0.4088 - val_binary_accuracy: 0.8027\n","Epoch 4/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4004 - binary_accuracy: 0.8091 - val_loss: 0.4091 - val_binary_accuracy: 0.8010\n","Epoch 5/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3969 - binary_accuracy: 0.8097 - val_loss: 0.4071 - val_binary_accuracy: 0.8028\n","Epoch 6/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3899 - binary_accuracy: 0.8153 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 7/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3875 - binary_accuracy: 0.8162 - val_loss: 0.4084 - val_binary_accuracy: 0.8053\n","Epoch 8/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3812 - binary_accuracy: 0.8206 - val_loss: 0.4083 - val_binary_accuracy: 0.8043\n","Epoch 9/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3759 - binary_accuracy: 0.8227 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n","Epoch 10/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3647 - binary_accuracy: 0.8293 - val_loss: 0.4158 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3577 - binary_accuracy: 0.8315 - val_loss: 0.4201 - val_binary_accuracy: 0.8003\n","Epoch 12/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3472 - binary_accuracy: 0.8383 - val_loss: 0.4279 - val_binary_accuracy: 0.7989\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 4/4 [12:13<00:00, 183.31s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"sJNNB6qYzGiW","executionInfo":{"status":"ok","timestamp":1611335043606,"user_tz":-60,"elapsed":1015,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"dafffe98-65d4-47ea-a9f7-07db2b4e6bf4"},"source":["# Get search results for all evaluated hyperparameter combinations sorted by val_accuracy\n","analyze_object = talos.Analyze(search_object)\n","analyze_object.data.sort_values(by=\"val_binary_accuracy\", ascending=False).round(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>duration</th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>binary_accuracy</th>\n","      <th>val_loss</th>\n","      <th>val_binary_accuracy</th>\n","      <th>activation_function</th>\n","      <th>batch_size</th>\n","      <th>network_decay</th>\n","      <th>network_shape</th>\n","      <th>number_of_layers</th>\n","      <th>number_of_units_first_layer</th>\n","      <th>optimizer</th>\n","      <th>reg_rate</th>\n","      <th>regularization</th>\n","      <th>weight_initializer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01/22/21-165147</td>\n","      <td>01/22/21-165704</td>\n","      <td>317.0095</td>\n","      <td>23</td>\n","      <td>0.3924</td>\n","      <td>0.8137</td>\n","      <td>0.4044</td>\n","      <td>0.8060</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01/22/21-170102</td>\n","      <td>01/22/21-170400</td>\n","      <td>177.4552</td>\n","      <td>12</td>\n","      <td>0.3504</td>\n","      <td>0.8370</td>\n","      <td>0.4279</td>\n","      <td>0.7989</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>gaussian_noise</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01/22/21-165845</td>\n","      <td>01/22/21-170102</td>\n","      <td>136.6777</td>\n","      <td>7</td>\n","      <td>0.3588</td>\n","      <td>0.8314</td>\n","      <td>0.4337</td>\n","      <td>0.7960</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>layer_normalization</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01/22/21-165704</td>\n","      <td>01/22/21-165845</td>\n","      <td>101.2021</td>\n","      <td>7</td>\n","      <td>0.3529</td>\n","      <td>0.8374</td>\n","      <td>0.4352</td>\n","      <td>0.7921</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>batch_normalization</td>\n","      <td>he_uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             start              end  duration  round_epochs    loss  \\\n","0  01/22/21-165147  01/22/21-165704  317.0095            23  0.3924   \n","3  01/22/21-170102  01/22/21-170400  177.4552            12  0.3504   \n","2  01/22/21-165845  01/22/21-170102  136.6777             7  0.3588   \n","1  01/22/21-165704  01/22/21-165845  101.2021             7  0.3529   \n","\n","   binary_accuracy  val_loss  val_binary_accuracy activation_function  \\\n","0           0.8137    0.4044               0.8060                gelu   \n","3           0.8370    0.4279               0.7989                gelu   \n","2           0.8314    0.4337               0.7960                gelu   \n","1           0.8374    0.4352               0.7921                gelu   \n","\n","   batch_size  network_decay network_shape  number_of_layers  \\\n","0         512            0.7      triangle                 3   \n","3         512            0.7      triangle                 3   \n","2         512            0.7      triangle                 3   \n","1         512            0.7      triangle                 3   \n","\n","   number_of_units_first_layer optimizer  reg_rate       regularization  \\\n","0                          500      Adam      0.01              dropout   \n","3                          500      Adam      0.01       gaussian_noise   \n","2                          500      Adam      0.01  layer_normalization   \n","1                          500      Adam      0.01  batch_normalization   \n","\n","  weight_initializer  \n","0         he_uniform  \n","3         he_uniform  \n","2         he_uniform  \n","1         he_uniform  "]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"markdown","metadata":{"id":"zATSny3RDiHt"},"source":["Result:\n","- dropout performed by far the best\n","- but: also Gaussian noise was promising"]},{"cell_type":"markdown","metadata":{"id":"ZJwKn1WMDre-"},"source":["###### Test if regularizers before the activation can improve results:"]},{"cell_type":"code","metadata":{"id":"tzF9aj8lDvv7"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","  if regularization==\"L2\":\n","     reg_rate = params[\"reg_rate\"]\n","  else:\n","    reg_rate=0\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, kernel_initializer=init, kernel_regularizer=L2(reg_rate)))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if regularization==\"batch_normalization\":\n","      model.add(BatchNormalization())\n","    \n","    if regularization==\"layer_normalization\":\n","      model.add(LayerNormalization())\n","    \n","    if regularization==\"gaussian_noise\":\n","      model.add(GaussianNoise(stddev=0.1))\n","\n","    model.add(Activation(activation=activation_function))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L2(l2=reg_rate), kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JfNzA71DvwF","executionInfo":{"status":"ok","timestamp":1611335920482,"user_tz":-60,"elapsed":684357,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"aaed9eed-ca78-410b-bc7e-d4dee9f1f3dc"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\", \"batch_normalization\", \"layer_normalization\", \"gaussian_noise\"],\n","    \"reg_rate\" : [0.01],\n","    \"optimizer\" : [\"Adam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.5115 - binary_accuracy: 0.7403 - val_loss: 0.4407 - val_binary_accuracy: 0.7902\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4287 - binary_accuracy: 0.7916 - val_loss: 0.4331 - val_binary_accuracy: 0.7960\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4177 - binary_accuracy: 0.8005 - val_loss: 0.4254 - val_binary_accuracy: 0.7961\n","Epoch 4/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4139 - binary_accuracy: 0.8033 - val_loss: 0.4408 - val_binary_accuracy: 0.7989\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4107 - binary_accuracy: 0.8043 - val_loss: 0.4362 - val_binary_accuracy: 0.7998\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4061 - binary_accuracy: 0.8077 - val_loss: 0.4372 - val_binary_accuracy: 0.7990\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4050 - binary_accuracy: 0.8076 - val_loss: 0.4508 - val_binary_accuracy: 0.8008\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4031 - binary_accuracy: 0.8080 - val_loss: 0.4471 - val_binary_accuracy: 0.8018\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3995 - binary_accuracy: 0.8112 - val_loss: 0.4478 - val_binary_accuracy: 0.8009\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3950 - binary_accuracy: 0.8134 - val_loss: 0.4449 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3948 - binary_accuracy: 0.8135 - val_loss: 0.4472 - val_binary_accuracy: 0.8009\n","Epoch 12/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3924 - binary_accuracy: 0.8141 - val_loss: 0.4655 - val_binary_accuracy: 0.8006\n","Epoch 13/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3914 - binary_accuracy: 0.8144 - val_loss: 0.4712 - val_binary_accuracy: 0.8017\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|       | 1/4 [03:01<09:04, 181.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'batch_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 17s 45ms/step - loss: 0.4582 - binary_accuracy: 0.7758 - val_loss: 0.4146 - val_binary_accuracy: 0.7983\n","Epoch 2/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4014 - binary_accuracy: 0.8084 - val_loss: 0.4111 - val_binary_accuracy: 0.8002\n","Epoch 3/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3899 - binary_accuracy: 0.8162 - val_loss: 0.4116 - val_binary_accuracy: 0.8021\n","Epoch 4/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3834 - binary_accuracy: 0.8190 - val_loss: 0.4126 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3752 - binary_accuracy: 0.8233 - val_loss: 0.4178 - val_binary_accuracy: 0.7995\n","Epoch 6/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3607 - binary_accuracy: 0.8327 - val_loss: 0.4206 - val_binary_accuracy: 0.7959\n","Epoch 7/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3488 - binary_accuracy: 0.8381 - val_loss: 0.4300 - val_binary_accuracy: 0.7934\n","Epoch 8/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3321 - binary_accuracy: 0.8487 - val_loss: 0.4480 - val_binary_accuracy: 0.7904\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|     | 2/4 [05:00<05:25, 162.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'layer_normalization', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 21s 59ms/step - loss: 0.4632 - binary_accuracy: 0.7708 - val_loss: 0.4124 - val_binary_accuracy: 0.8005\n","Epoch 2/100\n","338/338 [==============================] - 20s 58ms/step - loss: 0.4042 - binary_accuracy: 0.8060 - val_loss: 0.4109 - val_binary_accuracy: 0.8006\n","Epoch 3/100\n","338/338 [==============================] - 20s 59ms/step - loss: 0.3947 - binary_accuracy: 0.8129 - val_loss: 0.4093 - val_binary_accuracy: 0.8013\n","Epoch 4/100\n","338/338 [==============================] - 20s 58ms/step - loss: 0.3886 - binary_accuracy: 0.8149 - val_loss: 0.4122 - val_binary_accuracy: 0.7989\n","Epoch 5/100\n","338/338 [==============================] - 20s 59ms/step - loss: 0.3817 - binary_accuracy: 0.8189 - val_loss: 0.4119 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 20s 59ms/step - loss: 0.3692 - binary_accuracy: 0.8267 - val_loss: 0.4169 - val_binary_accuracy: 0.8005\n","Epoch 7/100\n","338/338 [==============================] - 20s 59ms/step - loss: 0.3596 - binary_accuracy: 0.8317 - val_loss: 0.4303 - val_binary_accuracy: 0.7980\n","Epoch 8/100\n","338/338 [==============================] - 21s 62ms/step - loss: 0.3464 - binary_accuracy: 0.8394 - val_loss: 0.4330 - val_binary_accuracy: 0.7982\n","Epoch 9/100\n","338/338 [==============================] - 20s 58ms/step - loss: 0.3294 - binary_accuracy: 0.8491 - val_loss: 0.4513 - val_binary_accuracy: 0.7942\n","Epoch 10/100\n","338/338 [==============================] - 20s 59ms/step - loss: 0.3062 - binary_accuracy: 0.8611 - val_loss: 0.4669 - val_binary_accuracy: 0.7874\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|  | 3/4 [08:21<02:54, 174.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'gaussian_noise', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 45ms/step - loss: 0.4501 - binary_accuracy: 0.7727 - val_loss: 0.4121 - val_binary_accuracy: 0.8003\n","Epoch 2/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4085 - binary_accuracy: 0.8031 - val_loss: 0.4084 - val_binary_accuracy: 0.8022\n","Epoch 3/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4012 - binary_accuracy: 0.8088 - val_loss: 0.4086 - val_binary_accuracy: 0.8025\n","Epoch 4/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3979 - binary_accuracy: 0.8103 - val_loss: 0.4088 - val_binary_accuracy: 0.8009\n","Epoch 5/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3941 - binary_accuracy: 0.8122 - val_loss: 0.4076 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3863 - binary_accuracy: 0.8179 - val_loss: 0.4073 - val_binary_accuracy: 0.8033\n","Epoch 7/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3825 - binary_accuracy: 0.8179 - val_loss: 0.4107 - val_binary_accuracy: 0.8050\n","Epoch 8/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3761 - binary_accuracy: 0.8217 - val_loss: 0.4115 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3685 - binary_accuracy: 0.8260 - val_loss: 0.4169 - val_binary_accuracy: 0.8012\n","Epoch 10/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3545 - binary_accuracy: 0.8349 - val_loss: 0.4243 - val_binary_accuracy: 0.7988\n","Epoch 11/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3441 - binary_accuracy: 0.8393 - val_loss: 0.4309 - val_binary_accuracy: 0.7973\n","Epoch 12/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3308 - binary_accuracy: 0.8470 - val_loss: 0.4449 - val_binary_accuracy: 0.7945\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 4/4 [11:23<00:00, 170.90s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"am0Zue3xDvwI","executionInfo":{"status":"ok","timestamp":1611335926264,"user_tz":-60,"elapsed":734,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"b202a4dc-87e8-43e4-9542-6e07ee308889"},"source":["# Get search results for all evaluated hyperparameter combinations sorted by val_accuracy\n","analyze_object = talos.Analyze(search_object)\n","analyze_object.data.sort_values(by=\"val_binary_accuracy\", ascending=False).round(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>duration</th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>binary_accuracy</th>\n","      <th>val_loss</th>\n","      <th>val_binary_accuracy</th>\n","      <th>activation_function</th>\n","      <th>batch_size</th>\n","      <th>network_decay</th>\n","      <th>network_shape</th>\n","      <th>number_of_layers</th>\n","      <th>number_of_units_first_layer</th>\n","      <th>optimizer</th>\n","      <th>reg_rate</th>\n","      <th>regularization</th>\n","      <th>weight_initializer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01/22/21-170718</td>\n","      <td>01/22/21-171019</td>\n","      <td>181.4161</td>\n","      <td>13</td>\n","      <td>0.3923</td>\n","      <td>0.8143</td>\n","      <td>0.4712</td>\n","      <td>0.8017</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01/22/21-171539</td>\n","      <td>01/22/21-171841</td>\n","      <td>182.0131</td>\n","      <td>12</td>\n","      <td>0.3346</td>\n","      <td>0.8445</td>\n","      <td>0.4449</td>\n","      <td>0.7945</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>gaussian_noise</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01/22/21-171019</td>\n","      <td>01/22/21-171218</td>\n","      <td>118.8821</td>\n","      <td>8</td>\n","      <td>0.3364</td>\n","      <td>0.8455</td>\n","      <td>0.4480</td>\n","      <td>0.7904</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>batch_normalization</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01/22/21-171218</td>\n","      <td>01/22/21-171539</td>\n","      <td>200.3671</td>\n","      <td>10</td>\n","      <td>0.3147</td>\n","      <td>0.8559</td>\n","      <td>0.4669</td>\n","      <td>0.7874</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>Adam</td>\n","      <td>0.01</td>\n","      <td>layer_normalization</td>\n","      <td>he_uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             start              end  duration  round_epochs    loss  \\\n","0  01/22/21-170718  01/22/21-171019  181.4161            13  0.3923   \n","3  01/22/21-171539  01/22/21-171841  182.0131            12  0.3346   \n","1  01/22/21-171019  01/22/21-171218  118.8821             8  0.3364   \n","2  01/22/21-171218  01/22/21-171539  200.3671            10  0.3147   \n","\n","   binary_accuracy  val_loss  val_binary_accuracy activation_function  \\\n","0           0.8143    0.4712               0.8017                gelu   \n","3           0.8445    0.4449               0.7945                gelu   \n","1           0.8455    0.4480               0.7904                gelu   \n","2           0.8559    0.4669               0.7874                gelu   \n","\n","   batch_size  network_decay network_shape  number_of_layers  \\\n","0         512            0.7      triangle                 3   \n","3         512            0.7      triangle                 3   \n","1         512            0.7      triangle                 3   \n","2         512            0.7      triangle                 3   \n","\n","   number_of_units_first_layer optimizer  reg_rate       regularization  \\\n","0                          500      Adam      0.01              dropout   \n","3                          500      Adam      0.01       gaussian_noise   \n","1                          500      Adam      0.01  batch_normalization   \n","2                          500      Adam      0.01  layer_normalization   \n","\n","  weight_initializer  \n","0         he_uniform  \n","3         he_uniform  \n","1         he_uniform  \n","2         he_uniform  "]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"jK6Jk417GzRW"},"source":["Result:\n","- performing regularization before the activation decreased performance\n","- only for Gaussian noise the performance increased"]},{"cell_type":"markdown","metadata":{"id":"V0tUOvOcHAaQ"},"source":["###### Test if Gaussian Noise + Dropout can increase performance:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YusO_EGO5KGr","executionInfo":{"status":"ok","timestamp":1611338276522,"user_tz":-60,"elapsed":726474,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"b3638d8f-3a97-4253-c334-4ba5bbfc320e"},"source":["# New Baseline which needs to be improved\n","model = Sequential()\n","model.add(GaussianNoise(stddev=0.1))\n","model.add(Dropout(rate=0.2, seed=seed_value))\n","\n","model.add(Dense(500, kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(GaussianNoise(stddev=0.1))\n","model.add(Activation(activation=\"gelu\"))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(350, kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(GaussianNoise(stddev=0.1))\n","model.add(Activation(activation=\"gelu\"))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(245, kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(GaussianNoise(stddev=0.1))\n","model.add(Activation(activation=\"gelu\"))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=HeUniform(seed=seed_value)))\n","\n","model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val),batch_size=512, epochs=100, verbose=1, shuffle=True, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.5533 - binary_accuracy: 0.7125 - val_loss: 0.4429 - val_binary_accuracy: 0.7908\n","Epoch 2/100\n","338/338 [==============================] - 18s 55ms/step - loss: 0.4898 - binary_accuracy: 0.7544 - val_loss: 0.4398 - val_binary_accuracy: 0.7919\n","Epoch 3/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4854 - binary_accuracy: 0.7565 - val_loss: 0.4409 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4817 - binary_accuracy: 0.7579 - val_loss: 0.4276 - val_binary_accuracy: 0.7939\n","Epoch 5/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4806 - binary_accuracy: 0.7600 - val_loss: 0.4373 - val_binary_accuracy: 0.7962\n","Epoch 6/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4775 - binary_accuracy: 0.7631 - val_loss: 0.4310 - val_binary_accuracy: 0.7953\n","Epoch 7/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4759 - binary_accuracy: 0.7633 - val_loss: 0.4258 - val_binary_accuracy: 0.7972\n","Epoch 8/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4773 - binary_accuracy: 0.7623 - val_loss: 0.4233 - val_binary_accuracy: 0.7969\n","Epoch 9/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4723 - binary_accuracy: 0.7661 - val_loss: 0.4266 - val_binary_accuracy: 0.7983\n","Epoch 10/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4716 - binary_accuracy: 0.7658 - val_loss: 0.4290 - val_binary_accuracy: 0.7977\n","Epoch 11/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4713 - binary_accuracy: 0.7674 - val_loss: 0.4260 - val_binary_accuracy: 0.7969\n","Epoch 12/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4693 - binary_accuracy: 0.7688 - val_loss: 0.4243 - val_binary_accuracy: 0.7986\n","Epoch 13/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4712 - binary_accuracy: 0.7662 - val_loss: 0.4233 - val_binary_accuracy: 0.7972\n","Epoch 14/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4708 - binary_accuracy: 0.7663 - val_loss: 0.4234 - val_binary_accuracy: 0.7979\n","Epoch 15/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4678 - binary_accuracy: 0.7679 - val_loss: 0.4311 - val_binary_accuracy: 0.7988\n","Epoch 16/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4692 - binary_accuracy: 0.7687 - val_loss: 0.4240 - val_binary_accuracy: 0.7980\n","Epoch 17/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.4633 - binary_accuracy: 0.7728 - val_loss: 0.4223 - val_binary_accuracy: 0.7996\n","Epoch 18/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4677 - binary_accuracy: 0.7698 - val_loss: 0.4233 - val_binary_accuracy: 0.7985\n","Epoch 19/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4682 - binary_accuracy: 0.7699 - val_loss: 0.4264 - val_binary_accuracy: 0.7989\n","Epoch 20/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4643 - binary_accuracy: 0.7708 - val_loss: 0.4212 - val_binary_accuracy: 0.7987\n","Epoch 21/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4654 - binary_accuracy: 0.7724 - val_loss: 0.4204 - val_binary_accuracy: 0.7984\n","Epoch 22/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4627 - binary_accuracy: 0.7725 - val_loss: 0.4245 - val_binary_accuracy: 0.8003\n","Epoch 23/100\n","338/338 [==============================] - 19s 56ms/step - loss: 0.4609 - binary_accuracy: 0.7742 - val_loss: 0.4233 - val_binary_accuracy: 0.7996\n","Epoch 24/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4646 - binary_accuracy: 0.7704 - val_loss: 0.4235 - val_binary_accuracy: 0.8001\n","Epoch 25/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4615 - binary_accuracy: 0.7744 - val_loss: 0.4182 - val_binary_accuracy: 0.8014\n","Epoch 26/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4623 - binary_accuracy: 0.7740 - val_loss: 0.4216 - val_binary_accuracy: 0.8003\n","Epoch 27/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4607 - binary_accuracy: 0.7729 - val_loss: 0.4159 - val_binary_accuracy: 0.8013\n","Epoch 28/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4647 - binary_accuracy: 0.7727 - val_loss: 0.4203 - val_binary_accuracy: 0.8013\n","Epoch 29/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4621 - binary_accuracy: 0.7725 - val_loss: 0.4183 - val_binary_accuracy: 0.8017\n","Epoch 30/100\n","338/338 [==============================] - 20s 58ms/step - loss: 0.4634 - binary_accuracy: 0.7730 - val_loss: 0.4254 - val_binary_accuracy: 0.8009\n","Epoch 31/100\n","338/338 [==============================] - 21s 61ms/step - loss: 0.4622 - binary_accuracy: 0.7737 - val_loss: 0.4208 - val_binary_accuracy: 0.8005\n","Epoch 32/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4625 - binary_accuracy: 0.7717 - val_loss: 0.4195 - val_binary_accuracy: 0.8005\n","Epoch 33/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4614 - binary_accuracy: 0.7739 - val_loss: 0.4233 - val_binary_accuracy: 0.8018\n","Epoch 34/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4613 - binary_accuracy: 0.7747 - val_loss: 0.4180 - val_binary_accuracy: 0.8010\n","Epoch 35/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4635 - binary_accuracy: 0.7711 - val_loss: 0.4196 - val_binary_accuracy: 0.8017\n","Epoch 36/100\n","338/338 [==============================] - 20s 58ms/step - loss: 0.4602 - binary_accuracy: 0.7752 - val_loss: 0.4155 - val_binary_accuracy: 0.8015\n","Epoch 37/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4604 - binary_accuracy: 0.7747 - val_loss: 0.4220 - val_binary_accuracy: 0.8006\n","Epoch 38/100\n","338/338 [==============================] - 19s 57ms/step - loss: 0.4618 - binary_accuracy: 0.7738 - val_loss: 0.4184 - val_binary_accuracy: 0.8006\n","Training Accuracy: 0.807\n","Validation Accuracy: 0.802\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PII9KZB-Pwlu"},"source":["Result: it didn't help"]},{"cell_type":"markdown","metadata":{"id":"uXiqpQmKP0Lp"},"source":["###### Test if adding dropout to the input layer helps:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mL04jUKi5J9w","executionInfo":{"status":"ok","timestamp":1611338732051,"user_tz":-60,"elapsed":348245,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"bc6bd1ed-c534-4910-d258-327825c62224"},"source":["model = Sequential()\n","model.add(Dropout(rate=0.2, seed=seed_value))\n","\n","model.add(Dense(500, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(350, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(245, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=HeUniform(seed=seed_value)))\n","\n","model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val),batch_size=512, epochs=100, verbose=1, shuffle=True, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.5393 - binary_accuracy: 0.7216 - val_loss: 0.4322 - val_binary_accuracy: 0.7957\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4746 - binary_accuracy: 0.7642 - val_loss: 0.4283 - val_binary_accuracy: 0.7976\n","Epoch 3/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4702 - binary_accuracy: 0.7668 - val_loss: 0.4311 - val_binary_accuracy: 0.7982\n","Epoch 4/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4659 - binary_accuracy: 0.7707 - val_loss: 0.4199 - val_binary_accuracy: 0.7991\n","Epoch 5/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4654 - binary_accuracy: 0.7693 - val_loss: 0.4276 - val_binary_accuracy: 0.8008\n","Epoch 6/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4632 - binary_accuracy: 0.7722 - val_loss: 0.4212 - val_binary_accuracy: 0.7993\n","Epoch 7/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4614 - binary_accuracy: 0.7724 - val_loss: 0.4164 - val_binary_accuracy: 0.7994\n","Epoch 8/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4625 - binary_accuracy: 0.7725 - val_loss: 0.4162 - val_binary_accuracy: 0.8003\n","Epoch 9/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4582 - binary_accuracy: 0.7750 - val_loss: 0.4200 - val_binary_accuracy: 0.8011\n","Epoch 10/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4572 - binary_accuracy: 0.7751 - val_loss: 0.4205 - val_binary_accuracy: 0.8011\n","Epoch 11/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4569 - binary_accuracy: 0.7766 - val_loss: 0.4190 - val_binary_accuracy: 0.8012\n","Epoch 12/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4557 - binary_accuracy: 0.7767 - val_loss: 0.4172 - val_binary_accuracy: 0.8015\n","Epoch 13/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4569 - binary_accuracy: 0.7761 - val_loss: 0.4163 - val_binary_accuracy: 0.8007\n","Epoch 14/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4571 - binary_accuracy: 0.7767 - val_loss: 0.4164 - val_binary_accuracy: 0.8012\n","Epoch 15/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4534 - binary_accuracy: 0.7780 - val_loss: 0.4235 - val_binary_accuracy: 0.8022\n","Epoch 16/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4546 - binary_accuracy: 0.7778 - val_loss: 0.4169 - val_binary_accuracy: 0.8014\n","Epoch 17/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4495 - binary_accuracy: 0.7817 - val_loss: 0.4159 - val_binary_accuracy: 0.8020\n","Epoch 18/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4538 - binary_accuracy: 0.7796 - val_loss: 0.4161 - val_binary_accuracy: 0.8014\n","Epoch 19/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4542 - binary_accuracy: 0.7784 - val_loss: 0.4192 - val_binary_accuracy: 0.8040\n","Epoch 20/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4504 - binary_accuracy: 0.7795 - val_loss: 0.4143 - val_binary_accuracy: 0.8011\n","Epoch 21/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4521 - binary_accuracy: 0.7803 - val_loss: 0.4133 - val_binary_accuracy: 0.8020\n","Epoch 22/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4487 - binary_accuracy: 0.7809 - val_loss: 0.4173 - val_binary_accuracy: 0.8027\n","Epoch 23/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4467 - binary_accuracy: 0.7812 - val_loss: 0.4158 - val_binary_accuracy: 0.8030\n","Epoch 24/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4502 - binary_accuracy: 0.7784 - val_loss: 0.4157 - val_binary_accuracy: 0.8028\n","Training Accuracy: 0.810\n","Validation Accuracy: 0.804\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cbeNq9tbRUi0"},"source":["Result: only add dropout to the hidden layers, but not the input layer"]},{"cell_type":"markdown","metadata":{"id":"MhuNUHuxQLOu"},"source":["###### Test if adding Gaussian noise just to the input layer helps:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oajNZwurzGLD","executionInfo":{"status":"ok","timestamp":1611338939883,"user_tz":-60,"elapsed":195216,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"009c7768-0145-44da-8555-b1da7277dc23"},"source":["model = Sequential()\n","model.add(GaussianNoise(stddev=0.1))\n","\n","model.add(Dense(500, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(350, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(245, activation=\"gelu\", kernel_initializer=HeUniform(seed=seed_value)))\n","model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=HeUniform(seed=seed_value)))\n","\n","model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val),batch_size=512, epochs=100, verbose=1, shuffle=True, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","print(\"Training Accuracy: {:.3f}\".format(model.evaluate(X_subtrain, y_subtrain, batch_size=512, verbose=0)[1]))\n","print(\"Validation Accuracy: {:.3f}\".format(model.evaluate(X_val, y_val, batch_size=512, verbose=0)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","338/338 [==============================] - 16s 44ms/step - loss: 0.5029 - binary_accuracy: 0.7448 - val_loss: 0.4265 - val_binary_accuracy: 0.7915\n","Epoch 2/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4438 - binary_accuracy: 0.7830 - val_loss: 0.4215 - val_binary_accuracy: 0.7955\n","Epoch 3/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4365 - binary_accuracy: 0.7879 - val_loss: 0.4228 - val_binary_accuracy: 0.7964\n","Epoch 4/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4341 - binary_accuracy: 0.7885 - val_loss: 0.4160 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4310 - binary_accuracy: 0.7911 - val_loss: 0.4172 - val_binary_accuracy: 0.7989\n","Epoch 6/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4291 - binary_accuracy: 0.7933 - val_loss: 0.4144 - val_binary_accuracy: 0.8000\n","Epoch 7/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4274 - binary_accuracy: 0.7916 - val_loss: 0.4124 - val_binary_accuracy: 0.8000\n","Epoch 8/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4257 - binary_accuracy: 0.7944 - val_loss: 0.4110 - val_binary_accuracy: 0.8027\n","Epoch 9/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4243 - binary_accuracy: 0.7961 - val_loss: 0.4109 - val_binary_accuracy: 0.8017\n","Epoch 10/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4219 - binary_accuracy: 0.7971 - val_loss: 0.4118 - val_binary_accuracy: 0.8023\n","Epoch 11/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4211 - binary_accuracy: 0.7984 - val_loss: 0.4111 - val_binary_accuracy: 0.8011\n","Epoch 12/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4195 - binary_accuracy: 0.7988 - val_loss: 0.4095 - val_binary_accuracy: 0.8015\n","Epoch 13/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4197 - binary_accuracy: 0.7966 - val_loss: 0.4088 - val_binary_accuracy: 0.8022\n","Training Accuracy: 0.805\n","Validation Accuracy: 0.803\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nieeT5S8SRb1"},"source":["Result: it didn't help, i.e. keep only dropout at hidden layers"]},{"cell_type":"markdown","metadata":{"id":"ASaXIT05SWcQ"},"source":["###### Test if weight decay helps:"]},{"cell_type":"code","metadata":{"id":"g2OUoMZRSnaP"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","  reg_rate = params[\"reg_rate\"]\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init, kernel_regularizer=L2(reg_rate)))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if regularization==\"batch_normalization\":\n","      model.add(BatchNormalization())\n","    \n","    if regularization==\"layer_normalization\":\n","      model.add(LayerNormalization())\n","    \n","    if regularization==\"gaussian_noise\":\n","      model.add(GaussianNoise(stddev=0.1))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L2(l2=reg_rate), kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8pa1Sc_SnaQ","executionInfo":{"status":"ok","timestamp":1611339502702,"user_tz":-60,"elapsed":397141,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"e0cf430c-2891-4274-b962-85cbe1960fed"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\"],\n","    \"reg_rate\" : [0.001, 0.01, 1],\n","    \"optimizer\" : [\"Adam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.001, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 44ms/step - loss: 1.6334 - binary_accuracy: 0.7504 - val_loss: 0.5421 - val_binary_accuracy: 0.7890\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.5148 - binary_accuracy: 0.7872 - val_loss: 0.4671 - val_binary_accuracy: 0.7902\n","Epoch 3/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4676 - binary_accuracy: 0.7911 - val_loss: 0.4597 - val_binary_accuracy: 0.7906\n","Epoch 4/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4618 - binary_accuracy: 0.7909 - val_loss: 0.4576 - val_binary_accuracy: 0.7902\n","Epoch 5/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4605 - binary_accuracy: 0.7902 - val_loss: 0.4555 - val_binary_accuracy: 0.7920\n","Epoch 6/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4581 - binary_accuracy: 0.7919 - val_loss: 0.4546 - val_binary_accuracy: 0.7924\n","Epoch 7/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4592 - binary_accuracy: 0.7901 - val_loss: 0.4609 - val_binary_accuracy: 0.7870\n","Epoch 8/100\n","338/338 [==============================] - 16s 46ms/step - loss: 0.4598 - binary_accuracy: 0.7898 - val_loss: 0.4559 - val_binary_accuracy: 0.7913\n","Epoch 9/100\n","338/338 [==============================] - 15s 46ms/step - loss: 0.4584 - binary_accuracy: 0.7896 - val_loss: 0.4543 - val_binary_accuracy: 0.7917\n","Epoch 10/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4562 - binary_accuracy: 0.7920 - val_loss: 0.4547 - val_binary_accuracy: 0.7917\n","Epoch 11/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4578 - binary_accuracy: 0.7919 - val_loss: 0.4545 - val_binary_accuracy: 0.7918\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|      | 1/3 [02:46<05:32, 166.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 0.01, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 17s 46ms/step - loss: 8.0264 - binary_accuracy: 0.7335 - val_loss: 0.5678 - val_binary_accuracy: 0.7693\n","Epoch 2/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.5707 - binary_accuracy: 0.7660 - val_loss: 0.5541 - val_binary_accuracy: 0.7722\n","Epoch 3/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.5641 - binary_accuracy: 0.7650 - val_loss: 0.5498 - val_binary_accuracy: 0.7717\n","Epoch 4/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.5629 - binary_accuracy: 0.7628 - val_loss: 0.5454 - val_binary_accuracy: 0.7724\n","Epoch 5/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.5614 - binary_accuracy: 0.7628 - val_loss: 0.5444 - val_binary_accuracy: 0.7749\n","Epoch 6/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.5588 - binary_accuracy: 0.7636 - val_loss: 0.5426 - val_binary_accuracy: 0.7720\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.5601 - binary_accuracy: 0.7613 - val_loss: 0.5467 - val_binary_accuracy: 0.7647\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.5613 - binary_accuracy: 0.7600 - val_loss: 0.5436 - val_binary_accuracy: 0.7743\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.5583 - binary_accuracy: 0.7613 - val_loss: 0.5407 - val_binary_accuracy: 0.7722\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.5570 - binary_accuracy: 0.7613 - val_loss: 0.5406 - val_binary_accuracy: 0.7704\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|   | 2/3 [05:11<02:40, 160.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'reg_rate': 1, 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 41ms/step - loss: 712.9702 - binary_accuracy: 0.6174 - val_loss: 0.7074 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.6651 - binary_accuracy: 0.6533 - val_loss: 0.6492 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.6480 - binary_accuracy: 0.6513 - val_loss: 0.6476 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.6474 - binary_accuracy: 0.6503 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.6477 - binary_accuracy: 0.6496 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.6479 - binary_accuracy: 0.6493 - val_loss: 0.6474 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 3/3 [06:36<00:00, 132.24s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"F11QYJscUNca"},"source":["Result: adding weight decay significantly reduced the performance of the network (i.e. keep dropout as regularization technique)"]},{"cell_type":"markdown","metadata":{"id":"RwBkrDXwUVXd"},"source":["###### Tune the dropout rate:"]},{"cell_type":"code","metadata":{"id":"YVkqwIk95JiK"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  dropout_rate = params[\"dropout_rate\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=dropout_rate, seed=seed_value))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-J-Uvfk5JZh","executionInfo":{"status":"ok","timestamp":1611340628725,"user_tz":-60,"elapsed":955837,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"b71c62b9-6844-4931-a03b-e0171a394890"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\"],\n","    \"dropout_rate\" : [0.4, 0.5, 0.6],\n","    \"optimizer\" : [\"Adam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'dropout_rate': 0.4, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4752 - binary_accuracy: 0.7615 - val_loss: 0.4162 - val_binary_accuracy: 0.7988\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4219 - binary_accuracy: 0.7954 - val_loss: 0.4120 - val_binary_accuracy: 0.8007\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4143 - binary_accuracy: 0.8018 - val_loss: 0.4123 - val_binary_accuracy: 0.8025\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4124 - binary_accuracy: 0.8017 - val_loss: 0.4103 - val_binary_accuracy: 0.8022\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4106 - binary_accuracy: 0.8038 - val_loss: 0.4082 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4070 - binary_accuracy: 0.8060 - val_loss: 0.4061 - val_binary_accuracy: 0.8034\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4058 - binary_accuracy: 0.8059 - val_loss: 0.4059 - val_binary_accuracy: 0.8041\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4045 - binary_accuracy: 0.8070 - val_loss: 0.4044 - val_binary_accuracy: 0.8058\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4026 - binary_accuracy: 0.8082 - val_loss: 0.4042 - val_binary_accuracy: 0.8039\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3980 - binary_accuracy: 0.8125 - val_loss: 0.4043 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3979 - binary_accuracy: 0.8107 - val_loss: 0.4041 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3966 - binary_accuracy: 0.8115 - val_loss: 0.4043 - val_binary_accuracy: 0.8037\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3950 - binary_accuracy: 0.8122 - val_loss: 0.4040 - val_binary_accuracy: 0.8044\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|      | 1/3 [03:01<06:03, 181.79s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'dropout_rate': 0.5, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|   | 2/3 [08:20<03:42, 222.89s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'dropout_rate': 0.6, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.5199 - binary_accuracy: 0.7361 - val_loss: 0.4223 - val_binary_accuracy: 0.7946\n","Epoch 2/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4350 - binary_accuracy: 0.7899 - val_loss: 0.4165 - val_binary_accuracy: 0.7992\n","Epoch 3/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4256 - binary_accuracy: 0.7971 - val_loss: 0.4162 - val_binary_accuracy: 0.7998\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4218 - binary_accuracy: 0.7974 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 5/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4191 - binary_accuracy: 0.7986 - val_loss: 0.4111 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4164 - binary_accuracy: 0.8019 - val_loss: 0.4100 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4157 - binary_accuracy: 0.8014 - val_loss: 0.4091 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4153 - binary_accuracy: 0.8012 - val_loss: 0.4080 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4129 - binary_accuracy: 0.8039 - val_loss: 0.4075 - val_binary_accuracy: 0.8028\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4092 - binary_accuracy: 0.8056 - val_loss: 0.4072 - val_binary_accuracy: 0.8043\n","Epoch 11/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4098 - binary_accuracy: 0.8052 - val_loss: 0.4080 - val_binary_accuracy: 0.8022\n","Epoch 12/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4085 - binary_accuracy: 0.8064 - val_loss: 0.4064 - val_binary_accuracy: 0.8030\n","Epoch 13/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4082 - binary_accuracy: 0.8060 - val_loss: 0.4058 - val_binary_accuracy: 0.8041\n","Epoch 14/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4077 - binary_accuracy: 0.8064 - val_loss: 0.4062 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4065 - binary_accuracy: 0.8064 - val_loss: 0.4069 - val_binary_accuracy: 0.8043\n","Epoch 16/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4068 - binary_accuracy: 0.8068 - val_loss: 0.4054 - val_binary_accuracy: 0.8040\n","Epoch 17/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4007 - binary_accuracy: 0.8099 - val_loss: 0.4056 - val_binary_accuracy: 0.8038\n","Epoch 18/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4064 - binary_accuracy: 0.8078 - val_loss: 0.4053 - val_binary_accuracy: 0.8042\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4037 - binary_accuracy: 0.8080 - val_loss: 0.4049 - val_binary_accuracy: 0.8050\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4005 - binary_accuracy: 0.8094 - val_loss: 0.4048 - val_binary_accuracy: 0.8051\n","Epoch 21/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4031 - binary_accuracy: 0.8099 - val_loss: 0.4042 - val_binary_accuracy: 0.8052\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4003 - binary_accuracy: 0.8101 - val_loss: 0.4055 - val_binary_accuracy: 0.8029\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3980 - binary_accuracy: 0.8110 - val_loss: 0.4048 - val_binary_accuracy: 0.8043\n","Epoch 24/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4000 - binary_accuracy: 0.8105 - val_loss: 0.4039 - val_binary_accuracy: 0.8058\n","Epoch 25/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3976 - binary_accuracy: 0.8107 - val_loss: 0.4069 - val_binary_accuracy: 0.8043\n","Epoch 26/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4001 - binary_accuracy: 0.8110 - val_loss: 0.4041 - val_binary_accuracy: 0.8053\n","Epoch 27/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3976 - binary_accuracy: 0.8114 - val_loss: 0.4079 - val_binary_accuracy: 0.8049\n","Epoch 28/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3983 - binary_accuracy: 0.8128 - val_loss: 0.4052 - val_binary_accuracy: 0.8059\n","Epoch 29/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3965 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8053\n","Epoch 30/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3971 - binary_accuracy: 0.8126 - val_loss: 0.4048 - val_binary_accuracy: 0.8048\n","Epoch 31/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3958 - binary_accuracy: 0.8123 - val_loss: 0.4077 - val_binary_accuracy: 0.8030\n","Epoch 32/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3941 - binary_accuracy: 0.8141 - val_loss: 0.4050 - val_binary_accuracy: 0.8053\n","Epoch 33/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3920 - binary_accuracy: 0.8144 - val_loss: 0.4070 - val_binary_accuracy: 0.8039\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|| 3/3 [15:55<00:00, 318.35s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-GDXsMNPXnLl"},"source":["Result: default rate of 0.5 is the best dropout rate"]},{"cell_type":"markdown","metadata":{"id":"RFuuKLchXfWY"},"source":["###### Test different activation functions:"]},{"cell_type":"code","metadata":{"id":"Ae0of54xYy-a"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"Adadelta\": opt = Adadelta()\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wn8kFupfYy-d","executionInfo":{"status":"ok","timestamp":1611342763015,"user_tz":-60,"elapsed":2001376,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"67f6822d-0ac9-437f-bf2e-b91d818830a8"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"sigmoid\", \"tanh\", \"relu\", \"elu\", \"selu\", \"gelu\", \"swish\"],\n","    \"regularization\" : [\"dropout\"],\n","    \"optimizer\" : [\"Adam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'sigmoid', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 36ms/step - loss: 0.5985 - binary_accuracy: 0.6774 - val_loss: 0.4334 - val_binary_accuracy: 0.7901\n","Epoch 2/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4451 - binary_accuracy: 0.7809 - val_loss: 0.4278 - val_binary_accuracy: 0.7931\n","Epoch 3/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4355 - binary_accuracy: 0.7879 - val_loss: 0.4274 - val_binary_accuracy: 0.7942\n","Epoch 4/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4324 - binary_accuracy: 0.7914 - val_loss: 0.4242 - val_binary_accuracy: 0.7939\n","Epoch 5/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4303 - binary_accuracy: 0.7920 - val_loss: 0.4251 - val_binary_accuracy: 0.7951\n","Epoch 6/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4267 - binary_accuracy: 0.7950 - val_loss: 0.4217 - val_binary_accuracy: 0.7954\n","Epoch 7/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4281 - binary_accuracy: 0.7918 - val_loss: 0.4219 - val_binary_accuracy: 0.7950\n","Epoch 8/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4265 - binary_accuracy: 0.7930 - val_loss: 0.4195 - val_binary_accuracy: 0.7958\n","Epoch 9/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4243 - binary_accuracy: 0.7952 - val_loss: 0.4196 - val_binary_accuracy: 0.7965\n","Epoch 10/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4211 - binary_accuracy: 0.7978 - val_loss: 0.4191 - val_binary_accuracy: 0.7975\n","Epoch 11/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4211 - binary_accuracy: 0.7961 - val_loss: 0.4188 - val_binary_accuracy: 0.7974\n","Epoch 12/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4198 - binary_accuracy: 0.7982 - val_loss: 0.4176 - val_binary_accuracy: 0.7982\n","Epoch 13/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4194 - binary_accuracy: 0.7964 - val_loss: 0.4172 - val_binary_accuracy: 0.7986\n","Epoch 14/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4197 - binary_accuracy: 0.7972 - val_loss: 0.4175 - val_binary_accuracy: 0.7983\n","Epoch 15/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4186 - binary_accuracy: 0.7986 - val_loss: 0.4184 - val_binary_accuracy: 0.7986\n","Epoch 16/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4198 - binary_accuracy: 0.7981 - val_loss: 0.4158 - val_binary_accuracy: 0.7987\n","Epoch 17/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4132 - binary_accuracy: 0.8020 - val_loss: 0.4154 - val_binary_accuracy: 0.7990\n","Epoch 18/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4188 - binary_accuracy: 0.7972 - val_loss: 0.4168 - val_binary_accuracy: 0.7994\n","Epoch 19/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4168 - binary_accuracy: 0.8003 - val_loss: 0.4154 - val_binary_accuracy: 0.7995\n","Epoch 20/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4141 - binary_accuracy: 0.8004 - val_loss: 0.4142 - val_binary_accuracy: 0.7999\n","Epoch 21/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4151 - binary_accuracy: 0.8013 - val_loss: 0.4129 - val_binary_accuracy: 0.8004\n","Epoch 22/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4126 - binary_accuracy: 0.8016 - val_loss: 0.4131 - val_binary_accuracy: 0.8002\n","Epoch 23/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4116 - binary_accuracy: 0.8026 - val_loss: 0.4119 - val_binary_accuracy: 0.8013\n","Epoch 24/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4118 - binary_accuracy: 0.8010 - val_loss: 0.4113 - val_binary_accuracy: 0.8016\n","Epoch 25/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4105 - binary_accuracy: 0.8026 - val_loss: 0.4110 - val_binary_accuracy: 0.8018\n","Epoch 26/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4116 - binary_accuracy: 0.8029 - val_loss: 0.4111 - val_binary_accuracy: 0.8018\n","Epoch 27/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4105 - binary_accuracy: 0.8030 - val_loss: 0.4110 - val_binary_accuracy: 0.8022\n","Epoch 28/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4109 - binary_accuracy: 0.8029 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 29/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4095 - binary_accuracy: 0.8029 - val_loss: 0.4096 - val_binary_accuracy: 0.8028\n","Epoch 30/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4101 - binary_accuracy: 0.8028 - val_loss: 0.4090 - val_binary_accuracy: 0.8034\n","Epoch 31/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4094 - binary_accuracy: 0.8031 - val_loss: 0.4090 - val_binary_accuracy: 0.8030\n","Epoch 32/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4082 - binary_accuracy: 0.8043 - val_loss: 0.4082 - val_binary_accuracy: 0.8041\n","Epoch 33/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4055 - binary_accuracy: 0.8053 - val_loss: 0.4085 - val_binary_accuracy: 0.8036\n","Epoch 34/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4074 - binary_accuracy: 0.8053 - val_loss: 0.4079 - val_binary_accuracy: 0.8034\n","Epoch 35/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4072 - binary_accuracy: 0.8047 - val_loss: 0.4079 - val_binary_accuracy: 0.8040\n","Epoch 36/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4064 - binary_accuracy: 0.8054 - val_loss: 0.4076 - val_binary_accuracy: 0.8032\n","Epoch 37/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4069 - binary_accuracy: 0.8056 - val_loss: 0.4074 - val_binary_accuracy: 0.8040\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 14%|        | 1/7 [07:29<44:59, 449.90s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'tanh', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 35ms/step - loss: 0.5367 - binary_accuracy: 0.7375 - val_loss: 0.4342 - val_binary_accuracy: 0.7924\n","Epoch 2/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4413 - binary_accuracy: 0.7852 - val_loss: 0.4278 - val_binary_accuracy: 0.7929\n","Epoch 3/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4331 - binary_accuracy: 0.7902 - val_loss: 0.4220 - val_binary_accuracy: 0.7941\n","Epoch 4/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4306 - binary_accuracy: 0.7922 - val_loss: 0.4234 - val_binary_accuracy: 0.7970\n","Epoch 5/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4282 - binary_accuracy: 0.7934 - val_loss: 0.4215 - val_binary_accuracy: 0.7951\n","Epoch 6/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4251 - binary_accuracy: 0.7960 - val_loss: 0.4178 - val_binary_accuracy: 0.7987\n","Epoch 7/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4256 - binary_accuracy: 0.7956 - val_loss: 0.4209 - val_binary_accuracy: 0.7980\n","Epoch 8/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4239 - binary_accuracy: 0.7959 - val_loss: 0.4192 - val_binary_accuracy: 0.7999\n","Epoch 9/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4226 - binary_accuracy: 0.7971 - val_loss: 0.4155 - val_binary_accuracy: 0.7996\n","Epoch 10/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4185 - binary_accuracy: 0.7999 - val_loss: 0.4143 - val_binary_accuracy: 0.8010\n","Epoch 11/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4140 - val_binary_accuracy: 0.8002\n","Epoch 12/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4189 - binary_accuracy: 0.7995 - val_loss: 0.4143 - val_binary_accuracy: 0.8002\n","Epoch 13/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4163 - binary_accuracy: 0.7992 - val_loss: 0.4140 - val_binary_accuracy: 0.8006\n","Epoch 14/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4167 - binary_accuracy: 0.7988 - val_loss: 0.4160 - val_binary_accuracy: 0.8013\n","Epoch 15/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4160 - binary_accuracy: 0.8004 - val_loss: 0.4136 - val_binary_accuracy: 0.7994\n","Epoch 16/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4163 - binary_accuracy: 0.7999 - val_loss: 0.4125 - val_binary_accuracy: 0.8016\n","Epoch 17/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4110 - binary_accuracy: 0.8020 - val_loss: 0.4138 - val_binary_accuracy: 0.7991\n","Epoch 18/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4159 - binary_accuracy: 0.8009 - val_loss: 0.4141 - val_binary_accuracy: 0.8023\n","Epoch 19/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4140 - binary_accuracy: 0.8017 - val_loss: 0.4126 - val_binary_accuracy: 0.8014\n","Epoch 20/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4110 - binary_accuracy: 0.8026 - val_loss: 0.4157 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4133 - binary_accuracy: 0.8030 - val_loss: 0.4103 - val_binary_accuracy: 0.8036\n","Epoch 22/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4107 - binary_accuracy: 0.8029 - val_loss: 0.4120 - val_binary_accuracy: 0.8015\n","Epoch 23/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4096 - binary_accuracy: 0.8031 - val_loss: 0.4127 - val_binary_accuracy: 0.8016\n","Epoch 24/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4111 - binary_accuracy: 0.8019 - val_loss: 0.4118 - val_binary_accuracy: 0.8012\n","Epoch 25/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4092 - binary_accuracy: 0.8035 - val_loss: 0.4147 - val_binary_accuracy: 0.7985\n","Epoch 26/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4100 - binary_accuracy: 0.8035 - val_loss: 0.4109 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 29%|       | 2/7 [12:43<34:05, 409.09s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'relu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 36ms/step - loss: 0.5280 - binary_accuracy: 0.7320 - val_loss: 0.4343 - val_binary_accuracy: 0.7958\n","Epoch 2/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4330 - binary_accuracy: 0.7902 - val_loss: 0.4244 - val_binary_accuracy: 0.7995\n","Epoch 3/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4218 - binary_accuracy: 0.7981 - val_loss: 0.4273 - val_binary_accuracy: 0.8008\n","Epoch 4/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4174 - binary_accuracy: 0.8016 - val_loss: 0.4123 - val_binary_accuracy: 0.8023\n","Epoch 5/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4139 - binary_accuracy: 0.8033 - val_loss: 0.4136 - val_binary_accuracy: 0.8043\n","Epoch 6/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4087 - binary_accuracy: 0.8068 - val_loss: 0.4119 - val_binary_accuracy: 0.8039\n","Epoch 7/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4080 - binary_accuracy: 0.8056 - val_loss: 0.4083 - val_binary_accuracy: 0.8038\n","Epoch 8/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4056 - binary_accuracy: 0.8082 - val_loss: 0.4073 - val_binary_accuracy: 0.8036\n","Epoch 9/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4012 - binary_accuracy: 0.8101 - val_loss: 0.4070 - val_binary_accuracy: 0.8039\n","Epoch 10/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3958 - binary_accuracy: 0.8134 - val_loss: 0.4073 - val_binary_accuracy: 0.8054\n","Epoch 11/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3959 - binary_accuracy: 0.8136 - val_loss: 0.4085 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3930 - binary_accuracy: 0.8154 - val_loss: 0.4072 - val_binary_accuracy: 0.8052\n","Epoch 13/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3917 - binary_accuracy: 0.8148 - val_loss: 0.4055 - val_binary_accuracy: 0.8043\n","Epoch 14/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3899 - binary_accuracy: 0.8164 - val_loss: 0.4053 - val_binary_accuracy: 0.8046\n","Epoch 15/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.3872 - binary_accuracy: 0.8172 - val_loss: 0.4079 - val_binary_accuracy: 0.8049\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|     | 3/7 [15:41<22:38, 339.67s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'elu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.5774 - binary_accuracy: 0.7322 - val_loss: 0.4243 - val_binary_accuracy: 0.7933\n","Epoch 2/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4374 - binary_accuracy: 0.7860 - val_loss: 0.4207 - val_binary_accuracy: 0.7952\n","Epoch 3/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4278 - binary_accuracy: 0.7933 - val_loss: 0.4211 - val_binary_accuracy: 0.7954\n","Epoch 4/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4255 - binary_accuracy: 0.7951 - val_loss: 0.4176 - val_binary_accuracy: 0.7970\n","Epoch 5/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4235 - binary_accuracy: 0.7957 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4208 - binary_accuracy: 0.7982 - val_loss: 0.4149 - val_binary_accuracy: 0.8007\n","Epoch 7/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4206 - binary_accuracy: 0.7982 - val_loss: 0.4141 - val_binary_accuracy: 0.8000\n","Epoch 8/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4204 - binary_accuracy: 0.7985 - val_loss: 0.4133 - val_binary_accuracy: 0.8005\n","Epoch 9/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4181 - binary_accuracy: 0.7995 - val_loss: 0.4126 - val_binary_accuracy: 0.8005\n","Epoch 10/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4151 - binary_accuracy: 0.8026 - val_loss: 0.4120 - val_binary_accuracy: 0.8017\n","Epoch 11/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4155 - binary_accuracy: 0.8018 - val_loss: 0.4112 - val_binary_accuracy: 0.8016\n","Epoch 12/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4149 - binary_accuracy: 0.8016 - val_loss: 0.4122 - val_binary_accuracy: 0.8013\n","Epoch 13/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4139 - binary_accuracy: 0.8016 - val_loss: 0.4105 - val_binary_accuracy: 0.8009\n","Epoch 14/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4140 - binary_accuracy: 0.8017 - val_loss: 0.4103 - val_binary_accuracy: 0.8018\n","Epoch 15/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4131 - binary_accuracy: 0.8037 - val_loss: 0.4137 - val_binary_accuracy: 0.8020\n","Epoch 16/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4136 - binary_accuracy: 0.8021 - val_loss: 0.4100 - val_binary_accuracy: 0.8019\n","Epoch 17/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4091 - binary_accuracy: 0.8052 - val_loss: 0.4106 - val_binary_accuracy: 0.8006\n","Epoch 18/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4130 - binary_accuracy: 0.8027 - val_loss: 0.4103 - val_binary_accuracy: 0.8032\n","Epoch 19/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4118 - binary_accuracy: 0.8032 - val_loss: 0.4115 - val_binary_accuracy: 0.8003\n","Epoch 20/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4085 - binary_accuracy: 0.8059 - val_loss: 0.4094 - val_binary_accuracy: 0.8025\n","Epoch 21/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4112 - binary_accuracy: 0.8047 - val_loss: 0.4075 - val_binary_accuracy: 0.8039\n","Epoch 22/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4079 - binary_accuracy: 0.8055 - val_loss: 0.4108 - val_binary_accuracy: 0.8011\n","Epoch 23/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4065 - binary_accuracy: 0.8055 - val_loss: 0.4091 - val_binary_accuracy: 0.8018\n","Epoch 24/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4091 - binary_accuracy: 0.8038 - val_loss: 0.4075 - val_binary_accuracy: 0.8035\n","Epoch 25/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4059 - binary_accuracy: 0.8069 - val_loss: 0.4113 - val_binary_accuracy: 0.8008\n","Epoch 26/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4077 - binary_accuracy: 0.8059 - val_loss: 0.4079 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|    | 4/7 [21:09<16:48, 336.19s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'selu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.7398 - binary_accuracy: 0.7149 - val_loss: 0.4294 - val_binary_accuracy: 0.7902\n","Epoch 2/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4432 - binary_accuracy: 0.7832 - val_loss: 0.4254 - val_binary_accuracy: 0.7933\n","Epoch 3/100\n","338/338 [==============================] - 12s 37ms/step - loss: 0.4332 - binary_accuracy: 0.7903 - val_loss: 0.4232 - val_binary_accuracy: 0.7926\n","Epoch 4/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4301 - binary_accuracy: 0.7916 - val_loss: 0.4199 - val_binary_accuracy: 0.7961\n","Epoch 5/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4282 - binary_accuracy: 0.7936 - val_loss: 0.4189 - val_binary_accuracy: 0.7972\n","Epoch 6/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4247 - binary_accuracy: 0.7965 - val_loss: 0.4169 - val_binary_accuracy: 0.7993\n","Epoch 7/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4249 - binary_accuracy: 0.7951 - val_loss: 0.4170 - val_binary_accuracy: 0.7993\n","Epoch 8/100\n","338/338 [==============================] - 12s 36ms/step - loss: 0.4242 - binary_accuracy: 0.7964 - val_loss: 0.4165 - val_binary_accuracy: 0.7986\n","Epoch 9/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4221 - binary_accuracy: 0.7971 - val_loss: 0.4159 - val_binary_accuracy: 0.7990\n","Epoch 10/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4192 - binary_accuracy: 0.8010 - val_loss: 0.4133 - val_binary_accuracy: 0.8006\n","Epoch 11/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4198 - binary_accuracy: 0.7984 - val_loss: 0.4131 - val_binary_accuracy: 0.8002\n","Epoch 12/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4186 - binary_accuracy: 0.7987 - val_loss: 0.4139 - val_binary_accuracy: 0.8003\n","Epoch 13/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4177 - binary_accuracy: 0.7994 - val_loss: 0.4130 - val_binary_accuracy: 0.7991\n","Epoch 14/100\n","338/338 [==============================] - 13s 37ms/step - loss: 0.4173 - binary_accuracy: 0.7987 - val_loss: 0.4122 - val_binary_accuracy: 0.8018\n","Epoch 15/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4174 - binary_accuracy: 0.8009 - val_loss: 0.4162 - val_binary_accuracy: 0.7988\n","Epoch 16/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4178 - binary_accuracy: 0.7994 - val_loss: 0.4129 - val_binary_accuracy: 0.8012\n","Epoch 17/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4129 - binary_accuracy: 0.8024 - val_loss: 0.4160 - val_binary_accuracy: 0.7973\n","Epoch 18/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4179 - binary_accuracy: 0.8006 - val_loss: 0.4117 - val_binary_accuracy: 0.8015\n","Epoch 19/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4157 - binary_accuracy: 0.8007 - val_loss: 0.4150 - val_binary_accuracy: 0.7976\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 71%|  | 5/7 [25:09<10:14, 307.38s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 41ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 86%| | 6/7 [30:31<05:11, 311.75s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'swish', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 14s 39ms/step - loss: 0.4841 - binary_accuracy: 0.7558 - val_loss: 0.4209 - val_binary_accuracy: 0.7965\n","Epoch 2/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4289 - binary_accuracy: 0.7923 - val_loss: 0.4165 - val_binary_accuracy: 0.7978\n","Epoch 3/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4219 - binary_accuracy: 0.7988 - val_loss: 0.4173 - val_binary_accuracy: 0.7993\n","Epoch 4/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4194 - binary_accuracy: 0.7991 - val_loss: 0.4130 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4179 - binary_accuracy: 0.7988 - val_loss: 0.4119 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4150 - binary_accuracy: 0.8016 - val_loss: 0.4108 - val_binary_accuracy: 0.8022\n","Epoch 7/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4143 - binary_accuracy: 0.8014 - val_loss: 0.4098 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4143 - binary_accuracy: 0.8020 - val_loss: 0.4087 - val_binary_accuracy: 0.8034\n","Epoch 9/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4117 - binary_accuracy: 0.8032 - val_loss: 0.4083 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4089 - binary_accuracy: 0.8061 - val_loss: 0.4079 - val_binary_accuracy: 0.8033\n","Epoch 11/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4089 - binary_accuracy: 0.8058 - val_loss: 0.4081 - val_binary_accuracy: 0.8033\n","Epoch 12/100\n","338/338 [==============================] - 13s 38ms/step - loss: 0.4082 - binary_accuracy: 0.8056 - val_loss: 0.4074 - val_binary_accuracy: 0.8034\n","Epoch 13/100\n","338/338 [==============================] - 13s 39ms/step - loss: 0.4069 - binary_accuracy: 0.8063 - val_loss: 0.4064 - val_binary_accuracy: 0.8024\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|| 7/7 [33:20<00:00, 285.81s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"28yHmpwBfaV_"},"source":["Result: gelu was the best; relu was the second-best"]},{"cell_type":"markdown","metadata":{"id":"gfyZxPOzg4aE"},"source":["###### Tune different optimizers:"]},{"cell_type":"code","metadata":{"id":"SZP09AKKg_iU"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebOM9CJcg_iW","executionInfo":{"status":"ok","timestamp":1611345127609,"user_tz":-60,"elapsed":2240912,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"7a51fb62-6028-4646-f338-dbd6b358efef"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [3],\n","    \"number_of_units_first_layer\" : [500],\n","    \"network_shape\" : [\"triangle\"],\n","    \"network_decay\" : [0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\"],\n","    \"optimizer\" : [\"RMSprop\", \"RMSprop_centered\", \"Adam\", \"Adam_amsgrad\", \"Adamax\", \"Nadam\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params,experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4850 - binary_accuracy: 0.7576 - val_loss: 0.4217 - val_binary_accuracy: 0.7966\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4268 - binary_accuracy: 0.7942 - val_loss: 0.4148 - val_binary_accuracy: 0.8002\n","Epoch 3/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4192 - binary_accuracy: 0.8004 - val_loss: 0.4126 - val_binary_accuracy: 0.8006\n","Epoch 4/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4169 - binary_accuracy: 0.8008 - val_loss: 0.4106 - val_binary_accuracy: 0.8013\n","Epoch 5/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4149 - binary_accuracy: 0.8024 - val_loss: 0.4098 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4123 - binary_accuracy: 0.8044 - val_loss: 0.4087 - val_binary_accuracy: 0.8039\n","Epoch 7/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4110 - binary_accuracy: 0.8048 - val_loss: 0.4098 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","338/338 [==============================] - 16s 46ms/step - loss: 0.4110 - binary_accuracy: 0.8047 - val_loss: 0.4070 - val_binary_accuracy: 0.8037\n","Epoch 9/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4073 - binary_accuracy: 0.8078 - val_loss: 0.4074 - val_binary_accuracy: 0.8041\n","Epoch 10/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4046 - binary_accuracy: 0.8104 - val_loss: 0.4067 - val_binary_accuracy: 0.8039\n","Epoch 11/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4058 - binary_accuracy: 0.8085 - val_loss: 0.4059 - val_binary_accuracy: 0.8039\n","Epoch 12/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4032 - binary_accuracy: 0.8098 - val_loss: 0.4062 - val_binary_accuracy: 0.8043\n","Epoch 13/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4025 - binary_accuracy: 0.8105 - val_loss: 0.4068 - val_binary_accuracy: 0.8046\n","Epoch 14/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4019 - binary_accuracy: 0.8101 - val_loss: 0.4056 - val_binary_accuracy: 0.8047\n","Epoch 15/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4010 - binary_accuracy: 0.8112 - val_loss: 0.4067 - val_binary_accuracy: 0.8054\n","Epoch 16/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4016 - binary_accuracy: 0.8104 - val_loss: 0.4123 - val_binary_accuracy: 0.8044\n","Epoch 17/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3958 - binary_accuracy: 0.8140 - val_loss: 0.4087 - val_binary_accuracy: 0.8034\n","Epoch 18/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4012 - binary_accuracy: 0.8117 - val_loss: 0.4061 - val_binary_accuracy: 0.8061\n","Epoch 19/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.3982 - binary_accuracy: 0.8115 - val_loss: 0.4090 - val_binary_accuracy: 0.8052\n","Epoch 20/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.3947 - binary_accuracy: 0.8148 - val_loss: 0.4068 - val_binary_accuracy: 0.8049\n","Epoch 21/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3979 - binary_accuracy: 0.8132 - val_loss: 0.4064 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3942 - binary_accuracy: 0.8135 - val_loss: 0.4079 - val_binary_accuracy: 0.8069\n","Epoch 23/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3923 - binary_accuracy: 0.8144 - val_loss: 0.4099 - val_binary_accuracy: 0.8053\n","Epoch 24/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3949 - binary_accuracy: 0.8147 - val_loss: 0.4068 - val_binary_accuracy: 0.8054\n","Epoch 25/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3923 - binary_accuracy: 0.8161 - val_loss: 0.4118 - val_binary_accuracy: 0.8054\n","Epoch 26/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3946 - binary_accuracy: 0.8146 - val_loss: 0.4065 - val_binary_accuracy: 0.8052\n","Epoch 27/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3918 - binary_accuracy: 0.8163 - val_loss: 0.4069 - val_binary_accuracy: 0.8057\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|        | 1/6 [06:30<32:32, 390.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop_centered', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 45ms/step - loss: 0.4823 - binary_accuracy: 0.7592 - val_loss: 0.4214 - val_binary_accuracy: 0.7968\n","Epoch 2/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4257 - binary_accuracy: 0.7945 - val_loss: 0.4148 - val_binary_accuracy: 0.8005\n","Epoch 3/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4187 - binary_accuracy: 0.8006 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 4/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4163 - binary_accuracy: 0.8014 - val_loss: 0.4103 - val_binary_accuracy: 0.8016\n","Epoch 5/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4145 - binary_accuracy: 0.8028 - val_loss: 0.4097 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4120 - binary_accuracy: 0.8046 - val_loss: 0.4081 - val_binary_accuracy: 0.8041\n","Epoch 7/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4106 - binary_accuracy: 0.8056 - val_loss: 0.4099 - val_binary_accuracy: 0.8029\n","Epoch 8/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4105 - binary_accuracy: 0.8051 - val_loss: 0.4067 - val_binary_accuracy: 0.8040\n","Epoch 9/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4071 - binary_accuracy: 0.8079 - val_loss: 0.4072 - val_binary_accuracy: 0.8043\n","Epoch 10/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4043 - binary_accuracy: 0.8101 - val_loss: 0.4061 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4054 - binary_accuracy: 0.8092 - val_loss: 0.4056 - val_binary_accuracy: 0.8043\n","Epoch 12/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4029 - binary_accuracy: 0.8100 - val_loss: 0.4061 - val_binary_accuracy: 0.8048\n","Epoch 13/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4020 - binary_accuracy: 0.8112 - val_loss: 0.4074 - val_binary_accuracy: 0.8041\n","Epoch 14/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4012 - binary_accuracy: 0.8106 - val_loss: 0.4062 - val_binary_accuracy: 0.8051\n","Epoch 15/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4003 - binary_accuracy: 0.8114 - val_loss: 0.4070 - val_binary_accuracy: 0.8053\n","Epoch 16/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.4010 - binary_accuracy: 0.8111 - val_loss: 0.4138 - val_binary_accuracy: 0.8047\n","Epoch 17/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3952 - binary_accuracy: 0.8140 - val_loss: 0.4092 - val_binary_accuracy: 0.8026\n","Epoch 18/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4006 - binary_accuracy: 0.8123 - val_loss: 0.4063 - val_binary_accuracy: 0.8060\n","Epoch 19/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3976 - binary_accuracy: 0.8128 - val_loss: 0.4105 - val_binary_accuracy: 0.8050\n","Epoch 20/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3936 - binary_accuracy: 0.8157 - val_loss: 0.4069 - val_binary_accuracy: 0.8045\n","Epoch 21/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3971 - binary_accuracy: 0.8136 - val_loss: 0.4067 - val_binary_accuracy: 0.8059\n","Epoch 22/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3935 - binary_accuracy: 0.8140 - val_loss: 0.4078 - val_binary_accuracy: 0.8067\n","Epoch 23/100\n","338/338 [==============================] - 16s 48ms/step - loss: 0.3917 - binary_accuracy: 0.8157 - val_loss: 0.4105 - val_binary_accuracy: 0.8050\n","Epoch 24/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3943 - binary_accuracy: 0.8154 - val_loss: 0.4074 - val_binary_accuracy: 0.8058\n","Epoch 25/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.3917 - binary_accuracy: 0.8169 - val_loss: 0.4148 - val_binary_accuracy: 0.8054\n","Epoch 26/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3935 - binary_accuracy: 0.8154 - val_loss: 0.4074 - val_binary_accuracy: 0.8054\n","Epoch 27/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3910 - binary_accuracy: 0.8175 - val_loss: 0.4067 - val_binary_accuracy: 0.8063\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|      | 2/6 [13:15<26:18, 394.75s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7998 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4167 - binary_accuracy: 0.8005 - val_loss: 0.4103 - val_binary_accuracy: 0.8015\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4147 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4116 - binary_accuracy: 0.8035 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 7/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4106 - binary_accuracy: 0.8035 - val_loss: 0.4072 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4073 - binary_accuracy: 0.8058 - val_loss: 0.4056 - val_binary_accuracy: 0.8035\n","Epoch 10/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4039 - binary_accuracy: 0.8087 - val_loss: 0.4056 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4042 - binary_accuracy: 0.8077 - val_loss: 0.4057 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4029 - binary_accuracy: 0.8084 - val_loss: 0.4051 - val_binary_accuracy: 0.8038\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4016 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4012 - binary_accuracy: 0.8096 - val_loss: 0.4050 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3993 - binary_accuracy: 0.8104 - val_loss: 0.4053 - val_binary_accuracy: 0.8057\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3994 - binary_accuracy: 0.8094 - val_loss: 0.4040 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3934 - binary_accuracy: 0.8137 - val_loss: 0.4044 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3983 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3960 - binary_accuracy: 0.8109 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3918 - binary_accuracy: 0.8134 - val_loss: 0.4053 - val_binary_accuracy: 0.8059\n","Epoch 21/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3948 - binary_accuracy: 0.8132 - val_loss: 0.4034 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3912 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|     | 3/6 [18:37<18:39, 373.08s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adam_amsgrad', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 42ms/step - loss: 0.4913 - binary_accuracy: 0.7510 - val_loss: 0.4187 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4272 - binary_accuracy: 0.7928 - val_loss: 0.4139 - val_binary_accuracy: 0.7998\n","Epoch 3/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4190 - binary_accuracy: 0.7999 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 4/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4167 - binary_accuracy: 0.8004 - val_loss: 0.4102 - val_binary_accuracy: 0.8016\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4146 - binary_accuracy: 0.8012 - val_loss: 0.4089 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4114 - binary_accuracy: 0.8036 - val_loss: 0.4079 - val_binary_accuracy: 0.8031\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4105 - binary_accuracy: 0.8037 - val_loss: 0.4070 - val_binary_accuracy: 0.8033\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4057 - val_binary_accuracy: 0.8042\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4073 - binary_accuracy: 0.8060 - val_loss: 0.4055 - val_binary_accuracy: 0.8034\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4038 - binary_accuracy: 0.8080 - val_loss: 0.4056 - val_binary_accuracy: 0.8044\n","Epoch 11/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4042 - binary_accuracy: 0.8071 - val_loss: 0.4059 - val_binary_accuracy: 0.8033\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4030 - binary_accuracy: 0.8081 - val_loss: 0.4051 - val_binary_accuracy: 0.8042\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4017 - binary_accuracy: 0.8089 - val_loss: 0.4047 - val_binary_accuracy: 0.8050\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4013 - binary_accuracy: 0.8093 - val_loss: 0.4051 - val_binary_accuracy: 0.8045\n","Epoch 15/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3997 - binary_accuracy: 0.8096 - val_loss: 0.4047 - val_binary_accuracy: 0.8049\n","Epoch 16/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3999 - binary_accuracy: 0.8097 - val_loss: 0.4037 - val_binary_accuracy: 0.8050\n","Epoch 17/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3940 - binary_accuracy: 0.8127 - val_loss: 0.4041 - val_binary_accuracy: 0.8046\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3991 - binary_accuracy: 0.8104 - val_loss: 0.4049 - val_binary_accuracy: 0.8053\n","Epoch 19/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3970 - binary_accuracy: 0.8104 - val_loss: 0.4037 - val_binary_accuracy: 0.8057\n","Epoch 20/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3929 - binary_accuracy: 0.8129 - val_loss: 0.4047 - val_binary_accuracy: 0.8066\n","Epoch 21/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3957 - binary_accuracy: 0.8127 - val_loss: 0.4027 - val_binary_accuracy: 0.8061\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3927 - binary_accuracy: 0.8131 - val_loss: 0.4037 - val_binary_accuracy: 0.8048\n","Epoch 23/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3904 - binary_accuracy: 0.8139 - val_loss: 0.4037 - val_binary_accuracy: 0.8051\n","Epoch 24/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3919 - binary_accuracy: 0.8133 - val_loss: 0.4036 - val_binary_accuracy: 0.8063\n","Epoch 25/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3900 - binary_accuracy: 0.8149 - val_loss: 0.4041 - val_binary_accuracy: 0.8068\n","Epoch 26/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3915 - binary_accuracy: 0.8148 - val_loss: 0.4035 - val_binary_accuracy: 0.8054\n","Epoch 27/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3880 - binary_accuracy: 0.8154 - val_loss: 0.4054 - val_binary_accuracy: 0.8059\n","Epoch 28/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3895 - binary_accuracy: 0.8160 - val_loss: 0.4050 - val_binary_accuracy: 0.8053\n","Epoch 29/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3876 - binary_accuracy: 0.8163 - val_loss: 0.4040 - val_binary_accuracy: 0.8064\n","Epoch 30/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.3882 - binary_accuracy: 0.8153 - val_loss: 0.4039 - val_binary_accuracy: 0.8053\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|   | 4/6 [25:39<12:55, 387.77s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Adamax', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 15s 41ms/step - loss: 0.5127 - binary_accuracy: 0.7377 - val_loss: 0.4291 - val_binary_accuracy: 0.7903\n","Epoch 2/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4451 - binary_accuracy: 0.7821 - val_loss: 0.4222 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 13s 40ms/step - loss: 0.4341 - binary_accuracy: 0.7897 - val_loss: 0.4184 - val_binary_accuracy: 0.7971\n","Epoch 4/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4292 - binary_accuracy: 0.7920 - val_loss: 0.4161 - val_binary_accuracy: 0.7982\n","Epoch 5/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4262 - binary_accuracy: 0.7948 - val_loss: 0.4138 - val_binary_accuracy: 0.7998\n","Epoch 6/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4216 - binary_accuracy: 0.7965 - val_loss: 0.4135 - val_binary_accuracy: 0.7998\n","Epoch 7/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4205 - binary_accuracy: 0.7970 - val_loss: 0.4124 - val_binary_accuracy: 0.8006\n","Epoch 8/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4197 - binary_accuracy: 0.7981 - val_loss: 0.4111 - val_binary_accuracy: 0.8022\n","Epoch 9/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4169 - binary_accuracy: 0.7999 - val_loss: 0.4110 - val_binary_accuracy: 0.8005\n","Epoch 10/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4138 - binary_accuracy: 0.8032 - val_loss: 0.4099 - val_binary_accuracy: 0.8025\n","Epoch 11/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4137 - binary_accuracy: 0.8019 - val_loss: 0.4095 - val_binary_accuracy: 0.8027\n","Epoch 12/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4121 - binary_accuracy: 0.8018 - val_loss: 0.4092 - val_binary_accuracy: 0.8025\n","Epoch 13/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4119 - binary_accuracy: 0.8018 - val_loss: 0.4088 - val_binary_accuracy: 0.8029\n","Epoch 14/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4115 - binary_accuracy: 0.8025 - val_loss: 0.4084 - val_binary_accuracy: 0.8031\n","Epoch 15/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4107 - binary_accuracy: 0.8041 - val_loss: 0.4081 - val_binary_accuracy: 0.8028\n","Epoch 16/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4104 - binary_accuracy: 0.8022 - val_loss: 0.4076 - val_binary_accuracy: 0.8037\n","Epoch 17/100\n","338/338 [==============================] - 14s 40ms/step - loss: 0.4050 - binary_accuracy: 0.8072 - val_loss: 0.4078 - val_binary_accuracy: 0.8022\n","Epoch 18/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4102 - binary_accuracy: 0.8042 - val_loss: 0.4071 - val_binary_accuracy: 0.8043\n","Epoch 19/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4085 - binary_accuracy: 0.8045 - val_loss: 0.4068 - val_binary_accuracy: 0.8040\n","Epoch 20/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4057 - binary_accuracy: 0.8060 - val_loss: 0.4070 - val_binary_accuracy: 0.8034\n","Epoch 21/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4079 - binary_accuracy: 0.8057 - val_loss: 0.4059 - val_binary_accuracy: 0.8038\n","Epoch 22/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4046 - binary_accuracy: 0.8074 - val_loss: 0.4060 - val_binary_accuracy: 0.8033\n","Epoch 23/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4037 - binary_accuracy: 0.8070 - val_loss: 0.4056 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%| | 5/6 [30:56<06:06, 366.61s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'Nadam', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 16s 45ms/step - loss: 0.4943 - binary_accuracy: 0.7496 - val_loss: 0.4191 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4273 - binary_accuracy: 0.7928 - val_loss: 0.4136 - val_binary_accuracy: 0.8003\n","Epoch 3/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4122 - val_binary_accuracy: 0.8005\n","Epoch 4/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4165 - binary_accuracy: 0.8006 - val_loss: 0.4102 - val_binary_accuracy: 0.8019\n","Epoch 5/100\n","338/338 [==============================] - 15s 43ms/step - loss: 0.4145 - binary_accuracy: 0.8013 - val_loss: 0.4077 - val_binary_accuracy: 0.8027\n","Epoch 6/100\n","338/338 [==============================] - 16s 47ms/step - loss: 0.4115 - binary_accuracy: 0.8038 - val_loss: 0.4076 - val_binary_accuracy: 0.8035\n","Epoch 7/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.4101 - binary_accuracy: 0.8039 - val_loss: 0.4077 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4097 - binary_accuracy: 0.8052 - val_loss: 0.4063 - val_binary_accuracy: 0.8042\n","Epoch 9/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4071 - binary_accuracy: 0.8061 - val_loss: 0.4058 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4037 - binary_accuracy: 0.8091 - val_loss: 0.4052 - val_binary_accuracy: 0.8044\n","Epoch 11/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4042 - binary_accuracy: 0.8074 - val_loss: 0.4049 - val_binary_accuracy: 0.8031\n","Epoch 12/100\n","338/338 [==============================] - 14s 41ms/step - loss: 0.4023 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8051\n","Epoch 13/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.4015 - binary_accuracy: 0.8090 - val_loss: 0.4046 - val_binary_accuracy: 0.8046\n","Epoch 14/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.4007 - binary_accuracy: 0.8094 - val_loss: 0.4043 - val_binary_accuracy: 0.8050\n","Epoch 15/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.3992 - binary_accuracy: 0.8105 - val_loss: 0.4047 - val_binary_accuracy: 0.8056\n","Epoch 16/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.3993 - binary_accuracy: 0.8106 - val_loss: 0.4058 - val_binary_accuracy: 0.8054\n","Epoch 17/100\n","338/338 [==============================] - 14s 42ms/step - loss: 0.3931 - binary_accuracy: 0.8137 - val_loss: 0.4048 - val_binary_accuracy: 0.8035\n","Epoch 18/100\n","338/338 [==============================] - 14s 43ms/step - loss: 0.3982 - binary_accuracy: 0.8122 - val_loss: 0.4039 - val_binary_accuracy: 0.8059\n","Epoch 19/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3956 - binary_accuracy: 0.8115 - val_loss: 0.4047 - val_binary_accuracy: 0.8051\n","Epoch 20/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3918 - binary_accuracy: 0.8142 - val_loss: 0.4051 - val_binary_accuracy: 0.8049\n","Epoch 21/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3946 - binary_accuracy: 0.8130 - val_loss: 0.4036 - val_binary_accuracy: 0.8060\n","Epoch 22/100\n","338/338 [==============================] - 15s 45ms/step - loss: 0.3912 - binary_accuracy: 0.8140 - val_loss: 0.4040 - val_binary_accuracy: 0.8050\n","Epoch 23/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3888 - binary_accuracy: 0.8159 - val_loss: 0.4045 - val_binary_accuracy: 0.8052\n","Epoch 24/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3902 - binary_accuracy: 0.8153 - val_loss: 0.4046 - val_binary_accuracy: 0.8057\n","Epoch 25/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3882 - binary_accuracy: 0.8159 - val_loss: 0.4087 - val_binary_accuracy: 0.8050\n","Epoch 26/100\n","338/338 [==============================] - 15s 44ms/step - loss: 0.3897 - binary_accuracy: 0.8162 - val_loss: 0.4048 - val_binary_accuracy: 0.8057\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|| 6/6 [37:20<00:00, 373.39s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"hRgoVEr2pXGr"},"source":["Result: RMSprop and RMSprop_centered performed best; Adam_amsgrad second"]},{"cell_type":"markdown","metadata":{"id":"-YrApbLcvvCg"},"source":["###### Perform last random search with different network architectures:"]},{"cell_type":"code","metadata":{"id":"Rb-6I-v3v1tu"},"source":["# Define the Neural Network\n","def neural_network(X_subtrain, y_subtrain, X_val, y_val, params):\n","  \n","  # Get hyperparameters from parameter_grid\n","  number_of_layers = params[\"number_of_layers\"]\n","  number_of_units = params[\"number_of_units_first_layer\"]\n","  network_shape = params[\"network_shape\"]\n","  network_decay = params[\"network_decay\"]\n","  activation_function = params[\"activation_function\"]\n","  regularization = params[\"regularization\"]\n","  optimizer = params[\"optimizer\"]\n","  weight_initializer = params[\"weight_initializer\"]\n","  batch_size = params[\"batch_size\"]\n","  if weight_initializer==\"glorot_normal\" : init = GlorotNormal(seed=seed_value)\n","  if weight_initializer==\"glorot_uniform\" : init = GlorotUniform(seed=seed_value)\n","  if weight_initializer==\"he_normal\" : init = HeNormal(seed=seed_value)\n","  if weight_initializer==\"he_uniform\" : init = HeUniform(seed=seed_value)\n","  if weight_initializer==\"lecun_normal\" : init = LecunNormal(seed=seed_value)\n","  if weight_initializer==\"lecun_uniform\" : init = LecunUniform(seed=seed_value)\n","  if optimizer==\"RMSprop\": opt = RMSprop()\n","  if optimizer==\"RMSprop_centered\": opt = RMSprop(centered=True)\n","  if optimizer==\"Adam\": opt = Adam()\n","  if optimizer==\"Adam_amsgrad\": opt = Adam(amsgrad=True)\n","  if optimizer==\"Adamax\": opt = Adamax()\n","  if optimizer==\"Nadam\": opt = Nadam()\n","\n","  # Define Model\n","  model = Sequential()\n","\n","  # Add hidden layers\n","  for i in range(0, number_of_layers):\n","    model.add(Dense(number_of_units, activation=activation_function, kernel_initializer=init))\n","    \n","    if regularization==\"dropout\":\n","      model.add(Dropout(rate=0.5, seed=seed_value))\n","\n","    if network_shape==\"triangle\":\n","      number_of_units = round(number_of_units * network_decay)\n","\n","  # Add output layer\n","  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=init))\n","\n","  # Compile Model\n","  model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","  \n","  # Fit Model to Training Data\n","  history = model.fit(X_subtrain, y_subtrain, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=True, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", patience=5, restore_best_weights=True)])\n","  return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uet3SBYvv1tv","executionInfo":{"status":"ok","timestamp":1611364534260,"user_tz":-60,"elapsed":12255497,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"2ae03005-84af-4c12-b633-e8bc71436d2e"},"source":["# Run Hyperparameter Search\n","params = {\n","    \"number_of_layers\" : [1, 2, 3, 5],\n","    \"number_of_units_first_layer\" : [30, 50, 100, 200, 250, 500, 1000],\n","    \"network_shape\" : [\"triangle\", \"brick\"],\n","    \"network_decay\" : [0.3, 0.5, 0.7],\n","    \"activation_function\" : [\"gelu\"],\n","    \"regularization\" : [\"dropout\"],\n","    \"optimizer\" : [\"RMSprop\"],\n","    \"weight_initializer\" : [\"he_uniform\"],\n","    \"batch_size\" : [512],\n","}\n","search_object = talos.Scan(x=X_subtrain, y=y_subtrain, x_val=X_val, y_val=y_val, model=neural_network, params=params, fraction_limit=0.5, experiment_name=\"test1\", seed=seed_value, print_params=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/84 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.5801 - binary_accuracy: 0.6871 - val_loss: 0.4406 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4613 - binary_accuracy: 0.7814 - val_loss: 0.4365 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4480 - binary_accuracy: 0.7890 - val_loss: 0.4544 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4410 - binary_accuracy: 0.7911 - val_loss: 0.4594 - val_binary_accuracy: 0.7950\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4358 - binary_accuracy: 0.7935 - val_loss: 0.4761 - val_binary_accuracy: 0.7963\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4322 - binary_accuracy: 0.7959 - val_loss: 0.5114 - val_binary_accuracy: 0.7967\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4312 - binary_accuracy: 0.7947 - val_loss: 0.5238 - val_binary_accuracy: 0.7948\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4305 - binary_accuracy: 0.7955 - val_loss: 0.5323 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4275 - binary_accuracy: 0.7958 - val_loss: 0.5425 - val_binary_accuracy: 0.7946\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4236 - binary_accuracy: 0.7994 - val_loss: 0.5545 - val_binary_accuracy: 0.7939\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4232 - binary_accuracy: 0.7989 - val_loss: 0.5645 - val_binary_accuracy: 0.7958\n"],"name":"stdout"},{"output_type":"stream","text":["\r  1%|          | 1/84 [00:16<22:31, 16.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.5757 - binary_accuracy: 0.6965 - val_loss: 0.4475 - val_binary_accuracy: 0.7913\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4547 - binary_accuracy: 0.7846 - val_loss: 0.4468 - val_binary_accuracy: 0.7959\n","Epoch 3/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4417 - binary_accuracy: 0.7928 - val_loss: 0.4672 - val_binary_accuracy: 0.7971\n","Epoch 4/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4359 - binary_accuracy: 0.7944 - val_loss: 0.4800 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4310 - binary_accuracy: 0.7959 - val_loss: 0.4808 - val_binary_accuracy: 0.7987\n","Epoch 6/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4280 - binary_accuracy: 0.7977 - val_loss: 0.4988 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4269 - binary_accuracy: 0.7973 - val_loss: 0.4949 - val_binary_accuracy: 0.7976\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4238 - binary_accuracy: 0.7983 - val_loss: 0.4996 - val_binary_accuracy: 0.7978\n","Epoch 9/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4219 - binary_accuracy: 0.7995 - val_loss: 0.4818 - val_binary_accuracy: 0.7995\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4178 - binary_accuracy: 0.8021 - val_loss: 0.4845 - val_binary_accuracy: 0.8016\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4181 - binary_accuracy: 0.8015 - val_loss: 0.4904 - val_binary_accuracy: 0.8004\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4173 - binary_accuracy: 0.8020 - val_loss: 0.4944 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4154 - binary_accuracy: 0.8033 - val_loss: 0.4813 - val_binary_accuracy: 0.8021\n","Epoch 14/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4156 - binary_accuracy: 0.8024 - val_loss: 0.4954 - val_binary_accuracy: 0.8021\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4150 - binary_accuracy: 0.8041 - val_loss: 0.4986 - val_binary_accuracy: 0.8028\n","Epoch 16/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4155 - binary_accuracy: 0.8030 - val_loss: 0.4848 - val_binary_accuracy: 0.8025\n","Epoch 17/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4098 - binary_accuracy: 0.8077 - val_loss: 0.4772 - val_binary_accuracy: 0.8034\n","Epoch 18/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4154 - binary_accuracy: 0.8027 - val_loss: 0.4910 - val_binary_accuracy: 0.8017\n","Epoch 19/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4139 - binary_accuracy: 0.8055 - val_loss: 0.4929 - val_binary_accuracy: 0.8026\n","Epoch 20/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4102 - binary_accuracy: 0.8068 - val_loss: 0.4996 - val_binary_accuracy: 0.8013\n","Epoch 21/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4119 - binary_accuracy: 0.8054 - val_loss: 0.4936 - val_binary_accuracy: 0.8006\n","Epoch 22/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4102 - binary_accuracy: 0.8054 - val_loss: 0.5050 - val_binary_accuracy: 0.7985\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|         | 2/84 [01:46<52:41, 38.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4968 - binary_accuracy: 0.7493 - val_loss: 0.4216 - val_binary_accuracy: 0.7956\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4302 - binary_accuracy: 0.7919 - val_loss: 0.4164 - val_binary_accuracy: 0.7987\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4226 - binary_accuracy: 0.7985 - val_loss: 0.4148 - val_binary_accuracy: 0.7992\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4213 - binary_accuracy: 0.7985 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4183 - binary_accuracy: 0.7998 - val_loss: 0.4117 - val_binary_accuracy: 0.8012\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4156 - binary_accuracy: 0.8023 - val_loss: 0.4111 - val_binary_accuracy: 0.8014\n","Epoch 7/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4144 - binary_accuracy: 0.8015 - val_loss: 0.4111 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4155 - binary_accuracy: 0.8024 - val_loss: 0.4096 - val_binary_accuracy: 0.8025\n","Epoch 9/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4128 - binary_accuracy: 0.8031 - val_loss: 0.4093 - val_binary_accuracy: 0.8027\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4098 - binary_accuracy: 0.8056 - val_loss: 0.4090 - val_binary_accuracy: 0.8024\n","Epoch 11/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4106 - binary_accuracy: 0.8069 - val_loss: 0.4087 - val_binary_accuracy: 0.8039\n","Epoch 12/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4100 - binary_accuracy: 0.8053 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 13/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4077 - binary_accuracy: 0.8053 - val_loss: 0.4082 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4082 - binary_accuracy: 0.8057 - val_loss: 0.4080 - val_binary_accuracy: 0.8041\n","Epoch 15/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4078 - binary_accuracy: 0.8071 - val_loss: 0.4085 - val_binary_accuracy: 0.8026\n","Epoch 16/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4096 - binary_accuracy: 0.8065 - val_loss: 0.4080 - val_binary_accuracy: 0.8033\n","Epoch 17/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4032 - binary_accuracy: 0.8104 - val_loss: 0.4079 - val_binary_accuracy: 0.8030\n","Epoch 18/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4082 - binary_accuracy: 0.8062 - val_loss: 0.4078 - val_binary_accuracy: 0.8035\n","Epoch 19/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4065 - binary_accuracy: 0.8074 - val_loss: 0.4074 - val_binary_accuracy: 0.8036\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|         | 3/84 [02:38<57:10, 42.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.4904 - binary_accuracy: 0.7519 - val_loss: 0.4212 - val_binary_accuracy: 0.7958\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4281 - binary_accuracy: 0.7943 - val_loss: 0.4163 - val_binary_accuracy: 0.7985\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4213 - binary_accuracy: 0.7984 - val_loss: 0.4147 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4191 - binary_accuracy: 0.7994 - val_loss: 0.4134 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4171 - binary_accuracy: 0.8003 - val_loss: 0.4115 - val_binary_accuracy: 0.8023\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4142 - binary_accuracy: 0.8032 - val_loss: 0.4110 - val_binary_accuracy: 0.8022\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4143 - binary_accuracy: 0.8011 - val_loss: 0.4110 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4141 - binary_accuracy: 0.8028 - val_loss: 0.4095 - val_binary_accuracy: 0.8022\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4112 - binary_accuracy: 0.8039 - val_loss: 0.4093 - val_binary_accuracy: 0.8025\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4081 - binary_accuracy: 0.8066 - val_loss: 0.4087 - val_binary_accuracy: 0.8027\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4089 - binary_accuracy: 0.8062 - val_loss: 0.4080 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4080 - binary_accuracy: 0.8059 - val_loss: 0.4081 - val_binary_accuracy: 0.8034\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4072 - binary_accuracy: 0.8066 - val_loss: 0.4076 - val_binary_accuracy: 0.8035\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4073 - binary_accuracy: 0.8066 - val_loss: 0.4075 - val_binary_accuracy: 0.8039\n","Epoch 15/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4066 - binary_accuracy: 0.8070 - val_loss: 0.4078 - val_binary_accuracy: 0.8037\n","Epoch 16/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4076 - binary_accuracy: 0.8067 - val_loss: 0.4074 - val_binary_accuracy: 0.8042\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4010 - binary_accuracy: 0.8112 - val_loss: 0.4074 - val_binary_accuracy: 0.8038\n","Epoch 18/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4069 - binary_accuracy: 0.8068 - val_loss: 0.4070 - val_binary_accuracy: 0.8037\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4051 - binary_accuracy: 0.8087 - val_loss: 0.4068 - val_binary_accuracy: 0.8040\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4020 - binary_accuracy: 0.8090 - val_loss: 0.4071 - val_binary_accuracy: 0.8045\n","Epoch 21/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4038 - binary_accuracy: 0.8099 - val_loss: 0.4058 - val_binary_accuracy: 0.8044\n","Epoch 22/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4022 - binary_accuracy: 0.8091 - val_loss: 0.4065 - val_binary_accuracy: 0.8049\n","Epoch 23/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4012 - binary_accuracy: 0.8107 - val_loss: 0.4067 - val_binary_accuracy: 0.8035\n","Epoch 24/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4019 - binary_accuracy: 0.8087 - val_loss: 0.4059 - val_binary_accuracy: 0.8045\n","Epoch 25/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4003 - binary_accuracy: 0.8103 - val_loss: 0.4061 - val_binary_accuracy: 0.8047\n","Epoch 26/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4036 - binary_accuracy: 0.8099 - val_loss: 0.4058 - val_binary_accuracy: 0.8039\n","Epoch 27/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4008 - binary_accuracy: 0.8104 - val_loss: 0.4058 - val_binary_accuracy: 0.8046\n"],"name":"stdout"},{"output_type":"stream","text":["\r  5%|         | 4/84 [03:57<1:11:31, 53.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 15ms/step - loss: 0.4936 - binary_accuracy: 0.7509 - val_loss: 0.4209 - val_binary_accuracy: 0.7972\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4301 - binary_accuracy: 0.7941 - val_loss: 0.4161 - val_binary_accuracy: 0.7984\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4231 - binary_accuracy: 0.7987 - val_loss: 0.4139 - val_binary_accuracy: 0.8005\n","Epoch 4/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4203 - binary_accuracy: 0.8010 - val_loss: 0.4131 - val_binary_accuracy: 0.8003\n","Epoch 5/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4106 - val_binary_accuracy: 0.8024\n","Epoch 6/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4143 - binary_accuracy: 0.8032 - val_loss: 0.4102 - val_binary_accuracy: 0.8027\n","Epoch 7/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4148 - binary_accuracy: 0.8024 - val_loss: 0.4111 - val_binary_accuracy: 0.8029\n","Epoch 8/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4143 - binary_accuracy: 0.8037 - val_loss: 0.4090 - val_binary_accuracy: 0.8031\n","Epoch 9/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4120 - binary_accuracy: 0.8043 - val_loss: 0.4094 - val_binary_accuracy: 0.8037\n","Epoch 10/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4100 - binary_accuracy: 0.8068 - val_loss: 0.4081 - val_binary_accuracy: 0.8044\n","Epoch 11/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4095 - binary_accuracy: 0.8064 - val_loss: 0.4073 - val_binary_accuracy: 0.8043\n","Epoch 12/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4088 - binary_accuracy: 0.8071 - val_loss: 0.4079 - val_binary_accuracy: 0.8046\n","Epoch 13/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4084 - binary_accuracy: 0.8061 - val_loss: 0.4096 - val_binary_accuracy: 0.8037\n","Epoch 14/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4079 - binary_accuracy: 0.8072 - val_loss: 0.4069 - val_binary_accuracy: 0.8046\n","Epoch 15/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4067 - binary_accuracy: 0.8080 - val_loss: 0.4093 - val_binary_accuracy: 0.8045\n","Epoch 16/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4081 - binary_accuracy: 0.8071 - val_loss: 0.4092 - val_binary_accuracy: 0.8052\n","Epoch 17/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4019 - binary_accuracy: 0.8120 - val_loss: 0.4071 - val_binary_accuracy: 0.8044\n","Epoch 18/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4078 - binary_accuracy: 0.8078 - val_loss: 0.4062 - val_binary_accuracy: 0.8053\n","Epoch 19/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4048 - binary_accuracy: 0.8095 - val_loss: 0.4068 - val_binary_accuracy: 0.8052\n","Epoch 20/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4030 - binary_accuracy: 0.8112 - val_loss: 0.4075 - val_binary_accuracy: 0.8037\n","Epoch 21/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4051 - binary_accuracy: 0.8096 - val_loss: 0.4055 - val_binary_accuracy: 0.8062\n","Epoch 22/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4026 - binary_accuracy: 0.8104 - val_loss: 0.4071 - val_binary_accuracy: 0.8056\n","Epoch 23/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4004 - binary_accuracy: 0.8120 - val_loss: 0.4107 - val_binary_accuracy: 0.8057\n","Epoch 24/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4022 - binary_accuracy: 0.8103 - val_loss: 0.4057 - val_binary_accuracy: 0.8056\n","Epoch 25/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4002 - binary_accuracy: 0.8108 - val_loss: 0.4088 - val_binary_accuracy: 0.8055\n","Epoch 26/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4026 - binary_accuracy: 0.8118 - val_loss: 0.4054 - val_binary_accuracy: 0.8055\n"],"name":"stdout"},{"output_type":"stream","text":["\r  6%|         | 5/84 [06:09<1:41:18, 76.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4722 - binary_accuracy: 0.7646 - val_loss: 0.4201 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4224 - binary_accuracy: 0.7952 - val_loss: 0.4138 - val_binary_accuracy: 0.8010\n","Epoch 3/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4165 - binary_accuracy: 0.8006 - val_loss: 0.4114 - val_binary_accuracy: 0.8021\n","Epoch 4/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4136 - binary_accuracy: 0.8015 - val_loss: 0.4101 - val_binary_accuracy: 0.8014\n","Epoch 5/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4117 - binary_accuracy: 0.8022 - val_loss: 0.4082 - val_binary_accuracy: 0.8034\n","Epoch 6/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4084 - binary_accuracy: 0.8063 - val_loss: 0.4077 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4079 - binary_accuracy: 0.8058 - val_loss: 0.4081 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4081 - binary_accuracy: 0.8056 - val_loss: 0.4065 - val_binary_accuracy: 0.8044\n","Epoch 9/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4049 - binary_accuracy: 0.8074 - val_loss: 0.4065 - val_binary_accuracy: 0.8040\n","Epoch 10/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4027 - binary_accuracy: 0.8097 - val_loss: 0.4064 - val_binary_accuracy: 0.8040\n","Epoch 11/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4032 - binary_accuracy: 0.8085 - val_loss: 0.4051 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4012 - binary_accuracy: 0.8095 - val_loss: 0.4060 - val_binary_accuracy: 0.8048\n","Epoch 13/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4009 - binary_accuracy: 0.8093 - val_loss: 0.4053 - val_binary_accuracy: 0.8048\n","Epoch 14/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.3996 - binary_accuracy: 0.8087 - val_loss: 0.4046 - val_binary_accuracy: 0.8042\n","Epoch 15/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3995 - binary_accuracy: 0.8116 - val_loss: 0.4059 - val_binary_accuracy: 0.8050\n","Epoch 16/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.4001 - binary_accuracy: 0.8099 - val_loss: 0.4070 - val_binary_accuracy: 0.8050\n","Epoch 17/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3938 - binary_accuracy: 0.8142 - val_loss: 0.4056 - val_binary_accuracy: 0.8046\n","Epoch 18/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3996 - binary_accuracy: 0.8108 - val_loss: 0.4048 - val_binary_accuracy: 0.8060\n","Epoch 19/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.3966 - binary_accuracy: 0.8113 - val_loss: 0.4051 - val_binary_accuracy: 0.8065\n","Epoch 20/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.3929 - binary_accuracy: 0.8151 - val_loss: 0.4059 - val_binary_accuracy: 0.8051\n","Epoch 21/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.3961 - binary_accuracy: 0.8128 - val_loss: 0.4043 - val_binary_accuracy: 0.8055\n","Epoch 22/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3926 - binary_accuracy: 0.8138 - val_loss: 0.4044 - val_binary_accuracy: 0.8062\n","Epoch 23/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3913 - binary_accuracy: 0.8152 - val_loss: 0.4055 - val_binary_accuracy: 0.8065\n","Epoch 24/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.3927 - binary_accuracy: 0.8139 - val_loss: 0.4040 - val_binary_accuracy: 0.8064\n"],"name":"stdout"},{"output_type":"stream","text":["\r  7%|         | 6/84 [09:42<2:33:02, 117.72s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 18s 52ms/step - loss: 0.4871 - binary_accuracy: 0.7570 - val_loss: 0.4236 - val_binary_accuracy: 0.7963\n","Epoch 2/100\n","338/338 [==============================] - 18s 52ms/step - loss: 0.4267 - binary_accuracy: 0.7939 - val_loss: 0.4148 - val_binary_accuracy: 0.7995\n","Epoch 3/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4196 - binary_accuracy: 0.7996 - val_loss: 0.4126 - val_binary_accuracy: 0.8003\n","Epoch 4/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4171 - binary_accuracy: 0.8009 - val_loss: 0.4112 - val_binary_accuracy: 0.8007\n","Epoch 5/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4146 - binary_accuracy: 0.8023 - val_loss: 0.4094 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4123 - binary_accuracy: 0.8041 - val_loss: 0.4090 - val_binary_accuracy: 0.8050\n","Epoch 7/100\n","338/338 [==============================] - 17s 52ms/step - loss: 0.4114 - binary_accuracy: 0.8039 - val_loss: 0.4101 - val_binary_accuracy: 0.8046\n","Epoch 8/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4108 - binary_accuracy: 0.8045 - val_loss: 0.4076 - val_binary_accuracy: 0.8040\n","Epoch 9/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4074 - binary_accuracy: 0.8066 - val_loss: 0.4085 - val_binary_accuracy: 0.8041\n","Epoch 10/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4048 - binary_accuracy: 0.8092 - val_loss: 0.4073 - val_binary_accuracy: 0.8046\n","Epoch 11/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4050 - binary_accuracy: 0.8096 - val_loss: 0.4069 - val_binary_accuracy: 0.8046\n"],"name":"stdout"},{"output_type":"stream","text":["\r  8%|         | 7/84 [12:50<2:58:16, 138.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 4ms/step - loss: 0.6692 - binary_accuracy: 0.6202 - val_loss: 0.5419 - val_binary_accuracy: 0.6826\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6760 - val_loss: 0.5017 - val_binary_accuracy: 0.7679\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5755 - binary_accuracy: 0.6888 - val_loss: 0.4855 - val_binary_accuracy: 0.7766\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5652 - binary_accuracy: 0.6933 - val_loss: 0.4727 - val_binary_accuracy: 0.7845\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5580 - binary_accuracy: 0.6993 - val_loss: 0.4711 - val_binary_accuracy: 0.7843\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5549 - binary_accuracy: 0.7060 - val_loss: 0.4706 - val_binary_accuracy: 0.7786\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5511 - binary_accuracy: 0.7141 - val_loss: 0.4692 - val_binary_accuracy: 0.7799\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5488 - binary_accuracy: 0.7163 - val_loss: 0.4630 - val_binary_accuracy: 0.7840\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5433 - binary_accuracy: 0.7223 - val_loss: 0.4608 - val_binary_accuracy: 0.7872\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5444 - binary_accuracy: 0.7226 - val_loss: 0.4608 - val_binary_accuracy: 0.7853\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5416 - binary_accuracy: 0.7250 - val_loss: 0.4531 - val_binary_accuracy: 0.7889\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5393 - binary_accuracy: 0.7279 - val_loss: 0.4577 - val_binary_accuracy: 0.7875\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5386 - binary_accuracy: 0.7288 - val_loss: 0.4518 - val_binary_accuracy: 0.7915\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5365 - binary_accuracy: 0.7303 - val_loss: 0.4491 - val_binary_accuracy: 0.7887\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5334 - binary_accuracy: 0.7342 - val_loss: 0.4541 - val_binary_accuracy: 0.7872\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5343 - binary_accuracy: 0.7308 - val_loss: 0.4476 - val_binary_accuracy: 0.7885\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5320 - binary_accuracy: 0.7344 - val_loss: 0.4414 - val_binary_accuracy: 0.7937\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5338 - binary_accuracy: 0.7328 - val_loss: 0.4432 - val_binary_accuracy: 0.7859\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5346 - binary_accuracy: 0.7315 - val_loss: 0.4439 - val_binary_accuracy: 0.7866\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5310 - binary_accuracy: 0.7344 - val_loss: 0.4438 - val_binary_accuracy: 0.7881\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5300 - binary_accuracy: 0.7329 - val_loss: 0.4468 - val_binary_accuracy: 0.7882\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5280 - binary_accuracy: 0.7353 - val_loss: 0.4479 - val_binary_accuracy: 0.7848\n"],"name":"stdout"},{"output_type":"stream","text":["\r 10%|         | 8/84 [13:20<2:14:33, 106.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4889 - binary_accuracy: 0.7535 - val_loss: 0.4216 - val_binary_accuracy: 0.7958\n","Epoch 2/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4276 - binary_accuracy: 0.7934 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 3/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4211 - binary_accuracy: 0.7990 - val_loss: 0.4141 - val_binary_accuracy: 0.7999\n","Epoch 4/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4184 - binary_accuracy: 0.7994 - val_loss: 0.4131 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4166 - binary_accuracy: 0.8007 - val_loss: 0.4109 - val_binary_accuracy: 0.8021\n","Epoch 6/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4137 - binary_accuracy: 0.8038 - val_loss: 0.4106 - val_binary_accuracy: 0.8019\n","Epoch 7/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4130 - binary_accuracy: 0.8012 - val_loss: 0.4110 - val_binary_accuracy: 0.8022\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4136 - binary_accuracy: 0.8028 - val_loss: 0.4092 - val_binary_accuracy: 0.8027\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4107 - binary_accuracy: 0.8037 - val_loss: 0.4089 - val_binary_accuracy: 0.8031\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4078 - binary_accuracy: 0.8072 - val_loss: 0.4084 - val_binary_accuracy: 0.8026\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4082 - binary_accuracy: 0.8068 - val_loss: 0.4079 - val_binary_accuracy: 0.8036\n","Epoch 12/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4073 - binary_accuracy: 0.8059 - val_loss: 0.4080 - val_binary_accuracy: 0.8029\n","Epoch 13/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4062 - binary_accuracy: 0.8061 - val_loss: 0.4073 - val_binary_accuracy: 0.8030\n","Epoch 14/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4058 - binary_accuracy: 0.8059 - val_loss: 0.4074 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4059 - binary_accuracy: 0.8081 - val_loss: 0.4079 - val_binary_accuracy: 0.8035\n","Epoch 16/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4071 - binary_accuracy: 0.8067 - val_loss: 0.4077 - val_binary_accuracy: 0.8036\n","Epoch 17/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4007 - binary_accuracy: 0.8102 - val_loss: 0.4070 - val_binary_accuracy: 0.8036\n","Epoch 18/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4065 - binary_accuracy: 0.8072 - val_loss: 0.4068 - val_binary_accuracy: 0.8042\n","Epoch 19/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4043 - binary_accuracy: 0.8085 - val_loss: 0.4066 - val_binary_accuracy: 0.8044\n","Epoch 20/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4017 - binary_accuracy: 0.8100 - val_loss: 0.4069 - val_binary_accuracy: 0.8042\n","Epoch 21/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4043 - binary_accuracy: 0.8097 - val_loss: 0.4057 - val_binary_accuracy: 0.8049\n","Epoch 22/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4016 - binary_accuracy: 0.8107 - val_loss: 0.4060 - val_binary_accuracy: 0.8041\n","Epoch 23/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4001 - binary_accuracy: 0.8112 - val_loss: 0.4070 - val_binary_accuracy: 0.8041\n","Epoch 24/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4020 - binary_accuracy: 0.8096 - val_loss: 0.4054 - val_binary_accuracy: 0.8046\n","Epoch 25/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.3991 - binary_accuracy: 0.8110 - val_loss: 0.4061 - val_binary_accuracy: 0.8047\n","Epoch 26/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4025 - binary_accuracy: 0.8101 - val_loss: 0.4058 - val_binary_accuracy: 0.8044\n"],"name":"stdout"},{"output_type":"stream","text":["\r 11%|         | 9/84 [14:46<2:05:20, 100.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5566 - binary_accuracy: 0.7045 - val_loss: 0.4297 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4469 - binary_accuracy: 0.7874 - val_loss: 0.4231 - val_binary_accuracy: 0.7955\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4389 - binary_accuracy: 0.7932 - val_loss: 0.4226 - val_binary_accuracy: 0.7961\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4358 - binary_accuracy: 0.7937 - val_loss: 0.4221 - val_binary_accuracy: 0.7961\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4327 - binary_accuracy: 0.7951 - val_loss: 0.4237 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4305 - binary_accuracy: 0.7965 - val_loss: 0.4325 - val_binary_accuracy: 0.7970\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4294 - binary_accuracy: 0.7951 - val_loss: 0.4348 - val_binary_accuracy: 0.7958\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4285 - binary_accuracy: 0.7973 - val_loss: 0.4450 - val_binary_accuracy: 0.7968\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7968 - val_loss: 0.4539 - val_binary_accuracy: 0.7970\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7987 - val_loss: 0.4688 - val_binary_accuracy: 0.7960\n"],"name":"stdout"},{"output_type":"stream","text":["\r 12%|        | 10/84 [14:59<1:31:16, 74.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5046 - binary_accuracy: 0.7431 - val_loss: 0.4250 - val_binary_accuracy: 0.7933\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4333 - binary_accuracy: 0.7912 - val_loss: 0.4183 - val_binary_accuracy: 0.7974\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4241 - binary_accuracy: 0.7974 - val_loss: 0.4167 - val_binary_accuracy: 0.7987\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4231 - binary_accuracy: 0.7988 - val_loss: 0.4145 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4213 - binary_accuracy: 0.7993 - val_loss: 0.4132 - val_binary_accuracy: 0.8005\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4185 - binary_accuracy: 0.8021 - val_loss: 0.4129 - val_binary_accuracy: 0.8014\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4179 - binary_accuracy: 0.8009 - val_loss: 0.4126 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4181 - binary_accuracy: 0.8015 - val_loss: 0.4119 - val_binary_accuracy: 0.8018\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8018 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4120 - binary_accuracy: 0.8044 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4122 - binary_accuracy: 0.8049 - val_loss: 0.4106 - val_binary_accuracy: 0.8023\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4118 - binary_accuracy: 0.8048 - val_loss: 0.4116 - val_binary_accuracy: 0.8014\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4107 - binary_accuracy: 0.8039 - val_loss: 0.4098 - val_binary_accuracy: 0.8019\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8042 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4102 - binary_accuracy: 0.8058 - val_loss: 0.4135 - val_binary_accuracy: 0.8024\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4117 - binary_accuracy: 0.8050 - val_loss: 0.4114 - val_binary_accuracy: 0.8030\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8092 - val_loss: 0.4124 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4115 - binary_accuracy: 0.8049 - val_loss: 0.4128 - val_binary_accuracy: 0.8031\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4091 - binary_accuracy: 0.8055 - val_loss: 0.4148 - val_binary_accuracy: 0.8037\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4160 - val_binary_accuracy: 0.8025\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4070 - binary_accuracy: 0.8076 - val_loss: 0.4169 - val_binary_accuracy: 0.8038\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4056 - binary_accuracy: 0.8073 - val_loss: 0.4210 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8085 - val_loss: 0.4244 - val_binary_accuracy: 0.8020\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4055 - binary_accuracy: 0.8067 - val_loss: 0.4259 - val_binary_accuracy: 0.8037\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4045 - binary_accuracy: 0.8082 - val_loss: 0.4258 - val_binary_accuracy: 0.8019\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4053 - binary_accuracy: 0.8082 - val_loss: 0.4286 - val_binary_accuracy: 0.8029\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4035 - binary_accuracy: 0.8086 - val_loss: 0.4338 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["\r 13%|        | 11/84 [15:55<1:23:18, 68.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 90s 263ms/step - loss: 0.5618 - binary_accuracy: 0.7450 - val_loss: 0.4315 - val_binary_accuracy: 0.7946\n","Epoch 2/100\n","338/338 [==============================] - 88s 261ms/step - loss: 0.4346 - binary_accuracy: 0.7921 - val_loss: 0.4480 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","338/338 [==============================] - 87s 258ms/step - loss: 0.4279 - binary_accuracy: 0.7989 - val_loss: 0.4204 - val_binary_accuracy: 0.8009\n","Epoch 4/100\n","338/338 [==============================] - 87s 258ms/step - loss: 0.4257 - binary_accuracy: 0.7992 - val_loss: 0.4255 - val_binary_accuracy: 0.8008\n","Epoch 5/100\n","338/338 [==============================] - 87s 257ms/step - loss: 0.4258 - binary_accuracy: 0.8007 - val_loss: 0.4235 - val_binary_accuracy: 0.8001\n","Epoch 6/100\n","338/338 [==============================] - 87s 258ms/step - loss: 0.4219 - binary_accuracy: 0.8040 - val_loss: 0.4503 - val_binary_accuracy: 0.8000\n","Epoch 7/100\n","338/338 [==============================] - 87s 258ms/step - loss: 0.4209 - binary_accuracy: 0.8026 - val_loss: 0.4221 - val_binary_accuracy: 0.8030\n","Epoch 8/100\n","338/338 [==============================] - 86s 256ms/step - loss: 0.4211 - binary_accuracy: 0.8024 - val_loss: 0.4541 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 86s 255ms/step - loss: 0.4174 - binary_accuracy: 0.8055 - val_loss: 0.4426 - val_binary_accuracy: 0.8039\n","Epoch 10/100\n","338/338 [==============================] - 86s 256ms/step - loss: 0.4144 - binary_accuracy: 0.8061 - val_loss: 0.4589 - val_binary_accuracy: 0.8025\n","Epoch 11/100\n","338/338 [==============================] - 86s 256ms/step - loss: 0.4184 - binary_accuracy: 0.8080 - val_loss: 0.4569 - val_binary_accuracy: 0.8036\n","Epoch 12/100\n","338/338 [==============================] - 86s 255ms/step - loss: 0.4210 - binary_accuracy: 0.8084 - val_loss: 0.4839 - val_binary_accuracy: 0.8042\n","Epoch 13/100\n","338/338 [==============================] - 86s 255ms/step - loss: 0.4145 - binary_accuracy: 0.8087 - val_loss: 0.4812 - val_binary_accuracy: 0.8038\n","Epoch 14/100\n","338/338 [==============================] - 85s 253ms/step - loss: 0.4155 - binary_accuracy: 0.8087 - val_loss: 0.4537 - val_binary_accuracy: 0.8034\n","Epoch 15/100\n","338/338 [==============================] - 86s 254ms/step - loss: 0.4122 - binary_accuracy: 0.8121 - val_loss: 0.4713 - val_binary_accuracy: 0.8026\n","Epoch 16/100\n","338/338 [==============================] - 85s 253ms/step - loss: 0.4111 - binary_accuracy: 0.8089 - val_loss: 0.4546 - val_binary_accuracy: 0.8018\n","Epoch 17/100\n","338/338 [==============================] - 86s 254ms/step - loss: 0.4082 - binary_accuracy: 0.8138 - val_loss: 0.4726 - val_binary_accuracy: 0.7986\n"],"name":"stdout"},{"output_type":"stream","text":["\r 14%|        | 12/84 [40:29<9:48:10, 490.14s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 12ms/step - loss: 0.5070 - binary_accuracy: 0.7435 - val_loss: 0.4236 - val_binary_accuracy: 0.7939\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4322 - binary_accuracy: 0.7919 - val_loss: 0.4167 - val_binary_accuracy: 0.7982\n","Epoch 3/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4258 - binary_accuracy: 0.7974 - val_loss: 0.4154 - val_binary_accuracy: 0.7992\n","Epoch 4/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4222 - binary_accuracy: 0.7993 - val_loss: 0.4141 - val_binary_accuracy: 0.7997\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4198 - binary_accuracy: 0.8003 - val_loss: 0.4117 - val_binary_accuracy: 0.8017\n","Epoch 6/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4172 - binary_accuracy: 0.8032 - val_loss: 0.4113 - val_binary_accuracy: 0.8016\n","Epoch 7/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4158 - binary_accuracy: 0.8006 - val_loss: 0.4111 - val_binary_accuracy: 0.8029\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4169 - binary_accuracy: 0.8025 - val_loss: 0.4096 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4138 - binary_accuracy: 0.8046 - val_loss: 0.4098 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4111 - binary_accuracy: 0.8064 - val_loss: 0.4089 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4119 - binary_accuracy: 0.8064 - val_loss: 0.4085 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4111 - binary_accuracy: 0.8053 - val_loss: 0.4090 - val_binary_accuracy: 0.8035\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4104 - binary_accuracy: 0.8052 - val_loss: 0.4085 - val_binary_accuracy: 0.8030\n","Epoch 14/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4085 - binary_accuracy: 0.8063 - val_loss: 0.4078 - val_binary_accuracy: 0.8039\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4080 - binary_accuracy: 0.8073 - val_loss: 0.4082 - val_binary_accuracy: 0.8038\n","Epoch 16/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4104 - binary_accuracy: 0.8061 - val_loss: 0.4104 - val_binary_accuracy: 0.8032\n","Epoch 17/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4048 - binary_accuracy: 0.8107 - val_loss: 0.4081 - val_binary_accuracy: 0.8034\n","Epoch 18/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4099 - binary_accuracy: 0.8059 - val_loss: 0.4065 - val_binary_accuracy: 0.8042\n","Epoch 19/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4075 - binary_accuracy: 0.8080 - val_loss: 0.4074 - val_binary_accuracy: 0.8044\n","Epoch 20/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4045 - binary_accuracy: 0.8092 - val_loss: 0.4074 - val_binary_accuracy: 0.8036\n","Epoch 21/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4065 - binary_accuracy: 0.8098 - val_loss: 0.4061 - val_binary_accuracy: 0.8052\n","Epoch 22/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4047 - binary_accuracy: 0.8092 - val_loss: 0.4079 - val_binary_accuracy: 0.8046\n","Epoch 23/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4035 - binary_accuracy: 0.8107 - val_loss: 0.4099 - val_binary_accuracy: 0.8046\n","Epoch 24/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4057 - binary_accuracy: 0.8091 - val_loss: 0.4059 - val_binary_accuracy: 0.8046\n","Epoch 25/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4030 - binary_accuracy: 0.8109 - val_loss: 0.4092 - val_binary_accuracy: 0.8039\n","Epoch 26/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4056 - binary_accuracy: 0.8103 - val_loss: 0.4062 - val_binary_accuracy: 0.8050\n"],"name":"stdout"},{"output_type":"stream","text":["\r 15%|        | 13/84 [42:12<7:22:48, 374.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5566 - binary_accuracy: 0.7045 - val_loss: 0.4297 - val_binary_accuracy: 0.7925\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4469 - binary_accuracy: 0.7874 - val_loss: 0.4231 - val_binary_accuracy: 0.7955\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4389 - binary_accuracy: 0.7932 - val_loss: 0.4226 - val_binary_accuracy: 0.7961\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7937 - val_loss: 0.4221 - val_binary_accuracy: 0.7961\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4327 - binary_accuracy: 0.7951 - val_loss: 0.4237 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4305 - binary_accuracy: 0.7965 - val_loss: 0.4325 - val_binary_accuracy: 0.7970\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4294 - binary_accuracy: 0.7951 - val_loss: 0.4348 - val_binary_accuracy: 0.7958\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4285 - binary_accuracy: 0.7973 - val_loss: 0.4450 - val_binary_accuracy: 0.7968\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7968 - val_loss: 0.4539 - val_binary_accuracy: 0.7970\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7987 - val_loss: 0.4688 - val_binary_accuracy: 0.7960\n"],"name":"stdout"},{"output_type":"stream","text":["\r 17%|        | 14/84 [42:25<5:09:55, 265.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5514 - binary_accuracy: 0.7126 - val_loss: 0.4263 - val_binary_accuracy: 0.7919\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4460 - binary_accuracy: 0.7875 - val_loss: 0.4195 - val_binary_accuracy: 0.7968\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4354 - binary_accuracy: 0.7951 - val_loss: 0.4175 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4331 - binary_accuracy: 0.7965 - val_loss: 0.4168 - val_binary_accuracy: 0.7984\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4305 - binary_accuracy: 0.7966 - val_loss: 0.4143 - val_binary_accuracy: 0.8004\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4289 - binary_accuracy: 0.7988 - val_loss: 0.4139 - val_binary_accuracy: 0.8006\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4290 - binary_accuracy: 0.7973 - val_loss: 0.4144 - val_binary_accuracy: 0.8013\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4272 - binary_accuracy: 0.7983 - val_loss: 0.4125 - val_binary_accuracy: 0.8015\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4259 - binary_accuracy: 0.7999 - val_loss: 0.4123 - val_binary_accuracy: 0.8023\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4234 - binary_accuracy: 0.8022 - val_loss: 0.4117 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4227 - binary_accuracy: 0.8032 - val_loss: 0.4110 - val_binary_accuracy: 0.8020\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4223 - binary_accuracy: 0.8034 - val_loss: 0.4113 - val_binary_accuracy: 0.8014\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4214 - binary_accuracy: 0.8022 - val_loss: 0.4104 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4200 - binary_accuracy: 0.8036 - val_loss: 0.4104 - val_binary_accuracy: 0.8027\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4206 - binary_accuracy: 0.8027 - val_loss: 0.4107 - val_binary_accuracy: 0.8024\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4204 - binary_accuracy: 0.8026 - val_loss: 0.4098 - val_binary_accuracy: 0.8029\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4152 - binary_accuracy: 0.8080 - val_loss: 0.4096 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4220 - binary_accuracy: 0.8025 - val_loss: 0.4097 - val_binary_accuracy: 0.8036\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4187 - binary_accuracy: 0.8050 - val_loss: 0.4093 - val_binary_accuracy: 0.8024\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4160 - binary_accuracy: 0.8068 - val_loss: 0.4092 - val_binary_accuracy: 0.8025\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4183 - binary_accuracy: 0.8045 - val_loss: 0.4085 - val_binary_accuracy: 0.8037\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8063 - val_loss: 0.4087 - val_binary_accuracy: 0.8033\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4159 - binary_accuracy: 0.8070 - val_loss: 0.4086 - val_binary_accuracy: 0.8022\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4157 - binary_accuracy: 0.8059 - val_loss: 0.4078 - val_binary_accuracy: 0.8040\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4154 - binary_accuracy: 0.8071 - val_loss: 0.4080 - val_binary_accuracy: 0.8035\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4163 - binary_accuracy: 0.8073 - val_loss: 0.4084 - val_binary_accuracy: 0.8044\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4153 - binary_accuracy: 0.8072 - val_loss: 0.4079 - val_binary_accuracy: 0.8040\n","Epoch 28/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4156 - binary_accuracy: 0.8066 - val_loss: 0.4080 - val_binary_accuracy: 0.8044\n","Epoch 29/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4167 - binary_accuracy: 0.8062 - val_loss: 0.4079 - val_binary_accuracy: 0.8035\n","Epoch 30/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4155 - binary_accuracy: 0.8062 - val_loss: 0.4079 - val_binary_accuracy: 0.8048\n","Epoch 31/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4163 - binary_accuracy: 0.8063 - val_loss: 0.4080 - val_binary_accuracy: 0.8036\n","Epoch 32/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4144 - binary_accuracy: 0.8080 - val_loss: 0.4081 - val_binary_accuracy: 0.8051\n","Epoch 33/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4127 - binary_accuracy: 0.8080 - val_loss: 0.4081 - val_binary_accuracy: 0.8045\n","Epoch 34/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4135 - binary_accuracy: 0.8075 - val_loss: 0.4081 - val_binary_accuracy: 0.8046\n","Epoch 35/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8078 - val_loss: 0.4074 - val_binary_accuracy: 0.8040\n","Epoch 36/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4149 - binary_accuracy: 0.8073 - val_loss: 0.4078 - val_binary_accuracy: 0.8044\n","Epoch 37/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4164 - binary_accuracy: 0.8065 - val_loss: 0.4073 - val_binary_accuracy: 0.8039\n"],"name":"stdout"},{"output_type":"stream","text":["\r 18%|        | 15/84 [43:37<3:58:54, 207.75s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5801 - binary_accuracy: 0.6871 - val_loss: 0.4406 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4613 - binary_accuracy: 0.7814 - val_loss: 0.4365 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4480 - binary_accuracy: 0.7890 - val_loss: 0.4544 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4410 - binary_accuracy: 0.7911 - val_loss: 0.4594 - val_binary_accuracy: 0.7950\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4358 - binary_accuracy: 0.7935 - val_loss: 0.4761 - val_binary_accuracy: 0.7963\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4322 - binary_accuracy: 0.7959 - val_loss: 0.5114 - val_binary_accuracy: 0.7967\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4312 - binary_accuracy: 0.7947 - val_loss: 0.5238 - val_binary_accuracy: 0.7948\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4305 - binary_accuracy: 0.7955 - val_loss: 0.5323 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4275 - binary_accuracy: 0.7958 - val_loss: 0.5425 - val_binary_accuracy: 0.7946\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4236 - binary_accuracy: 0.7994 - val_loss: 0.5545 - val_binary_accuracy: 0.7939\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4232 - binary_accuracy: 0.7989 - val_loss: 0.5645 - val_binary_accuracy: 0.7958\n"],"name":"stdout"},{"output_type":"stream","text":["\r 19%|        | 16/84 [43:53<2:50:13, 150.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.6516 - binary_accuracy: 0.6481 - val_loss: 0.5088 - val_binary_accuracy: 0.7684\n","Epoch 2/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5719 - binary_accuracy: 0.6922 - val_loss: 0.4833 - val_binary_accuracy: 0.7740\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5560 - binary_accuracy: 0.6989 - val_loss: 0.4664 - val_binary_accuracy: 0.7898\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5506 - binary_accuracy: 0.7035 - val_loss: 0.4593 - val_binary_accuracy: 0.7906\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5437 - binary_accuracy: 0.7100 - val_loss: 0.4574 - val_binary_accuracy: 0.7911\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5400 - binary_accuracy: 0.7127 - val_loss: 0.4584 - val_binary_accuracy: 0.7867\n","Epoch 7/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5363 - binary_accuracy: 0.7139 - val_loss: 0.4510 - val_binary_accuracy: 0.7891\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5341 - binary_accuracy: 0.7267 - val_loss: 0.4559 - val_binary_accuracy: 0.7903\n","Epoch 9/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5296 - binary_accuracy: 0.7329 - val_loss: 0.4489 - val_binary_accuracy: 0.7917\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5274 - binary_accuracy: 0.7386 - val_loss: 0.4516 - val_binary_accuracy: 0.7929\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5236 - binary_accuracy: 0.7414 - val_loss: 0.4451 - val_binary_accuracy: 0.7956\n","Epoch 12/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5209 - binary_accuracy: 0.7446 - val_loss: 0.4439 - val_binary_accuracy: 0.7929\n","Epoch 13/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5188 - binary_accuracy: 0.7440 - val_loss: 0.4365 - val_binary_accuracy: 0.7987\n","Epoch 14/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5197 - binary_accuracy: 0.7459 - val_loss: 0.4335 - val_binary_accuracy: 0.8005\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5164 - binary_accuracy: 0.7472 - val_loss: 0.4399 - val_binary_accuracy: 0.7935\n","Epoch 16/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5152 - binary_accuracy: 0.7474 - val_loss: 0.4348 - val_binary_accuracy: 0.7966\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5123 - binary_accuracy: 0.7500 - val_loss: 0.4283 - val_binary_accuracy: 0.8006\n","Epoch 18/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5151 - binary_accuracy: 0.7482 - val_loss: 0.4359 - val_binary_accuracy: 0.7938\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.5141 - binary_accuracy: 0.7473 - val_loss: 0.4265 - val_binary_accuracy: 0.7978\n","Epoch 20/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5113 - binary_accuracy: 0.7489 - val_loss: 0.4266 - val_binary_accuracy: 0.7988\n","Epoch 21/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5108 - binary_accuracy: 0.7503 - val_loss: 0.4298 - val_binary_accuracy: 0.7970\n","Epoch 22/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.5081 - binary_accuracy: 0.7520 - val_loss: 0.4370 - val_binary_accuracy: 0.7927\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|        | 17/84 [44:57<2:18:52, 124.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5506 - binary_accuracy: 0.7059 - val_loss: 0.4280 - val_binary_accuracy: 0.7920\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4409 - binary_accuracy: 0.7882 - val_loss: 0.4219 - val_binary_accuracy: 0.7956\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4330 - binary_accuracy: 0.7937 - val_loss: 0.4200 - val_binary_accuracy: 0.7971\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4319 - binary_accuracy: 0.7953 - val_loss: 0.4192 - val_binary_accuracy: 0.7972\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4285 - binary_accuracy: 0.7969 - val_loss: 0.4168 - val_binary_accuracy: 0.7989\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4274 - binary_accuracy: 0.7985 - val_loss: 0.4166 - val_binary_accuracy: 0.7985\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4279 - binary_accuracy: 0.7966 - val_loss: 0.4169 - val_binary_accuracy: 0.7988\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4272 - binary_accuracy: 0.7976 - val_loss: 0.4154 - val_binary_accuracy: 0.7996\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4254 - binary_accuracy: 0.7977 - val_loss: 0.4148 - val_binary_accuracy: 0.7998\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4233 - binary_accuracy: 0.7997 - val_loss: 0.4144 - val_binary_accuracy: 0.7998\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4233 - binary_accuracy: 0.8012 - val_loss: 0.4139 - val_binary_accuracy: 0.7997\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4235 - binary_accuracy: 0.8006 - val_loss: 0.4137 - val_binary_accuracy: 0.8009\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4226 - binary_accuracy: 0.8005 - val_loss: 0.4133 - val_binary_accuracy: 0.8014\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4220 - binary_accuracy: 0.7997 - val_loss: 0.4133 - val_binary_accuracy: 0.8014\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4226 - binary_accuracy: 0.8004 - val_loss: 0.4128 - val_binary_accuracy: 0.8009\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4217 - binary_accuracy: 0.8003 - val_loss: 0.4129 - val_binary_accuracy: 0.8012\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4167 - binary_accuracy: 0.8046 - val_loss: 0.4124 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4234 - binary_accuracy: 0.7999 - val_loss: 0.4127 - val_binary_accuracy: 0.8009\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4206 - binary_accuracy: 0.8009 - val_loss: 0.4123 - val_binary_accuracy: 0.8017\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4185 - binary_accuracy: 0.8035 - val_loss: 0.4119 - val_binary_accuracy: 0.8022\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4200 - binary_accuracy: 0.8022 - val_loss: 0.4112 - val_binary_accuracy: 0.8024\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4189 - binary_accuracy: 0.8030 - val_loss: 0.4114 - val_binary_accuracy: 0.8020\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4176 - binary_accuracy: 0.8043 - val_loss: 0.4112 - val_binary_accuracy: 0.8015\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4192 - binary_accuracy: 0.8018 - val_loss: 0.4105 - val_binary_accuracy: 0.8024\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4172 - binary_accuracy: 0.8028 - val_loss: 0.4107 - val_binary_accuracy: 0.8024\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4184 - binary_accuracy: 0.8047 - val_loss: 0.4105 - val_binary_accuracy: 0.8026\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4173 - binary_accuracy: 0.8041 - val_loss: 0.4104 - val_binary_accuracy: 0.8029\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4191 - binary_accuracy: 0.8036 - val_loss: 0.4104 - val_binary_accuracy: 0.8029\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4182 - binary_accuracy: 0.8037 - val_loss: 0.4101 - val_binary_accuracy: 0.8033\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4185 - binary_accuracy: 0.8028 - val_loss: 0.4102 - val_binary_accuracy: 0.8038\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4178 - binary_accuracy: 0.8039 - val_loss: 0.4102 - val_binary_accuracy: 0.8026\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4171 - binary_accuracy: 0.8054 - val_loss: 0.4099 - val_binary_accuracy: 0.8033\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4151 - binary_accuracy: 0.8060 - val_loss: 0.4102 - val_binary_accuracy: 0.8043\n","Epoch 34/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4171 - binary_accuracy: 0.8062 - val_loss: 0.4100 - val_binary_accuracy: 0.8039\n","Epoch 35/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4184 - binary_accuracy: 0.8036 - val_loss: 0.4094 - val_binary_accuracy: 0.8041\n","Epoch 36/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4180 - binary_accuracy: 0.8050 - val_loss: 0.4096 - val_binary_accuracy: 0.8034\n","Epoch 37/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4194 - binary_accuracy: 0.8033 - val_loss: 0.4095 - val_binary_accuracy: 0.8033\n","Epoch 38/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4176 - binary_accuracy: 0.8046 - val_loss: 0.4092 - val_binary_accuracy: 0.8034\n"],"name":"stdout"},{"output_type":"stream","text":["\r 21%|       | 18/84 [45:47<1:52:01, 101.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 15ms/step - loss: 0.5583 - binary_accuracy: 0.7101 - val_loss: 0.4316 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4481 - binary_accuracy: 0.7874 - val_loss: 0.4195 - val_binary_accuracy: 0.7978\n","Epoch 3/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4388 - binary_accuracy: 0.7951 - val_loss: 0.4190 - val_binary_accuracy: 0.7979\n","Epoch 4/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4328 - binary_accuracy: 0.7970 - val_loss: 0.4174 - val_binary_accuracy: 0.7983\n","Epoch 5/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4306 - binary_accuracy: 0.7971 - val_loss: 0.4144 - val_binary_accuracy: 0.8007\n","Epoch 6/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4284 - binary_accuracy: 0.7998 - val_loss: 0.4148 - val_binary_accuracy: 0.8011\n","Epoch 7/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4257 - binary_accuracy: 0.7987 - val_loss: 0.4129 - val_binary_accuracy: 0.8017\n","Epoch 8/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4272 - binary_accuracy: 0.8000 - val_loss: 0.4130 - val_binary_accuracy: 0.8030\n","Epoch 9/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4236 - binary_accuracy: 0.8011 - val_loss: 0.4117 - val_binary_accuracy: 0.8013\n","Epoch 10/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4216 - binary_accuracy: 0.8044 - val_loss: 0.4114 - val_binary_accuracy: 0.8027\n","Epoch 11/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4215 - binary_accuracy: 0.8035 - val_loss: 0.4107 - val_binary_accuracy: 0.8023\n","Epoch 12/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4198 - binary_accuracy: 0.8030 - val_loss: 0.4114 - val_binary_accuracy: 0.8021\n","Epoch 13/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4184 - binary_accuracy: 0.8043 - val_loss: 0.4121 - val_binary_accuracy: 0.8015\n"],"name":"stdout"},{"output_type":"stream","text":["\r 23%|       | 19/84 [46:51<1:37:58, 90.44s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5046 - binary_accuracy: 0.7431 - val_loss: 0.4250 - val_binary_accuracy: 0.7933\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4333 - binary_accuracy: 0.7912 - val_loss: 0.4183 - val_binary_accuracy: 0.7974\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4241 - binary_accuracy: 0.7974 - val_loss: 0.4167 - val_binary_accuracy: 0.7987\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4231 - binary_accuracy: 0.7988 - val_loss: 0.4145 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4213 - binary_accuracy: 0.7993 - val_loss: 0.4132 - val_binary_accuracy: 0.8005\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4185 - binary_accuracy: 0.8021 - val_loss: 0.4129 - val_binary_accuracy: 0.8014\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4179 - binary_accuracy: 0.8009 - val_loss: 0.4126 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4181 - binary_accuracy: 0.8015 - val_loss: 0.4119 - val_binary_accuracy: 0.8018\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8018 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4120 - binary_accuracy: 0.8044 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4122 - binary_accuracy: 0.8049 - val_loss: 0.4106 - val_binary_accuracy: 0.8023\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4118 - binary_accuracy: 0.8048 - val_loss: 0.4116 - val_binary_accuracy: 0.8014\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4107 - binary_accuracy: 0.8039 - val_loss: 0.4098 - val_binary_accuracy: 0.8019\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8042 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4102 - binary_accuracy: 0.8058 - val_loss: 0.4135 - val_binary_accuracy: 0.8024\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4117 - binary_accuracy: 0.8050 - val_loss: 0.4114 - val_binary_accuracy: 0.8030\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8092 - val_loss: 0.4124 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4115 - binary_accuracy: 0.8049 - val_loss: 0.4128 - val_binary_accuracy: 0.8031\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4091 - binary_accuracy: 0.8055 - val_loss: 0.4148 - val_binary_accuracy: 0.8037\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4160 - val_binary_accuracy: 0.8025\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4070 - binary_accuracy: 0.8076 - val_loss: 0.4169 - val_binary_accuracy: 0.8038\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4056 - binary_accuracy: 0.8073 - val_loss: 0.4210 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8085 - val_loss: 0.4244 - val_binary_accuracy: 0.8020\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4055 - binary_accuracy: 0.8067 - val_loss: 0.4259 - val_binary_accuracy: 0.8037\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4045 - binary_accuracy: 0.8082 - val_loss: 0.4258 - val_binary_accuracy: 0.8019\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4053 - binary_accuracy: 0.8082 - val_loss: 0.4286 - val_binary_accuracy: 0.8029\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4035 - binary_accuracy: 0.8086 - val_loss: 0.4338 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["\r 24%|       | 20/84 [47:45<1:24:59, 79.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 7ms/step - loss: 0.6653 - binary_accuracy: 0.6296 - val_loss: 0.4593 - val_binary_accuracy: 0.7885\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.5228 - binary_accuracy: 0.7402 - val_loss: 0.4376 - val_binary_accuracy: 0.7935\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4987 - binary_accuracy: 0.7563 - val_loss: 0.4319 - val_binary_accuracy: 0.7965\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4902 - binary_accuracy: 0.7615 - val_loss: 0.4270 - val_binary_accuracy: 0.7947\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4824 - binary_accuracy: 0.7665 - val_loss: 0.4247 - val_binary_accuracy: 0.7964\n","Epoch 6/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4780 - binary_accuracy: 0.7695 - val_loss: 0.4223 - val_binary_accuracy: 0.7995\n","Epoch 7/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4745 - binary_accuracy: 0.7704 - val_loss: 0.4223 - val_binary_accuracy: 0.7962\n","Epoch 8/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4707 - binary_accuracy: 0.7726 - val_loss: 0.4203 - val_binary_accuracy: 0.7995\n","Epoch 9/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4694 - binary_accuracy: 0.7734 - val_loss: 0.4171 - val_binary_accuracy: 0.8000\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4642 - binary_accuracy: 0.7772 - val_loss: 0.4180 - val_binary_accuracy: 0.8003\n","Epoch 11/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4646 - binary_accuracy: 0.7767 - val_loss: 0.4181 - val_binary_accuracy: 0.8007\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4625 - binary_accuracy: 0.7790 - val_loss: 0.4187 - val_binary_accuracy: 0.8006\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4586 - binary_accuracy: 0.7817 - val_loss: 0.4159 - val_binary_accuracy: 0.8008\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4590 - binary_accuracy: 0.7800 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4564 - binary_accuracy: 0.7824 - val_loss: 0.4151 - val_binary_accuracy: 0.8020\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4571 - binary_accuracy: 0.7818 - val_loss: 0.4138 - val_binary_accuracy: 0.8021\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4493 - binary_accuracy: 0.7874 - val_loss: 0.4143 - val_binary_accuracy: 0.8020\n","Epoch 18/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4553 - binary_accuracy: 0.7841 - val_loss: 0.4177 - val_binary_accuracy: 0.8002\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4528 - binary_accuracy: 0.7868 - val_loss: 0.4137 - val_binary_accuracy: 0.8029\n","Epoch 20/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4493 - binary_accuracy: 0.7865 - val_loss: 0.4126 - val_binary_accuracy: 0.8022\n","Epoch 21/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4497 - binary_accuracy: 0.7873 - val_loss: 0.4147 - val_binary_accuracy: 0.8004\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4483 - binary_accuracy: 0.7875 - val_loss: 0.4146 - val_binary_accuracy: 0.8009\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4485 - binary_accuracy: 0.7892 - val_loss: 0.4146 - val_binary_accuracy: 0.8027\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4484 - binary_accuracy: 0.7888 - val_loss: 0.4111 - val_binary_accuracy: 0.8035\n","Epoch 25/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4433 - binary_accuracy: 0.7923 - val_loss: 0.4110 - val_binary_accuracy: 0.8031\n","Epoch 26/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4482 - binary_accuracy: 0.7910 - val_loss: 0.4132 - val_binary_accuracy: 0.8029\n","Epoch 27/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4467 - binary_accuracy: 0.7917 - val_loss: 0.4119 - val_binary_accuracy: 0.8026\n","Epoch 28/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4476 - binary_accuracy: 0.7914 - val_loss: 0.4122 - val_binary_accuracy: 0.8030\n","Epoch 29/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4445 - binary_accuracy: 0.7906 - val_loss: 0.4108 - val_binary_accuracy: 0.8029\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|       | 21/84 [48:52<1:19:38, 75.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 11ms/step - loss: 0.6462 - binary_accuracy: 0.6387 - val_loss: 0.4910 - val_binary_accuracy: 0.7804\n","Epoch 2/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5663 - binary_accuracy: 0.6969 - val_loss: 0.4726 - val_binary_accuracy: 0.7819\n","Epoch 3/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5524 - binary_accuracy: 0.7062 - val_loss: 0.4663 - val_binary_accuracy: 0.7875\n","Epoch 4/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.5467 - binary_accuracy: 0.7086 - val_loss: 0.4570 - val_binary_accuracy: 0.7878\n","Epoch 5/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.5379 - binary_accuracy: 0.7149 - val_loss: 0.4544 - val_binary_accuracy: 0.7955\n","Epoch 6/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5346 - binary_accuracy: 0.7172 - val_loss: 0.4506 - val_binary_accuracy: 0.7921\n","Epoch 7/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5313 - binary_accuracy: 0.7177 - val_loss: 0.4488 - val_binary_accuracy: 0.7924\n","Epoch 8/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5291 - binary_accuracy: 0.7197 - val_loss: 0.4535 - val_binary_accuracy: 0.7929\n","Epoch 9/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5229 - binary_accuracy: 0.7332 - val_loss: 0.4492 - val_binary_accuracy: 0.7947\n","Epoch 10/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.5203 - binary_accuracy: 0.7421 - val_loss: 0.4458 - val_binary_accuracy: 0.7924\n"],"name":"stdout"},{"output_type":"stream","text":["\r 26%|       | 22/84 [49:28<1:06:02, 63.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.5184 - binary_accuracy: 0.7336 - val_loss: 0.4236 - val_binary_accuracy: 0.7947\n","Epoch 2/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4403 - binary_accuracy: 0.7895 - val_loss: 0.4172 - val_binary_accuracy: 0.7983\n","Epoch 3/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4321 - binary_accuracy: 0.7970 - val_loss: 0.4155 - val_binary_accuracy: 0.8001\n","Epoch 4/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4289 - binary_accuracy: 0.7986 - val_loss: 0.4146 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4268 - binary_accuracy: 0.7990 - val_loss: 0.4117 - val_binary_accuracy: 0.8012\n","Epoch 6/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4248 - binary_accuracy: 0.8020 - val_loss: 0.4117 - val_binary_accuracy: 0.8030\n","Epoch 7/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4247 - binary_accuracy: 0.7999 - val_loss: 0.4124 - val_binary_accuracy: 0.8027\n","Epoch 8/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4237 - binary_accuracy: 0.8019 - val_loss: 0.4102 - val_binary_accuracy: 0.8030\n","Epoch 9/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4209 - binary_accuracy: 0.8030 - val_loss: 0.4106 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4183 - binary_accuracy: 0.8050 - val_loss: 0.4102 - val_binary_accuracy: 0.8037\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4185 - binary_accuracy: 0.8056 - val_loss: 0.4088 - val_binary_accuracy: 0.8031\n","Epoch 12/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4173 - binary_accuracy: 0.8041 - val_loss: 0.4096 - val_binary_accuracy: 0.8040\n","Epoch 13/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4174 - binary_accuracy: 0.8051 - val_loss: 0.4086 - val_binary_accuracy: 0.8027\n","Epoch 14/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4173 - binary_accuracy: 0.8048 - val_loss: 0.4082 - val_binary_accuracy: 0.8032\n","Epoch 15/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4170 - binary_accuracy: 0.8061 - val_loss: 0.4085 - val_binary_accuracy: 0.8036\n","Epoch 16/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4176 - binary_accuracy: 0.8049 - val_loss: 0.4077 - val_binary_accuracy: 0.8040\n","Epoch 17/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4106 - binary_accuracy: 0.8097 - val_loss: 0.4081 - val_binary_accuracy: 0.8044\n","Epoch 18/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4175 - binary_accuracy: 0.8056 - val_loss: 0.4077 - val_binary_accuracy: 0.8044\n","Epoch 19/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4148 - binary_accuracy: 0.8077 - val_loss: 0.4073 - val_binary_accuracy: 0.8046\n","Epoch 20/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4130 - binary_accuracy: 0.8086 - val_loss: 0.4079 - val_binary_accuracy: 0.8040\n","Epoch 21/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4143 - binary_accuracy: 0.8077 - val_loss: 0.4067 - val_binary_accuracy: 0.8042\n","Epoch 22/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4126 - binary_accuracy: 0.8085 - val_loss: 0.4068 - val_binary_accuracy: 0.8045\n","Epoch 23/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4104 - binary_accuracy: 0.8104 - val_loss: 0.4073 - val_binary_accuracy: 0.8049\n","Epoch 24/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4116 - binary_accuracy: 0.8090 - val_loss: 0.4063 - val_binary_accuracy: 0.8046\n","Epoch 25/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4095 - binary_accuracy: 0.8101 - val_loss: 0.4068 - val_binary_accuracy: 0.8049\n","Epoch 26/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4127 - binary_accuracy: 0.8097 - val_loss: 0.4066 - val_binary_accuracy: 0.8046\n","Epoch 27/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4090 - binary_accuracy: 0.8109 - val_loss: 0.4069 - val_binary_accuracy: 0.8045\n","Epoch 28/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4105 - binary_accuracy: 0.8101 - val_loss: 0.4068 - val_binary_accuracy: 0.8052\n","Epoch 29/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4100 - binary_accuracy: 0.8087 - val_loss: 0.4068 - val_binary_accuracy: 0.8054\n","Epoch 30/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4096 - binary_accuracy: 0.8094 - val_loss: 0.4064 - val_binary_accuracy: 0.8050\n","Epoch 31/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4103 - binary_accuracy: 0.8101 - val_loss: 0.4067 - val_binary_accuracy: 0.8057\n","Epoch 32/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4080 - binary_accuracy: 0.8109 - val_loss: 0.4062 - val_binary_accuracy: 0.8051\n","Epoch 33/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4071 - binary_accuracy: 0.8130 - val_loss: 0.4066 - val_binary_accuracy: 0.8053\n","Epoch 34/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4089 - binary_accuracy: 0.8122 - val_loss: 0.4075 - val_binary_accuracy: 0.8042\n","Epoch 35/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4085 - binary_accuracy: 0.8110 - val_loss: 0.4061 - val_binary_accuracy: 0.8063\n","Epoch 36/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4080 - binary_accuracy: 0.8107 - val_loss: 0.4066 - val_binary_accuracy: 0.8051\n","Epoch 37/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4093 - binary_accuracy: 0.8106 - val_loss: 0.4072 - val_binary_accuracy: 0.8050\n","Epoch 38/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4092 - binary_accuracy: 0.8107 - val_loss: 0.4060 - val_binary_accuracy: 0.8060\n","Epoch 39/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4069 - binary_accuracy: 0.8127 - val_loss: 0.4056 - val_binary_accuracy: 0.8059\n","Epoch 40/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4039 - binary_accuracy: 0.8153 - val_loss: 0.4067 - val_binary_accuracy: 0.8053\n"],"name":"stdout"},{"output_type":"stream","text":["\r 27%|       | 23/84 [51:41<1:26:09, 84.75s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 29%|       | 24/84 [52:18<1:10:25, 70.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5456 - binary_accuracy: 0.7094 - val_loss: 0.4271 - val_binary_accuracy: 0.7921\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4387 - binary_accuracy: 0.7875 - val_loss: 0.4210 - val_binary_accuracy: 0.7960\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4313 - binary_accuracy: 0.7946 - val_loss: 0.4197 - val_binary_accuracy: 0.7965\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4287 - binary_accuracy: 0.7956 - val_loss: 0.4191 - val_binary_accuracy: 0.7965\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4268 - binary_accuracy: 0.7969 - val_loss: 0.4172 - val_binary_accuracy: 0.7984\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4253 - binary_accuracy: 0.7981 - val_loss: 0.4165 - val_binary_accuracy: 0.7990\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4258 - binary_accuracy: 0.7963 - val_loss: 0.4169 - val_binary_accuracy: 0.7992\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4255 - binary_accuracy: 0.7982 - val_loss: 0.4150 - val_binary_accuracy: 0.8009\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4237 - binary_accuracy: 0.7993 - val_loss: 0.4150 - val_binary_accuracy: 0.7990\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4208 - binary_accuracy: 0.8002 - val_loss: 0.4143 - val_binary_accuracy: 0.8002\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4210 - binary_accuracy: 0.8009 - val_loss: 0.4139 - val_binary_accuracy: 0.8004\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4214 - binary_accuracy: 0.8016 - val_loss: 0.4138 - val_binary_accuracy: 0.7998\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4211 - binary_accuracy: 0.8004 - val_loss: 0.4132 - val_binary_accuracy: 0.8012\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4205 - binary_accuracy: 0.8001 - val_loss: 0.4130 - val_binary_accuracy: 0.8014\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4207 - binary_accuracy: 0.7997 - val_loss: 0.4130 - val_binary_accuracy: 0.8010\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4204 - binary_accuracy: 0.8006 - val_loss: 0.4125 - val_binary_accuracy: 0.8009\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4152 - binary_accuracy: 0.8045 - val_loss: 0.4122 - val_binary_accuracy: 0.8011\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4220 - binary_accuracy: 0.8006 - val_loss: 0.4127 - val_binary_accuracy: 0.8020\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4200 - binary_accuracy: 0.8022 - val_loss: 0.4118 - val_binary_accuracy: 0.8022\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4180 - binary_accuracy: 0.8034 - val_loss: 0.4118 - val_binary_accuracy: 0.8016\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4195 - binary_accuracy: 0.8021 - val_loss: 0.4110 - val_binary_accuracy: 0.8034\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4177 - binary_accuracy: 0.8029 - val_loss: 0.4112 - val_binary_accuracy: 0.8036\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4152 - binary_accuracy: 0.8043 - val_loss: 0.4112 - val_binary_accuracy: 0.8020\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4178 - binary_accuracy: 0.8025 - val_loss: 0.4103 - val_binary_accuracy: 0.8038\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4145 - binary_accuracy: 0.8042 - val_loss: 0.4106 - val_binary_accuracy: 0.8025\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4175 - binary_accuracy: 0.8042 - val_loss: 0.4107 - val_binary_accuracy: 0.8037\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4160 - binary_accuracy: 0.8049 - val_loss: 0.4102 - val_binary_accuracy: 0.8036\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4172 - binary_accuracy: 0.8039 - val_loss: 0.4100 - val_binary_accuracy: 0.8042\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4171 - binary_accuracy: 0.8043 - val_loss: 0.4097 - val_binary_accuracy: 0.8035\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4176 - binary_accuracy: 0.8027 - val_loss: 0.4101 - val_binary_accuracy: 0.8041\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4163 - binary_accuracy: 0.8050 - val_loss: 0.4098 - val_binary_accuracy: 0.8030\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4148 - binary_accuracy: 0.8054 - val_loss: 0.4096 - val_binary_accuracy: 0.8046\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4135 - binary_accuracy: 0.8063 - val_loss: 0.4098 - val_binary_accuracy: 0.8041\n","Epoch 34/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4159 - binary_accuracy: 0.8054 - val_loss: 0.4098 - val_binary_accuracy: 0.8043\n","Epoch 35/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4158 - binary_accuracy: 0.8052 - val_loss: 0.4092 - val_binary_accuracy: 0.8037\n","Epoch 36/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4167 - binary_accuracy: 0.8040 - val_loss: 0.4094 - val_binary_accuracy: 0.8047\n","Epoch 37/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4177 - binary_accuracy: 0.8040 - val_loss: 0.4093 - val_binary_accuracy: 0.8046\n","Epoch 38/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4168 - binary_accuracy: 0.8038 - val_loss: 0.4091 - val_binary_accuracy: 0.8039\n","Epoch 39/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4152 - binary_accuracy: 0.8043 - val_loss: 0.4093 - val_binary_accuracy: 0.8045\n","Epoch 40/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4113 - binary_accuracy: 0.8086 - val_loss: 0.4093 - val_binary_accuracy: 0.8030\n","Epoch 41/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4155 - binary_accuracy: 0.8057 - val_loss: 0.4091 - val_binary_accuracy: 0.8043\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|       | 25/84 [53:12<1:04:22, 65.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 21ms/step - loss: 0.5283 - binary_accuracy: 0.7554 - val_loss: 0.4192 - val_binary_accuracy: 0.7976\n","Epoch 2/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4178 - binary_accuracy: 0.7989 - val_loss: 0.4144 - val_binary_accuracy: 0.8004\n","Epoch 3/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4130 - binary_accuracy: 0.8035 - val_loss: 0.4119 - val_binary_accuracy: 0.8015\n","Epoch 4/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4114 - binary_accuracy: 0.8033 - val_loss: 0.4116 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4103 - binary_accuracy: 0.8050 - val_loss: 0.4091 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4089 - val_binary_accuracy: 0.8036\n","Epoch 7/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4071 - binary_accuracy: 0.8050 - val_loss: 0.4096 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4078 - binary_accuracy: 0.8056 - val_loss: 0.4082 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4048 - binary_accuracy: 0.8074 - val_loss: 0.4081 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4018 - binary_accuracy: 0.8091 - val_loss: 0.4076 - val_binary_accuracy: 0.8033\n","Epoch 11/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4018 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4010 - binary_accuracy: 0.8080 - val_loss: 0.4072 - val_binary_accuracy: 0.8031\n","Epoch 13/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4009 - binary_accuracy: 0.8082 - val_loss: 0.4076 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3995 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8041\n","Epoch 15/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3992 - binary_accuracy: 0.8107 - val_loss: 0.4078 - val_binary_accuracy: 0.8032\n","Epoch 16/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4001 - binary_accuracy: 0.8102 - val_loss: 0.4081 - val_binary_accuracy: 0.8044\n","Epoch 17/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3939 - binary_accuracy: 0.8143 - val_loss: 0.4070 - val_binary_accuracy: 0.8037\n","Epoch 18/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4000 - binary_accuracy: 0.8092 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 19/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3974 - binary_accuracy: 0.8134 - val_loss: 0.4064 - val_binary_accuracy: 0.8039\n","Epoch 20/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3942 - binary_accuracy: 0.8134 - val_loss: 0.4088 - val_binary_accuracy: 0.8033\n","Epoch 21/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3969 - binary_accuracy: 0.8129 - val_loss: 0.4057 - val_binary_accuracy: 0.8049\n","Epoch 22/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3937 - binary_accuracy: 0.8127 - val_loss: 0.4063 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3927 - binary_accuracy: 0.8153 - val_loss: 0.4063 - val_binary_accuracy: 0.8044\n","Epoch 24/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3930 - binary_accuracy: 0.8136 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 25/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3909 - binary_accuracy: 0.8152 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 26/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3940 - binary_accuracy: 0.8131 - val_loss: 0.4058 - val_binary_accuracy: 0.8047\n"],"name":"stdout"},{"output_type":"stream","text":["\r 31%|       | 26/84 [56:17<1:37:44, 101.12s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 21ms/step - loss: 0.5283 - binary_accuracy: 0.7554 - val_loss: 0.4192 - val_binary_accuracy: 0.7976\n","Epoch 2/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4178 - binary_accuracy: 0.7989 - val_loss: 0.4144 - val_binary_accuracy: 0.8004\n","Epoch 3/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4130 - binary_accuracy: 0.8035 - val_loss: 0.4119 - val_binary_accuracy: 0.8015\n","Epoch 4/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4114 - binary_accuracy: 0.8033 - val_loss: 0.4116 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4103 - binary_accuracy: 0.8050 - val_loss: 0.4091 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4089 - val_binary_accuracy: 0.8036\n","Epoch 7/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4071 - binary_accuracy: 0.8050 - val_loss: 0.4096 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4078 - binary_accuracy: 0.8056 - val_loss: 0.4082 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4048 - binary_accuracy: 0.8074 - val_loss: 0.4081 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4018 - binary_accuracy: 0.8091 - val_loss: 0.4076 - val_binary_accuracy: 0.8033\n","Epoch 11/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4018 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4010 - binary_accuracy: 0.8080 - val_loss: 0.4072 - val_binary_accuracy: 0.8031\n","Epoch 13/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4009 - binary_accuracy: 0.8082 - val_loss: 0.4076 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3995 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8041\n","Epoch 15/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3992 - binary_accuracy: 0.8107 - val_loss: 0.4078 - val_binary_accuracy: 0.8032\n","Epoch 16/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4001 - binary_accuracy: 0.8102 - val_loss: 0.4081 - val_binary_accuracy: 0.8044\n","Epoch 17/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3939 - binary_accuracy: 0.8143 - val_loss: 0.4070 - val_binary_accuracy: 0.8037\n","Epoch 18/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4000 - binary_accuracy: 0.8092 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 19/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3974 - binary_accuracy: 0.8134 - val_loss: 0.4064 - val_binary_accuracy: 0.8039\n","Epoch 20/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3942 - binary_accuracy: 0.8134 - val_loss: 0.4088 - val_binary_accuracy: 0.8033\n","Epoch 21/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3969 - binary_accuracy: 0.8129 - val_loss: 0.4057 - val_binary_accuracy: 0.8049\n","Epoch 22/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.3937 - binary_accuracy: 0.8127 - val_loss: 0.4063 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3927 - binary_accuracy: 0.8153 - val_loss: 0.4063 - val_binary_accuracy: 0.8044\n","Epoch 24/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3930 - binary_accuracy: 0.8136 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 25/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3909 - binary_accuracy: 0.8152 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 26/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.3940 - binary_accuracy: 0.8131 - val_loss: 0.4058 - val_binary_accuracy: 0.8047\n"],"name":"stdout"},{"output_type":"stream","text":["\r 32%|      | 27/84 [59:19<1:59:21, 125.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 87s 254ms/step - loss: 0.5618 - binary_accuracy: 0.7450 - val_loss: 0.4315 - val_binary_accuracy: 0.7946\n","Epoch 2/100\n","338/338 [==============================] - 85s 252ms/step - loss: 0.4346 - binary_accuracy: 0.7921 - val_loss: 0.4480 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","338/338 [==============================] - 86s 253ms/step - loss: 0.4279 - binary_accuracy: 0.7989 - val_loss: 0.4204 - val_binary_accuracy: 0.8009\n","Epoch 4/100\n","338/338 [==============================] - 86s 253ms/step - loss: 0.4257 - binary_accuracy: 0.7992 - val_loss: 0.4255 - val_binary_accuracy: 0.8008\n","Epoch 5/100\n","338/338 [==============================] - 86s 255ms/step - loss: 0.4258 - binary_accuracy: 0.8007 - val_loss: 0.4235 - val_binary_accuracy: 0.8001\n","Epoch 6/100\n","338/338 [==============================] - 86s 254ms/step - loss: 0.4219 - binary_accuracy: 0.8040 - val_loss: 0.4503 - val_binary_accuracy: 0.8000\n","Epoch 7/100\n","338/338 [==============================] - 87s 256ms/step - loss: 0.4209 - binary_accuracy: 0.8026 - val_loss: 0.4221 - val_binary_accuracy: 0.8030\n","Epoch 8/100\n","338/338 [==============================] - 87s 259ms/step - loss: 0.4211 - binary_accuracy: 0.8024 - val_loss: 0.4541 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 86s 255ms/step - loss: 0.4174 - binary_accuracy: 0.8055 - val_loss: 0.4426 - val_binary_accuracy: 0.8039\n","Epoch 10/100\n","338/338 [==============================] - 86s 254ms/step - loss: 0.4144 - binary_accuracy: 0.8061 - val_loss: 0.4589 - val_binary_accuracy: 0.8025\n","Epoch 11/100\n","338/338 [==============================] - 94s 277ms/step - loss: 0.4184 - binary_accuracy: 0.8080 - val_loss: 0.4569 - val_binary_accuracy: 0.8036\n","Epoch 12/100\n","338/338 [==============================] - 94s 278ms/step - loss: 0.4210 - binary_accuracy: 0.8084 - val_loss: 0.4839 - val_binary_accuracy: 0.8042\n","Epoch 13/100\n","338/338 [==============================] - 103s 304ms/step - loss: 0.4145 - binary_accuracy: 0.8087 - val_loss: 0.4812 - val_binary_accuracy: 0.8038\n","Epoch 14/100\n","338/338 [==============================] - 97s 288ms/step - loss: 0.4155 - binary_accuracy: 0.8087 - val_loss: 0.4537 - val_binary_accuracy: 0.8034\n","Epoch 15/100\n","338/338 [==============================] - 91s 270ms/step - loss: 0.4122 - binary_accuracy: 0.8121 - val_loss: 0.4713 - val_binary_accuracy: 0.8026\n","Epoch 16/100\n","338/338 [==============================] - 90s 265ms/step - loss: 0.4111 - binary_accuracy: 0.8089 - val_loss: 0.4546 - val_binary_accuracy: 0.8018\n","Epoch 17/100\n","338/338 [==============================] - 87s 258ms/step - loss: 0.4082 - binary_accuracy: 0.8138 - val_loss: 0.4726 - val_binary_accuracy: 0.7986\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|      | 28/84 [1:24:37<8:27:02, 543.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 11ms/step - loss: 0.6018 - binary_accuracy: 0.6778 - val_loss: 0.4310 - val_binary_accuracy: 0.7903\n","Epoch 2/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4715 - binary_accuracy: 0.7788 - val_loss: 0.4198 - val_binary_accuracy: 0.7962\n","Epoch 3/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4577 - binary_accuracy: 0.7888 - val_loss: 0.4196 - val_binary_accuracy: 0.7979\n","Epoch 4/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4524 - binary_accuracy: 0.7891 - val_loss: 0.4175 - val_binary_accuracy: 0.7983\n","Epoch 5/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4488 - binary_accuracy: 0.7914 - val_loss: 0.4154 - val_binary_accuracy: 0.8003\n","Epoch 6/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4452 - binary_accuracy: 0.7945 - val_loss: 0.4150 - val_binary_accuracy: 0.8006\n","Epoch 7/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4436 - binary_accuracy: 0.7928 - val_loss: 0.4138 - val_binary_accuracy: 0.8016\n","Epoch 8/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4412 - binary_accuracy: 0.7953 - val_loss: 0.4129 - val_binary_accuracy: 0.8021\n","Epoch 9/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4394 - binary_accuracy: 0.7952 - val_loss: 0.4127 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4379 - binary_accuracy: 0.7989 - val_loss: 0.4127 - val_binary_accuracy: 0.8026\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4383 - binary_accuracy: 0.7984 - val_loss: 0.4117 - val_binary_accuracy: 0.8022\n","Epoch 12/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4376 - binary_accuracy: 0.7977 - val_loss: 0.4129 - val_binary_accuracy: 0.8022\n","Epoch 13/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4347 - binary_accuracy: 0.7980 - val_loss: 0.4105 - val_binary_accuracy: 0.8035\n","Epoch 14/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4334 - binary_accuracy: 0.7982 - val_loss: 0.4101 - val_binary_accuracy: 0.8034\n","Epoch 15/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4332 - binary_accuracy: 0.8006 - val_loss: 0.4115 - val_binary_accuracy: 0.8022\n","Epoch 16/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4339 - binary_accuracy: 0.7999 - val_loss: 0.4104 - val_binary_accuracy: 0.8035\n","Epoch 17/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4280 - binary_accuracy: 0.8048 - val_loss: 0.4106 - val_binary_accuracy: 0.8024\n","Epoch 18/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4338 - binary_accuracy: 0.7992 - val_loss: 0.4109 - val_binary_accuracy: 0.8029\n"],"name":"stdout"},{"output_type":"stream","text":["\r 35%|      | 29/84 [1:25:45<6:07:11, 400.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 10s 26ms/step - loss: 0.5474 - binary_accuracy: 0.7226 - val_loss: 0.4333 - val_binary_accuracy: 0.7939\n","Epoch 2/100\n","338/338 [==============================] - 9s 27ms/step - loss: 0.4443 - binary_accuracy: 0.7888 - val_loss: 0.4212 - val_binary_accuracy: 0.7977\n","Epoch 3/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4343 - binary_accuracy: 0.7956 - val_loss: 0.4218 - val_binary_accuracy: 0.7985\n","Epoch 4/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4305 - binary_accuracy: 0.7959 - val_loss: 0.4199 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4270 - binary_accuracy: 0.7988 - val_loss: 0.4171 - val_binary_accuracy: 0.8000\n","Epoch 6/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4228 - binary_accuracy: 0.8010 - val_loss: 0.4218 - val_binary_accuracy: 0.7996\n","Epoch 7/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4219 - binary_accuracy: 0.7996 - val_loss: 0.4143 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4221 - binary_accuracy: 0.8010 - val_loss: 0.4150 - val_binary_accuracy: 0.8020\n","Epoch 9/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4181 - binary_accuracy: 0.8019 - val_loss: 0.4120 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4173 - binary_accuracy: 0.8033 - val_loss: 0.4131 - val_binary_accuracy: 0.8038\n","Epoch 11/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4163 - binary_accuracy: 0.8045 - val_loss: 0.4155 - val_binary_accuracy: 0.8008\n","Epoch 12/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4144 - binary_accuracy: 0.8032 - val_loss: 0.4168 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4139 - binary_accuracy: 0.8032 - val_loss: 0.4146 - val_binary_accuracy: 0.8024\n","Epoch 14/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4124 - binary_accuracy: 0.8043 - val_loss: 0.4108 - val_binary_accuracy: 0.8036\n","Epoch 15/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4129 - binary_accuracy: 0.8054 - val_loss: 0.4170 - val_binary_accuracy: 0.8039\n","Epoch 16/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4134 - binary_accuracy: 0.8044 - val_loss: 0.4096 - val_binary_accuracy: 0.8035\n","Epoch 17/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4069 - binary_accuracy: 0.8084 - val_loss: 0.4127 - val_binary_accuracy: 0.8010\n","Epoch 18/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4124 - binary_accuracy: 0.8049 - val_loss: 0.4130 - val_binary_accuracy: 0.8032\n","Epoch 19/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4104 - binary_accuracy: 0.8067 - val_loss: 0.4128 - val_binary_accuracy: 0.8033\n","Epoch 20/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4073 - binary_accuracy: 0.8085 - val_loss: 0.4155 - val_binary_accuracy: 0.8030\n"],"name":"stdout"},{"output_type":"stream","text":["\r 36%|      | 30/84 [1:28:40<4:59:36, 332.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4871 - binary_accuracy: 0.7570 - val_loss: 0.4236 - val_binary_accuracy: 0.7963\n","Epoch 2/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4267 - binary_accuracy: 0.7939 - val_loss: 0.4148 - val_binary_accuracy: 0.7995\n","Epoch 3/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4196 - binary_accuracy: 0.7996 - val_loss: 0.4126 - val_binary_accuracy: 0.8003\n","Epoch 4/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4171 - binary_accuracy: 0.8009 - val_loss: 0.4112 - val_binary_accuracy: 0.8007\n","Epoch 5/100\n","338/338 [==============================] - 16s 49ms/step - loss: 0.4146 - binary_accuracy: 0.8023 - val_loss: 0.4094 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","338/338 [==============================] - 16s 49ms/step - loss: 0.4123 - binary_accuracy: 0.8041 - val_loss: 0.4090 - val_binary_accuracy: 0.8050\n","Epoch 7/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4114 - binary_accuracy: 0.8039 - val_loss: 0.4101 - val_binary_accuracy: 0.8046\n","Epoch 8/100\n","338/338 [==============================] - 17s 49ms/step - loss: 0.4108 - binary_accuracy: 0.8045 - val_loss: 0.4076 - val_binary_accuracy: 0.8040\n","Epoch 9/100\n","338/338 [==============================] - 16s 48ms/step - loss: 0.4074 - binary_accuracy: 0.8066 - val_loss: 0.4085 - val_binary_accuracy: 0.8041\n","Epoch 10/100\n","338/338 [==============================] - 17s 50ms/step - loss: 0.4048 - binary_accuracy: 0.8092 - val_loss: 0.4073 - val_binary_accuracy: 0.8046\n","Epoch 11/100\n","338/338 [==============================] - 16s 49ms/step - loss: 0.4050 - binary_accuracy: 0.8096 - val_loss: 0.4069 - val_binary_accuracy: 0.8046\n"],"name":"stdout"},{"output_type":"stream","text":["\r 37%|      | 31/84 [1:31:43<4:14:26, 288.05s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5277 - binary_accuracy: 0.7272 - val_loss: 0.4267 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4309 - binary_accuracy: 0.7909 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4239 - binary_accuracy: 0.7962 - val_loss: 0.4179 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4219 - binary_accuracy: 0.7978 - val_loss: 0.4171 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4202 - binary_accuracy: 0.7979 - val_loss: 0.4154 - val_binary_accuracy: 0.7993\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4190 - binary_accuracy: 0.7988 - val_loss: 0.4151 - val_binary_accuracy: 0.8001\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.7985 - val_loss: 0.4150 - val_binary_accuracy: 0.7997\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.7993 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8001 - val_loss: 0.4137 - val_binary_accuracy: 0.8008\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8014 - val_loss: 0.4133 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8029 - val_loss: 0.4129 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8015 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8016 - val_loss: 0.4126 - val_binary_accuracy: 0.8018\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8012 - val_loss: 0.4126 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8025 - val_loss: 0.4127 - val_binary_accuracy: 0.8011\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8022 - val_loss: 0.4124 - val_binary_accuracy: 0.8017\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8063 - val_loss: 0.4121 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8019 - val_loss: 0.4124 - val_binary_accuracy: 0.8019\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8040 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\r 38%|      | 32/84 [1:32:03<2:59:51, 207.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.6777 - binary_accuracy: 0.6142 - val_loss: 0.5055 - val_binary_accuracy: 0.7699\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5497 - binary_accuracy: 0.7231 - val_loss: 0.4447 - val_binary_accuracy: 0.7921\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5103 - binary_accuracy: 0.7498 - val_loss: 0.4355 - val_binary_accuracy: 0.7939\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4967 - binary_accuracy: 0.7607 - val_loss: 0.4338 - val_binary_accuracy: 0.7925\n","Epoch 5/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4919 - binary_accuracy: 0.7634 - val_loss: 0.4297 - val_binary_accuracy: 0.7950\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4856 - binary_accuracy: 0.7663 - val_loss: 0.4298 - val_binary_accuracy: 0.7939\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4835 - binary_accuracy: 0.7652 - val_loss: 0.4287 - val_binary_accuracy: 0.7936\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4818 - binary_accuracy: 0.7681 - val_loss: 0.4267 - val_binary_accuracy: 0.7939\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4780 - binary_accuracy: 0.7694 - val_loss: 0.4264 - val_binary_accuracy: 0.7943\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4747 - binary_accuracy: 0.7726 - val_loss: 0.4250 - val_binary_accuracy: 0.7946\n"],"name":"stdout"},{"output_type":"stream","text":["\r 39%|      | 33/84 [1:32:19<2:07:31, 150.03s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 10s 26ms/step - loss: 0.5474 - binary_accuracy: 0.7226 - val_loss: 0.4333 - val_binary_accuracy: 0.7939\n","Epoch 2/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4443 - binary_accuracy: 0.7888 - val_loss: 0.4212 - val_binary_accuracy: 0.7977\n","Epoch 3/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4343 - binary_accuracy: 0.7956 - val_loss: 0.4218 - val_binary_accuracy: 0.7985\n","Epoch 4/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4305 - binary_accuracy: 0.7959 - val_loss: 0.4199 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4270 - binary_accuracy: 0.7988 - val_loss: 0.4171 - val_binary_accuracy: 0.8000\n","Epoch 6/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4228 - binary_accuracy: 0.8010 - val_loss: 0.4218 - val_binary_accuracy: 0.7996\n","Epoch 7/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4219 - binary_accuracy: 0.7996 - val_loss: 0.4143 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4221 - binary_accuracy: 0.8010 - val_loss: 0.4150 - val_binary_accuracy: 0.8020\n","Epoch 9/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4181 - binary_accuracy: 0.8019 - val_loss: 0.4120 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4173 - binary_accuracy: 0.8033 - val_loss: 0.4131 - val_binary_accuracy: 0.8038\n","Epoch 11/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4163 - binary_accuracy: 0.8045 - val_loss: 0.4155 - val_binary_accuracy: 0.8008\n","Epoch 12/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4144 - binary_accuracy: 0.8032 - val_loss: 0.4168 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4139 - binary_accuracy: 0.8032 - val_loss: 0.4146 - val_binary_accuracy: 0.8024\n","Epoch 14/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4124 - binary_accuracy: 0.8043 - val_loss: 0.4108 - val_binary_accuracy: 0.8036\n","Epoch 15/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4129 - binary_accuracy: 0.8054 - val_loss: 0.4170 - val_binary_accuracy: 0.8039\n","Epoch 16/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4134 - binary_accuracy: 0.8044 - val_loss: 0.4096 - val_binary_accuracy: 0.8035\n","Epoch 17/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4069 - binary_accuracy: 0.8084 - val_loss: 0.4127 - val_binary_accuracy: 0.8010\n","Epoch 18/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4124 - binary_accuracy: 0.8049 - val_loss: 0.4130 - val_binary_accuracy: 0.8032\n","Epoch 19/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4104 - binary_accuracy: 0.8067 - val_loss: 0.4128 - val_binary_accuracy: 0.8033\n","Epoch 20/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4073 - binary_accuracy: 0.8085 - val_loss: 0.4155 - val_binary_accuracy: 0.8030\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|      | 34/84 [1:35:13<2:10:58, 157.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.6075 - binary_accuracy: 0.6843 - val_loss: 0.4575 - val_binary_accuracy: 0.7883\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.5163 - binary_accuracy: 0.7556 - val_loss: 0.4419 - val_binary_accuracy: 0.7905\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4992 - binary_accuracy: 0.7607 - val_loss: 0.4356 - val_binary_accuracy: 0.7932\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4924 - binary_accuracy: 0.7607 - val_loss: 0.4301 - val_binary_accuracy: 0.7938\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4867 - binary_accuracy: 0.7634 - val_loss: 0.4286 - val_binary_accuracy: 0.7939\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4820 - binary_accuracy: 0.7662 - val_loss: 0.4284 - val_binary_accuracy: 0.7940\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4800 - binary_accuracy: 0.7668 - val_loss: 0.4283 - val_binary_accuracy: 0.7934\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4797 - binary_accuracy: 0.7662 - val_loss: 0.4232 - val_binary_accuracy: 0.7954\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4743 - binary_accuracy: 0.7698 - val_loss: 0.4232 - val_binary_accuracy: 0.7975\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4715 - binary_accuracy: 0.7715 - val_loss: 0.4247 - val_binary_accuracy: 0.7951\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4721 - binary_accuracy: 0.7709 - val_loss: 0.4206 - val_binary_accuracy: 0.7985\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4702 - binary_accuracy: 0.7706 - val_loss: 0.4214 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4686 - binary_accuracy: 0.7716 - val_loss: 0.4207 - val_binary_accuracy: 0.7983\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4660 - binary_accuracy: 0.7720 - val_loss: 0.4193 - val_binary_accuracy: 0.7974\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4639 - binary_accuracy: 0.7757 - val_loss: 0.4201 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4649 - binary_accuracy: 0.7749 - val_loss: 0.4178 - val_binary_accuracy: 0.7982\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4610 - binary_accuracy: 0.7763 - val_loss: 0.4178 - val_binary_accuracy: 0.8003\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4657 - binary_accuracy: 0.7755 - val_loss: 0.4198 - val_binary_accuracy: 0.7984\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4634 - binary_accuracy: 0.7771 - val_loss: 0.4186 - val_binary_accuracy: 0.8000\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4605 - binary_accuracy: 0.7798 - val_loss: 0.4161 - val_binary_accuracy: 0.8010\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4607 - binary_accuracy: 0.7792 - val_loss: 0.4164 - val_binary_accuracy: 0.8018\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4592 - binary_accuracy: 0.7813 - val_loss: 0.4186 - val_binary_accuracy: 0.8001\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4561 - binary_accuracy: 0.7839 - val_loss: 0.4172 - val_binary_accuracy: 0.8023\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4583 - binary_accuracy: 0.7805 - val_loss: 0.4163 - val_binary_accuracy: 0.8008\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4566 - binary_accuracy: 0.7821 - val_loss: 0.4152 - val_binary_accuracy: 0.8024\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4567 - binary_accuracy: 0.7841 - val_loss: 0.4163 - val_binary_accuracy: 0.8017\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4564 - binary_accuracy: 0.7846 - val_loss: 0.4149 - val_binary_accuracy: 0.8022\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4563 - binary_accuracy: 0.7827 - val_loss: 0.4136 - val_binary_accuracy: 0.8025\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4575 - binary_accuracy: 0.7825 - val_loss: 0.4138 - val_binary_accuracy: 0.8025\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4565 - binary_accuracy: 0.7843 - val_loss: 0.4145 - val_binary_accuracy: 0.8022\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4572 - binary_accuracy: 0.7841 - val_loss: 0.4137 - val_binary_accuracy: 0.8023\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4549 - binary_accuracy: 0.7841 - val_loss: 0.4152 - val_binary_accuracy: 0.8028\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4519 - binary_accuracy: 0.7886 - val_loss: 0.4164 - val_binary_accuracy: 0.8030\n","Epoch 34/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4551 - binary_accuracy: 0.7852 - val_loss: 0.4153 - val_binary_accuracy: 0.8017\n","Epoch 35/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4533 - binary_accuracy: 0.7846 - val_loss: 0.4136 - val_binary_accuracy: 0.8026\n","Epoch 36/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4552 - binary_accuracy: 0.7854 - val_loss: 0.4135 - val_binary_accuracy: 0.8027\n","Epoch 37/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4573 - binary_accuracy: 0.7840 - val_loss: 0.4143 - val_binary_accuracy: 0.8027\n","Epoch 38/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4550 - binary_accuracy: 0.7852 - val_loss: 0.4134 - val_binary_accuracy: 0.8020\n"],"name":"stdout"},{"output_type":"stream","text":["\r 42%|     | 35/84 [1:36:04<1:42:22, 125.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5138 - binary_accuracy: 0.7408 - val_loss: 0.4234 - val_binary_accuracy: 0.7959\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4247 - binary_accuracy: 0.7947 - val_loss: 0.4170 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4180 - binary_accuracy: 0.8001 - val_loss: 0.4142 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4164 - binary_accuracy: 0.7997 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4135 - binary_accuracy: 0.8021 - val_loss: 0.4114 - val_binary_accuracy: 0.8013\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4112 - binary_accuracy: 0.8039 - val_loss: 0.4109 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8030 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4114 - binary_accuracy: 0.8032 - val_loss: 0.4098 - val_binary_accuracy: 0.8036\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4094 - binary_accuracy: 0.8039 - val_loss: 0.4096 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4066 - binary_accuracy: 0.8065 - val_loss: 0.4093 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4072 - binary_accuracy: 0.8069 - val_loss: 0.4090 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8064 - val_loss: 0.4090 - val_binary_accuracy: 0.8026\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4051 - binary_accuracy: 0.8075 - val_loss: 0.4090 - val_binary_accuracy: 0.8022\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8063 - val_loss: 0.4088 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4054 - binary_accuracy: 0.8072 - val_loss: 0.4089 - val_binary_accuracy: 0.8025\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4092 - val_binary_accuracy: 0.8036\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4002 - binary_accuracy: 0.8110 - val_loss: 0.4085 - val_binary_accuracy: 0.8026\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4065 - binary_accuracy: 0.8074 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 19/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4043 - binary_accuracy: 0.8088 - val_loss: 0.4084 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 43%|     | 36/84 [1:36:44<1:19:57, 99.94s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.6593 - binary_accuracy: 0.6342 - val_loss: 0.5348 - val_binary_accuracy: 0.6501\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.6031 - binary_accuracy: 0.6658 - val_loss: 0.5208 - val_binary_accuracy: 0.6501\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5912 - binary_accuracy: 0.6746 - val_loss: 0.5114 - val_binary_accuracy: 0.6501\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5876 - binary_accuracy: 0.6787 - val_loss: 0.5075 - val_binary_accuracy: 0.6501\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.5840 - binary_accuracy: 0.6823 - val_loss: 0.5042 - val_binary_accuracy: 0.6501\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5821 - binary_accuracy: 0.6863 - val_loss: 0.5084 - val_binary_accuracy: 0.6501\n"],"name":"stdout"},{"output_type":"stream","text":["\r 44%|     | 37/84 [1:36:57<57:48, 73.79s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 20ms/step - loss: 0.4938 - binary_accuracy: 0.7519 - val_loss: 0.4239 - val_binary_accuracy: 0.7959\n","Epoch 2/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4302 - binary_accuracy: 0.7943 - val_loss: 0.4160 - val_binary_accuracy: 0.7984\n","Epoch 3/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4228 - binary_accuracy: 0.7987 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 4/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4208 - binary_accuracy: 0.8008 - val_loss: 0.4128 - val_binary_accuracy: 0.8005\n","Epoch 5/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4188 - binary_accuracy: 0.8011 - val_loss: 0.4107 - val_binary_accuracy: 0.8020\n","Epoch 6/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4149 - binary_accuracy: 0.8032 - val_loss: 0.4105 - val_binary_accuracy: 0.8029\n","Epoch 7/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4156 - binary_accuracy: 0.8030 - val_loss: 0.4098 - val_binary_accuracy: 0.8033\n","Epoch 8/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4140 - binary_accuracy: 0.8035 - val_loss: 0.4094 - val_binary_accuracy: 0.8027\n","Epoch 9/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4122 - binary_accuracy: 0.8043 - val_loss: 0.4093 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4095 - binary_accuracy: 0.8065 - val_loss: 0.4080 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4093 - binary_accuracy: 0.8074 - val_loss: 0.4076 - val_binary_accuracy: 0.8049\n","Epoch 12/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4088 - binary_accuracy: 0.8072 - val_loss: 0.4087 - val_binary_accuracy: 0.8044\n","Epoch 13/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4070 - binary_accuracy: 0.8066 - val_loss: 0.4099 - val_binary_accuracy: 0.8035\n","Epoch 14/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4068 - binary_accuracy: 0.8066 - val_loss: 0.4075 - val_binary_accuracy: 0.8047\n","Epoch 15/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4068 - binary_accuracy: 0.8073 - val_loss: 0.4101 - val_binary_accuracy: 0.8042\n","Epoch 16/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4071 - binary_accuracy: 0.8071 - val_loss: 0.4106 - val_binary_accuracy: 0.8048\n"],"name":"stdout"},{"output_type":"stream","text":["\r 45%|     | 38/84 [1:38:47<1:04:53, 84.65s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 46%|     | 39/84 [1:39:25<53:00, 70.69s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5983 - binary_accuracy: 0.6735 - val_loss: 0.4339 - val_binary_accuracy: 0.7898\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4651 - binary_accuracy: 0.7807 - val_loss: 0.4252 - val_binary_accuracy: 0.7930\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4521 - binary_accuracy: 0.7888 - val_loss: 0.4238 - val_binary_accuracy: 0.7943\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4504 - binary_accuracy: 0.7896 - val_loss: 0.4244 - val_binary_accuracy: 0.7934\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4480 - binary_accuracy: 0.7905 - val_loss: 0.4212 - val_binary_accuracy: 0.7962\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4441 - binary_accuracy: 0.7910 - val_loss: 0.4215 - val_binary_accuracy: 0.7957\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4440 - binary_accuracy: 0.7899 - val_loss: 0.4217 - val_binary_accuracy: 0.7954\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4457 - binary_accuracy: 0.7920 - val_loss: 0.4199 - val_binary_accuracy: 0.7976\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4424 - binary_accuracy: 0.7914 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4391 - binary_accuracy: 0.7951 - val_loss: 0.4195 - val_binary_accuracy: 0.7982\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4385 - binary_accuracy: 0.7941 - val_loss: 0.4184 - val_binary_accuracy: 0.7982\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4380 - binary_accuracy: 0.7950 - val_loss: 0.4186 - val_binary_accuracy: 0.7979\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4367 - binary_accuracy: 0.7948 - val_loss: 0.4182 - val_binary_accuracy: 0.7985\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4380 - binary_accuracy: 0.7944 - val_loss: 0.4173 - val_binary_accuracy: 0.7993\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4365 - binary_accuracy: 0.7949 - val_loss: 0.4173 - val_binary_accuracy: 0.7992\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4384 - binary_accuracy: 0.7950 - val_loss: 0.4173 - val_binary_accuracy: 0.7981\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4347 - binary_accuracy: 0.7985 - val_loss: 0.4169 - val_binary_accuracy: 0.7987\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4382 - binary_accuracy: 0.7958 - val_loss: 0.4171 - val_binary_accuracy: 0.7993\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4356 - binary_accuracy: 0.7961 - val_loss: 0.4173 - val_binary_accuracy: 0.7993\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4336 - binary_accuracy: 0.7977 - val_loss: 0.4161 - val_binary_accuracy: 0.8000\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4352 - binary_accuracy: 0.7965 - val_loss: 0.4153 - val_binary_accuracy: 0.8003\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4338 - binary_accuracy: 0.7981 - val_loss: 0.4166 - val_binary_accuracy: 0.7998\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4334 - binary_accuracy: 0.7992 - val_loss: 0.4161 - val_binary_accuracy: 0.7993\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4344 - binary_accuracy: 0.7964 - val_loss: 0.4157 - val_binary_accuracy: 0.8006\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4320 - binary_accuracy: 0.7982 - val_loss: 0.4155 - val_binary_accuracy: 0.7996\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4338 - binary_accuracy: 0.7983 - val_loss: 0.4155 - val_binary_accuracy: 0.8007\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4317 - binary_accuracy: 0.7989 - val_loss: 0.4152 - val_binary_accuracy: 0.8005\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4330 - binary_accuracy: 0.7996 - val_loss: 0.4152 - val_binary_accuracy: 0.8005\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4326 - binary_accuracy: 0.7983 - val_loss: 0.4151 - val_binary_accuracy: 0.8007\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4336 - binary_accuracy: 0.7972 - val_loss: 0.4153 - val_binary_accuracy: 0.8005\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4343 - binary_accuracy: 0.7977 - val_loss: 0.4153 - val_binary_accuracy: 0.8002\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4310 - binary_accuracy: 0.7987 - val_loss: 0.4153 - val_binary_accuracy: 0.8003\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4288 - binary_accuracy: 0.8019 - val_loss: 0.4154 - val_binary_accuracy: 0.8005\n","Epoch 34/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4316 - binary_accuracy: 0.8006 - val_loss: 0.4158 - val_binary_accuracy: 0.8002\n"],"name":"stdout"},{"output_type":"stream","text":["\r 48%|     | 40/84 [1:40:09<45:59, 62.72s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5277 - binary_accuracy: 0.7272 - val_loss: 0.4267 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4309 - binary_accuracy: 0.7909 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4239 - binary_accuracy: 0.7962 - val_loss: 0.4179 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4219 - binary_accuracy: 0.7978 - val_loss: 0.4171 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4202 - binary_accuracy: 0.7979 - val_loss: 0.4154 - val_binary_accuracy: 0.7993\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4190 - binary_accuracy: 0.7988 - val_loss: 0.4151 - val_binary_accuracy: 0.8001\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.7985 - val_loss: 0.4150 - val_binary_accuracy: 0.7997\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.7993 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8001 - val_loss: 0.4137 - val_binary_accuracy: 0.8008\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8014 - val_loss: 0.4133 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8029 - val_loss: 0.4129 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8015 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8016 - val_loss: 0.4126 - val_binary_accuracy: 0.8018\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8012 - val_loss: 0.4126 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8025 - val_loss: 0.4127 - val_binary_accuracy: 0.8011\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8022 - val_loss: 0.4124 - val_binary_accuracy: 0.8017\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8063 - val_loss: 0.4121 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8019 - val_loss: 0.4124 - val_binary_accuracy: 0.8019\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8040 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\r 49%|     | 41/84 [1:40:29<35:43, 49.84s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5138 - binary_accuracy: 0.7408 - val_loss: 0.4234 - val_binary_accuracy: 0.7959\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4247 - binary_accuracy: 0.7947 - val_loss: 0.4170 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4180 - binary_accuracy: 0.8001 - val_loss: 0.4142 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4164 - binary_accuracy: 0.7997 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4135 - binary_accuracy: 0.8021 - val_loss: 0.4114 - val_binary_accuracy: 0.8013\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4112 - binary_accuracy: 0.8039 - val_loss: 0.4109 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8030 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4114 - binary_accuracy: 0.8032 - val_loss: 0.4098 - val_binary_accuracy: 0.8036\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4094 - binary_accuracy: 0.8039 - val_loss: 0.4096 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4066 - binary_accuracy: 0.8065 - val_loss: 0.4093 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4072 - binary_accuracy: 0.8069 - val_loss: 0.4090 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8064 - val_loss: 0.4090 - val_binary_accuracy: 0.8026\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4051 - binary_accuracy: 0.8075 - val_loss: 0.4090 - val_binary_accuracy: 0.8022\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8063 - val_loss: 0.4088 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4054 - binary_accuracy: 0.8072 - val_loss: 0.4089 - val_binary_accuracy: 0.8025\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4092 - val_binary_accuracy: 0.8036\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4002 - binary_accuracy: 0.8110 - val_loss: 0.4085 - val_binary_accuracy: 0.8026\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4065 - binary_accuracy: 0.8074 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8088 - val_loss: 0.4084 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|     | 42/84 [1:41:09<32:52, 46.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5046 - binary_accuracy: 0.7431 - val_loss: 0.4250 - val_binary_accuracy: 0.7933\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4333 - binary_accuracy: 0.7912 - val_loss: 0.4183 - val_binary_accuracy: 0.7974\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4241 - binary_accuracy: 0.7974 - val_loss: 0.4167 - val_binary_accuracy: 0.7987\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4231 - binary_accuracy: 0.7988 - val_loss: 0.4145 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4213 - binary_accuracy: 0.7993 - val_loss: 0.4132 - val_binary_accuracy: 0.8005\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4185 - binary_accuracy: 0.8021 - val_loss: 0.4129 - val_binary_accuracy: 0.8014\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4179 - binary_accuracy: 0.8009 - val_loss: 0.4126 - val_binary_accuracy: 0.8014\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4181 - binary_accuracy: 0.8015 - val_loss: 0.4119 - val_binary_accuracy: 0.8018\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4158 - binary_accuracy: 0.8018 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4120 - binary_accuracy: 0.8044 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4122 - binary_accuracy: 0.8049 - val_loss: 0.4106 - val_binary_accuracy: 0.8023\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4118 - binary_accuracy: 0.8048 - val_loss: 0.4116 - val_binary_accuracy: 0.8014\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4107 - binary_accuracy: 0.8039 - val_loss: 0.4098 - val_binary_accuracy: 0.8019\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8042 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4102 - binary_accuracy: 0.8058 - val_loss: 0.4135 - val_binary_accuracy: 0.8024\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4117 - binary_accuracy: 0.8050 - val_loss: 0.4114 - val_binary_accuracy: 0.8030\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8092 - val_loss: 0.4124 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4115 - binary_accuracy: 0.8049 - val_loss: 0.4128 - val_binary_accuracy: 0.8031\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4091 - binary_accuracy: 0.8055 - val_loss: 0.4148 - val_binary_accuracy: 0.8037\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4160 - val_binary_accuracy: 0.8025\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4070 - binary_accuracy: 0.8076 - val_loss: 0.4169 - val_binary_accuracy: 0.8038\n","Epoch 22/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4056 - binary_accuracy: 0.8073 - val_loss: 0.4210 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8085 - val_loss: 0.4244 - val_binary_accuracy: 0.8020\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4055 - binary_accuracy: 0.8067 - val_loss: 0.4259 - val_binary_accuracy: 0.8037\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4045 - binary_accuracy: 0.8082 - val_loss: 0.4258 - val_binary_accuracy: 0.8019\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4053 - binary_accuracy: 0.8082 - val_loss: 0.4286 - val_binary_accuracy: 0.8029\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4035 - binary_accuracy: 0.8086 - val_loss: 0.4338 - val_binary_accuracy: 0.8026\n"],"name":"stdout"},{"output_type":"stream","text":["\r 51%|     | 43/84 [1:42:06<34:00, 49.76s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 28s 81ms/step - loss: 0.4840 - binary_accuracy: 0.7669 - val_loss: 0.4202 - val_binary_accuracy: 0.7964\n","Epoch 2/100\n","338/338 [==============================] - 27s 81ms/step - loss: 0.4199 - binary_accuracy: 0.7979 - val_loss: 0.4166 - val_binary_accuracy: 0.7999\n","Epoch 3/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.4129 - binary_accuracy: 0.8036 - val_loss: 0.4113 - val_binary_accuracy: 0.8025\n","Epoch 4/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4110 - binary_accuracy: 0.8034 - val_loss: 0.4092 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.4088 - binary_accuracy: 0.8058 - val_loss: 0.4075 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4050 - binary_accuracy: 0.8081 - val_loss: 0.4069 - val_binary_accuracy: 0.8038\n","Epoch 7/100\n","338/338 [==============================] - 27s 81ms/step - loss: 0.4043 - binary_accuracy: 0.8076 - val_loss: 0.4061 - val_binary_accuracy: 0.8038\n","Epoch 8/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4049 - binary_accuracy: 0.8075 - val_loss: 0.4052 - val_binary_accuracy: 0.8051\n","Epoch 9/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4016 - binary_accuracy: 0.8099 - val_loss: 0.4064 - val_binary_accuracy: 0.8050\n","Epoch 10/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3969 - binary_accuracy: 0.8124 - val_loss: 0.4067 - val_binary_accuracy: 0.8036\n","Epoch 11/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3970 - binary_accuracy: 0.8122 - val_loss: 0.4051 - val_binary_accuracy: 0.8049\n","Epoch 12/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3960 - binary_accuracy: 0.8121 - val_loss: 0.4057 - val_binary_accuracy: 0.8040\n","Epoch 13/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3951 - binary_accuracy: 0.8128 - val_loss: 0.4051 - val_binary_accuracy: 0.8055\n","Epoch 14/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3933 - binary_accuracy: 0.8134 - val_loss: 0.4064 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 27s 81ms/step - loss: 0.3927 - binary_accuracy: 0.8146 - val_loss: 0.4058 - val_binary_accuracy: 0.8055\n","Epoch 16/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3929 - binary_accuracy: 0.8144 - val_loss: 0.4081 - val_binary_accuracy: 0.8042\n","Epoch 17/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3862 - binary_accuracy: 0.8184 - val_loss: 0.4065 - val_binary_accuracy: 0.8060\n","Epoch 18/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3914 - binary_accuracy: 0.8167 - val_loss: 0.4066 - val_binary_accuracy: 0.8060\n","Epoch 19/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3879 - binary_accuracy: 0.8182 - val_loss: 0.4074 - val_binary_accuracy: 0.8049\n","Epoch 20/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.3845 - binary_accuracy: 0.8194 - val_loss: 0.4077 - val_binary_accuracy: 0.8038\n","Epoch 21/100\n","338/338 [==============================] - 27s 81ms/step - loss: 0.3856 - binary_accuracy: 0.8191 - val_loss: 0.4071 - val_binary_accuracy: 0.8050\n","Epoch 22/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3832 - binary_accuracy: 0.8184 - val_loss: 0.4087 - val_binary_accuracy: 0.8053\n"],"name":"stdout"},{"output_type":"stream","text":["\r 52%|    | 44/84 [1:52:16<2:25:11, 217.79s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5277 - binary_accuracy: 0.7272 - val_loss: 0.4267 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4309 - binary_accuracy: 0.7909 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4239 - binary_accuracy: 0.7962 - val_loss: 0.4179 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4219 - binary_accuracy: 0.7978 - val_loss: 0.4171 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4202 - binary_accuracy: 0.7979 - val_loss: 0.4154 - val_binary_accuracy: 0.7993\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4190 - binary_accuracy: 0.7988 - val_loss: 0.4151 - val_binary_accuracy: 0.8001\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.7985 - val_loss: 0.4150 - val_binary_accuracy: 0.7997\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.7993 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8001 - val_loss: 0.4137 - val_binary_accuracy: 0.8008\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8014 - val_loss: 0.4133 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8029 - val_loss: 0.4129 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8015 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8016 - val_loss: 0.4126 - val_binary_accuracy: 0.8018\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8012 - val_loss: 0.4126 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8025 - val_loss: 0.4127 - val_binary_accuracy: 0.8011\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8022 - val_loss: 0.4124 - val_binary_accuracy: 0.8017\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8063 - val_loss: 0.4121 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8019 - val_loss: 0.4124 - val_binary_accuracy: 0.8019\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4143 - binary_accuracy: 0.8040 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\r 54%|    | 45/84 [1:52:36<1:43:02, 158.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 2ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|    | 46/84 [1:53:13<1:17:25, 122.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5480 - binary_accuracy: 0.7097 - val_loss: 0.4294 - val_binary_accuracy: 0.7905\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4466 - binary_accuracy: 0.7872 - val_loss: 0.4217 - val_binary_accuracy: 0.7951\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4379 - binary_accuracy: 0.7936 - val_loss: 0.4201 - val_binary_accuracy: 0.7968\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4369 - binary_accuracy: 0.7944 - val_loss: 0.4201 - val_binary_accuracy: 0.7962\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4346 - binary_accuracy: 0.7945 - val_loss: 0.4174 - val_binary_accuracy: 0.7982\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4326 - binary_accuracy: 0.7964 - val_loss: 0.4168 - val_binary_accuracy: 0.7988\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4321 - binary_accuracy: 0.7950 - val_loss: 0.4171 - val_binary_accuracy: 0.7989\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4314 - binary_accuracy: 0.7967 - val_loss: 0.4151 - val_binary_accuracy: 0.8000\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4304 - binary_accuracy: 0.7962 - val_loss: 0.4152 - val_binary_accuracy: 0.7998\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7991 - val_loss: 0.4146 - val_binary_accuracy: 0.8001\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4267 - binary_accuracy: 0.8004 - val_loss: 0.4138 - val_binary_accuracy: 0.8003\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4269 - binary_accuracy: 0.7980 - val_loss: 0.4138 - val_binary_accuracy: 0.8001\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4252 - binary_accuracy: 0.8006 - val_loss: 0.4133 - val_binary_accuracy: 0.8009\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4266 - binary_accuracy: 0.7988 - val_loss: 0.4128 - val_binary_accuracy: 0.8011\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4254 - binary_accuracy: 0.7999 - val_loss: 0.4129 - val_binary_accuracy: 0.8007\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4268 - binary_accuracy: 0.7984 - val_loss: 0.4127 - val_binary_accuracy: 0.8015\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4209 - binary_accuracy: 0.8046 - val_loss: 0.4124 - val_binary_accuracy: 0.8015\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4268 - binary_accuracy: 0.8003 - val_loss: 0.4125 - val_binary_accuracy: 0.8012\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4250 - binary_accuracy: 0.7998 - val_loss: 0.4122 - val_binary_accuracy: 0.8022\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4224 - binary_accuracy: 0.8026 - val_loss: 0.4120 - val_binary_accuracy: 0.8014\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4242 - binary_accuracy: 0.8013 - val_loss: 0.4111 - val_binary_accuracy: 0.8027\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4214 - binary_accuracy: 0.8018 - val_loss: 0.4115 - val_binary_accuracy: 0.8024\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4208 - binary_accuracy: 0.8022 - val_loss: 0.4114 - val_binary_accuracy: 0.8013\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4227 - binary_accuracy: 0.8009 - val_loss: 0.4108 - val_binary_accuracy: 0.8029\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4208 - binary_accuracy: 0.8026 - val_loss: 0.4105 - val_binary_accuracy: 0.8019\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4221 - binary_accuracy: 0.8037 - val_loss: 0.4111 - val_binary_accuracy: 0.8027\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4212 - binary_accuracy: 0.8037 - val_loss: 0.4104 - val_binary_accuracy: 0.8027\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4208 - binary_accuracy: 0.8021 - val_loss: 0.4105 - val_binary_accuracy: 0.8027\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4212 - binary_accuracy: 0.8025 - val_loss: 0.4105 - val_binary_accuracy: 0.8022\n"],"name":"stdout"},{"output_type":"stream","text":["\r 56%|    | 47/84 [1:53:50<59:33, 96.58s/it]   "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4792 - binary_accuracy: 0.7599 - val_loss: 0.4207 - val_binary_accuracy: 0.7969\n","Epoch 2/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4263 - binary_accuracy: 0.7945 - val_loss: 0.4153 - val_binary_accuracy: 0.7987\n","Epoch 3/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4187 - binary_accuracy: 0.8002 - val_loss: 0.4130 - val_binary_accuracy: 0.8012\n","Epoch 4/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4168 - binary_accuracy: 0.8011 - val_loss: 0.4125 - val_binary_accuracy: 0.8007\n","Epoch 5/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4149 - binary_accuracy: 0.8016 - val_loss: 0.4097 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4116 - binary_accuracy: 0.8043 - val_loss: 0.4093 - val_binary_accuracy: 0.8028\n","Epoch 7/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4121 - binary_accuracy: 0.8030 - val_loss: 0.4092 - val_binary_accuracy: 0.8042\n","Epoch 8/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4110 - binary_accuracy: 0.8039 - val_loss: 0.4083 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4085 - binary_accuracy: 0.8047 - val_loss: 0.4081 - val_binary_accuracy: 0.8040\n","Epoch 10/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.4065 - binary_accuracy: 0.8074 - val_loss: 0.4074 - val_binary_accuracy: 0.8047\n","Epoch 11/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4060 - binary_accuracy: 0.8075 - val_loss: 0.4065 - val_binary_accuracy: 0.8045\n","Epoch 12/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4053 - binary_accuracy: 0.8073 - val_loss: 0.4072 - val_binary_accuracy: 0.8047\n","Epoch 13/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4044 - binary_accuracy: 0.8076 - val_loss: 0.4063 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4043 - binary_accuracy: 0.8077 - val_loss: 0.4060 - val_binary_accuracy: 0.8042\n","Epoch 15/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.4038 - binary_accuracy: 0.8081 - val_loss: 0.4068 - val_binary_accuracy: 0.8046\n","Epoch 16/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4043 - binary_accuracy: 0.8070 - val_loss: 0.4062 - val_binary_accuracy: 0.8050\n","Epoch 17/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3987 - binary_accuracy: 0.8118 - val_loss: 0.4056 - val_binary_accuracy: 0.8046\n","Epoch 18/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4046 - binary_accuracy: 0.8086 - val_loss: 0.4054 - val_binary_accuracy: 0.8042\n","Epoch 19/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4019 - binary_accuracy: 0.8097 - val_loss: 0.4055 - val_binary_accuracy: 0.8050\n","Epoch 20/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3995 - binary_accuracy: 0.8104 - val_loss: 0.4057 - val_binary_accuracy: 0.8050\n","Epoch 21/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4009 - binary_accuracy: 0.8109 - val_loss: 0.4043 - val_binary_accuracy: 0.8055\n","Epoch 22/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3985 - binary_accuracy: 0.8112 - val_loss: 0.4054 - val_binary_accuracy: 0.8054\n","Epoch 23/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3975 - binary_accuracy: 0.8123 - val_loss: 0.4051 - val_binary_accuracy: 0.8056\n","Epoch 24/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3987 - binary_accuracy: 0.8104 - val_loss: 0.4044 - val_binary_accuracy: 0.8054\n","Epoch 25/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3969 - binary_accuracy: 0.8115 - val_loss: 0.4051 - val_binary_accuracy: 0.8056\n","Epoch 26/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4002 - binary_accuracy: 0.8122 - val_loss: 0.4045 - val_binary_accuracy: 0.8057\n","Epoch 27/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3963 - binary_accuracy: 0.8128 - val_loss: 0.4049 - val_binary_accuracy: 0.8066\n","Epoch 28/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3978 - binary_accuracy: 0.8128 - val_loss: 0.4045 - val_binary_accuracy: 0.8063\n","Epoch 29/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3973 - binary_accuracy: 0.8132 - val_loss: 0.4043 - val_binary_accuracy: 0.8060\n","Epoch 30/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3967 - binary_accuracy: 0.8123 - val_loss: 0.4046 - val_binary_accuracy: 0.8065\n","Epoch 31/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3967 - binary_accuracy: 0.8126 - val_loss: 0.4046 - val_binary_accuracy: 0.8067\n","Epoch 32/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3943 - binary_accuracy: 0.8144 - val_loss: 0.4045 - val_binary_accuracy: 0.8059\n","Epoch 33/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3937 - binary_accuracy: 0.8162 - val_loss: 0.4047 - val_binary_accuracy: 0.8063\n","Epoch 34/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3960 - binary_accuracy: 0.8142 - val_loss: 0.4052 - val_binary_accuracy: 0.8063\n","Epoch 35/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3948 - binary_accuracy: 0.8146 - val_loss: 0.4045 - val_binary_accuracy: 0.8060\n","Epoch 36/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3941 - binary_accuracy: 0.8149 - val_loss: 0.4055 - val_binary_accuracy: 0.8069\n","Epoch 37/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3962 - binary_accuracy: 0.8133 - val_loss: 0.4050 - val_binary_accuracy: 0.8061\n","Epoch 38/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3964 - binary_accuracy: 0.8132 - val_loss: 0.4048 - val_binary_accuracy: 0.8060\n","Epoch 39/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3934 - binary_accuracy: 0.8155 - val_loss: 0.4045 - val_binary_accuracy: 0.8066\n","Epoch 40/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.3902 - binary_accuracy: 0.8171 - val_loss: 0.4052 - val_binary_accuracy: 0.8057\n","Epoch 41/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.3924 - binary_accuracy: 0.8155 - val_loss: 0.4048 - val_binary_accuracy: 0.8054\n"],"name":"stdout"},{"output_type":"stream","text":["\r 57%|    | 48/84 [1:57:00<1:14:49, 124.72s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 12ms/step - loss: 0.5102 - binary_accuracy: 0.7513 - val_loss: 0.4200 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4201 - binary_accuracy: 0.7963 - val_loss: 0.4151 - val_binary_accuracy: 0.7993\n","Epoch 3/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4149 - binary_accuracy: 0.8015 - val_loss: 0.4125 - val_binary_accuracy: 0.8014\n","Epoch 4/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4130 - binary_accuracy: 0.8028 - val_loss: 0.4120 - val_binary_accuracy: 0.8006\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4112 - binary_accuracy: 0.8026 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 6/100\n","338/338 [==============================] - 4s 11ms/step - loss: 0.4085 - binary_accuracy: 0.8054 - val_loss: 0.4093 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4083 - binary_accuracy: 0.8045 - val_loss: 0.4097 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4084 - binary_accuracy: 0.8052 - val_loss: 0.4084 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4061 - binary_accuracy: 0.8064 - val_loss: 0.4085 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4032 - binary_accuracy: 0.8083 - val_loss: 0.4085 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4036 - binary_accuracy: 0.8083 - val_loss: 0.4077 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4019 - binary_accuracy: 0.8095 - val_loss: 0.4076 - val_binary_accuracy: 0.8030\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4023 - binary_accuracy: 0.8079 - val_loss: 0.4073 - val_binary_accuracy: 0.8034\n"],"name":"stdout"},{"output_type":"stream","text":["\r 58%|    | 49/84 [1:57:53<1:00:07, 103.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4840 - binary_accuracy: 0.7669 - val_loss: 0.4202 - val_binary_accuracy: 0.7964\n","Epoch 2/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4199 - binary_accuracy: 0.7979 - val_loss: 0.4166 - val_binary_accuracy: 0.7999\n","Epoch 3/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4129 - binary_accuracy: 0.8036 - val_loss: 0.4113 - val_binary_accuracy: 0.8025\n","Epoch 4/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4110 - binary_accuracy: 0.8034 - val_loss: 0.4092 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","338/338 [==============================] - 28s 82ms/step - loss: 0.4088 - binary_accuracy: 0.8058 - val_loss: 0.4075 - val_binary_accuracy: 0.8014\n","Epoch 6/100\n","338/338 [==============================] - 31s 91ms/step - loss: 0.4050 - binary_accuracy: 0.8081 - val_loss: 0.4069 - val_binary_accuracy: 0.8038\n","Epoch 7/100\n","338/338 [==============================] - 32s 95ms/step - loss: 0.4043 - binary_accuracy: 0.8076 - val_loss: 0.4061 - val_binary_accuracy: 0.8038\n","Epoch 8/100\n","338/338 [==============================] - 32s 93ms/step - loss: 0.4049 - binary_accuracy: 0.8075 - val_loss: 0.4052 - val_binary_accuracy: 0.8051\n","Epoch 9/100\n","338/338 [==============================] - 32s 94ms/step - loss: 0.4016 - binary_accuracy: 0.8099 - val_loss: 0.4064 - val_binary_accuracy: 0.8050\n","Epoch 10/100\n","338/338 [==============================] - 32s 96ms/step - loss: 0.3969 - binary_accuracy: 0.8124 - val_loss: 0.4067 - val_binary_accuracy: 0.8036\n","Epoch 11/100\n","338/338 [==============================] - 32s 94ms/step - loss: 0.3970 - binary_accuracy: 0.8122 - val_loss: 0.4051 - val_binary_accuracy: 0.8049\n","Epoch 12/100\n","338/338 [==============================] - 32s 95ms/step - loss: 0.3960 - binary_accuracy: 0.8121 - val_loss: 0.4057 - val_binary_accuracy: 0.8040\n","Epoch 13/100\n","338/338 [==============================] - 31s 90ms/step - loss: 0.3951 - binary_accuracy: 0.8128 - val_loss: 0.4051 - val_binary_accuracy: 0.8055\n","Epoch 14/100\n","338/338 [==============================] - 31s 90ms/step - loss: 0.3933 - binary_accuracy: 0.8134 - val_loss: 0.4064 - val_binary_accuracy: 0.8044\n","Epoch 15/100\n","338/338 [==============================] - 30s 87ms/step - loss: 0.3927 - binary_accuracy: 0.8146 - val_loss: 0.4058 - val_binary_accuracy: 0.8055\n","Epoch 16/100\n","338/338 [==============================] - 28s 84ms/step - loss: 0.3929 - binary_accuracy: 0.8144 - val_loss: 0.4081 - val_binary_accuracy: 0.8042\n","Epoch 17/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3862 - binary_accuracy: 0.8184 - val_loss: 0.4065 - val_binary_accuracy: 0.8060\n","Epoch 18/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3914 - binary_accuracy: 0.8167 - val_loss: 0.4066 - val_binary_accuracy: 0.8060\n","Epoch 19/100\n","338/338 [==============================] - 28s 83ms/step - loss: 0.3879 - binary_accuracy: 0.8182 - val_loss: 0.4074 - val_binary_accuracy: 0.8049\n","Epoch 20/100\n","338/338 [==============================] - 29s 85ms/step - loss: 0.3845 - binary_accuracy: 0.8194 - val_loss: 0.4077 - val_binary_accuracy: 0.8038\n","Epoch 21/100\n","338/338 [==============================] - 28s 84ms/step - loss: 0.3856 - binary_accuracy: 0.8191 - val_loss: 0.4071 - val_binary_accuracy: 0.8050\n","Epoch 22/100\n","338/338 [==============================] - 29s 85ms/step - loss: 0.3832 - binary_accuracy: 0.8184 - val_loss: 0.4087 - val_binary_accuracy: 0.8053\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|    | 50/84 [2:08:44<2:31:36, 267.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 61%|    | 51/84 [2:09:22<1:49:17, 198.71s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.5036 - binary_accuracy: 0.7435 - val_loss: 0.4240 - val_binary_accuracy: 0.7943\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4270 - binary_accuracy: 0.7923 - val_loss: 0.4183 - val_binary_accuracy: 0.7975\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4198 - binary_accuracy: 0.7983 - val_loss: 0.4157 - val_binary_accuracy: 0.7995\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4183 - binary_accuracy: 0.7997 - val_loss: 0.4148 - val_binary_accuracy: 0.7999\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4168 - binary_accuracy: 0.7998 - val_loss: 0.4129 - val_binary_accuracy: 0.8002\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4148 - binary_accuracy: 0.8021 - val_loss: 0.4125 - val_binary_accuracy: 0.8007\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4151 - binary_accuracy: 0.8014 - val_loss: 0.4128 - val_binary_accuracy: 0.8012\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4148 - binary_accuracy: 0.8015 - val_loss: 0.4115 - val_binary_accuracy: 0.8018\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4130 - binary_accuracy: 0.8022 - val_loss: 0.4113 - val_binary_accuracy: 0.8010\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4100 - binary_accuracy: 0.8050 - val_loss: 0.4109 - val_binary_accuracy: 0.8027\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4105 - binary_accuracy: 0.8053 - val_loss: 0.4105 - val_binary_accuracy: 0.8026\n","Epoch 12/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4095 - binary_accuracy: 0.8049 - val_loss: 0.4103 - val_binary_accuracy: 0.8021\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4092 - binary_accuracy: 0.8038 - val_loss: 0.4101 - val_binary_accuracy: 0.8015\n","Epoch 14/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4087 - binary_accuracy: 0.8056 - val_loss: 0.4101 - val_binary_accuracy: 0.8027\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4087 - binary_accuracy: 0.8060 - val_loss: 0.4100 - val_binary_accuracy: 0.8021\n","Epoch 16/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4103 - binary_accuracy: 0.8049 - val_loss: 0.4100 - val_binary_accuracy: 0.8025\n","Epoch 17/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4036 - binary_accuracy: 0.8085 - val_loss: 0.4097 - val_binary_accuracy: 0.8025\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4110 - binary_accuracy: 0.8049 - val_loss: 0.4098 - val_binary_accuracy: 0.8026\n","Epoch 19/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4085 - binary_accuracy: 0.8059 - val_loss: 0.4095 - val_binary_accuracy: 0.8029\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4058 - binary_accuracy: 0.8072 - val_loss: 0.4099 - val_binary_accuracy: 0.8029\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4073 - binary_accuracy: 0.8066 - val_loss: 0.4088 - val_binary_accuracy: 0.8034\n","Epoch 22/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4049 - binary_accuracy: 0.8075 - val_loss: 0.4090 - val_binary_accuracy: 0.8033\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4050 - binary_accuracy: 0.8080 - val_loss: 0.4090 - val_binary_accuracy: 0.8028\n","Epoch 24/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4061 - binary_accuracy: 0.8064 - val_loss: 0.4086 - val_binary_accuracy: 0.8031\n","Epoch 25/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4046 - binary_accuracy: 0.8069 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4061 - binary_accuracy: 0.8079 - val_loss: 0.4086 - val_binary_accuracy: 0.8037\n","Epoch 27/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4048 - binary_accuracy: 0.8074 - val_loss: 0.4088 - val_binary_accuracy: 0.8030\n","Epoch 28/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4059 - binary_accuracy: 0.8076 - val_loss: 0.4088 - val_binary_accuracy: 0.8035\n","Epoch 29/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4056 - binary_accuracy: 0.8068 - val_loss: 0.4086 - val_binary_accuracy: 0.8034\n","Epoch 30/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4052 - binary_accuracy: 0.8070 - val_loss: 0.4085 - val_binary_accuracy: 0.8040\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4071 - binary_accuracy: 0.8080 - val_loss: 0.4088 - val_binary_accuracy: 0.8040\n","Epoch 32/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4041 - binary_accuracy: 0.8090 - val_loss: 0.4083 - val_binary_accuracy: 0.8040\n","Epoch 33/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4037 - binary_accuracy: 0.8085 - val_loss: 0.4083 - val_binary_accuracy: 0.8044\n","Epoch 34/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4046 - binary_accuracy: 0.8088 - val_loss: 0.4085 - val_binary_accuracy: 0.8043\n","Epoch 35/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4051 - binary_accuracy: 0.8090 - val_loss: 0.4081 - val_binary_accuracy: 0.8042\n","Epoch 36/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4052 - binary_accuracy: 0.8080 - val_loss: 0.4084 - val_binary_accuracy: 0.8035\n","Epoch 37/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4064 - binary_accuracy: 0.8071 - val_loss: 0.4084 - val_binary_accuracy: 0.8043\n","Epoch 38/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4063 - binary_accuracy: 0.8081 - val_loss: 0.4084 - val_binary_accuracy: 0.8041\n"],"name":"stdout"},{"output_type":"stream","text":["\r 62%|   | 52/84 [2:10:16<1:22:48, 155.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.5757 - binary_accuracy: 0.6965 - val_loss: 0.4475 - val_binary_accuracy: 0.7913\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4547 - binary_accuracy: 0.7846 - val_loss: 0.4468 - val_binary_accuracy: 0.7959\n","Epoch 3/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4417 - binary_accuracy: 0.7928 - val_loss: 0.4672 - val_binary_accuracy: 0.7971\n","Epoch 4/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4359 - binary_accuracy: 0.7944 - val_loss: 0.4800 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4310 - binary_accuracy: 0.7959 - val_loss: 0.4808 - val_binary_accuracy: 0.7987\n","Epoch 6/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4280 - binary_accuracy: 0.7977 - val_loss: 0.4988 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4269 - binary_accuracy: 0.7973 - val_loss: 0.4949 - val_binary_accuracy: 0.7976\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4238 - binary_accuracy: 0.7983 - val_loss: 0.4996 - val_binary_accuracy: 0.7978\n","Epoch 9/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4219 - binary_accuracy: 0.7995 - val_loss: 0.4818 - val_binary_accuracy: 0.7995\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4178 - binary_accuracy: 0.8021 - val_loss: 0.4845 - val_binary_accuracy: 0.8016\n","Epoch 11/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4181 - binary_accuracy: 0.8015 - val_loss: 0.4904 - val_binary_accuracy: 0.8004\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4173 - binary_accuracy: 0.8020 - val_loss: 0.4944 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4154 - binary_accuracy: 0.8033 - val_loss: 0.4813 - val_binary_accuracy: 0.8021\n","Epoch 14/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4156 - binary_accuracy: 0.8024 - val_loss: 0.4954 - val_binary_accuracy: 0.8021\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4150 - binary_accuracy: 0.8041 - val_loss: 0.4986 - val_binary_accuracy: 0.8028\n","Epoch 16/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4155 - binary_accuracy: 0.8030 - val_loss: 0.4848 - val_binary_accuracy: 0.8025\n","Epoch 17/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4098 - binary_accuracy: 0.8077 - val_loss: 0.4772 - val_binary_accuracy: 0.8034\n","Epoch 18/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4154 - binary_accuracy: 0.8027 - val_loss: 0.4910 - val_binary_accuracy: 0.8017\n","Epoch 19/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4139 - binary_accuracy: 0.8055 - val_loss: 0.4929 - val_binary_accuracy: 0.8026\n","Epoch 20/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4102 - binary_accuracy: 0.8068 - val_loss: 0.4996 - val_binary_accuracy: 0.8013\n","Epoch 21/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4119 - binary_accuracy: 0.8054 - val_loss: 0.4936 - val_binary_accuracy: 0.8006\n","Epoch 22/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4102 - binary_accuracy: 0.8054 - val_loss: 0.5050 - val_binary_accuracy: 0.7985\n"],"name":"stdout"},{"output_type":"stream","text":["\r 63%|   | 53/84 [2:11:50<1:10:41, 136.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 1, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 5s 13ms/step - loss: 0.5102 - binary_accuracy: 0.7513 - val_loss: 0.4200 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4201 - binary_accuracy: 0.7963 - val_loss: 0.4151 - val_binary_accuracy: 0.7993\n","Epoch 3/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4149 - binary_accuracy: 0.8015 - val_loss: 0.4125 - val_binary_accuracy: 0.8014\n","Epoch 4/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4130 - binary_accuracy: 0.8028 - val_loss: 0.4120 - val_binary_accuracy: 0.8006\n","Epoch 5/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4112 - binary_accuracy: 0.8026 - val_loss: 0.4097 - val_binary_accuracy: 0.8023\n","Epoch 6/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4085 - binary_accuracy: 0.8054 - val_loss: 0.4093 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4083 - binary_accuracy: 0.8045 - val_loss: 0.4097 - val_binary_accuracy: 0.8036\n","Epoch 8/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4084 - binary_accuracy: 0.8052 - val_loss: 0.4084 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4061 - binary_accuracy: 0.8064 - val_loss: 0.4085 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4032 - binary_accuracy: 0.8083 - val_loss: 0.4085 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4036 - binary_accuracy: 0.8083 - val_loss: 0.4077 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4019 - binary_accuracy: 0.8095 - val_loss: 0.4076 - val_binary_accuracy: 0.8030\n","Epoch 13/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4023 - binary_accuracy: 0.8079 - val_loss: 0.4073 - val_binary_accuracy: 0.8034\n"],"name":"stdout"},{"output_type":"stream","text":["\r 64%|   | 54/84 [2:12:44<56:00, 112.02s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5138 - binary_accuracy: 0.7408 - val_loss: 0.4234 - val_binary_accuracy: 0.7959\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4247 - binary_accuracy: 0.7947 - val_loss: 0.4170 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4180 - binary_accuracy: 0.8001 - val_loss: 0.4142 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4164 - binary_accuracy: 0.7997 - val_loss: 0.4138 - val_binary_accuracy: 0.8002\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4135 - binary_accuracy: 0.8021 - val_loss: 0.4114 - val_binary_accuracy: 0.8013\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4112 - binary_accuracy: 0.8039 - val_loss: 0.4109 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4109 - binary_accuracy: 0.8030 - val_loss: 0.4113 - val_binary_accuracy: 0.8023\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4114 - binary_accuracy: 0.8032 - val_loss: 0.4098 - val_binary_accuracy: 0.8036\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4094 - binary_accuracy: 0.8039 - val_loss: 0.4096 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4066 - binary_accuracy: 0.8065 - val_loss: 0.4093 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4072 - binary_accuracy: 0.8069 - val_loss: 0.4090 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4059 - binary_accuracy: 0.8064 - val_loss: 0.4090 - val_binary_accuracy: 0.8026\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4051 - binary_accuracy: 0.8075 - val_loss: 0.4090 - val_binary_accuracy: 0.8022\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4046 - binary_accuracy: 0.8063 - val_loss: 0.4088 - val_binary_accuracy: 0.8037\n","Epoch 15/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4054 - binary_accuracy: 0.8072 - val_loss: 0.4089 - val_binary_accuracy: 0.8025\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4092 - val_binary_accuracy: 0.8036\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4002 - binary_accuracy: 0.8110 - val_loss: 0.4085 - val_binary_accuracy: 0.8026\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4065 - binary_accuracy: 0.8074 - val_loss: 0.4087 - val_binary_accuracy: 0.8026\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4043 - binary_accuracy: 0.8088 - val_loss: 0.4084 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|   | 55/84 [2:13:25<43:51, 90.74s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 20s 56ms/step - loss: 0.4680 - binary_accuracy: 0.7678 - val_loss: 0.4194 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4199 - binary_accuracy: 0.7972 - val_loss: 0.4147 - val_binary_accuracy: 0.8002\n","Epoch 3/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4133 - binary_accuracy: 0.8035 - val_loss: 0.4105 - val_binary_accuracy: 0.8031\n","Epoch 4/100\n","338/338 [==============================] - 18s 55ms/step - loss: 0.4112 - binary_accuracy: 0.8039 - val_loss: 0.4095 - val_binary_accuracy: 0.8013\n","Epoch 5/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.4089 - binary_accuracy: 0.8059 - val_loss: 0.4077 - val_binary_accuracy: 0.8020\n","Epoch 6/100\n","338/338 [==============================] - 21s 61ms/step - loss: 0.4056 - binary_accuracy: 0.8081 - val_loss: 0.4065 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","338/338 [==============================] - 21s 63ms/step - loss: 0.4049 - binary_accuracy: 0.8073 - val_loss: 0.4070 - val_binary_accuracy: 0.8035\n","Epoch 8/100\n","338/338 [==============================] - 20s 60ms/step - loss: 0.4050 - binary_accuracy: 0.8073 - val_loss: 0.4057 - val_binary_accuracy: 0.8037\n","Epoch 9/100\n","338/338 [==============================] - 20s 60ms/step - loss: 0.4021 - binary_accuracy: 0.8092 - val_loss: 0.4062 - val_binary_accuracy: 0.8040\n","Epoch 10/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.3983 - binary_accuracy: 0.8112 - val_loss: 0.4057 - val_binary_accuracy: 0.8047\n","Epoch 11/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.3990 - binary_accuracy: 0.8119 - val_loss: 0.4043 - val_binary_accuracy: 0.8057\n","Epoch 12/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.3969 - binary_accuracy: 0.8118 - val_loss: 0.4058 - val_binary_accuracy: 0.8054\n","Epoch 13/100\n","338/338 [==============================] - 19s 55ms/step - loss: 0.3960 - binary_accuracy: 0.8125 - val_loss: 0.4050 - val_binary_accuracy: 0.8050\n","Epoch 14/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.3949 - binary_accuracy: 0.8119 - val_loss: 0.4055 - val_binary_accuracy: 0.8046\n","Epoch 15/100\n","338/338 [==============================] - 18s 53ms/step - loss: 0.3945 - binary_accuracy: 0.8152 - val_loss: 0.4051 - val_binary_accuracy: 0.8050\n","Epoch 16/100\n","338/338 [==============================] - 18s 53ms/step - loss: 0.3942 - binary_accuracy: 0.8135 - val_loss: 0.4076 - val_binary_accuracy: 0.8064\n","Epoch 17/100\n","338/338 [==============================] - 18s 53ms/step - loss: 0.3873 - binary_accuracy: 0.8177 - val_loss: 0.4058 - val_binary_accuracy: 0.8061\n","Epoch 18/100\n","338/338 [==============================] - 18s 53ms/step - loss: 0.3937 - binary_accuracy: 0.8142 - val_loss: 0.4058 - val_binary_accuracy: 0.8063\n","Epoch 19/100\n","338/338 [==============================] - 20s 60ms/step - loss: 0.3903 - binary_accuracy: 0.8159 - val_loss: 0.4060 - val_binary_accuracy: 0.8053\n","Epoch 20/100\n","338/338 [==============================] - 18s 55ms/step - loss: 0.3857 - binary_accuracy: 0.8178 - val_loss: 0.4067 - val_binary_accuracy: 0.8054\n","Epoch 21/100\n","338/338 [==============================] - 18s 54ms/step - loss: 0.3886 - binary_accuracy: 0.8176 - val_loss: 0.4058 - val_binary_accuracy: 0.8050\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|   | 56/84 [2:20:05<1:25:33, 183.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5277 - binary_accuracy: 0.7272 - val_loss: 0.4267 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4309 - binary_accuracy: 0.7909 - val_loss: 0.4202 - val_binary_accuracy: 0.7966\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4239 - binary_accuracy: 0.7962 - val_loss: 0.4179 - val_binary_accuracy: 0.7986\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4219 - binary_accuracy: 0.7978 - val_loss: 0.4171 - val_binary_accuracy: 0.7979\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4202 - binary_accuracy: 0.7979 - val_loss: 0.4154 - val_binary_accuracy: 0.7993\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4190 - binary_accuracy: 0.7988 - val_loss: 0.4151 - val_binary_accuracy: 0.8001\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.7985 - val_loss: 0.4150 - val_binary_accuracy: 0.7997\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.7993 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8001 - val_loss: 0.4137 - val_binary_accuracy: 0.8008\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8014 - val_loss: 0.4133 - val_binary_accuracy: 0.8015\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8029 - val_loss: 0.4129 - val_binary_accuracy: 0.8006\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8015 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8016 - val_loss: 0.4126 - val_binary_accuracy: 0.8018\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8012 - val_loss: 0.4126 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8025 - val_loss: 0.4127 - val_binary_accuracy: 0.8011\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8022 - val_loss: 0.4124 - val_binary_accuracy: 0.8017\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8063 - val_loss: 0.4121 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8019 - val_loss: 0.4124 - val_binary_accuracy: 0.8019\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8040 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n"],"name":"stdout"},{"output_type":"stream","text":["\r 68%|   | 57/84 [2:20:25<1:00:26, 134.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.4853 - binary_accuracy: 0.7546 - val_loss: 0.4214 - val_binary_accuracy: 0.7960\n","Epoch 2/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4286 - binary_accuracy: 0.7931 - val_loss: 0.4157 - val_binary_accuracy: 0.7986\n","Epoch 3/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4208 - binary_accuracy: 0.7992 - val_loss: 0.4137 - val_binary_accuracy: 0.8004\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4179 - binary_accuracy: 0.8003 - val_loss: 0.4130 - val_binary_accuracy: 0.8001\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4160 - binary_accuracy: 0.8015 - val_loss: 0.4106 - val_binary_accuracy: 0.8017\n","Epoch 6/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4135 - binary_accuracy: 0.8038 - val_loss: 0.4101 - val_binary_accuracy: 0.8028\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4138 - binary_accuracy: 0.8028 - val_loss: 0.4106 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4131 - binary_accuracy: 0.8037 - val_loss: 0.4090 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4113 - binary_accuracy: 0.8045 - val_loss: 0.4091 - val_binary_accuracy: 0.8030\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4085 - binary_accuracy: 0.8069 - val_loss: 0.4084 - val_binary_accuracy: 0.8039\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4080 - binary_accuracy: 0.8069 - val_loss: 0.4077 - val_binary_accuracy: 0.8038\n","Epoch 12/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4071 - binary_accuracy: 0.8066 - val_loss: 0.4078 - val_binary_accuracy: 0.8031\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4067 - binary_accuracy: 0.8064 - val_loss: 0.4075 - val_binary_accuracy: 0.8037\n","Epoch 14/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4066 - binary_accuracy: 0.8069 - val_loss: 0.4072 - val_binary_accuracy: 0.8039\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4062 - binary_accuracy: 0.8079 - val_loss: 0.4077 - val_binary_accuracy: 0.8033\n","Epoch 16/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4074 - binary_accuracy: 0.8068 - val_loss: 0.4073 - val_binary_accuracy: 0.8037\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4013 - binary_accuracy: 0.8105 - val_loss: 0.4069 - val_binary_accuracy: 0.8045\n","Epoch 18/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4070 - binary_accuracy: 0.8076 - val_loss: 0.4070 - val_binary_accuracy: 0.8038\n","Epoch 19/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4051 - binary_accuracy: 0.8087 - val_loss: 0.4065 - val_binary_accuracy: 0.8038\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4021 - binary_accuracy: 0.8105 - val_loss: 0.4070 - val_binary_accuracy: 0.8038\n","Epoch 21/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4043 - binary_accuracy: 0.8088 - val_loss: 0.4058 - val_binary_accuracy: 0.8043\n","Epoch 22/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4012 - binary_accuracy: 0.8100 - val_loss: 0.4061 - val_binary_accuracy: 0.8043\n"],"name":"stdout"},{"output_type":"stream","text":["\r 69%|   | 58/84 [2:21:34<49:47, 114.92s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 13s 34ms/step - loss: 0.5333 - binary_accuracy: 0.7313 - val_loss: 0.4330 - val_binary_accuracy: 0.7936\n","Epoch 2/100\n","338/338 [==============================] - 11s 34ms/step - loss: 0.4406 - binary_accuracy: 0.7900 - val_loss: 0.4216 - val_binary_accuracy: 0.7976\n","Epoch 3/100\n","338/338 [==============================] - 11s 34ms/step - loss: 0.4320 - binary_accuracy: 0.7958 - val_loss: 0.4230 - val_binary_accuracy: 0.7993\n","Epoch 4/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4291 - binary_accuracy: 0.7983 - val_loss: 0.4186 - val_binary_accuracy: 0.7973\n","Epoch 5/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4262 - binary_accuracy: 0.8004 - val_loss: 0.4159 - val_binary_accuracy: 0.8015\n","Epoch 6/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4223 - binary_accuracy: 0.8013 - val_loss: 0.4167 - val_binary_accuracy: 0.8023\n","Epoch 7/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4214 - binary_accuracy: 0.8012 - val_loss: 0.4120 - val_binary_accuracy: 0.8035\n","Epoch 8/100\n","338/338 [==============================] - 12s 35ms/step - loss: 0.4202 - binary_accuracy: 0.8012 - val_loss: 0.4157 - val_binary_accuracy: 0.8022\n","Epoch 9/100\n","338/338 [==============================] - 11s 34ms/step - loss: 0.4184 - binary_accuracy: 0.8019 - val_loss: 0.4116 - val_binary_accuracy: 0.8029\n","Epoch 10/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4149 - binary_accuracy: 0.8044 - val_loss: 0.4116 - val_binary_accuracy: 0.8036\n","Epoch 11/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4148 - binary_accuracy: 0.8046 - val_loss: 0.4127 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4132 - binary_accuracy: 0.8046 - val_loss: 0.4179 - val_binary_accuracy: 0.8028\n","Epoch 13/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4121 - binary_accuracy: 0.8045 - val_loss: 0.4153 - val_binary_accuracy: 0.8032\n","Epoch 14/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4124 - binary_accuracy: 0.8053 - val_loss: 0.4101 - val_binary_accuracy: 0.8048\n","Epoch 15/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4111 - binary_accuracy: 0.8056 - val_loss: 0.4158 - val_binary_accuracy: 0.8038\n","Epoch 16/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4124 - binary_accuracy: 0.8047 - val_loss: 0.4108 - val_binary_accuracy: 0.8033\n","Epoch 17/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4060 - binary_accuracy: 0.8093 - val_loss: 0.4111 - val_binary_accuracy: 0.8025\n","Epoch 18/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4125 - binary_accuracy: 0.8059 - val_loss: 0.4118 - val_binary_accuracy: 0.8037\n","Epoch 19/100\n","338/338 [==============================] - 11s 33ms/step - loss: 0.4094 - binary_accuracy: 0.8067 - val_loss: 0.4112 - val_binary_accuracy: 0.8029\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|   | 59/84 [2:25:09<1:00:24, 144.99s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 11s 31ms/step - loss: 0.4714 - binary_accuracy: 0.7641 - val_loss: 0.4200 - val_binary_accuracy: 0.7974\n","Epoch 2/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4224 - binary_accuracy: 0.7962 - val_loss: 0.4139 - val_binary_accuracy: 0.8000\n","Epoch 3/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4163 - binary_accuracy: 0.8013 - val_loss: 0.4115 - val_binary_accuracy: 0.8017\n","Epoch 4/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4138 - binary_accuracy: 0.8010 - val_loss: 0.4099 - val_binary_accuracy: 0.8016\n","Epoch 5/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4114 - binary_accuracy: 0.8026 - val_loss: 0.4082 - val_binary_accuracy: 0.8024\n","Epoch 6/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4088 - binary_accuracy: 0.8053 - val_loss: 0.4078 - val_binary_accuracy: 0.8043\n","Epoch 7/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4075 - binary_accuracy: 0.8053 - val_loss: 0.4079 - val_binary_accuracy: 0.8038\n","Epoch 8/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4081 - binary_accuracy: 0.8054 - val_loss: 0.4064 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4051 - binary_accuracy: 0.8074 - val_loss: 0.4067 - val_binary_accuracy: 0.8036\n","Epoch 10/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.4020 - binary_accuracy: 0.8101 - val_loss: 0.4065 - val_binary_accuracy: 0.8038\n","Epoch 11/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4026 - binary_accuracy: 0.8096 - val_loss: 0.4054 - val_binary_accuracy: 0.8039\n","Epoch 12/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4013 - binary_accuracy: 0.8101 - val_loss: 0.4063 - val_binary_accuracy: 0.8042\n","Epoch 13/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.3995 - binary_accuracy: 0.8096 - val_loss: 0.4056 - val_binary_accuracy: 0.8041\n"],"name":"stdout"},{"output_type":"stream","text":["\r 71%|  | 60/84 [2:27:22<56:29, 141.22s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5157 - binary_accuracy: 0.7327 - val_loss: 0.4256 - val_binary_accuracy: 0.7933\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4346 - binary_accuracy: 0.7906 - val_loss: 0.4190 - val_binary_accuracy: 0.7976\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4269 - binary_accuracy: 0.7969 - val_loss: 0.4167 - val_binary_accuracy: 0.7993\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4152 - val_binary_accuracy: 0.7990\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4216 - binary_accuracy: 0.7976 - val_loss: 0.4132 - val_binary_accuracy: 0.8011\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4199 - binary_accuracy: 0.7989 - val_loss: 0.4128 - val_binary_accuracy: 0.8009\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4193 - binary_accuracy: 0.7992 - val_loss: 0.4131 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4198 - binary_accuracy: 0.8001 - val_loss: 0.4114 - val_binary_accuracy: 0.8016\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4171 - binary_accuracy: 0.8016 - val_loss: 0.4108 - val_binary_accuracy: 0.8017\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4145 - binary_accuracy: 0.8031 - val_loss: 0.4106 - val_binary_accuracy: 0.8027\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4146 - binary_accuracy: 0.8033 - val_loss: 0.4099 - val_binary_accuracy: 0.8022\n","Epoch 12/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4148 - binary_accuracy: 0.8039 - val_loss: 0.4098 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4127 - binary_accuracy: 0.8038 - val_loss: 0.4093 - val_binary_accuracy: 0.8030\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4121 - binary_accuracy: 0.8041 - val_loss: 0.4093 - val_binary_accuracy: 0.8030\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4126 - binary_accuracy: 0.8040 - val_loss: 0.4095 - val_binary_accuracy: 0.8025\n","Epoch 16/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4135 - binary_accuracy: 0.8042 - val_loss: 0.4088 - val_binary_accuracy: 0.8028\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4073 - binary_accuracy: 0.8084 - val_loss: 0.4085 - val_binary_accuracy: 0.8027\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4147 - binary_accuracy: 0.8045 - val_loss: 0.4085 - val_binary_accuracy: 0.8037\n","Epoch 19/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4114 - binary_accuracy: 0.8054 - val_loss: 0.4084 - val_binary_accuracy: 0.8038\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4083 - binary_accuracy: 0.8079 - val_loss: 0.4085 - val_binary_accuracy: 0.8040\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4107 - binary_accuracy: 0.8050 - val_loss: 0.4076 - val_binary_accuracy: 0.8031\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4092 - binary_accuracy: 0.8067 - val_loss: 0.4077 - val_binary_accuracy: 0.8042\n","Epoch 23/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4071 - binary_accuracy: 0.8084 - val_loss: 0.4077 - val_binary_accuracy: 0.8040\n","Epoch 24/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4082 - binary_accuracy: 0.8060 - val_loss: 0.4070 - val_binary_accuracy: 0.8042\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4074 - binary_accuracy: 0.8081 - val_loss: 0.4073 - val_binary_accuracy: 0.8039\n","Epoch 26/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4091 - binary_accuracy: 0.8065 - val_loss: 0.4074 - val_binary_accuracy: 0.8043\n","Epoch 27/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4076 - binary_accuracy: 0.8087 - val_loss: 0.4071 - val_binary_accuracy: 0.8045\n","Epoch 28/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4086 - binary_accuracy: 0.8075 - val_loss: 0.4069 - val_binary_accuracy: 0.8051\n","Epoch 29/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4090 - binary_accuracy: 0.8058 - val_loss: 0.4071 - val_binary_accuracy: 0.8042\n","Epoch 30/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4075 - binary_accuracy: 0.8082 - val_loss: 0.4072 - val_binary_accuracy: 0.8054\n","Epoch 31/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4095 - binary_accuracy: 0.8076 - val_loss: 0.4070 - val_binary_accuracy: 0.8044\n","Epoch 32/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4071 - binary_accuracy: 0.8088 - val_loss: 0.4068 - val_binary_accuracy: 0.8052\n","Epoch 33/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4062 - binary_accuracy: 0.8092 - val_loss: 0.4068 - val_binary_accuracy: 0.8051\n","Epoch 34/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4071 - binary_accuracy: 0.8091 - val_loss: 0.4072 - val_binary_accuracy: 0.8044\n","Epoch 35/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4081 - binary_accuracy: 0.8084 - val_loss: 0.4064 - val_binary_accuracy: 0.8047\n"],"name":"stdout"},{"output_type":"stream","text":["\r 73%|  | 61/84 [2:28:27<45:24, 118.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.5283 - binary_accuracy: 0.7554 - val_loss: 0.4192 - val_binary_accuracy: 0.7976\n","Epoch 2/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4178 - binary_accuracy: 0.7989 - val_loss: 0.4144 - val_binary_accuracy: 0.8004\n","Epoch 3/100\n","338/338 [==============================] - 8s 24ms/step - loss: 0.4130 - binary_accuracy: 0.8035 - val_loss: 0.4119 - val_binary_accuracy: 0.8015\n","Epoch 4/100\n","338/338 [==============================] - 8s 23ms/step - loss: 0.4114 - binary_accuracy: 0.8033 - val_loss: 0.4116 - val_binary_accuracy: 0.8004\n","Epoch 5/100\n","338/338 [==============================] - 8s 24ms/step - loss: 0.4103 - binary_accuracy: 0.8050 - val_loss: 0.4091 - val_binary_accuracy: 0.8018\n","Epoch 6/100\n","338/338 [==============================] - 8s 24ms/step - loss: 0.4064 - binary_accuracy: 0.8065 - val_loss: 0.4089 - val_binary_accuracy: 0.8036\n","Epoch 7/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4071 - binary_accuracy: 0.8050 - val_loss: 0.4096 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4078 - binary_accuracy: 0.8056 - val_loss: 0.4082 - val_binary_accuracy: 0.8035\n","Epoch 9/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4048 - binary_accuracy: 0.8074 - val_loss: 0.4081 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4018 - binary_accuracy: 0.8091 - val_loss: 0.4076 - val_binary_accuracy: 0.8033\n","Epoch 11/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4018 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4010 - binary_accuracy: 0.8080 - val_loss: 0.4072 - val_binary_accuracy: 0.8031\n","Epoch 13/100\n","338/338 [==============================] - 8s 24ms/step - loss: 0.4009 - binary_accuracy: 0.8082 - val_loss: 0.4076 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.3995 - binary_accuracy: 0.8094 - val_loss: 0.4074 - val_binary_accuracy: 0.8041\n","Epoch 15/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.3992 - binary_accuracy: 0.8107 - val_loss: 0.4078 - val_binary_accuracy: 0.8032\n","Epoch 16/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.4001 - binary_accuracy: 0.8102 - val_loss: 0.4081 - val_binary_accuracy: 0.8044\n","Epoch 17/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.3939 - binary_accuracy: 0.8143 - val_loss: 0.4070 - val_binary_accuracy: 0.8037\n","Epoch 18/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.4000 - binary_accuracy: 0.8092 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 19/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.3974 - binary_accuracy: 0.8134 - val_loss: 0.4064 - val_binary_accuracy: 0.8039\n","Epoch 20/100\n","338/338 [==============================] - 7s 22ms/step - loss: 0.3942 - binary_accuracy: 0.8134 - val_loss: 0.4088 - val_binary_accuracy: 0.8033\n","Epoch 21/100\n","338/338 [==============================] - 8s 22ms/step - loss: 0.3969 - binary_accuracy: 0.8129 - val_loss: 0.4057 - val_binary_accuracy: 0.8049\n","Epoch 22/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.3937 - binary_accuracy: 0.8127 - val_loss: 0.4063 - val_binary_accuracy: 0.8043\n","Epoch 23/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3927 - binary_accuracy: 0.8153 - val_loss: 0.4063 - val_binary_accuracy: 0.8044\n","Epoch 24/100\n","338/338 [==============================] - 10s 29ms/step - loss: 0.3930 - binary_accuracy: 0.8136 - val_loss: 0.4058 - val_binary_accuracy: 0.8045\n","Epoch 25/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.3909 - binary_accuracy: 0.8152 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 26/100\n","338/338 [==============================] - 9s 28ms/step - loss: 0.3940 - binary_accuracy: 0.8131 - val_loss: 0.4058 - val_binary_accuracy: 0.8047\n"],"name":"stdout"},{"output_type":"stream","text":["\r 74%|  | 62/84 [2:31:57<53:27, 145.78s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 18s 52ms/step - loss: 0.4672 - binary_accuracy: 0.7697 - val_loss: 0.4191 - val_binary_accuracy: 0.7975\n","Epoch 2/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4207 - binary_accuracy: 0.7960 - val_loss: 0.4142 - val_binary_accuracy: 0.7999\n","Epoch 3/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4138 - binary_accuracy: 0.8037 - val_loss: 0.4107 - val_binary_accuracy: 0.8020\n","Epoch 4/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4116 - binary_accuracy: 0.8036 - val_loss: 0.4092 - val_binary_accuracy: 0.8019\n","Epoch 5/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4099 - binary_accuracy: 0.8052 - val_loss: 0.4076 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4064 - binary_accuracy: 0.8073 - val_loss: 0.4064 - val_binary_accuracy: 0.8039\n","Epoch 7/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4058 - binary_accuracy: 0.8065 - val_loss: 0.4067 - val_binary_accuracy: 0.8044\n","Epoch 8/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4056 - binary_accuracy: 0.8071 - val_loss: 0.4056 - val_binary_accuracy: 0.8034\n","Epoch 9/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.4029 - binary_accuracy: 0.8089 - val_loss: 0.4062 - val_binary_accuracy: 0.8041\n","Epoch 10/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3985 - binary_accuracy: 0.8125 - val_loss: 0.4053 - val_binary_accuracy: 0.8048\n","Epoch 11/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3990 - binary_accuracy: 0.8120 - val_loss: 0.4044 - val_binary_accuracy: 0.8052\n","Epoch 12/100\n","338/338 [==============================] - 18s 52ms/step - loss: 0.3982 - binary_accuracy: 0.8111 - val_loss: 0.4049 - val_binary_accuracy: 0.8047\n","Epoch 13/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3968 - binary_accuracy: 0.8127 - val_loss: 0.4048 - val_binary_accuracy: 0.8059\n","Epoch 14/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3959 - binary_accuracy: 0.8109 - val_loss: 0.4048 - val_binary_accuracy: 0.8043\n","Epoch 15/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3958 - binary_accuracy: 0.8136 - val_loss: 0.4045 - val_binary_accuracy: 0.8046\n","Epoch 16/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3949 - binary_accuracy: 0.8137 - val_loss: 0.4072 - val_binary_accuracy: 0.8049\n","Epoch 17/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3899 - binary_accuracy: 0.8168 - val_loss: 0.4056 - val_binary_accuracy: 0.8056\n","Epoch 18/100\n","338/338 [==============================] - 17s 51ms/step - loss: 0.3948 - binary_accuracy: 0.8134 - val_loss: 0.4048 - val_binary_accuracy: 0.8052\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|  | 63/84 [2:37:09<1:08:30, 195.75s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 15ms/step - loss: 0.4907 - binary_accuracy: 0.7528 - val_loss: 0.4213 - val_binary_accuracy: 0.7959\n","Epoch 2/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4274 - binary_accuracy: 0.7940 - val_loss: 0.4159 - val_binary_accuracy: 0.7985\n","Epoch 3/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4208 - binary_accuracy: 0.7995 - val_loss: 0.4141 - val_binary_accuracy: 0.8000\n","Epoch 4/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4181 - binary_accuracy: 0.7999 - val_loss: 0.4131 - val_binary_accuracy: 0.8005\n","Epoch 5/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4166 - binary_accuracy: 0.8005 - val_loss: 0.4105 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4127 - binary_accuracy: 0.8031 - val_loss: 0.4101 - val_binary_accuracy: 0.8024\n","Epoch 7/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4126 - binary_accuracy: 0.8020 - val_loss: 0.4103 - val_binary_accuracy: 0.8031\n","Epoch 8/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4132 - binary_accuracy: 0.8037 - val_loss: 0.4088 - val_binary_accuracy: 0.8029\n","Epoch 9/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4104 - binary_accuracy: 0.8048 - val_loss: 0.4083 - val_binary_accuracy: 0.8034\n","Epoch 10/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4076 - binary_accuracy: 0.8067 - val_loss: 0.4081 - val_binary_accuracy: 0.8032\n","Epoch 11/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4077 - binary_accuracy: 0.8071 - val_loss: 0.4075 - val_binary_accuracy: 0.8034\n","Epoch 12/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4072 - binary_accuracy: 0.8058 - val_loss: 0.4079 - val_binary_accuracy: 0.8039\n","Epoch 13/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4063 - binary_accuracy: 0.8064 - val_loss: 0.4071 - val_binary_accuracy: 0.8031\n","Epoch 14/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4057 - binary_accuracy: 0.8071 - val_loss: 0.4067 - val_binary_accuracy: 0.8043\n","Epoch 15/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4053 - binary_accuracy: 0.8081 - val_loss: 0.4077 - val_binary_accuracy: 0.8034\n","Epoch 16/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4065 - binary_accuracy: 0.8068 - val_loss: 0.4071 - val_binary_accuracy: 0.8048\n","Epoch 17/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4000 - binary_accuracy: 0.8108 - val_loss: 0.4066 - val_binary_accuracy: 0.8039\n","Epoch 18/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4053 - binary_accuracy: 0.8082 - val_loss: 0.4065 - val_binary_accuracy: 0.8039\n","Epoch 19/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4036 - binary_accuracy: 0.8090 - val_loss: 0.4062 - val_binary_accuracy: 0.8047\n","Epoch 20/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4001 - binary_accuracy: 0.8111 - val_loss: 0.4068 - val_binary_accuracy: 0.8052\n","Epoch 21/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4032 - binary_accuracy: 0.8095 - val_loss: 0.4051 - val_binary_accuracy: 0.8054\n","Epoch 22/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4009 - binary_accuracy: 0.8101 - val_loss: 0.4059 - val_binary_accuracy: 0.8053\n","Epoch 23/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3991 - binary_accuracy: 0.8112 - val_loss: 0.4068 - val_binary_accuracy: 0.8052\n","Epoch 24/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4008 - binary_accuracy: 0.8101 - val_loss: 0.4052 - val_binary_accuracy: 0.8044\n","Epoch 25/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.3985 - binary_accuracy: 0.8115 - val_loss: 0.4057 - val_binary_accuracy: 0.8050\n","Epoch 26/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4009 - binary_accuracy: 0.8106 - val_loss: 0.4057 - val_binary_accuracy: 0.8050\n"],"name":"stdout"},{"output_type":"stream","text":["\r 76%|  | 64/84 [2:39:16<58:22, 175.13s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.6040 - binary_accuracy: 0.6677 - val_loss: 0.4367 - val_binary_accuracy: 0.7897\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4840 - binary_accuracy: 0.7711 - val_loss: 0.4259 - val_binary_accuracy: 0.7941\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4690 - binary_accuracy: 0.7785 - val_loss: 0.4242 - val_binary_accuracy: 0.7953\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4643 - binary_accuracy: 0.7797 - val_loss: 0.4228 - val_binary_accuracy: 0.7947\n","Epoch 5/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4612 - binary_accuracy: 0.7818 - val_loss: 0.4216 - val_binary_accuracy: 0.7952\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4590 - binary_accuracy: 0.7812 - val_loss: 0.4216 - val_binary_accuracy: 0.7961\n","Epoch 7/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4592 - binary_accuracy: 0.7825 - val_loss: 0.4215 - val_binary_accuracy: 0.7950\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4575 - binary_accuracy: 0.7828 - val_loss: 0.4206 - val_binary_accuracy: 0.7958\n","Epoch 9/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4542 - binary_accuracy: 0.7838 - val_loss: 0.4208 - val_binary_accuracy: 0.7958\n","Epoch 10/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4530 - binary_accuracy: 0.7868 - val_loss: 0.4203 - val_binary_accuracy: 0.7966\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4511 - binary_accuracy: 0.7862 - val_loss: 0.4194 - val_binary_accuracy: 0.7967\n","Epoch 12/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4506 - binary_accuracy: 0.7854 - val_loss: 0.4198 - val_binary_accuracy: 0.7969\n","Epoch 13/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4491 - binary_accuracy: 0.7873 - val_loss: 0.4186 - val_binary_accuracy: 0.7980\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4501 - binary_accuracy: 0.7853 - val_loss: 0.4183 - val_binary_accuracy: 0.7978\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4484 - binary_accuracy: 0.7886 - val_loss: 0.4193 - val_binary_accuracy: 0.7981\n","Epoch 16/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4501 - binary_accuracy: 0.7872 - val_loss: 0.4180 - val_binary_accuracy: 0.7975\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4439 - binary_accuracy: 0.7922 - val_loss: 0.4186 - val_binary_accuracy: 0.7979\n","Epoch 18/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4494 - binary_accuracy: 0.7880 - val_loss: 0.4187 - val_binary_accuracy: 0.7977\n","Epoch 19/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4466 - binary_accuracy: 0.7915 - val_loss: 0.4179 - val_binary_accuracy: 0.7983\n","Epoch 20/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4446 - binary_accuracy: 0.7918 - val_loss: 0.4171 - val_binary_accuracy: 0.7989\n","Epoch 21/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4458 - binary_accuracy: 0.7906 - val_loss: 0.4168 - val_binary_accuracy: 0.7987\n","Epoch 22/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4428 - binary_accuracy: 0.7929 - val_loss: 0.4182 - val_binary_accuracy: 0.7981\n","Epoch 23/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4426 - binary_accuracy: 0.7939 - val_loss: 0.4170 - val_binary_accuracy: 0.7984\n","Epoch 24/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4450 - binary_accuracy: 0.7911 - val_loss: 0.4162 - val_binary_accuracy: 0.7990\n","Epoch 25/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4427 - binary_accuracy: 0.7937 - val_loss: 0.4164 - val_binary_accuracy: 0.7981\n","Epoch 26/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4439 - binary_accuracy: 0.7930 - val_loss: 0.4168 - val_binary_accuracy: 0.7987\n","Epoch 27/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4421 - binary_accuracy: 0.7928 - val_loss: 0.4164 - val_binary_accuracy: 0.7993\n","Epoch 28/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4419 - binary_accuracy: 0.7938 - val_loss: 0.4155 - val_binary_accuracy: 0.7998\n","Epoch 29/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4419 - binary_accuracy: 0.7940 - val_loss: 0.4152 - val_binary_accuracy: 0.8008\n","Epoch 30/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4435 - binary_accuracy: 0.7919 - val_loss: 0.4159 - val_binary_accuracy: 0.7997\n","Epoch 31/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4429 - binary_accuracy: 0.7936 - val_loss: 0.4155 - val_binary_accuracy: 0.8000\n","Epoch 32/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4403 - binary_accuracy: 0.7949 - val_loss: 0.4153 - val_binary_accuracy: 0.7999\n","Epoch 33/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4396 - binary_accuracy: 0.7960 - val_loss: 0.4158 - val_binary_accuracy: 0.8003\n","Epoch 34/100\n","338/338 [==============================] - 2s 4ms/step - loss: 0.4423 - binary_accuracy: 0.7940 - val_loss: 0.4164 - val_binary_accuracy: 0.7999\n"],"name":"stdout"},{"output_type":"stream","text":["\r 77%|  | 65/84 [2:40:09<43:51, 138.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.5505 - binary_accuracy: 0.7055 - val_loss: 0.4290 - val_binary_accuracy: 0.7920\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4395 - binary_accuracy: 0.7883 - val_loss: 0.4210 - val_binary_accuracy: 0.7958\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4311 - binary_accuracy: 0.7947 - val_loss: 0.4204 - val_binary_accuracy: 0.7976\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4283 - binary_accuracy: 0.7957 - val_loss: 0.4191 - val_binary_accuracy: 0.7976\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4260 - binary_accuracy: 0.7972 - val_loss: 0.4176 - val_binary_accuracy: 0.7988\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4248 - binary_accuracy: 0.7983 - val_loss: 0.4189 - val_binary_accuracy: 0.7995\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4245 - binary_accuracy: 0.7977 - val_loss: 0.4192 - val_binary_accuracy: 0.7998\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4227 - binary_accuracy: 0.7982 - val_loss: 0.4218 - val_binary_accuracy: 0.8008\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4198 - binary_accuracy: 0.7993 - val_loss: 0.4238 - val_binary_accuracy: 0.8010\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4176 - binary_accuracy: 0.8012 - val_loss: 0.4280 - val_binary_accuracy: 0.8014\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4178 - binary_accuracy: 0.8022 - val_loss: 0.4329 - val_binary_accuracy: 0.8008\n","Epoch 12/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4166 - binary_accuracy: 0.8019 - val_loss: 0.4405 - val_binary_accuracy: 0.8008\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4154 - binary_accuracy: 0.8016 - val_loss: 0.4395 - val_binary_accuracy: 0.8010\n","Epoch 14/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4146 - binary_accuracy: 0.8014 - val_loss: 0.4405 - val_binary_accuracy: 0.8019\n","Epoch 15/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4150 - binary_accuracy: 0.8020 - val_loss: 0.4570 - val_binary_accuracy: 0.8012\n","Epoch 16/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4155 - binary_accuracy: 0.8015 - val_loss: 0.4560 - val_binary_accuracy: 0.8008\n","Epoch 17/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8057 - val_loss: 0.4647 - val_binary_accuracy: 0.8001\n","Epoch 18/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4160 - binary_accuracy: 0.8009 - val_loss: 0.4628 - val_binary_accuracy: 0.8008\n","Epoch 19/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4127 - binary_accuracy: 0.8025 - val_loss: 0.4654 - val_binary_accuracy: 0.8025\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4696 - val_binary_accuracy: 0.8003\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4126 - binary_accuracy: 0.8029 - val_loss: 0.4742 - val_binary_accuracy: 0.7991\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8045 - val_loss: 0.4826 - val_binary_accuracy: 0.7999\n","Epoch 23/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4081 - binary_accuracy: 0.8066 - val_loss: 0.4837 - val_binary_accuracy: 0.7992\n","Epoch 24/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4100 - binary_accuracy: 0.8033 - val_loss: 0.4898 - val_binary_accuracy: 0.7978\n"],"name":"stdout"},{"output_type":"stream","text":["\r 79%|  | 66/84 [2:40:53<33:00, 110.04s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 2, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 16ms/step - loss: 0.4845 - binary_accuracy: 0.7561 - val_loss: 0.4204 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4272 - binary_accuracy: 0.7937 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 3/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4187 - binary_accuracy: 0.7996 - val_loss: 0.4132 - val_binary_accuracy: 0.8004\n","Epoch 4/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4170 - binary_accuracy: 0.8013 - val_loss: 0.4123 - val_binary_accuracy: 0.8007\n","Epoch 5/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4154 - binary_accuracy: 0.8015 - val_loss: 0.4100 - val_binary_accuracy: 0.8024\n","Epoch 6/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4114 - binary_accuracy: 0.8046 - val_loss: 0.4095 - val_binary_accuracy: 0.8028\n","Epoch 7/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4117 - binary_accuracy: 0.8030 - val_loss: 0.4102 - val_binary_accuracy: 0.8032\n","Epoch 8/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4117 - binary_accuracy: 0.8049 - val_loss: 0.4083 - val_binary_accuracy: 0.8034\n","Epoch 9/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4091 - binary_accuracy: 0.8042 - val_loss: 0.4081 - val_binary_accuracy: 0.8037\n","Epoch 10/100\n","338/338 [==============================] - 5s 14ms/step - loss: 0.4063 - binary_accuracy: 0.8065 - val_loss: 0.4077 - val_binary_accuracy: 0.8044\n","Epoch 11/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4059 - binary_accuracy: 0.8082 - val_loss: 0.4066 - val_binary_accuracy: 0.8041\n","Epoch 12/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4060 - binary_accuracy: 0.8071 - val_loss: 0.4071 - val_binary_accuracy: 0.8039\n","Epoch 13/100\n","338/338 [==============================] - 4s 13ms/step - loss: 0.4049 - binary_accuracy: 0.8062 - val_loss: 0.4066 - val_binary_accuracy: 0.8038\n","Epoch 14/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4050 - binary_accuracy: 0.8069 - val_loss: 0.4059 - val_binary_accuracy: 0.8041\n","Epoch 15/100\n","338/338 [==============================] - 4s 12ms/step - loss: 0.4046 - binary_accuracy: 0.8075 - val_loss: 0.4072 - val_binary_accuracy: 0.8042\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|  | 67/84 [2:42:06<28:02, 99.00s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 100, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 9ms/step - loss: 0.5893 - binary_accuracy: 0.6873 - val_loss: 0.4331 - val_binary_accuracy: 0.7889\n","Epoch 2/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4631 - binary_accuracy: 0.7801 - val_loss: 0.4223 - val_binary_accuracy: 0.7965\n","Epoch 3/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4503 - binary_accuracy: 0.7915 - val_loss: 0.4207 - val_binary_accuracy: 0.7975\n","Epoch 4/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4447 - binary_accuracy: 0.7912 - val_loss: 0.4190 - val_binary_accuracy: 0.7980\n","Epoch 5/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4403 - binary_accuracy: 0.7948 - val_loss: 0.4165 - val_binary_accuracy: 0.8003\n","Epoch 6/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4369 - binary_accuracy: 0.7966 - val_loss: 0.4162 - val_binary_accuracy: 0.8002\n","Epoch 7/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4379 - binary_accuracy: 0.7959 - val_loss: 0.4154 - val_binary_accuracy: 0.8006\n","Epoch 8/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4369 - binary_accuracy: 0.7962 - val_loss: 0.4146 - val_binary_accuracy: 0.8010\n","Epoch 9/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4338 - binary_accuracy: 0.7979 - val_loss: 0.4147 - val_binary_accuracy: 0.8011\n","Epoch 10/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4310 - binary_accuracy: 0.8005 - val_loss: 0.4146 - val_binary_accuracy: 0.8017\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4305 - binary_accuracy: 0.8009 - val_loss: 0.4130 - val_binary_accuracy: 0.8011\n","Epoch 12/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4304 - binary_accuracy: 0.8009 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 13/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4285 - binary_accuracy: 0.8016 - val_loss: 0.4123 - val_binary_accuracy: 0.8010\n","Epoch 14/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4285 - binary_accuracy: 0.8002 - val_loss: 0.4122 - val_binary_accuracy: 0.8021\n","Epoch 15/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4289 - binary_accuracy: 0.8002 - val_loss: 0.4124 - val_binary_accuracy: 0.8018\n","Epoch 16/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4294 - binary_accuracy: 0.8010 - val_loss: 0.4113 - val_binary_accuracy: 0.8027\n","Epoch 17/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4225 - binary_accuracy: 0.8043 - val_loss: 0.4116 - val_binary_accuracy: 0.8014\n","Epoch 18/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4300 - binary_accuracy: 0.8007 - val_loss: 0.4112 - val_binary_accuracy: 0.8030\n","Epoch 19/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4256 - binary_accuracy: 0.8023 - val_loss: 0.4115 - val_binary_accuracy: 0.8030\n","Epoch 20/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4231 - binary_accuracy: 0.8043 - val_loss: 0.4109 - val_binary_accuracy: 0.8027\n","Epoch 21/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4246 - binary_accuracy: 0.8033 - val_loss: 0.4101 - val_binary_accuracy: 0.8029\n","Epoch 22/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4243 - binary_accuracy: 0.8036 - val_loss: 0.4108 - val_binary_accuracy: 0.8039\n","Epoch 23/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4216 - binary_accuracy: 0.8052 - val_loss: 0.4118 - val_binary_accuracy: 0.8027\n","Epoch 24/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4232 - binary_accuracy: 0.8040 - val_loss: 0.4095 - val_binary_accuracy: 0.8029\n","Epoch 25/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4219 - binary_accuracy: 0.8044 - val_loss: 0.4100 - val_binary_accuracy: 0.8033\n","Epoch 26/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4239 - binary_accuracy: 0.8046 - val_loss: 0.4095 - val_binary_accuracy: 0.8041\n","Epoch 27/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4225 - binary_accuracy: 0.8048 - val_loss: 0.4090 - val_binary_accuracy: 0.8045\n","Epoch 28/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4221 - binary_accuracy: 0.8035 - val_loss: 0.4092 - val_binary_accuracy: 0.8043\n","Epoch 29/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4219 - binary_accuracy: 0.8036 - val_loss: 0.4090 - val_binary_accuracy: 0.8039\n","Epoch 30/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4223 - binary_accuracy: 0.8053 - val_loss: 0.4096 - val_binary_accuracy: 0.8041\n","Epoch 31/100\n","338/338 [==============================] - 3s 8ms/step - loss: 0.4234 - binary_accuracy: 0.8052 - val_loss: 0.4094 - val_binary_accuracy: 0.8035\n","Epoch 32/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4211 - binary_accuracy: 0.8060 - val_loss: 0.4102 - val_binary_accuracy: 0.8047\n","Epoch 33/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4196 - binary_accuracy: 0.8066 - val_loss: 0.4101 - val_binary_accuracy: 0.8051\n","Epoch 34/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4212 - binary_accuracy: 0.8066 - val_loss: 0.4090 - val_binary_accuracy: 0.8048\n","Epoch 35/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4213 - binary_accuracy: 0.8057 - val_loss: 0.4095 - val_binary_accuracy: 0.8042\n","Epoch 36/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4208 - binary_accuracy: 0.8068 - val_loss: 0.4086 - val_binary_accuracy: 0.8043\n","Epoch 37/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4215 - binary_accuracy: 0.8054 - val_loss: 0.4088 - val_binary_accuracy: 0.8038\n","Epoch 38/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4222 - binary_accuracy: 0.8058 - val_loss: 0.4094 - val_binary_accuracy: 0.8034\n"],"name":"stdout"},{"output_type":"stream","text":["\r 81%|  | 68/84 [2:43:57<27:20, 102.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 6ms/step - loss: 0.6194 - binary_accuracy: 0.6615 - val_loss: 0.4888 - val_binary_accuracy: 0.7856\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4885 - binary_accuracy: 0.7621 - val_loss: 0.5055 - val_binary_accuracy: 0.7861\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4646 - binary_accuracy: 0.7797 - val_loss: 0.5255 - val_binary_accuracy: 0.7789\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4543 - binary_accuracy: 0.7834 - val_loss: 0.5374 - val_binary_accuracy: 0.7709\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4459 - binary_accuracy: 0.7891 - val_loss: 0.5341 - val_binary_accuracy: 0.7651\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4414 - binary_accuracy: 0.7909 - val_loss: 0.5583 - val_binary_accuracy: 0.7414\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4394 - binary_accuracy: 0.7904 - val_loss: 0.5685 - val_binary_accuracy: 0.7186\n"],"name":"stdout"},{"output_type":"stream","text":["\r 82%| | 69/84 [2:44:11<19:02, 76.16s/it] "],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.5801 - binary_accuracy: 0.6871 - val_loss: 0.4406 - val_binary_accuracy: 0.7916\n","Epoch 2/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4613 - binary_accuracy: 0.7814 - val_loss: 0.4365 - val_binary_accuracy: 0.7947\n","Epoch 3/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4480 - binary_accuracy: 0.7890 - val_loss: 0.4544 - val_binary_accuracy: 0.7949\n","Epoch 4/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4410 - binary_accuracy: 0.7911 - val_loss: 0.4594 - val_binary_accuracy: 0.7950\n","Epoch 5/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4358 - binary_accuracy: 0.7935 - val_loss: 0.4761 - val_binary_accuracy: 0.7963\n","Epoch 6/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4322 - binary_accuracy: 0.7959 - val_loss: 0.5114 - val_binary_accuracy: 0.7967\n","Epoch 7/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4312 - binary_accuracy: 0.7947 - val_loss: 0.5238 - val_binary_accuracy: 0.7948\n","Epoch 8/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4305 - binary_accuracy: 0.7955 - val_loss: 0.5323 - val_binary_accuracy: 0.7952\n","Epoch 9/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4275 - binary_accuracy: 0.7958 - val_loss: 0.5425 - val_binary_accuracy: 0.7946\n","Epoch 10/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4236 - binary_accuracy: 0.7994 - val_loss: 0.5545 - val_binary_accuracy: 0.7939\n","Epoch 11/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4232 - binary_accuracy: 0.7989 - val_loss: 0.5645 - val_binary_accuracy: 0.7958\n"],"name":"stdout"},{"output_type":"stream","text":["\r 83%| | 70/84 [2:44:28<13:35, 58.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%| | 71/84 [2:45:06<11:17, 52.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'triangle', 'number_of_layers': 5, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 8s 21ms/step - loss: 0.6144 - binary_accuracy: 0.6848 - val_loss: 0.4638 - val_binary_accuracy: 0.7920\n","Epoch 2/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.5261 - binary_accuracy: 0.7486 - val_loss: 0.4449 - val_binary_accuracy: 0.7923\n","Epoch 3/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.5060 - binary_accuracy: 0.7574 - val_loss: 0.4330 - val_binary_accuracy: 0.7988\n","Epoch 4/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4986 - binary_accuracy: 0.7600 - val_loss: 0.4258 - val_binary_accuracy: 0.7998\n","Epoch 5/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4905 - binary_accuracy: 0.7647 - val_loss: 0.4297 - val_binary_accuracy: 0.7942\n","Epoch 6/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4840 - binary_accuracy: 0.7674 - val_loss: 0.4246 - val_binary_accuracy: 0.7971\n","Epoch 7/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4829 - binary_accuracy: 0.7667 - val_loss: 0.4272 - val_binary_accuracy: 0.7960\n","Epoch 8/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4819 - binary_accuracy: 0.7670 - val_loss: 0.4197 - val_binary_accuracy: 0.8012\n","Epoch 9/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4750 - binary_accuracy: 0.7706 - val_loss: 0.4179 - val_binary_accuracy: 0.8015\n","Epoch 10/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4725 - binary_accuracy: 0.7736 - val_loss: 0.4182 - val_binary_accuracy: 0.8019\n","Epoch 11/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4722 - binary_accuracy: 0.7720 - val_loss: 0.4143 - val_binary_accuracy: 0.8020\n","Epoch 12/100\n","338/338 [==============================] - 7s 21ms/step - loss: 0.4713 - binary_accuracy: 0.7709 - val_loss: 0.4188 - val_binary_accuracy: 0.8032\n","Epoch 13/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4680 - binary_accuracy: 0.7745 - val_loss: 0.4149 - val_binary_accuracy: 0.8036\n","Epoch 14/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4636 - binary_accuracy: 0.7748 - val_loss: 0.4133 - val_binary_accuracy: 0.8025\n","Epoch 15/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4597 - binary_accuracy: 0.7781 - val_loss: 0.4164 - val_binary_accuracy: 0.8043\n","Epoch 16/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4621 - binary_accuracy: 0.7768 - val_loss: 0.4118 - val_binary_accuracy: 0.8031\n","Epoch 17/100\n","338/338 [==============================] - 6s 19ms/step - loss: 0.4574 - binary_accuracy: 0.7802 - val_loss: 0.4126 - val_binary_accuracy: 0.8048\n","Epoch 18/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4597 - binary_accuracy: 0.7784 - val_loss: 0.4122 - val_binary_accuracy: 0.8045\n","Epoch 19/100\n","338/338 [==============================] - 7s 20ms/step - loss: 0.4570 - binary_accuracy: 0.7810 - val_loss: 0.4105 - val_binary_accuracy: 0.8032\n","Epoch 20/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4543 - binary_accuracy: 0.7835 - val_loss: 0.4105 - val_binary_accuracy: 0.8032\n","Epoch 21/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4548 - binary_accuracy: 0.7833 - val_loss: 0.4102 - val_binary_accuracy: 0.8039\n","Epoch 22/100\n","338/338 [==============================] - 7s 19ms/step - loss: 0.4521 - binary_accuracy: 0.7850 - val_loss: 0.4131 - val_binary_accuracy: 0.8028\n"],"name":"stdout"},{"output_type":"stream","text":["\r 86%| | 72/84 [2:47:35<16:14, 81.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 48s 139ms/step - loss: 0.5113 - binary_accuracy: 0.7602 - val_loss: 0.4235 - val_binary_accuracy: 0.7973\n","Epoch 2/100\n","338/338 [==============================] - 48s 141ms/step - loss: 0.4242 - binary_accuracy: 0.7949 - val_loss: 0.4235 - val_binary_accuracy: 0.8000\n","Epoch 3/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4173 - binary_accuracy: 0.8022 - val_loss: 0.4129 - val_binary_accuracy: 0.8009\n","Epoch 4/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4150 - binary_accuracy: 0.8025 - val_loss: 0.4111 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","338/338 [==============================] - 47s 139ms/step - loss: 0.4136 - binary_accuracy: 0.8049 - val_loss: 0.4115 - val_binary_accuracy: 0.8027\n","Epoch 6/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4093 - binary_accuracy: 0.8075 - val_loss: 0.4083 - val_binary_accuracy: 0.8034\n","Epoch 7/100\n","338/338 [==============================] - 47s 139ms/step - loss: 0.4090 - binary_accuracy: 0.8069 - val_loss: 0.4092 - val_binary_accuracy: 0.8046\n","Epoch 8/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4089 - binary_accuracy: 0.8064 - val_loss: 0.4075 - val_binary_accuracy: 0.8042\n","Epoch 9/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4065 - binary_accuracy: 0.8075 - val_loss: 0.4083 - val_binary_accuracy: 0.8038\n","Epoch 10/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4016 - binary_accuracy: 0.8113 - val_loss: 0.4068 - val_binary_accuracy: 0.8051\n","Epoch 11/100\n","338/338 [==============================] - 47s 140ms/step - loss: 0.4007 - binary_accuracy: 0.8123 - val_loss: 0.4077 - val_binary_accuracy: 0.8055\n","Epoch 12/100\n","338/338 [==============================] - 51s 151ms/step - loss: 0.4000 - binary_accuracy: 0.8096 - val_loss: 0.4079 - val_binary_accuracy: 0.8050\n","Epoch 13/100\n","338/338 [==============================] - 53s 156ms/step - loss: 0.3986 - binary_accuracy: 0.8106 - val_loss: 0.4085 - val_binary_accuracy: 0.8040\n","Epoch 14/100\n","338/338 [==============================] - 54s 161ms/step - loss: 0.3964 - binary_accuracy: 0.8123 - val_loss: 0.4090 - val_binary_accuracy: 0.8051\n","Epoch 15/100\n","338/338 [==============================] - 58s 173ms/step - loss: 0.3958 - binary_accuracy: 0.8144 - val_loss: 0.4089 - val_binary_accuracy: 0.8047\n","Epoch 16/100\n","338/338 [==============================] - 57s 170ms/step - loss: 0.3948 - binary_accuracy: 0.8138 - val_loss: 0.4161 - val_binary_accuracy: 0.8049\n"],"name":"stdout"},{"output_type":"stream","text":["\r 87%| | 73/84 [3:00:50<54:10, 295.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5615 - binary_accuracy: 0.7043 - val_loss: 0.4344 - val_binary_accuracy: 0.7913\n","Epoch 2/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4505 - binary_accuracy: 0.7841 - val_loss: 0.4254 - val_binary_accuracy: 0.7950\n","Epoch 3/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4398 - binary_accuracy: 0.7923 - val_loss: 0.4280 - val_binary_accuracy: 0.7968\n","Epoch 4/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4349 - binary_accuracy: 0.7939 - val_loss: 0.4303 - val_binary_accuracy: 0.7969\n","Epoch 5/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4304 - binary_accuracy: 0.7958 - val_loss: 0.4402 - val_binary_accuracy: 0.7984\n","Epoch 6/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4277 - binary_accuracy: 0.7969 - val_loss: 0.4611 - val_binary_accuracy: 0.7978\n","Epoch 7/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4260 - binary_accuracy: 0.7965 - val_loss: 0.4738 - val_binary_accuracy: 0.7983\n","Epoch 8/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4245 - binary_accuracy: 0.7979 - val_loss: 0.4940 - val_binary_accuracy: 0.7993\n","Epoch 9/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4222 - binary_accuracy: 0.7991 - val_loss: 0.4975 - val_binary_accuracy: 0.7989\n","Epoch 10/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4189 - binary_accuracy: 0.8008 - val_loss: 0.5098 - val_binary_accuracy: 0.7989\n","Epoch 11/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4196 - binary_accuracy: 0.8015 - val_loss: 0.5244 - val_binary_accuracy: 0.7996\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4182 - binary_accuracy: 0.8006 - val_loss: 0.5429 - val_binary_accuracy: 0.7986\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4173 - binary_accuracy: 0.8017 - val_loss: 0.5346 - val_binary_accuracy: 0.7990\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4166 - binary_accuracy: 0.8008 - val_loss: 0.5400 - val_binary_accuracy: 0.7997\n","Epoch 15/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4165 - binary_accuracy: 0.8011 - val_loss: 0.5510 - val_binary_accuracy: 0.8008\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4176 - binary_accuracy: 0.8004 - val_loss: 0.5496 - val_binary_accuracy: 0.8001\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4110 - binary_accuracy: 0.8054 - val_loss: 0.5528 - val_binary_accuracy: 0.7988\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4175 - binary_accuracy: 0.8013 - val_loss: 0.5546 - val_binary_accuracy: 0.8001\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4146 - binary_accuracy: 0.8027 - val_loss: 0.5543 - val_binary_accuracy: 0.8002\n","Epoch 20/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4123 - binary_accuracy: 0.8044 - val_loss: 0.5551 - val_binary_accuracy: 0.8012\n","Epoch 21/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4143 - binary_accuracy: 0.8027 - val_loss: 0.5582 - val_binary_accuracy: 0.7999\n","Epoch 22/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4119 - binary_accuracy: 0.8040 - val_loss: 0.5653 - val_binary_accuracy: 0.8002\n","Epoch 23/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4104 - binary_accuracy: 0.8057 - val_loss: 0.5664 - val_binary_accuracy: 0.8003\n","Epoch 24/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4126 - binary_accuracy: 0.8034 - val_loss: 0.5715 - val_binary_accuracy: 0.7971\n","Epoch 25/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4100 - binary_accuracy: 0.8049 - val_loss: 0.5670 - val_binary_accuracy: 0.8002\n"],"name":"stdout"},{"output_type":"stream","text":["\r 88%| | 74/84 [3:01:46<37:15, 223.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 12s 31ms/step - loss: 0.4839 - binary_accuracy: 0.7576 - val_loss: 0.4223 - val_binary_accuracy: 0.7952\n","Epoch 2/100\n","338/338 [==============================] - 11s 31ms/step - loss: 0.4269 - binary_accuracy: 0.7934 - val_loss: 0.4146 - val_binary_accuracy: 0.7994\n","Epoch 3/100\n","338/338 [==============================] - 11s 31ms/step - loss: 0.4214 - binary_accuracy: 0.7988 - val_loss: 0.4130 - val_binary_accuracy: 0.8008\n","Epoch 4/100\n","338/338 [==============================] - 10s 31ms/step - loss: 0.4183 - binary_accuracy: 0.8010 - val_loss: 0.4119 - val_binary_accuracy: 0.8014\n","Epoch 5/100\n","338/338 [==============================] - 11s 31ms/step - loss: 0.4150 - binary_accuracy: 0.8013 - val_loss: 0.4092 - val_binary_accuracy: 0.8023\n","Epoch 6/100\n","338/338 [==============================] - 10s 31ms/step - loss: 0.4130 - binary_accuracy: 0.8042 - val_loss: 0.4083 - val_binary_accuracy: 0.8037\n","Epoch 7/100\n","338/338 [==============================] - 10s 31ms/step - loss: 0.4119 - binary_accuracy: 0.8041 - val_loss: 0.4097 - val_binary_accuracy: 0.8043\n","Epoch 8/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4121 - binary_accuracy: 0.8043 - val_loss: 0.4075 - val_binary_accuracy: 0.8045\n","Epoch 9/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4084 - binary_accuracy: 0.8076 - val_loss: 0.4078 - val_binary_accuracy: 0.8036\n","Epoch 10/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4059 - binary_accuracy: 0.8095 - val_loss: 0.4073 - val_binary_accuracy: 0.8034\n","Epoch 11/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4060 - binary_accuracy: 0.8087 - val_loss: 0.4061 - val_binary_accuracy: 0.8035\n","Epoch 12/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4043 - binary_accuracy: 0.8097 - val_loss: 0.4065 - val_binary_accuracy: 0.8039\n","Epoch 13/100\n","338/338 [==============================] - 10s 30ms/step - loss: 0.4035 - binary_accuracy: 0.8092 - val_loss: 0.4072 - val_binary_accuracy: 0.8045\n"],"name":"stdout"},{"output_type":"stream","text":["\r 89%| | 75/84 [3:04:02<29:36, 197.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 2, 'number_of_units_first_layer': 50, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.5505 - binary_accuracy: 0.7055 - val_loss: 0.4290 - val_binary_accuracy: 0.7920\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4395 - binary_accuracy: 0.7883 - val_loss: 0.4210 - val_binary_accuracy: 0.7958\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4311 - binary_accuracy: 0.7947 - val_loss: 0.4204 - val_binary_accuracy: 0.7976\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4283 - binary_accuracy: 0.7957 - val_loss: 0.4191 - val_binary_accuracy: 0.7976\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4260 - binary_accuracy: 0.7972 - val_loss: 0.4176 - val_binary_accuracy: 0.7988\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4248 - binary_accuracy: 0.7983 - val_loss: 0.4189 - val_binary_accuracy: 0.7995\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4245 - binary_accuracy: 0.7977 - val_loss: 0.4192 - val_binary_accuracy: 0.7998\n","Epoch 8/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4227 - binary_accuracy: 0.7982 - val_loss: 0.4218 - val_binary_accuracy: 0.8008\n","Epoch 9/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4198 - binary_accuracy: 0.7993 - val_loss: 0.4238 - val_binary_accuracy: 0.8010\n","Epoch 10/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4176 - binary_accuracy: 0.8012 - val_loss: 0.4280 - val_binary_accuracy: 0.8014\n","Epoch 11/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4178 - binary_accuracy: 0.8022 - val_loss: 0.4329 - val_binary_accuracy: 0.8008\n","Epoch 12/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4166 - binary_accuracy: 0.8019 - val_loss: 0.4405 - val_binary_accuracy: 0.8008\n","Epoch 13/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4154 - binary_accuracy: 0.8016 - val_loss: 0.4395 - val_binary_accuracy: 0.8010\n","Epoch 14/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4146 - binary_accuracy: 0.8014 - val_loss: 0.4405 - val_binary_accuracy: 0.8019\n","Epoch 15/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4150 - binary_accuracy: 0.8020 - val_loss: 0.4570 - val_binary_accuracy: 0.8012\n","Epoch 16/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4155 - binary_accuracy: 0.8015 - val_loss: 0.4560 - val_binary_accuracy: 0.8008\n","Epoch 17/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4096 - binary_accuracy: 0.8057 - val_loss: 0.4647 - val_binary_accuracy: 0.8001\n","Epoch 18/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4160 - binary_accuracy: 0.8009 - val_loss: 0.4628 - val_binary_accuracy: 0.8008\n","Epoch 19/100\n","338/338 [==============================] - 2s 6ms/step - loss: 0.4127 - binary_accuracy: 0.8025 - val_loss: 0.4654 - val_binary_accuracy: 0.8025\n","Epoch 20/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8049 - val_loss: 0.4696 - val_binary_accuracy: 0.8003\n","Epoch 21/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4126 - binary_accuracy: 0.8029 - val_loss: 0.4742 - val_binary_accuracy: 0.7991\n","Epoch 22/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8045 - val_loss: 0.4826 - val_binary_accuracy: 0.7999\n","Epoch 23/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4081 - binary_accuracy: 0.8066 - val_loss: 0.4837 - val_binary_accuracy: 0.7992\n","Epoch 24/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4100 - binary_accuracy: 0.8033 - val_loss: 0.4898 - val_binary_accuracy: 0.7978\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%| | 76/84 [3:04:46<20:10, 151.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 2s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7151 - val_loss: 0.4292 - val_binary_accuracy: 0.7917\n","Epoch 2/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4358 - binary_accuracy: 0.7895 - val_loss: 0.4221 - val_binary_accuracy: 0.7948\n","Epoch 3/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4273 - binary_accuracy: 0.7966 - val_loss: 0.4200 - val_binary_accuracy: 0.7967\n","Epoch 4/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4257 - binary_accuracy: 0.7964 - val_loss: 0.4193 - val_binary_accuracy: 0.7959\n","Epoch 5/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4242 - binary_accuracy: 0.7967 - val_loss: 0.4174 - val_binary_accuracy: 0.7980\n","Epoch 6/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7976 - val_loss: 0.4171 - val_binary_accuracy: 0.7986\n","Epoch 7/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4229 - binary_accuracy: 0.7964 - val_loss: 0.4170 - val_binary_accuracy: 0.7982\n","Epoch 8/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4241 - binary_accuracy: 0.7978 - val_loss: 0.4162 - val_binary_accuracy: 0.7985\n","Epoch 9/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4218 - binary_accuracy: 0.7975 - val_loss: 0.4160 - val_binary_accuracy: 0.7988\n","Epoch 10/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7999 - val_loss: 0.4155 - val_binary_accuracy: 0.7993\n","Epoch 11/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8006 - val_loss: 0.4154 - val_binary_accuracy: 0.7994\n","Epoch 12/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8002 - val_loss: 0.4153 - val_binary_accuracy: 0.7985\n","Epoch 13/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4194 - binary_accuracy: 0.7999 - val_loss: 0.4151 - val_binary_accuracy: 0.7992\n","Epoch 14/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4193 - binary_accuracy: 0.7991 - val_loss: 0.4150 - val_binary_accuracy: 0.7994\n","Epoch 15/100\n","338/338 [==============================] - 1s 4ms/step - loss: 0.4194 - binary_accuracy: 0.8004 - val_loss: 0.4151 - val_binary_accuracy: 0.7999\n","Epoch 16/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4206 - binary_accuracy: 0.7997 - val_loss: 0.4152 - val_binary_accuracy: 0.7994\n","Epoch 17/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8030 - val_loss: 0.4147 - val_binary_accuracy: 0.7997\n","Epoch 18/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4208 - binary_accuracy: 0.7999 - val_loss: 0.4147 - val_binary_accuracy: 0.7999\n","Epoch 19/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8016 - val_loss: 0.4146 - val_binary_accuracy: 0.8004\n","Epoch 20/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8024 - val_loss: 0.4145 - val_binary_accuracy: 0.8004\n","Epoch 21/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8009 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 22/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4142 - val_binary_accuracy: 0.8010\n","Epoch 23/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8023 - val_loss: 0.4141 - val_binary_accuracy: 0.8011\n","Epoch 24/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8004 - val_loss: 0.4139 - val_binary_accuracy: 0.8010\n","Epoch 25/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8010 - val_loss: 0.4140 - val_binary_accuracy: 0.8010\n","Epoch 26/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8028 - val_loss: 0.4139 - val_binary_accuracy: 0.8015\n","Epoch 27/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8020 - val_loss: 0.4139 - val_binary_accuracy: 0.8012\n","Epoch 28/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8022 - val_loss: 0.4137 - val_binary_accuracy: 0.8006\n","Epoch 29/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4168 - binary_accuracy: 0.8022 - val_loss: 0.4138 - val_binary_accuracy: 0.8013\n","Epoch 30/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8007 - val_loss: 0.4137 - val_binary_accuracy: 0.8019\n","Epoch 31/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8018 - val_loss: 0.4138 - val_binary_accuracy: 0.8008\n","Epoch 32/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8024 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n","Epoch 33/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8032 - val_loss: 0.4136 - val_binary_accuracy: 0.8013\n","Epoch 34/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8033 - val_loss: 0.4138 - val_binary_accuracy: 0.8018\n","Epoch 35/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8015 - val_loss: 0.4135 - val_binary_accuracy: 0.8021\n","Epoch 36/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8019 - val_loss: 0.4132 - val_binary_accuracy: 0.8014\n","Epoch 37/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8014 - val_loss: 0.4136 - val_binary_accuracy: 0.8018\n","Epoch 38/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8017 - val_loss: 0.4134 - val_binary_accuracy: 0.8013\n","Epoch 39/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4169 - binary_accuracy: 0.8027 - val_loss: 0.4134 - val_binary_accuracy: 0.8021\n","Epoch 40/100\n","338/338 [==============================] - 1s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.4135 - val_binary_accuracy: 0.8019\n"],"name":"stdout"},{"output_type":"stream","text":["\r 92%|| 77/84 [3:05:29<13:52, 118.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 500, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 35s 100ms/step - loss: 0.5167 - binary_accuracy: 0.7465 - val_loss: 0.4333 - val_binary_accuracy: 0.7927\n","Epoch 2/100\n","338/338 [==============================] - 33s 99ms/step - loss: 0.4349 - binary_accuracy: 0.7911 - val_loss: 0.4219 - val_binary_accuracy: 0.7994\n","Epoch 3/100\n","338/338 [==============================] - 33s 98ms/step - loss: 0.4278 - binary_accuracy: 0.7982 - val_loss: 0.4189 - val_binary_accuracy: 0.7976\n","Epoch 4/100\n","338/338 [==============================] - 36s 106ms/step - loss: 0.4249 - binary_accuracy: 0.7986 - val_loss: 0.4166 - val_binary_accuracy: 0.7984\n","Epoch 5/100\n","338/338 [==============================] - 34s 100ms/step - loss: 0.4233 - binary_accuracy: 0.8003 - val_loss: 0.4125 - val_binary_accuracy: 0.8019\n","Epoch 6/100\n","338/338 [==============================] - 33s 98ms/step - loss: 0.4214 - binary_accuracy: 0.8015 - val_loss: 0.4214 - val_binary_accuracy: 0.8016\n","Epoch 7/100\n","338/338 [==============================] - 33s 98ms/step - loss: 0.4196 - binary_accuracy: 0.8018 - val_loss: 0.4101 - val_binary_accuracy: 0.8040\n","Epoch 8/100\n","338/338 [==============================] - 33s 99ms/step - loss: 0.4192 - binary_accuracy: 0.8023 - val_loss: 0.4156 - val_binary_accuracy: 0.8023\n","Epoch 9/100\n","338/338 [==============================] - 32s 96ms/step - loss: 0.4154 - binary_accuracy: 0.8043 - val_loss: 0.4118 - val_binary_accuracy: 0.8033\n","Epoch 10/100\n","338/338 [==============================] - 32s 95ms/step - loss: 0.4126 - binary_accuracy: 0.8064 - val_loss: 0.4141 - val_binary_accuracy: 0.8037\n","Epoch 11/100\n","338/338 [==============================] - 32s 94ms/step - loss: 0.4137 - binary_accuracy: 0.8058 - val_loss: 0.4177 - val_binary_accuracy: 0.8028\n","Epoch 12/100\n","338/338 [==============================] - 31s 92ms/step - loss: 0.4120 - binary_accuracy: 0.8066 - val_loss: 0.4321 - val_binary_accuracy: 0.8021\n"],"name":"stdout"},{"output_type":"stream","text":["\r 93%|| 78/84 [3:12:08<20:17, 202.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 1000, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 23s 67ms/step - loss: 0.4785 - binary_accuracy: 0.7605 - val_loss: 0.4242 - val_binary_accuracy: 0.7962\n","Epoch 2/100\n","338/338 [==============================] - 23s 67ms/step - loss: 0.4250 - binary_accuracy: 0.7956 - val_loss: 0.4162 - val_binary_accuracy: 0.8000\n","Epoch 3/100\n","338/338 [==============================] - 22s 67ms/step - loss: 0.4171 - binary_accuracy: 0.8030 - val_loss: 0.4119 - val_binary_accuracy: 0.8015\n","Epoch 4/100\n","338/338 [==============================] - 23s 67ms/step - loss: 0.4145 - binary_accuracy: 0.8033 - val_loss: 0.4104 - val_binary_accuracy: 0.8014\n","Epoch 5/100\n","338/338 [==============================] - 22s 65ms/step - loss: 0.4125 - binary_accuracy: 0.8051 - val_loss: 0.4084 - val_binary_accuracy: 0.8026\n","Epoch 6/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.4086 - binary_accuracy: 0.8072 - val_loss: 0.4072 - val_binary_accuracy: 0.8035\n","Epoch 7/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.4077 - binary_accuracy: 0.8066 - val_loss: 0.4082 - val_binary_accuracy: 0.8039\n","Epoch 8/100\n","338/338 [==============================] - 22s 65ms/step - loss: 0.4072 - binary_accuracy: 0.8066 - val_loss: 0.4062 - val_binary_accuracy: 0.8043\n","Epoch 9/100\n","338/338 [==============================] - 22s 65ms/step - loss: 0.4047 - binary_accuracy: 0.8082 - val_loss: 0.4086 - val_binary_accuracy: 0.8040\n","Epoch 10/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.4003 - binary_accuracy: 0.8122 - val_loss: 0.4060 - val_binary_accuracy: 0.8047\n","Epoch 11/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.4004 - binary_accuracy: 0.8125 - val_loss: 0.4063 - val_binary_accuracy: 0.8059\n","Epoch 12/100\n","338/338 [==============================] - 25s 73ms/step - loss: 0.3991 - binary_accuracy: 0.8116 - val_loss: 0.4062 - val_binary_accuracy: 0.8049\n","Epoch 13/100\n","338/338 [==============================] - 23s 67ms/step - loss: 0.3980 - binary_accuracy: 0.8116 - val_loss: 0.4089 - val_binary_accuracy: 0.8047\n","Epoch 14/100\n","338/338 [==============================] - 22s 64ms/step - loss: 0.3965 - binary_accuracy: 0.8121 - val_loss: 0.4076 - val_binary_accuracy: 0.8049\n","Epoch 15/100\n","338/338 [==============================] - 21s 62ms/step - loss: 0.3952 - binary_accuracy: 0.8149 - val_loss: 0.4079 - val_binary_accuracy: 0.8050\n","Epoch 16/100\n","338/338 [==============================] - 21s 62ms/step - loss: 0.3960 - binary_accuracy: 0.8136 - val_loss: 0.4110 - val_binary_accuracy: 0.8059\n"],"name":"stdout"},{"output_type":"stream","text":["\r 94%|| 79/84 [3:18:03<20:41, 248.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.3, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 30, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 5ms/step - loss: 0.6194 - binary_accuracy: 0.6615 - val_loss: 0.4888 - val_binary_accuracy: 0.7856\n","Epoch 2/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4885 - binary_accuracy: 0.7621 - val_loss: 0.5055 - val_binary_accuracy: 0.7861\n","Epoch 3/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4646 - binary_accuracy: 0.7797 - val_loss: 0.5255 - val_binary_accuracy: 0.7789\n","Epoch 4/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4543 - binary_accuracy: 0.7834 - val_loss: 0.5374 - val_binary_accuracy: 0.7709\n","Epoch 5/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4459 - binary_accuracy: 0.7891 - val_loss: 0.5341 - val_binary_accuracy: 0.7651\n","Epoch 6/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4414 - binary_accuracy: 0.7909 - val_loss: 0.5583 - val_binary_accuracy: 0.7414\n","Epoch 7/100\n","338/338 [==============================] - 2s 5ms/step - loss: 0.4394 - binary_accuracy: 0.7904 - val_loss: 0.5685 - val_binary_accuracy: 0.7186\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|| 80/84 [3:18:16<11:51, 177.78s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'brick', 'number_of_layers': 5, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 10s 25ms/step - loss: 0.5474 - binary_accuracy: 0.7226 - val_loss: 0.4333 - val_binary_accuracy: 0.7939\n","Epoch 2/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4443 - binary_accuracy: 0.7888 - val_loss: 0.4212 - val_binary_accuracy: 0.7977\n","Epoch 3/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4343 - binary_accuracy: 0.7956 - val_loss: 0.4218 - val_binary_accuracy: 0.7985\n","Epoch 4/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4305 - binary_accuracy: 0.7959 - val_loss: 0.4199 - val_binary_accuracy: 0.7995\n","Epoch 5/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4270 - binary_accuracy: 0.7988 - val_loss: 0.4171 - val_binary_accuracy: 0.8000\n","Epoch 6/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4228 - binary_accuracy: 0.8010 - val_loss: 0.4218 - val_binary_accuracy: 0.7996\n","Epoch 7/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4219 - binary_accuracy: 0.7996 - val_loss: 0.4143 - val_binary_accuracy: 0.8019\n","Epoch 8/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4221 - binary_accuracy: 0.8010 - val_loss: 0.4150 - val_binary_accuracy: 0.8020\n","Epoch 9/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4181 - binary_accuracy: 0.8019 - val_loss: 0.4120 - val_binary_accuracy: 0.8026\n","Epoch 10/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4173 - binary_accuracy: 0.8033 - val_loss: 0.4131 - val_binary_accuracy: 0.8038\n","Epoch 11/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4163 - binary_accuracy: 0.8045 - val_loss: 0.4155 - val_binary_accuracy: 0.8008\n","Epoch 12/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4144 - binary_accuracy: 0.8032 - val_loss: 0.4168 - val_binary_accuracy: 0.8027\n","Epoch 13/100\n","338/338 [==============================] - 9s 26ms/step - loss: 0.4139 - binary_accuracy: 0.8032 - val_loss: 0.4146 - val_binary_accuracy: 0.8024\n","Epoch 14/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4124 - binary_accuracy: 0.8043 - val_loss: 0.4108 - val_binary_accuracy: 0.8036\n","Epoch 15/100\n","338/338 [==============================] - 8s 24ms/step - loss: 0.4129 - binary_accuracy: 0.8054 - val_loss: 0.4170 - val_binary_accuracy: 0.8039\n","Epoch 16/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4134 - binary_accuracy: 0.8044 - val_loss: 0.4096 - val_binary_accuracy: 0.8035\n","Epoch 17/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4069 - binary_accuracy: 0.8084 - val_loss: 0.4127 - val_binary_accuracy: 0.8010\n","Epoch 18/100\n","338/338 [==============================] - 9s 25ms/step - loss: 0.4124 - binary_accuracy: 0.8049 - val_loss: 0.4130 - val_binary_accuracy: 0.8032\n","Epoch 19/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4104 - binary_accuracy: 0.8067 - val_loss: 0.4128 - val_binary_accuracy: 0.8033\n","Epoch 20/100\n","338/338 [==============================] - 8s 25ms/step - loss: 0.4073 - binary_accuracy: 0.8085 - val_loss: 0.4155 - val_binary_accuracy: 0.8030\n"],"name":"stdout"},{"output_type":"stream","text":["\r 96%|| 81/84 [3:21:05<08:46, 175.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.5, 'network_shape': 'triangle', 'number_of_layers': 3, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 4s 10ms/step - loss: 0.5165 - binary_accuracy: 0.7367 - val_loss: 0.4232 - val_binary_accuracy: 0.7953\n","Epoch 2/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4358 - binary_accuracy: 0.7907 - val_loss: 0.4170 - val_binary_accuracy: 0.7973\n","Epoch 3/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4275 - binary_accuracy: 0.7977 - val_loss: 0.4151 - val_binary_accuracy: 0.7993\n","Epoch 4/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4241 - binary_accuracy: 0.7983 - val_loss: 0.4142 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4220 - binary_accuracy: 0.7997 - val_loss: 0.4117 - val_binary_accuracy: 0.8016\n","Epoch 6/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4196 - binary_accuracy: 0.8026 - val_loss: 0.4114 - val_binary_accuracy: 0.8025\n","Epoch 7/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4196 - binary_accuracy: 0.8008 - val_loss: 0.4119 - val_binary_accuracy: 0.8024\n","Epoch 8/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4191 - binary_accuracy: 0.8016 - val_loss: 0.4099 - val_binary_accuracy: 0.8021\n","Epoch 9/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4168 - binary_accuracy: 0.8027 - val_loss: 0.4099 - val_binary_accuracy: 0.8032\n","Epoch 10/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4134 - binary_accuracy: 0.8063 - val_loss: 0.4097 - val_binary_accuracy: 0.8042\n","Epoch 11/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4141 - binary_accuracy: 0.8061 - val_loss: 0.4086 - val_binary_accuracy: 0.8037\n","Epoch 12/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4137 - binary_accuracy: 0.8056 - val_loss: 0.4089 - val_binary_accuracy: 0.8035\n","Epoch 13/100\n","338/338 [==============================] - 3s 9ms/step - loss: 0.4124 - binary_accuracy: 0.8062 - val_loss: 0.4083 - val_binary_accuracy: 0.8036\n","Epoch 14/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4109 - binary_accuracy: 0.8062 - val_loss: 0.4083 - val_binary_accuracy: 0.8039\n","Epoch 15/100\n","338/338 [==============================] - 3s 10ms/step - loss: 0.4112 - binary_accuracy: 0.8072 - val_loss: 0.4090 - val_binary_accuracy: 0.8033\n"],"name":"stdout"},{"output_type":"stream","text":["\r 98%|| 82/84 [3:21:55<04:35, 137.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'triangle', 'number_of_layers': 1, 'number_of_units_first_layer': 250, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.5073 - binary_accuracy: 0.7453 - val_loss: 0.4216 - val_binary_accuracy: 0.7971\n","Epoch 2/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4233 - binary_accuracy: 0.7963 - val_loss: 0.4162 - val_binary_accuracy: 0.7988\n","Epoch 3/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4170 - binary_accuracy: 0.8003 - val_loss: 0.4136 - val_binary_accuracy: 0.8002\n","Epoch 4/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4153 - binary_accuracy: 0.8019 - val_loss: 0.4130 - val_binary_accuracy: 0.8000\n","Epoch 5/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4133 - binary_accuracy: 0.8027 - val_loss: 0.4109 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4101 - binary_accuracy: 0.8043 - val_loss: 0.4104 - val_binary_accuracy: 0.8036\n","Epoch 7/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4110 - binary_accuracy: 0.8028 - val_loss: 0.4112 - val_binary_accuracy: 0.8025\n","Epoch 8/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4110 - binary_accuracy: 0.8033 - val_loss: 0.4094 - val_binary_accuracy: 0.8039\n","Epoch 9/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4085 - binary_accuracy: 0.8048 - val_loss: 0.4093 - val_binary_accuracy: 0.8032\n","Epoch 10/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4051 - binary_accuracy: 0.8068 - val_loss: 0.4089 - val_binary_accuracy: 0.8034\n","Epoch 11/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.4051 - binary_accuracy: 0.8076 - val_loss: 0.4087 - val_binary_accuracy: 0.8044\n","Epoch 12/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4053 - binary_accuracy: 0.8073 - val_loss: 0.4087 - val_binary_accuracy: 0.8029\n","Epoch 13/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4050 - binary_accuracy: 0.8080 - val_loss: 0.4084 - val_binary_accuracy: 0.8026\n","Epoch 14/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4045 - binary_accuracy: 0.8072 - val_loss: 0.4086 - val_binary_accuracy: 0.8034\n","Epoch 15/100\n","338/338 [==============================] - 3s 7ms/step - loss: 0.4044 - binary_accuracy: 0.8073 - val_loss: 0.4085 - val_binary_accuracy: 0.8027\n","Epoch 16/100\n","338/338 [==============================] - 2s 7ms/step - loss: 0.4054 - binary_accuracy: 0.8068 - val_loss: 0.4087 - val_binary_accuracy: 0.8035\n"],"name":"stdout"},{"output_type":"stream","text":["\r 99%|| 83/84 [3:22:34<01:48, 108.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'activation_function': 'gelu', 'batch_size': 512, 'network_decay': 0.7, 'network_shape': 'brick', 'number_of_layers': 3, 'number_of_units_first_layer': 200, 'optimizer': 'RMSprop', 'regularization': 'dropout', 'weight_initializer': 'he_uniform'}\n","Epoch 1/100\n","338/338 [==============================] - 6s 16ms/step - loss: 0.5045 - binary_accuracy: 0.7456 - val_loss: 0.4232 - val_binary_accuracy: 0.7951\n","Epoch 2/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4337 - binary_accuracy: 0.7920 - val_loss: 0.4166 - val_binary_accuracy: 0.7984\n","Epoch 3/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4250 - binary_accuracy: 0.7983 - val_loss: 0.4155 - val_binary_accuracy: 0.7990\n","Epoch 4/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4224 - binary_accuracy: 0.7985 - val_loss: 0.4141 - val_binary_accuracy: 0.7996\n","Epoch 5/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4203 - binary_accuracy: 0.8013 - val_loss: 0.4117 - val_binary_accuracy: 0.8022\n","Epoch 6/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4166 - binary_accuracy: 0.8039 - val_loss: 0.4116 - val_binary_accuracy: 0.8022\n","Epoch 7/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4158 - binary_accuracy: 0.8017 - val_loss: 0.4114 - val_binary_accuracy: 0.8030\n","Epoch 8/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4162 - binary_accuracy: 0.8031 - val_loss: 0.4102 - val_binary_accuracy: 0.8031\n","Epoch 9/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4129 - binary_accuracy: 0.8050 - val_loss: 0.4090 - val_binary_accuracy: 0.8027\n","Epoch 10/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4102 - binary_accuracy: 0.8072 - val_loss: 0.4090 - val_binary_accuracy: 0.8029\n","Epoch 11/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4105 - binary_accuracy: 0.8079 - val_loss: 0.4091 - val_binary_accuracy: 0.8027\n","Epoch 12/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4100 - binary_accuracy: 0.8056 - val_loss: 0.4110 - val_binary_accuracy: 0.8033\n","Epoch 13/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4091 - binary_accuracy: 0.8058 - val_loss: 0.4093 - val_binary_accuracy: 0.8025\n","Epoch 14/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4084 - binary_accuracy: 0.8067 - val_loss: 0.4077 - val_binary_accuracy: 0.8040\n","Epoch 15/100\n","338/338 [==============================] - 5s 16ms/step - loss: 0.4076 - binary_accuracy: 0.8080 - val_loss: 0.4097 - val_binary_accuracy: 0.8027\n","Epoch 16/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4091 - binary_accuracy: 0.8065 - val_loss: 0.4082 - val_binary_accuracy: 0.8034\n","Epoch 17/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4017 - binary_accuracy: 0.8125 - val_loss: 0.4085 - val_binary_accuracy: 0.8025\n","Epoch 18/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4083 - binary_accuracy: 0.8071 - val_loss: 0.4081 - val_binary_accuracy: 0.8039\n","Epoch 19/100\n","338/338 [==============================] - 5s 15ms/step - loss: 0.4064 - binary_accuracy: 0.8080 - val_loss: 0.4076 - val_binary_accuracy: 0.8035\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 84/84 [3:24:15<00:00, 145.89s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7njtvrmO5I5y","executionInfo":{"status":"ok","timestamp":1611364534263,"user_tz":-60,"elapsed":12234322,"user":{"displayName":"David George","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4s7QtDtwIj_fTOPO9qNQzFmkL4lFy0SvQ-yOlTw=s64","userId":"17656817416818487894"}},"outputId":"15016459-1700-403f-9121-2eed23d43e7e"},"source":["# Get search results for all evaluated hyperparameter combinations sorted by val_accuracy\n","analyze_object = talos.Analyze(search_object)\n","analyze_object.data.sort_values(by=\"val_binary_accuracy\", ascending=False).round(4).head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>duration</th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>binary_accuracy</th>\n","      <th>val_loss</th>\n","      <th>val_binary_accuracy</th>\n","      <th>activation_function</th>\n","      <th>batch_size</th>\n","      <th>network_decay</th>\n","      <th>network_shape</th>\n","      <th>number_of_layers</th>\n","      <th>number_of_units_first_layer</th>\n","      <th>optimizer</th>\n","      <th>regularization</th>\n","      <th>weight_initializer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>01/22/21-215730</td>\n","      <td>01/22/21-220102</td>\n","      <td>212.7177</td>\n","      <td>24</td>\n","      <td>0.3934</td>\n","      <td>0.8145</td>\n","      <td>0.4040</td>\n","      <td>0.8064</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>2</td>\n","      <td>500</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>01/23/21-010329</td>\n","      <td>01/23/21-010923</td>\n","      <td>354.1986</td>\n","      <td>16</td>\n","      <td>0.3956</td>\n","      <td>0.8142</td>\n","      <td>0.4110</td>\n","      <td>0.8059</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01/22/21-215518</td>\n","      <td>01/22/21-215730</td>\n","      <td>131.1640</td>\n","      <td>26</td>\n","      <td>0.4021</td>\n","      <td>0.8114</td>\n","      <td>0.4054</td>\n","      <td>0.8055</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>250</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>01/22/21-234511</td>\n","      <td>01/22/21-234821</td>\n","      <td>190.1974</td>\n","      <td>41</td>\n","      <td>0.3936</td>\n","      <td>0.8147</td>\n","      <td>0.4048</td>\n","      <td>0.8054</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>2</td>\n","      <td>250</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>01/22/21-224049</td>\n","      <td>01/22/21-224302</td>\n","      <td>133.2169</td>\n","      <td>40</td>\n","      <td>0.4069</td>\n","      <td>0.8126</td>\n","      <td>0.4067</td>\n","      <td>0.8053</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.3</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>250</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>01/22/21-234914</td>\n","      <td>01/23/21-000005</td>\n","      <td>651.0824</td>\n","      <td>22</td>\n","      <td>0.3853</td>\n","      <td>0.8184</td>\n","      <td>0.4087</td>\n","      <td>0.8053</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>2</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>01/22/21-233327</td>\n","      <td>01/22/21-234336</td>\n","      <td>609.6853</td>\n","      <td>22</td>\n","      <td>0.3853</td>\n","      <td>0.8184</td>\n","      <td>0.4087</td>\n","      <td>0.8053</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.3</td>\n","      <td>brick</td>\n","      <td>2</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>01/23/21-002318</td>\n","      <td>01/23/21-002830</td>\n","      <td>312.1586</td>\n","      <td>18</td>\n","      <td>0.3935</td>\n","      <td>0.8144</td>\n","      <td>0.4048</td>\n","      <td>0.8052</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.3</td>\n","      <td>triangle</td>\n","      <td>2</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>01/23/21-002830</td>\n","      <td>01/23/21-003037</td>\n","      <td>126.8356</td>\n","      <td>26</td>\n","      <td>0.4003</td>\n","      <td>0.8106</td>\n","      <td>0.4057</td>\n","      <td>0.8050</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.3</td>\n","      <td>brick</td>\n","      <td>2</td>\n","      <td>200</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>01/23/21-000446</td>\n","      <td>01/23/21-001125</td>\n","      <td>399.2471</td>\n","      <td>21</td>\n","      <td>0.3886</td>\n","      <td>0.8178</td>\n","      <td>0.4058</td>\n","      <td>0.8050</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>triangle</td>\n","      <td>2</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>01/22/21-223150</td>\n","      <td>01/22/21-223333</td>\n","      <td>103.5346</td>\n","      <td>26</td>\n","      <td>0.4047</td>\n","      <td>0.8102</td>\n","      <td>0.4062</td>\n","      <td>0.8050</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>triangle</td>\n","      <td>3</td>\n","      <td>200</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>01/23/21-003856</td>\n","      <td>01/23/21-005211</td>\n","      <td>795.2076</td>\n","      <td>16</td>\n","      <td>0.3954</td>\n","      <td>0.8142</td>\n","      <td>0.4161</td>\n","      <td>0.8049</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>01/22/21-232818</td>\n","      <td>01/22/21-233008</td>\n","      <td>109.8156</td>\n","      <td>16</td>\n","      <td>0.4062</td>\n","      <td>0.8087</td>\n","      <td>0.4106</td>\n","      <td>0.8048</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>250</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>01/23/21-001843</td>\n","      <td>01/23/21-001948</td>\n","      <td>65.2286</td>\n","      <td>35</td>\n","      <td>0.4077</td>\n","      <td>0.8085</td>\n","      <td>0.4064</td>\n","      <td>0.8047</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>triangle</td>\n","      <td>2</td>\n","      <td>100</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>01/23/21-001948</td>\n","      <td>01/23/21-002317</td>\n","      <td>209.2959</td>\n","      <td>26</td>\n","      <td>0.3933</td>\n","      <td>0.8134</td>\n","      <td>0.4058</td>\n","      <td>0.8047</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>triangle</td>\n","      <td>1</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>01/22/21-224737</td>\n","      <td>01/22/21-225040</td>\n","      <td>182.7083</td>\n","      <td>26</td>\n","      <td>0.3933</td>\n","      <td>0.8134</td>\n","      <td>0.4058</td>\n","      <td>0.8047</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>brick</td>\n","      <td>1</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>01/22/21-224433</td>\n","      <td>01/22/21-224737</td>\n","      <td>184.1696</td>\n","      <td>26</td>\n","      <td>0.3933</td>\n","      <td>0.8134</td>\n","      <td>0.4058</td>\n","      <td>0.8047</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>1</td>\n","      <td>1000</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01/22/21-215358</td>\n","      <td>01/22/21-215518</td>\n","      <td>79.8218</td>\n","      <td>27</td>\n","      <td>0.4022</td>\n","      <td>0.8100</td>\n","      <td>0.4058</td>\n","      <td>0.8046</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>triangle</td>\n","      <td>2</td>\n","      <td>200</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>01/22/21-220103</td>\n","      <td>01/22/21-220411</td>\n","      <td>188.2054</td>\n","      <td>11</td>\n","      <td>0.4059</td>\n","      <td>0.8084</td>\n","      <td>0.4069</td>\n","      <td>0.8046</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.5</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>01/22/21-232001</td>\n","      <td>01/22/21-232304</td>\n","      <td>183.2442</td>\n","      <td>11</td>\n","      <td>0.4059</td>\n","      <td>0.8084</td>\n","      <td>0.4069</td>\n","      <td>0.8046</td>\n","      <td>gelu</td>\n","      <td>512</td>\n","      <td>0.7</td>\n","      <td>brick</td>\n","      <td>3</td>\n","      <td>500</td>\n","      <td>RMSprop</td>\n","      <td>dropout</td>\n","      <td>he_uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              start              end  duration  round_epochs    loss  \\\n","5   01/22/21-215730  01/22/21-220102  212.7177            24  0.3934   \n","78  01/23/21-010329  01/23/21-010923  354.1986            16  0.3956   \n","4   01/22/21-215518  01/22/21-215730  131.1640            26  0.4021   \n","47  01/22/21-234511  01/22/21-234821  190.1974            41  0.3936   \n","22  01/22/21-224049  01/22/21-224302  133.2169            40  0.4069   \n","49  01/22/21-234914  01/23/21-000005  651.0824            22  0.3853   \n","43  01/22/21-233327  01/22/21-234336  609.6853            22  0.3853   \n","62  01/23/21-002318  01/23/21-002830  312.1586            18  0.3935   \n","63  01/23/21-002830  01/23/21-003037  126.8356            26  0.4003   \n","55  01/23/21-000446  01/23/21-001125  399.2471            21  0.3886   \n","12  01/22/21-223150  01/22/21-223333  103.5346            26  0.4047   \n","72  01/23/21-003856  01/23/21-005211  795.2076            16  0.3954   \n","37  01/22/21-232818  01/22/21-233008  109.8156            16  0.4062   \n","60  01/23/21-001843  01/23/21-001948   65.2286            35  0.4077   \n","61  01/23/21-001948  01/23/21-002317  209.2959            26  0.3933   \n","26  01/22/21-224737  01/22/21-225040  182.7083            26  0.3933   \n","25  01/22/21-224433  01/22/21-224737  184.1696            26  0.3933   \n","3   01/22/21-215358  01/22/21-215518   79.8218            27  0.4022   \n","6   01/22/21-220103  01/22/21-220411  188.2054            11  0.4059   \n","30  01/22/21-232001  01/22/21-232304  183.2442            11  0.4059   \n","\n","    binary_accuracy  val_loss  val_binary_accuracy activation_function  \\\n","5            0.8145    0.4040               0.8064                gelu   \n","78           0.8142    0.4110               0.8059                gelu   \n","4            0.8114    0.4054               0.8055                gelu   \n","47           0.8147    0.4048               0.8054                gelu   \n","22           0.8126    0.4067               0.8053                gelu   \n","49           0.8184    0.4087               0.8053                gelu   \n","43           0.8184    0.4087               0.8053                gelu   \n","62           0.8144    0.4048               0.8052                gelu   \n","63           0.8106    0.4057               0.8050                gelu   \n","55           0.8178    0.4058               0.8050                gelu   \n","12           0.8102    0.4062               0.8050                gelu   \n","72           0.8142    0.4161               0.8049                gelu   \n","37           0.8087    0.4106               0.8048                gelu   \n","60           0.8085    0.4064               0.8047                gelu   \n","61           0.8134    0.4058               0.8047                gelu   \n","26           0.8134    0.4058               0.8047                gelu   \n","25           0.8134    0.4058               0.8047                gelu   \n","3            0.8100    0.4058               0.8046                gelu   \n","6            0.8084    0.4069               0.8046                gelu   \n","30           0.8084    0.4069               0.8046                gelu   \n","\n","    batch_size  network_decay network_shape  number_of_layers  \\\n","5          512            0.7      triangle                 2   \n","78         512            0.5      triangle                 3   \n","4          512            0.7      triangle                 3   \n","47         512            0.7         brick                 2   \n","22         512            0.3      triangle                 3   \n","49         512            0.7         brick                 2   \n","43         512            0.3         brick                 2   \n","62         512            0.3      triangle                 2   \n","63         512            0.3         brick                 2   \n","55         512            0.5      triangle                 2   \n","12         512            0.7      triangle                 3   \n","72         512            0.7         brick                 3   \n","37         512            0.5         brick                 3   \n","60         512            0.5      triangle                 2   \n","61         512            0.5      triangle                 1   \n","26         512            0.5         brick                 1   \n","25         512            0.7         brick                 1   \n","3          512            0.5      triangle                 2   \n","6          512            0.5         brick                 3   \n","30         512            0.7         brick                 3   \n","\n","    number_of_units_first_layer optimizer regularization weight_initializer  \n","5                           500   RMSprop        dropout         he_uniform  \n","78                         1000   RMSprop        dropout         he_uniform  \n","4                           250   RMSprop        dropout         he_uniform  \n","47                          250   RMSprop        dropout         he_uniform  \n","22                          250   RMSprop        dropout         he_uniform  \n","49                         1000   RMSprop        dropout         he_uniform  \n","43                         1000   RMSprop        dropout         he_uniform  \n","62                         1000   RMSprop        dropout         he_uniform  \n","63                          200   RMSprop        dropout         he_uniform  \n","55                         1000   RMSprop        dropout         he_uniform  \n","12                          200   RMSprop        dropout         he_uniform  \n","72                         1000   RMSprop        dropout         he_uniform  \n","37                          250   RMSprop        dropout         he_uniform  \n","60                          100   RMSprop        dropout         he_uniform  \n","61                         1000   RMSprop        dropout         he_uniform  \n","26                         1000   RMSprop        dropout         he_uniform  \n","25                         1000   RMSprop        dropout         he_uniform  \n","3                           200   RMSprop        dropout         he_uniform  \n","6                           500   RMSprop        dropout         he_uniform  \n","30                          500   RMSprop        dropout         he_uniform  "]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"8ndgvlvMOVOl"},"source":["Result: no better network shape could be found"]},{"cell_type":"markdown","metadata":{"id":"DbFki3lTy7uS"},"source":["#### d) Best-Found Model: NN Structured"]},{"cell_type":"markdown","metadata":{"id":"VV_XgZTx4mBL"},"source":["- Preprocessing = Yeo-Johnson + Standardization + PCA for numeric features; leave binary features as they are\n","- 3 hidden layers; [500, 350, 245] Units; GELU activation\n","- Dropout; Rate = 0.5\n","- HeUniform initialization\n","- RMSProp optimizer\n","- Batch Size: 512"]}]}